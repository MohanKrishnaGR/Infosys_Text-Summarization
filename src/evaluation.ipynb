{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive summarization\n",
    "### Method 1 - Model Evaluation (src/evaluation.ipynb)\n",
    "Performance metrics â€“ ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "\n",
    "implemented works:\n",
    "- Load fine-trained transformer\n",
    "    - From saved model \n",
    " \n",
    "- OOP implementation of Dataset \n",
    "    - Feature, Target\n",
    "    - Tokenize\n",
    "    - Padding, Truncate\n",
    "    - Convert to Tensor\n",
    "    - Pass to: DataLoader â€“ with batch size\n",
    "\n",
    "- Evaluate Model\n",
    "    - Set model to evaluation mode\n",
    "    - Load ROUGE metric\n",
    "    - Loop through batches in dataloader\n",
    "    - Move data to device\n",
    "    - Generate summaries\n",
    "    - Decode predictions and labels\n",
    "    - Add to ROUGE metric\n",
    "    - Compute ROUGE scores\n",
    "\n",
    "- Evaluate model on validation dataset\n",
    "    - Print results\n",
    "\n",
    "\n",
    "## Observations:\n",
    "\n",
    "The trained model from method 1 was not used for deployment:\n",
    "\n",
    "(Trained model from method 2 was used for deployment)\n",
    "\n",
    "Reason:\n",
    "- Even though the model has very minimal training loss but, the model performed inconsistenly in validation & testing phase.\n",
    "- There's a suspected tensor error while training using method 1, which could be attributed to the inconsistency of the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "# OOP implementation of Dataset \n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length=512):\n",
    "        self.dataset = pd.read_csv(file_path) # file path\n",
    "        self.tokenizer = tokenizer # Tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.iloc[idx, 0] # Feature\n",
    "        summary = self.dataset.iloc[idx, 1] # Target \n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, # Feature\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', # Padding \n",
    "            truncation=True, # Truncate\n",
    "            return_tensors=\"pt\" # Convert to Tensor\n",
    "        )\n",
    "        targets = self.tokenizer.encode_plus(\n",
    "            summary, # Target\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', # Padding \n",
    "            truncation=True, # Truncate\n",
    "            return_tensors=\"pt\" # Convert to Tensor\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(), # feature - converts - mutli-dimentional tensor to one dimensional tesor\n",
    "            'attention_mask': inputs['attention_mask'].flatten(), # padding - attention mask - ' '\n",
    "            'labels': targets['input_ids'].flatten() # target - ' '\n",
    "        }\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "val_dataset = SummarizationDataset('/home/mohan/infy/data/merged/final/validation.csv', tokenizer) # Data object\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "# Load saved model\n",
    "model_path = '/home/mohan/infy/models/fine_tuned_bart'\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device) # use cuda backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203647/2433365608.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric('rouge')\n",
      "/home/mohan/miniconda3/envs/infosys/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.00012757136022962845, recall=4.933423696380165e-05, fmeasure=6.732234645068214e-05), mid=Score(precision=0.00030696858555254343, recall=0.00016308813027728812, fmeasure=0.00018227662111640694), high=Score(precision=0.0005062988359113381, recall=0.0003339877030881791, fmeasure=0.00031219502877184973)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.00012747169510444914, recall=5.11262189764358e-05, fmeasure=6.883905408089956e-05), mid=Score(precision=0.00029500877053101576, recall=0.00013774946674766604, fmeasure=0.00016051378457393505), high=Score(precision=0.0004903524158826344, recall=0.0002557525156737812, fmeasure=0.0002807499266670898)), 'rougeLsum': AggregateScore(low=Score(precision=0.00011561154520810078, recall=5.25348883052483e-05, fmeasure=6.754474666699242e-05), mid=Score(precision=0.00029301546802742783, recall=0.000141219374677299, fmeasure=0.0001637905834947893), high=Score(precision=0.0005063985010365173, recall=0.0002518490193267542, fmeasure=0.00028050684026071287))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval() # set model to evaluation mode\n",
    "    rouge = load_metric('rouge') # ROGUE metric - 'HuggingFace'\n",
    "\n",
    "    # Loop through batched\n",
    "    for batch in dataloader: \n",
    "        inputs = batch['input_ids'].to(device) # feature\n",
    "        attention_mask = batch['attention_mask'].to(device) # padding - attention mask\n",
    "        labels = batch['labels'].to(device) # targets\n",
    "        \n",
    "        with torch.no_grad():  # no backpropagation needed\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs,  # features\n",
    "                attention_mask=attention_mask, # attention mask \n",
    "                max_length=150, # Maximum length for summerized text\n",
    "                min_length=40, # Minimum length for summerized text\n",
    "            )\n",
    "\n",
    "        # Decode the generated summaries and labels to human-readable text\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Add the decoded predictions and labels to the ROUGE metric\n",
    "        rouge.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "     # Compute the final ROUGE scores\n",
    "    result = rouge.compute()\n",
    "    return result\n",
    "\n",
    "# Evaluate the model on the validation dataset and print the results\n",
    "results = evaluate_model(model, val_loader, tokenizer)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.00012757136022962845, 4.933423696380165e-05...</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.00012747169510444914, 5.11262189764358e-05,...</td>\n",
       "      <td>(0.00011561154520810078, 5.25348883052483e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.00030696858555254343, 0.0001630881302772881...</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.00029500877053101576, 0.0001377494667476660...</td>\n",
       "      <td>(0.00029301546802742783, 0.000141219374677299,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0005062988359113381, 0.0003339877030881791,...</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0004903524158826344, 0.0002557525156737812,...</td>\n",
       "      <td>(0.0005063985010365173, 0.0002518490193267542,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              rouge1           rouge2  \\\n",
       "0  (0.00012757136022962845, 4.933423696380165e-05...  (0.0, 0.0, 0.0)   \n",
       "1  (0.00030696858555254343, 0.0001630881302772881...  (0.0, 0.0, 0.0)   \n",
       "2  (0.0005062988359113381, 0.0003339877030881791,...  (0.0, 0.0, 0.0)   \n",
       "\n",
       "                                              rougeL  \\\n",
       "0  (0.00012747169510444914, 5.11262189764358e-05,...   \n",
       "1  (0.00029500877053101576, 0.0001377494667476660...   \n",
       "2  (0.0004903524158826344, 0.0002557525156737812,...   \n",
       "\n",
       "                                           rougeLsum  \n",
       "0  (0.00011561154520810078, 5.25348883052483e-05,...  \n",
       "1  (0.00029301546802742783, 0.000141219374677299,...  \n",
       "2  (0.0005063985010365173, 0.0002518490193267542,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(results)\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Type</th>\n",
       "      <th>ROUGE-1 Precision</th>\n",
       "      <th>ROUGE-1 Recall</th>\n",
       "      <th>ROUGE-1 F-measure</th>\n",
       "      <th>ROUGE-2 Precision</th>\n",
       "      <th>ROUGE-2 Recall</th>\n",
       "      <th>ROUGE-2 F-measure</th>\n",
       "      <th>ROUGE-L Precision</th>\n",
       "      <th>ROUGE-L Recall</th>\n",
       "      <th>ROUGE-L F-measure</th>\n",
       "      <th>ROUGE-Lsum Precision</th>\n",
       "      <th>ROUGE-Lsum Recall</th>\n",
       "      <th>ROUGE-Lsum F-measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mid</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Score Type  ROUGE-1 Precision  ROUGE-1 Recall  ROUGE-1 F-measure  \\\n",
       "0        Low           0.000128        0.000049           0.000067   \n",
       "1        Mid           0.000307        0.000163           0.000182   \n",
       "2       High           0.000506        0.000334           0.000312   \n",
       "\n",
       "   ROUGE-2 Precision  ROUGE-2 Recall  ROUGE-2 F-measure  ROUGE-L Precision  \\\n",
       "0                0.0             0.0                0.0           0.000127   \n",
       "1                0.0             0.0                0.0           0.000295   \n",
       "2                0.0             0.0                0.0           0.000490   \n",
       "\n",
       "   ROUGE-L Recall  ROUGE-L F-measure  ROUGE-Lsum Precision  ROUGE-Lsum Recall  \\\n",
       "0        0.000051           0.000069              0.000116           0.000053   \n",
       "1        0.000138           0.000161              0.000293           0.000141   \n",
       "2        0.000256           0.000281              0.000506           0.000252   \n",
       "\n",
       "   ROUGE-Lsum F-measure  \n",
       "0              0.000068  \n",
       "1              0.000164  \n",
       "2              0.000281  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    \"Score Type\": [\"Low\", \"Mid\", \"High\"],\n",
    "    \"ROUGE-1 Precision\": [0.00012757136022962845, 0.00030696858555254343, 0.0005062988359113381],\n",
    "    \"ROUGE-1 Recall\": [4.933423696380165e-05, 0.00016308813027728812, 0.0003339877030881791],\n",
    "    \"ROUGE-1 F-measure\": [6.732234645068214e-05, 0.00018227662111640694, 0.00031219502877184973],\n",
    "    \"ROUGE-2 Precision\": [0.0, 0.0, 0.0],\n",
    "    \"ROUGE-2 Recall\": [0.0, 0.0, 0.0],\n",
    "    \"ROUGE-2 F-measure\": [0.0, 0.0, 0.0],\n",
    "    \"ROUGE-L Precision\": [0.00012747169510444914, 0.00029500877053101576, 0.0004903524158826344],\n",
    "    \"ROUGE-L Recall\": [5.11262189764358e-05, 0.00013774946674766604, 0.0002557525156737812],\n",
    "    \"ROUGE-L F-measure\": [6.883905408089956e-05, 0.00016051378457393505, 0.0002807499266670898],\n",
    "    \"ROUGE-Lsum Precision\": [0.00011561154520810078, 0.00029301546802742783, 0.0005063985010365173],\n",
    "    \"ROUGE-Lsum Recall\": [5.25348883052483e-05, 0.000141219374677299, 0.0002518490193267542],\n",
    "    \"ROUGE-Lsum F-measure\": [6.754474666699242e-05, 0.0001637905834947893, 0.00028050684026071287],\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infosys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
