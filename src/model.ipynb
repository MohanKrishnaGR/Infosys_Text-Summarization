{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization\n",
    "### Method 1 - Model Training \n",
    "### Native PyTorch implementation (src/model.ipynb)\n",
    "\n",
    "Implemented works:\n",
    "\n",
    "- Load pre-trained transformer\n",
    "    - Facebook’s Bart Large \n",
    " \n",
    "- OOP implementation of Dataset \n",
    "    - Feature, Target\n",
    "    - Tokenize\n",
    "    - Padding, Truncate\n",
    "    - Convert to Tensor\n",
    "    - Pass to: DataLoader – with batch size\n",
    "\n",
    "- Training Loop\n",
    "    - Train mode\n",
    "    - Adam optimizer\n",
    "    - Forward pass & compute loss\n",
    "    - Backward pass\n",
    "    - Update params – compute gradient\n",
    "    - Update Learning Rate\n",
    "    - Zero the gradients\n",
    "    - Update total loss\n",
    "    - [ Average Training Loss: 1.3280 ]\n",
    "\n",
    "- Saved the fine-tuned transformer model.\n",
    "    - https://drive.google.com/drive/folders/1oLf8SJnRP6JgVoOCx73M1JRoOxDfZBSd?usp=sharing -> saved model\n",
    "\n",
    "- Evalution loop\n",
    "    - Eval mode\n",
    "    - No gradient calculation\n",
    "    - Forward pass & compute loss\n",
    "    - Accumulate batch loss\n",
    "    - Print batch information\n",
    "    - Calculate average validation loss\n",
    "    - Print final evaluation results (loss and time)\n",
    "    - [ Validation Loss: 2.4502 ]\n",
    "\n",
    "The trained model from method 1 was not used for deployment:\n",
    "\n",
    "(Trained model from method 2 was used for deployment)\n",
    "\n",
    "Reason:\n",
    "- Even though the model has very minimal training loss but, the model performed inconsistenly in validation & testing phase.\n",
    "- There's a suspected tensor error while training using method 1, which could be attributed to the inconsistency of the model's output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "# OOP implementation of Dataset \n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length=512):\n",
    "        self.dataset = pd.read_csv(file_path) # file path\n",
    "        self.tokenizer = tokenizer # Tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.iloc[idx, 0] # Feature\n",
    "        summary = self.dataset.iloc[idx, 1] # Target \n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, # Feature\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', # Padding \n",
    "            truncation=True, # Truncate\n",
    "            return_tensors=\"pt\" # Convert to Tensor\n",
    "        )\n",
    "        targets = self.tokenizer.encode_plus(\n",
    "            summary, # Target\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', # Padding \n",
    "            truncation=True, # Truncate\n",
    "            return_tensors=\"pt\" # Convert to Tensor\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(), # feature - converts - mutli-dimentional tensor to one dimensional tesor\n",
    "            'attention_mask': inputs['attention_mask'].flatten(), # padding - attention mask - ' '\n",
    "            'labels': targets['input_ids'].flatten() # target - ' '\n",
    "        }\n",
    "\n",
    "# Tokenizer from foundational model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base') \n",
    "\n",
    "# Data objects\n",
    "train_dataset = SummarizationDataset('/home/mohan/infy/data/merged/final/train.csv', tokenizer)\n",
    "val_dataset = SummarizationDataset('/home/mohan/infy/data/merged/final/validation.csv', tokenizer)\n",
    "test_dataset = SummarizationDataset('/home/mohan/infy/data/merged/final/test.csv', tokenizer)\n",
    "\n",
    "# Pass to: DataLoader – with batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "# cuda access\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the foundational model\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model = model.to(device) # Use cuda backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d41f83999342529a1f553a6f862853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1 | Step 1/12542 | Batch Loss: 2.1976 | Learning Rate: 0.001000 | Batch Time: 0.82s\n",
      "Epoch 1 | Step 2/12542 | Batch Loss: 2.8412 | Learning Rate: 0.001000 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3/12542 | Batch Loss: 1.3823 | Learning Rate: 0.001000 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4/12542 | Batch Loss: 1.3652 | Learning Rate: 0.001000 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5/12542 | Batch Loss: 1.4219 | Learning Rate: 0.001000 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6/12542 | Batch Loss: 1.8671 | Learning Rate: 0.001000 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 7/12542 | Batch Loss: 1.2737 | Learning Rate: 0.001000 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8/12542 | Batch Loss: 1.4080 | Learning Rate: 0.001000 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9/12542 | Batch Loss: 1.0707 | Learning Rate: 0.001000 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10/12542 | Batch Loss: 2.3664 | Learning Rate: 0.001000 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11/12542 | Batch Loss: 2.2995 | Learning Rate: 0.001000 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12/12542 | Batch Loss: 1.5660 | Learning Rate: 0.001000 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 13/12542 | Batch Loss: 0.9434 | Learning Rate: 0.001000 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 14/12542 | Batch Loss: 0.8573 | Learning Rate: 0.001000 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 15/12542 | Batch Loss: 1.2420 | Learning Rate: 0.001000 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 16/12542 | Batch Loss: 3.1214 | Learning Rate: 0.001000 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 17/12542 | Batch Loss: 1.0427 | Learning Rate: 0.001000 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 18/12542 | Batch Loss: 1.9517 | Learning Rate: 0.001000 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 19/12542 | Batch Loss: 1.4843 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 20/12542 | Batch Loss: 1.2554 | Learning Rate: 0.000999 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 21/12542 | Batch Loss: 1.8188 | Learning Rate: 0.000999 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 22/12542 | Batch Loss: 1.9594 | Learning Rate: 0.000999 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 23/12542 | Batch Loss: 0.8071 | Learning Rate: 0.000999 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 24/12542 | Batch Loss: 2.4736 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 25/12542 | Batch Loss: 0.9013 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 26/12542 | Batch Loss: 1.4781 | Learning Rate: 0.000999 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 27/12542 | Batch Loss: 2.6455 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 28/12542 | Batch Loss: 1.0500 | Learning Rate: 0.000999 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 29/12542 | Batch Loss: 0.8045 | Learning Rate: 0.000999 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 30/12542 | Batch Loss: 1.8449 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 31/12542 | Batch Loss: 0.9382 | Learning Rate: 0.000999 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 32/12542 | Batch Loss: 1.0372 | Learning Rate: 0.000999 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 33/12542 | Batch Loss: 0.7157 | Learning Rate: 0.000999 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 34/12542 | Batch Loss: 2.2922 | Learning Rate: 0.000999 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 35/12542 | Batch Loss: 1.0552 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 36/12542 | Batch Loss: 1.9575 | Learning Rate: 0.000999 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 37/12542 | Batch Loss: 1.5324 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 38/12542 | Batch Loss: 1.0634 | Learning Rate: 0.000999 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 39/12542 | Batch Loss: 1.2502 | Learning Rate: 0.000999 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 40/12542 | Batch Loss: 1.4276 | Learning Rate: 0.000999 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 41/12542 | Batch Loss: 3.2373 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 42/12542 | Batch Loss: 1.3529 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 43/12542 | Batch Loss: 1.1022 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 44/12542 | Batch Loss: 2.5234 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 45/12542 | Batch Loss: 2.1878 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 46/12542 | Batch Loss: 1.5681 | Learning Rate: 0.000999 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 47/12542 | Batch Loss: 1.1154 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 48/12542 | Batch Loss: 2.1609 | Learning Rate: 0.000999 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 49/12542 | Batch Loss: 1.1194 | Learning Rate: 0.000999 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 50/12542 | Batch Loss: 0.8971 | Learning Rate: 0.000999 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 51/12542 | Batch Loss: 2.7001 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 52/12542 | Batch Loss: 2.3743 | Learning Rate: 0.000999 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 53/12542 | Batch Loss: 0.7731 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 54/12542 | Batch Loss: 1.3549 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 55/12542 | Batch Loss: 0.7625 | Learning Rate: 0.000999 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 56/12542 | Batch Loss: 1.2096 | Learning Rate: 0.000999 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 57/12542 | Batch Loss: 1.3774 | Learning Rate: 0.000998 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 58/12542 | Batch Loss: 0.9980 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 59/12542 | Batch Loss: 2.0355 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 60/12542 | Batch Loss: 0.7547 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 61/12542 | Batch Loss: 1.6480 | Learning Rate: 0.000998 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 62/12542 | Batch Loss: 1.9246 | Learning Rate: 0.000998 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 63/12542 | Batch Loss: 2.5844 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 64/12542 | Batch Loss: 1.8988 | Learning Rate: 0.000998 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 65/12542 | Batch Loss: 1.9253 | Learning Rate: 0.000998 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 66/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000998 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 67/12542 | Batch Loss: 1.8638 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 68/12542 | Batch Loss: 1.2871 | Learning Rate: 0.000998 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 69/12542 | Batch Loss: 0.6246 | Learning Rate: 0.000998 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 70/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000998 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 71/12542 | Batch Loss: 1.2858 | Learning Rate: 0.000998 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 72/12542 | Batch Loss: 1.6198 | Learning Rate: 0.000998 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 73/12542 | Batch Loss: 1.5970 | Learning Rate: 0.000998 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 74/12542 | Batch Loss: 1.5953 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 75/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000998 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 76/12542 | Batch Loss: 2.3194 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 77/12542 | Batch Loss: 1.4839 | Learning Rate: 0.000998 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 78/12542 | Batch Loss: 1.2653 | Learning Rate: 0.000998 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 79/12542 | Batch Loss: 2.5289 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 80/12542 | Batch Loss: 1.2233 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 81/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 82/12542 | Batch Loss: 1.8628 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 83/12542 | Batch Loss: 2.7178 | Learning Rate: 0.000998 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 84/12542 | Batch Loss: 1.2671 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 85/12542 | Batch Loss: 2.2850 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 86/12542 | Batch Loss: 1.9975 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 87/12542 | Batch Loss: 1.7909 | Learning Rate: 0.000998 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 88/12542 | Batch Loss: 1.5353 | Learning Rate: 0.000998 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 89/12542 | Batch Loss: 1.2754 | Learning Rate: 0.000998 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 90/12542 | Batch Loss: 2.2367 | Learning Rate: 0.000998 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 91/12542 | Batch Loss: 0.7657 | Learning Rate: 0.000998 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 92/12542 | Batch Loss: 1.2428 | Learning Rate: 0.000998 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 93/12542 | Batch Loss: 1.3300 | Learning Rate: 0.000998 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 94/12542 | Batch Loss: 1.1801 | Learning Rate: 0.000998 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 95/12542 | Batch Loss: 0.9327 | Learning Rate: 0.000997 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 96/12542 | Batch Loss: 2.1534 | Learning Rate: 0.000997 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 97/12542 | Batch Loss: 1.4037 | Learning Rate: 0.000997 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 98/12542 | Batch Loss: 1.0793 | Learning Rate: 0.000997 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 99/12542 | Batch Loss: 0.5347 | Learning Rate: 0.000997 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 100/12542 | Batch Loss: 0.7854 | Learning Rate: 0.000997 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 101/12542 | Batch Loss: 1.6123 | Learning Rate: 0.000997 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 102/12542 | Batch Loss: 0.6348 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 103/12542 | Batch Loss: 2.1780 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 104/12542 | Batch Loss: 1.7138 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 105/12542 | Batch Loss: 1.2477 | Learning Rate: 0.000997 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 106/12542 | Batch Loss: 1.6424 | Learning Rate: 0.000997 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 107/12542 | Batch Loss: 1.3447 | Learning Rate: 0.000997 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 108/12542 | Batch Loss: 0.5835 | Learning Rate: 0.000997 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 109/12542 | Batch Loss: 1.2979 | Learning Rate: 0.000997 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 110/12542 | Batch Loss: 1.6129 | Learning Rate: 0.000997 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 111/12542 | Batch Loss: 0.7292 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 112/12542 | Batch Loss: 2.3914 | Learning Rate: 0.000997 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 113/12542 | Batch Loss: 1.2983 | Learning Rate: 0.000997 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 114/12542 | Batch Loss: 0.9830 | Learning Rate: 0.000997 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 115/12542 | Batch Loss: 1.6017 | Learning Rate: 0.000997 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 116/12542 | Batch Loss: 2.1210 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 117/12542 | Batch Loss: 1.3233 | Learning Rate: 0.000997 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 118/12542 | Batch Loss: 0.7308 | Learning Rate: 0.000997 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 119/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 120/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000997 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 121/12542 | Batch Loss: 2.0159 | Learning Rate: 0.000997 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 122/12542 | Batch Loss: 2.3950 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 123/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000997 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 124/12542 | Batch Loss: 2.5905 | Learning Rate: 0.000997 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 125/12542 | Batch Loss: 1.0997 | Learning Rate: 0.000997 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 126/12542 | Batch Loss: 1.8594 | Learning Rate: 0.000997 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 127/12542 | Batch Loss: 0.7927 | Learning Rate: 0.000997 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 128/12542 | Batch Loss: 0.9127 | Learning Rate: 0.000997 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 129/12542 | Batch Loss: 1.0678 | Learning Rate: 0.000997 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 130/12542 | Batch Loss: 1.4042 | Learning Rate: 0.000997 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 131/12542 | Batch Loss: 1.4552 | Learning Rate: 0.000997 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 132/12542 | Batch Loss: 1.6908 | Learning Rate: 0.000996 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 133/12542 | Batch Loss: 1.4947 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 134/12542 | Batch Loss: 0.8990 | Learning Rate: 0.000996 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 135/12542 | Batch Loss: 2.1039 | Learning Rate: 0.000996 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 136/12542 | Batch Loss: 0.9736 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 137/12542 | Batch Loss: 0.9377 | Learning Rate: 0.000996 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 138/12542 | Batch Loss: 1.6329 | Learning Rate: 0.000996 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 139/12542 | Batch Loss: 1.9486 | Learning Rate: 0.000996 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 140/12542 | Batch Loss: 0.6803 | Learning Rate: 0.000996 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 141/12542 | Batch Loss: 2.0907 | Learning Rate: 0.000996 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 142/12542 | Batch Loss: 0.9549 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 143/12542 | Batch Loss: 2.0311 | Learning Rate: 0.000996 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 144/12542 | Batch Loss: 1.4298 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 145/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000996 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 146/12542 | Batch Loss: 1.4735 | Learning Rate: 0.000996 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 147/12542 | Batch Loss: 1.6244 | Learning Rate: 0.000996 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 148/12542 | Batch Loss: 1.6999 | Learning Rate: 0.000996 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 149/12542 | Batch Loss: 1.2650 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 150/12542 | Batch Loss: 1.8816 | Learning Rate: 0.000996 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 151/12542 | Batch Loss: 0.9328 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 152/12542 | Batch Loss: 1.7687 | Learning Rate: 0.000996 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 153/12542 | Batch Loss: 0.8156 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 154/12542 | Batch Loss: 0.8888 | Learning Rate: 0.000996 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 155/12542 | Batch Loss: 1.8215 | Learning Rate: 0.000996 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 156/12542 | Batch Loss: 1.6948 | Learning Rate: 0.000996 | Batch Time: 0.54s\n",
      "Epoch 1 | Step 157/12542 | Batch Loss: 0.6498 | Learning Rate: 0.000996 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 158/12542 | Batch Loss: 2.5977 | Learning Rate: 0.000996 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 159/12542 | Batch Loss: 0.9062 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 160/12542 | Batch Loss: 1.5853 | Learning Rate: 0.000996 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 161/12542 | Batch Loss: 0.8298 | Learning Rate: 0.000996 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 162/12542 | Batch Loss: 0.8365 | Learning Rate: 0.000996 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 163/12542 | Batch Loss: 0.9396 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 164/12542 | Batch Loss: 1.1334 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 165/12542 | Batch Loss: 1.1980 | Learning Rate: 0.000996 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 166/12542 | Batch Loss: 1.1688 | Learning Rate: 0.000996 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 167/12542 | Batch Loss: 2.1167 | Learning Rate: 0.000996 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 168/12542 | Batch Loss: 1.7910 | Learning Rate: 0.000996 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 169/12542 | Batch Loss: 1.7831 | Learning Rate: 0.000996 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 170/12542 | Batch Loss: 1.7859 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 171/12542 | Batch Loss: 2.1878 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 172/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 173/12542 | Batch Loss: 1.4761 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 174/12542 | Batch Loss: 1.4600 | Learning Rate: 0.000995 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 175/12542 | Batch Loss: 0.5677 | Learning Rate: 0.000995 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 176/12542 | Batch Loss: 0.9319 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 177/12542 | Batch Loss: 1.5557 | Learning Rate: 0.000995 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 178/12542 | Batch Loss: 1.5042 | Learning Rate: 0.000995 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 179/12542 | Batch Loss: 1.2477 | Learning Rate: 0.000995 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 180/12542 | Batch Loss: 1.5743 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 181/12542 | Batch Loss: 2.2622 | Learning Rate: 0.000995 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 182/12542 | Batch Loss: 1.1602 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 183/12542 | Batch Loss: 1.6646 | Learning Rate: 0.000995 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 184/12542 | Batch Loss: 0.8000 | Learning Rate: 0.000995 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 185/12542 | Batch Loss: 1.0355 | Learning Rate: 0.000995 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 186/12542 | Batch Loss: 2.0267 | Learning Rate: 0.000995 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 187/12542 | Batch Loss: 1.7343 | Learning Rate: 0.000995 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 188/12542 | Batch Loss: 2.5107 | Learning Rate: 0.000995 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 189/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000995 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 190/12542 | Batch Loss: 0.6539 | Learning Rate: 0.000995 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 191/12542 | Batch Loss: 1.1624 | Learning Rate: 0.000995 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 192/12542 | Batch Loss: 1.2921 | Learning Rate: 0.000995 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 193/12542 | Batch Loss: 2.2607 | Learning Rate: 0.000995 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 194/12542 | Batch Loss: 0.4507 | Learning Rate: 0.000995 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 195/12542 | Batch Loss: 2.2570 | Learning Rate: 0.000995 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 196/12542 | Batch Loss: 2.2001 | Learning Rate: 0.000995 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 197/12542 | Batch Loss: 2.0565 | Learning Rate: 0.000995 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 198/12542 | Batch Loss: 0.9908 | Learning Rate: 0.000995 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 199/12542 | Batch Loss: 1.9415 | Learning Rate: 0.000995 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 200/12542 | Batch Loss: 2.1011 | Learning Rate: 0.000995 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 201/12542 | Batch Loss: 1.9041 | Learning Rate: 0.000995 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 202/12542 | Batch Loss: 1.0369 | Learning Rate: 0.000995 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 203/12542 | Batch Loss: 2.7606 | Learning Rate: 0.000995 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 204/12542 | Batch Loss: 1.7059 | Learning Rate: 0.000995 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 205/12542 | Batch Loss: 0.9441 | Learning Rate: 0.000995 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 206/12542 | Batch Loss: 1.7235 | Learning Rate: 0.000995 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 207/12542 | Batch Loss: 0.5874 | Learning Rate: 0.000994 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 208/12542 | Batch Loss: 0.9039 | Learning Rate: 0.000994 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 209/12542 | Batch Loss: 2.1088 | Learning Rate: 0.000994 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 210/12542 | Batch Loss: 0.9479 | Learning Rate: 0.000994 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 211/12542 | Batch Loss: 0.9438 | Learning Rate: 0.000994 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 212/12542 | Batch Loss: 2.4569 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 213/12542 | Batch Loss: 1.5330 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 214/12542 | Batch Loss: 1.8804 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 215/12542 | Batch Loss: 2.1868 | Learning Rate: 0.000994 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 216/12542 | Batch Loss: 1.6900 | Learning Rate: 0.000994 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 217/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000994 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 218/12542 | Batch Loss: 0.7794 | Learning Rate: 0.000994 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 219/12542 | Batch Loss: 1.9928 | Learning Rate: 0.000994 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 220/12542 | Batch Loss: 0.9327 | Learning Rate: 0.000994 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 221/12542 | Batch Loss: 1.6424 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 222/12542 | Batch Loss: 2.9294 | Learning Rate: 0.000994 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 223/12542 | Batch Loss: 1.4777 | Learning Rate: 0.000994 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 224/12542 | Batch Loss: 3.7201 | Learning Rate: 0.000994 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 225/12542 | Batch Loss: 1.3617 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 226/12542 | Batch Loss: 1.3180 | Learning Rate: 0.000994 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 227/12542 | Batch Loss: 1.6260 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 228/12542 | Batch Loss: 2.5982 | Learning Rate: 0.000994 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 229/12542 | Batch Loss: 1.0339 | Learning Rate: 0.000994 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 230/12542 | Batch Loss: 1.8792 | Learning Rate: 0.000994 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 231/12542 | Batch Loss: 0.4330 | Learning Rate: 0.000994 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 232/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000994 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 233/12542 | Batch Loss: 1.0800 | Learning Rate: 0.000994 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 234/12542 | Batch Loss: 1.7891 | Learning Rate: 0.000994 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 235/12542 | Batch Loss: 1.1965 | Learning Rate: 0.000994 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 236/12542 | Batch Loss: 1.1685 | Learning Rate: 0.000994 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 237/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000994 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 238/12542 | Batch Loss: 0.5530 | Learning Rate: 0.000994 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 239/12542 | Batch Loss: 0.4119 | Learning Rate: 0.000994 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 240/12542 | Batch Loss: 1.8920 | Learning Rate: 0.000994 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 241/12542 | Batch Loss: 2.2612 | Learning Rate: 0.000994 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 242/12542 | Batch Loss: 1.0476 | Learning Rate: 0.000994 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 243/12542 | Batch Loss: 1.7746 | Learning Rate: 0.000994 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 244/12542 | Batch Loss: 1.6965 | Learning Rate: 0.000994 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 245/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000993 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 246/12542 | Batch Loss: 2.7898 | Learning Rate: 0.000993 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 247/12542 | Batch Loss: 1.0235 | Learning Rate: 0.000993 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 248/12542 | Batch Loss: 1.6889 | Learning Rate: 0.000993 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 249/12542 | Batch Loss: 0.5720 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 250/12542 | Batch Loss: 1.1635 | Learning Rate: 0.000993 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 251/12542 | Batch Loss: 1.4615 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 252/12542 | Batch Loss: 0.8288 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 253/12542 | Batch Loss: 0.9519 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 254/12542 | Batch Loss: 2.6777 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 255/12542 | Batch Loss: 2.0410 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 256/12542 | Batch Loss: 1.5576 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 257/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 258/12542 | Batch Loss: 2.0893 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 259/12542 | Batch Loss: 1.5376 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 260/12542 | Batch Loss: 1.2399 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 261/12542 | Batch Loss: 0.5845 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 262/12542 | Batch Loss: 1.1940 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 263/12542 | Batch Loss: 1.6926 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 264/12542 | Batch Loss: 1.3488 | Learning Rate: 0.000993 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 265/12542 | Batch Loss: 1.8389 | Learning Rate: 0.000993 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 266/12542 | Batch Loss: 0.9818 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 267/12542 | Batch Loss: 2.2189 | Learning Rate: 0.000993 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 268/12542 | Batch Loss: 2.2252 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 269/12542 | Batch Loss: 1.6140 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 270/12542 | Batch Loss: 1.7048 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 271/12542 | Batch Loss: 1.6640 | Learning Rate: 0.000993 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 272/12542 | Batch Loss: 3.0126 | Learning Rate: 0.000993 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 273/12542 | Batch Loss: 2.5729 | Learning Rate: 0.000993 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 274/12542 | Batch Loss: 2.9851 | Learning Rate: 0.000993 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 275/12542 | Batch Loss: 1.5350 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 276/12542 | Batch Loss: 0.9038 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 277/12542 | Batch Loss: 1.9798 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 278/12542 | Batch Loss: 1.3998 | Learning Rate: 0.000993 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 279/12542 | Batch Loss: 1.4749 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 280/12542 | Batch Loss: 0.8058 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 281/12542 | Batch Loss: 0.9569 | Learning Rate: 0.000993 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 282/12542 | Batch Loss: 1.9689 | Learning Rate: 0.000993 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 283/12542 | Batch Loss: 1.5770 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 284/12542 | Batch Loss: 1.9078 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 285/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000992 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 286/12542 | Batch Loss: 2.7655 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 287/12542 | Batch Loss: 1.6265 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 288/12542 | Batch Loss: 1.9074 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 289/12542 | Batch Loss: 1.1589 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 290/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 291/12542 | Batch Loss: 1.2842 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 292/12542 | Batch Loss: 1.0370 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 293/12542 | Batch Loss: 2.9800 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 294/12542 | Batch Loss: 1.4453 | Learning Rate: 0.000992 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 295/12542 | Batch Loss: 1.2243 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 296/12542 | Batch Loss: 1.1166 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 297/12542 | Batch Loss: 0.8116 | Learning Rate: 0.000992 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 298/12542 | Batch Loss: 0.6101 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 299/12542 | Batch Loss: 1.6909 | Learning Rate: 0.000992 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 300/12542 | Batch Loss: 1.5061 | Learning Rate: 0.000992 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 301/12542 | Batch Loss: 2.2578 | Learning Rate: 0.000992 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 302/12542 | Batch Loss: 2.0863 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 303/12542 | Batch Loss: 1.7985 | Learning Rate: 0.000992 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 304/12542 | Batch Loss: 1.5459 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 305/12542 | Batch Loss: 1.8638 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 306/12542 | Batch Loss: 1.3430 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 307/12542 | Batch Loss: 1.7389 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 308/12542 | Batch Loss: 1.5799 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 309/12542 | Batch Loss: 2.2495 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 310/12542 | Batch Loss: 2.5754 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 311/12542 | Batch Loss: 3.0232 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 312/12542 | Batch Loss: 2.6710 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 313/12542 | Batch Loss: 1.7753 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 314/12542 | Batch Loss: 1.0713 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 315/12542 | Batch Loss: 1.5550 | Learning Rate: 0.000992 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 316/12542 | Batch Loss: 1.0880 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 317/12542 | Batch Loss: 0.7041 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 318/12542 | Batch Loss: 0.7219 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 319/12542 | Batch Loss: 1.3995 | Learning Rate: 0.000992 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 320/12542 | Batch Loss: 1.5847 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 321/12542 | Batch Loss: 2.8043 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 322/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 323/12542 | Batch Loss: 1.4822 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 324/12542 | Batch Loss: 1.1257 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 325/12542 | Batch Loss: 1.1103 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 326/12542 | Batch Loss: 1.2876 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 327/12542 | Batch Loss: 2.8235 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 328/12542 | Batch Loss: 2.3010 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 329/12542 | Batch Loss: 1.4331 | Learning Rate: 0.000991 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 330/12542 | Batch Loss: 1.7918 | Learning Rate: 0.000991 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 331/12542 | Batch Loss: 1.4995 | Learning Rate: 0.000991 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 332/12542 | Batch Loss: 2.3458 | Learning Rate: 0.000991 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 333/12542 | Batch Loss: 2.7541 | Learning Rate: 0.000991 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 334/12542 | Batch Loss: 0.6458 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 335/12542 | Batch Loss: 1.5346 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 336/12542 | Batch Loss: 0.7454 | Learning Rate: 0.000991 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 337/12542 | Batch Loss: 2.2008 | Learning Rate: 0.000991 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 338/12542 | Batch Loss: 2.1163 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 339/12542 | Batch Loss: 0.9580 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 340/12542 | Batch Loss: 1.7779 | Learning Rate: 0.000991 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 341/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 342/12542 | Batch Loss: 1.3322 | Learning Rate: 0.000991 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 343/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 344/12542 | Batch Loss: 1.6379 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 345/12542 | Batch Loss: 1.7295 | Learning Rate: 0.000991 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 346/12542 | Batch Loss: 2.7628 | Learning Rate: 0.000991 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 347/12542 | Batch Loss: 1.4007 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 348/12542 | Batch Loss: 1.8310 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 349/12542 | Batch Loss: 0.6382 | Learning Rate: 0.000991 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 350/12542 | Batch Loss: 1.4334 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 351/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000991 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 352/12542 | Batch Loss: 1.0256 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 353/12542 | Batch Loss: 0.9441 | Learning Rate: 0.000991 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 354/12542 | Batch Loss: 2.1296 | Learning Rate: 0.000991 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 355/12542 | Batch Loss: 1.4318 | Learning Rate: 0.000991 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 356/12542 | Batch Loss: 0.9007 | Learning Rate: 0.000991 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 357/12542 | Batch Loss: 1.7448 | Learning Rate: 0.000991 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 358/12542 | Batch Loss: 1.6601 | Learning Rate: 0.000990 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 359/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 360/12542 | Batch Loss: 1.6261 | Learning Rate: 0.000990 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 361/12542 | Batch Loss: 0.6572 | Learning Rate: 0.000990 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 362/12542 | Batch Loss: 0.8840 | Learning Rate: 0.000990 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 363/12542 | Batch Loss: 1.3415 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 364/12542 | Batch Loss: 1.0757 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 365/12542 | Batch Loss: 2.1140 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 366/12542 | Batch Loss: 1.6888 | Learning Rate: 0.000990 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 367/12542 | Batch Loss: 2.2422 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 368/12542 | Batch Loss: 0.5066 | Learning Rate: 0.000990 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 369/12542 | Batch Loss: 2.4712 | Learning Rate: 0.000990 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 370/12542 | Batch Loss: 0.7107 | Learning Rate: 0.000990 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 371/12542 | Batch Loss: 2.4864 | Learning Rate: 0.000990 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 372/12542 | Batch Loss: 1.9620 | Learning Rate: 0.000990 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 373/12542 | Batch Loss: 2.3659 | Learning Rate: 0.000990 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 374/12542 | Batch Loss: 1.3724 | Learning Rate: 0.000990 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 375/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000990 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 376/12542 | Batch Loss: 1.2326 | Learning Rate: 0.000990 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 377/12542 | Batch Loss: 1.2348 | Learning Rate: 0.000990 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 378/12542 | Batch Loss: 0.7521 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 379/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000990 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 380/12542 | Batch Loss: 0.6863 | Learning Rate: 0.000990 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 381/12542 | Batch Loss: 1.9486 | Learning Rate: 0.000990 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 382/12542 | Batch Loss: 1.9601 | Learning Rate: 0.000990 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 383/12542 | Batch Loss: 0.9148 | Learning Rate: 0.000990 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 384/12542 | Batch Loss: 1.5710 | Learning Rate: 0.000990 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 385/12542 | Batch Loss: 0.9957 | Learning Rate: 0.000990 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 386/12542 | Batch Loss: 1.9108 | Learning Rate: 0.000990 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 387/12542 | Batch Loss: 2.1863 | Learning Rate: 0.000990 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 388/12542 | Batch Loss: 1.7030 | Learning Rate: 0.000990 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 389/12542 | Batch Loss: 1.7095 | Learning Rate: 0.000990 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 390/12542 | Batch Loss: 2.8537 | Learning Rate: 0.000990 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 391/12542 | Batch Loss: 2.7246 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 392/12542 | Batch Loss: 2.6761 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 393/12542 | Batch Loss: 1.6091 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 394/12542 | Batch Loss: 1.8183 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 395/12542 | Batch Loss: 0.8973 | Learning Rate: 0.000990 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 396/12542 | Batch Loss: 0.9551 | Learning Rate: 0.000989 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 397/12542 | Batch Loss: 1.6053 | Learning Rate: 0.000989 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 398/12542 | Batch Loss: 1.4209 | Learning Rate: 0.000989 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 399/12542 | Batch Loss: 1.5715 | Learning Rate: 0.000989 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 400/12542 | Batch Loss: 1.2396 | Learning Rate: 0.000989 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 401/12542 | Batch Loss: 2.3235 | Learning Rate: 0.000989 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 402/12542 | Batch Loss: 1.6321 | Learning Rate: 0.000989 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 403/12542 | Batch Loss: 0.7991 | Learning Rate: 0.000989 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 404/12542 | Batch Loss: 1.1240 | Learning Rate: 0.000989 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 405/12542 | Batch Loss: 1.2328 | Learning Rate: 0.000989 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 406/12542 | Batch Loss: 2.2827 | Learning Rate: 0.000989 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 407/12542 | Batch Loss: 0.8712 | Learning Rate: 0.000989 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 408/12542 | Batch Loss: 1.8241 | Learning Rate: 0.000989 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 409/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000989 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 410/12542 | Batch Loss: 1.3844 | Learning Rate: 0.000989 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 411/12542 | Batch Loss: 1.5147 | Learning Rate: 0.000989 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 412/12542 | Batch Loss: 0.9423 | Learning Rate: 0.000989 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 413/12542 | Batch Loss: 1.2198 | Learning Rate: 0.000989 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 414/12542 | Batch Loss: 2.8623 | Learning Rate: 0.000989 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 415/12542 | Batch Loss: 0.9814 | Learning Rate: 0.000989 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 416/12542 | Batch Loss: 1.5710 | Learning Rate: 0.000989 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 417/12542 | Batch Loss: 2.4016 | Learning Rate: 0.000989 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 418/12542 | Batch Loss: 1.6838 | Learning Rate: 0.000989 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 419/12542 | Batch Loss: 1.9467 | Learning Rate: 0.000989 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 420/12542 | Batch Loss: 1.3283 | Learning Rate: 0.000989 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 421/12542 | Batch Loss: 1.1630 | Learning Rate: 0.000989 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 422/12542 | Batch Loss: 1.0020 | Learning Rate: 0.000989 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 423/12542 | Batch Loss: 1.1483 | Learning Rate: 0.000989 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 424/12542 | Batch Loss: 1.8213 | Learning Rate: 0.000989 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 425/12542 | Batch Loss: 1.7821 | Learning Rate: 0.000989 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 426/12542 | Batch Loss: 1.4472 | Learning Rate: 0.000989 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 427/12542 | Batch Loss: 0.7992 | Learning Rate: 0.000989 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 428/12542 | Batch Loss: 1.8874 | Learning Rate: 0.000989 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 429/12542 | Batch Loss: 0.7526 | Learning Rate: 0.000989 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 430/12542 | Batch Loss: 0.8043 | Learning Rate: 0.000989 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 431/12542 | Batch Loss: 1.4033 | Learning Rate: 0.000989 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 432/12542 | Batch Loss: 0.7168 | Learning Rate: 0.000989 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 433/12542 | Batch Loss: 0.7286 | Learning Rate: 0.000988 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 434/12542 | Batch Loss: 3.2004 | Learning Rate: 0.000988 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 435/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000988 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 436/12542 | Batch Loss: 0.9433 | Learning Rate: 0.000988 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 437/12542 | Batch Loss: 1.6630 | Learning Rate: 0.000988 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 438/12542 | Batch Loss: 1.4696 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 439/12542 | Batch Loss: 1.4131 | Learning Rate: 0.000988 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 440/12542 | Batch Loss: 1.6351 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 441/12542 | Batch Loss: 1.6947 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 442/12542 | Batch Loss: 0.9797 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 443/12542 | Batch Loss: 1.6993 | Learning Rate: 0.000988 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 444/12542 | Batch Loss: 1.5007 | Learning Rate: 0.000988 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 445/12542 | Batch Loss: 0.7583 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 446/12542 | Batch Loss: 0.8730 | Learning Rate: 0.000988 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 447/12542 | Batch Loss: 0.9364 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 448/12542 | Batch Loss: 0.9063 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 449/12542 | Batch Loss: 0.8178 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 450/12542 | Batch Loss: 3.2701 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 451/12542 | Batch Loss: 1.2759 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 452/12542 | Batch Loss: 1.3543 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 453/12542 | Batch Loss: 2.5935 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 454/12542 | Batch Loss: 1.7709 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 455/12542 | Batch Loss: 2.2757 | Learning Rate: 0.000988 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 456/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000988 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 457/12542 | Batch Loss: 1.6555 | Learning Rate: 0.000988 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 458/12542 | Batch Loss: 1.2625 | Learning Rate: 0.000988 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 459/12542 | Batch Loss: 1.3045 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 460/12542 | Batch Loss: 0.7522 | Learning Rate: 0.000988 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 461/12542 | Batch Loss: 1.0047 | Learning Rate: 0.000988 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 462/12542 | Batch Loss: 2.6055 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 463/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000988 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 464/12542 | Batch Loss: 1.9019 | Learning Rate: 0.000988 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 465/12542 | Batch Loss: 1.3285 | Learning Rate: 0.000988 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 466/12542 | Batch Loss: 1.0124 | Learning Rate: 0.000988 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 467/12542 | Batch Loss: 2.3808 | Learning Rate: 0.000988 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 468/12542 | Batch Loss: 0.7706 | Learning Rate: 0.000988 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 469/12542 | Batch Loss: 2.2487 | Learning Rate: 0.000988 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 470/12542 | Batch Loss: 1.1156 | Learning Rate: 0.000988 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 471/12542 | Batch Loss: 0.7187 | Learning Rate: 0.000987 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 472/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000987 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 473/12542 | Batch Loss: 1.8393 | Learning Rate: 0.000987 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 474/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000987 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 475/12542 | Batch Loss: 1.5328 | Learning Rate: 0.000987 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 476/12542 | Batch Loss: 0.7574 | Learning Rate: 0.000987 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 477/12542 | Batch Loss: 1.7777 | Learning Rate: 0.000987 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 478/12542 | Batch Loss: 1.5639 | Learning Rate: 0.000987 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 479/12542 | Batch Loss: 2.2391 | Learning Rate: 0.000987 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 480/12542 | Batch Loss: 1.2049 | Learning Rate: 0.000987 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 481/12542 | Batch Loss: 1.0545 | Learning Rate: 0.000987 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 482/12542 | Batch Loss: 0.7915 | Learning Rate: 0.000987 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 483/12542 | Batch Loss: 1.1373 | Learning Rate: 0.000987 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 484/12542 | Batch Loss: 0.6173 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 485/12542 | Batch Loss: 1.3718 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 486/12542 | Batch Loss: 3.1218 | Learning Rate: 0.000987 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 487/12542 | Batch Loss: 1.4110 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 488/12542 | Batch Loss: 0.9962 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 489/12542 | Batch Loss: 2.7407 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 490/12542 | Batch Loss: 0.8294 | Learning Rate: 0.000987 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 491/12542 | Batch Loss: 0.7045 | Learning Rate: 0.000987 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 492/12542 | Batch Loss: 1.2375 | Learning Rate: 0.000987 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 493/12542 | Batch Loss: 1.2962 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 494/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 495/12542 | Batch Loss: 1.5816 | Learning Rate: 0.000987 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 496/12542 | Batch Loss: 1.3231 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 497/12542 | Batch Loss: 0.6705 | Learning Rate: 0.000987 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 498/12542 | Batch Loss: 0.9577 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 499/12542 | Batch Loss: 1.6570 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 500/12542 | Batch Loss: 1.1715 | Learning Rate: 0.000987 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 501/12542 | Batch Loss: 0.7019 | Learning Rate: 0.000987 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 502/12542 | Batch Loss: 2.1640 | Learning Rate: 0.000987 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 503/12542 | Batch Loss: 1.7607 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 504/12542 | Batch Loss: 0.7847 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 505/12542 | Batch Loss: 0.8629 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 506/12542 | Batch Loss: 0.7651 | Learning Rate: 0.000987 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 507/12542 | Batch Loss: 2.5202 | Learning Rate: 0.000987 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 508/12542 | Batch Loss: 1.9382 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 509/12542 | Batch Loss: 1.0912 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 510/12542 | Batch Loss: 1.1697 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 511/12542 | Batch Loss: 1.3706 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 512/12542 | Batch Loss: 2.4219 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 513/12542 | Batch Loss: 2.3225 | Learning Rate: 0.000986 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 514/12542 | Batch Loss: 0.5988 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 515/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000986 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 516/12542 | Batch Loss: 1.6654 | Learning Rate: 0.000986 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 517/12542 | Batch Loss: 1.0848 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 518/12542 | Batch Loss: 0.7562 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 519/12542 | Batch Loss: 2.3536 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 520/12542 | Batch Loss: 1.5456 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 521/12542 | Batch Loss: 3.2687 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 522/12542 | Batch Loss: 1.3767 | Learning Rate: 0.000986 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 523/12542 | Batch Loss: 1.4940 | Learning Rate: 0.000986 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 524/12542 | Batch Loss: 1.2547 | Learning Rate: 0.000986 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 525/12542 | Batch Loss: 1.4818 | Learning Rate: 0.000986 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 526/12542 | Batch Loss: 0.6821 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 527/12542 | Batch Loss: 1.0957 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 528/12542 | Batch Loss: 1.3338 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 529/12542 | Batch Loss: 1.4003 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 530/12542 | Batch Loss: 2.4350 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 531/12542 | Batch Loss: 1.6471 | Learning Rate: 0.000986 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 532/12542 | Batch Loss: 0.6549 | Learning Rate: 0.000986 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 533/12542 | Batch Loss: 1.5070 | Learning Rate: 0.000986 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 534/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000986 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 535/12542 | Batch Loss: 1.8399 | Learning Rate: 0.000986 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 536/12542 | Batch Loss: 0.7027 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 537/12542 | Batch Loss: 0.9782 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 538/12542 | Batch Loss: 2.9338 | Learning Rate: 0.000986 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 539/12542 | Batch Loss: 2.6005 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 540/12542 | Batch Loss: 0.7620 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 541/12542 | Batch Loss: 1.1818 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 542/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000986 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 543/12542 | Batch Loss: 1.4896 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 544/12542 | Batch Loss: 1.7512 | Learning Rate: 0.000986 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 545/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000986 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 546/12542 | Batch Loss: 0.6489 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 547/12542 | Batch Loss: 1.1885 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 548/12542 | Batch Loss: 1.3567 | Learning Rate: 0.000985 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 549/12542 | Batch Loss: 1.7868 | Learning Rate: 0.000985 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 550/12542 | Batch Loss: 1.3378 | Learning Rate: 0.000985 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 551/12542 | Batch Loss: 1.8956 | Learning Rate: 0.000985 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 552/12542 | Batch Loss: 2.1244 | Learning Rate: 0.000985 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 553/12542 | Batch Loss: 1.6054 | Learning Rate: 0.000985 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 554/12542 | Batch Loss: 1.8264 | Learning Rate: 0.000985 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 555/12542 | Batch Loss: 2.2911 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 556/12542 | Batch Loss: 1.6760 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 557/12542 | Batch Loss: 2.0765 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 558/12542 | Batch Loss: 1.5486 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 559/12542 | Batch Loss: 1.6052 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 560/12542 | Batch Loss: 1.3107 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 561/12542 | Batch Loss: 3.4588 | Learning Rate: 0.000985 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 562/12542 | Batch Loss: 2.2142 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 563/12542 | Batch Loss: 1.0005 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 564/12542 | Batch Loss: 1.8166 | Learning Rate: 0.000985 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 565/12542 | Batch Loss: 1.6778 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 566/12542 | Batch Loss: 1.5866 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 567/12542 | Batch Loss: 1.1108 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 568/12542 | Batch Loss: 1.0960 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 569/12542 | Batch Loss: 1.6409 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 570/12542 | Batch Loss: 0.9294 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 571/12542 | Batch Loss: 0.7309 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 572/12542 | Batch Loss: 1.6041 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 573/12542 | Batch Loss: 1.9066 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 574/12542 | Batch Loss: 2.2343 | Learning Rate: 0.000985 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 575/12542 | Batch Loss: 1.4622 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 576/12542 | Batch Loss: 1.5635 | Learning Rate: 0.000985 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 577/12542 | Batch Loss: 1.5143 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 578/12542 | Batch Loss: 0.8358 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 579/12542 | Batch Loss: 1.7801 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 580/12542 | Batch Loss: 0.9084 | Learning Rate: 0.000985 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 581/12542 | Batch Loss: 1.4599 | Learning Rate: 0.000985 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 582/12542 | Batch Loss: 0.8692 | Learning Rate: 0.000985 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 583/12542 | Batch Loss: 2.3899 | Learning Rate: 0.000985 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 584/12542 | Batch Loss: 1.9246 | Learning Rate: 0.000984 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 585/12542 | Batch Loss: 1.1710 | Learning Rate: 0.000984 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 586/12542 | Batch Loss: 2.4424 | Learning Rate: 0.000984 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 587/12542 | Batch Loss: 2.1064 | Learning Rate: 0.000984 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 588/12542 | Batch Loss: 0.8872 | Learning Rate: 0.000984 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 589/12542 | Batch Loss: 1.4960 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 590/12542 | Batch Loss: 1.4031 | Learning Rate: 0.000984 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 591/12542 | Batch Loss: 1.2496 | Learning Rate: 0.000984 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 592/12542 | Batch Loss: 0.8379 | Learning Rate: 0.000984 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 593/12542 | Batch Loss: 1.4993 | Learning Rate: 0.000984 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 594/12542 | Batch Loss: 2.4969 | Learning Rate: 0.000984 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 595/12542 | Batch Loss: 1.4527 | Learning Rate: 0.000984 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 596/12542 | Batch Loss: 1.9019 | Learning Rate: 0.000984 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 597/12542 | Batch Loss: 2.2057 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 598/12542 | Batch Loss: 0.9415 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 599/12542 | Batch Loss: 0.8479 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 600/12542 | Batch Loss: 1.5733 | Learning Rate: 0.000984 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 601/12542 | Batch Loss: 1.9489 | Learning Rate: 0.000984 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 602/12542 | Batch Loss: 1.0142 | Learning Rate: 0.000984 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 603/12542 | Batch Loss: 1.3340 | Learning Rate: 0.000984 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 604/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000984 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 605/12542 | Batch Loss: 0.6936 | Learning Rate: 0.000984 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 606/12542 | Batch Loss: 1.2884 | Learning Rate: 0.000984 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 607/12542 | Batch Loss: 2.4992 | Learning Rate: 0.000984 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 608/12542 | Batch Loss: 0.8316 | Learning Rate: 0.000984 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 609/12542 | Batch Loss: 1.7576 | Learning Rate: 0.000984 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 610/12542 | Batch Loss: 2.0591 | Learning Rate: 0.000984 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 611/12542 | Batch Loss: 0.8075 | Learning Rate: 0.000984 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 612/12542 | Batch Loss: 1.3766 | Learning Rate: 0.000984 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 613/12542 | Batch Loss: 1.2034 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 614/12542 | Batch Loss: 2.6019 | Learning Rate: 0.000984 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 615/12542 | Batch Loss: 1.2477 | Learning Rate: 0.000984 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 616/12542 | Batch Loss: 2.0830 | Learning Rate: 0.000984 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 617/12542 | Batch Loss: 2.7761 | Learning Rate: 0.000984 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 618/12542 | Batch Loss: 2.4614 | Learning Rate: 0.000984 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 619/12542 | Batch Loss: 1.1654 | Learning Rate: 0.000984 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 620/12542 | Batch Loss: 1.7826 | Learning Rate: 0.000984 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 621/12542 | Batch Loss: 0.8306 | Learning Rate: 0.000983 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 622/12542 | Batch Loss: 1.2224 | Learning Rate: 0.000983 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 623/12542 | Batch Loss: 2.0343 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 624/12542 | Batch Loss: 0.9309 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 625/12542 | Batch Loss: 1.6082 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 626/12542 | Batch Loss: 0.7181 | Learning Rate: 0.000983 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 627/12542 | Batch Loss: 0.9110 | Learning Rate: 0.000983 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 628/12542 | Batch Loss: 1.3214 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 629/12542 | Batch Loss: 1.3703 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 630/12542 | Batch Loss: 1.2988 | Learning Rate: 0.000983 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 631/12542 | Batch Loss: 2.5637 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 632/12542 | Batch Loss: 1.0058 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 633/12542 | Batch Loss: 0.5708 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 634/12542 | Batch Loss: 1.5122 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 635/12542 | Batch Loss: 1.0130 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 636/12542 | Batch Loss: 1.3886 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 637/12542 | Batch Loss: 1.1556 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 638/12542 | Batch Loss: 0.7421 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 639/12542 | Batch Loss: 0.7127 | Learning Rate: 0.000983 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 640/12542 | Batch Loss: 0.7085 | Learning Rate: 0.000983 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 641/12542 | Batch Loss: 1.3362 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 642/12542 | Batch Loss: 1.7324 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 643/12542 | Batch Loss: 0.7155 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 644/12542 | Batch Loss: 2.9365 | Learning Rate: 0.000983 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 645/12542 | Batch Loss: 1.6309 | Learning Rate: 0.000983 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 646/12542 | Batch Loss: 1.5351 | Learning Rate: 0.000983 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 647/12542 | Batch Loss: 1.0688 | Learning Rate: 0.000983 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 648/12542 | Batch Loss: 1.2926 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 649/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000983 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 650/12542 | Batch Loss: 2.0317 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 651/12542 | Batch Loss: 1.3886 | Learning Rate: 0.000983 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 652/12542 | Batch Loss: 1.7169 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 653/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 654/12542 | Batch Loss: 1.6190 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 655/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000983 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 656/12542 | Batch Loss: 1.5296 | Learning Rate: 0.000983 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 657/12542 | Batch Loss: 1.9835 | Learning Rate: 0.000983 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 658/12542 | Batch Loss: 1.2169 | Learning Rate: 0.000983 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 659/12542 | Batch Loss: 0.4570 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 660/12542 | Batch Loss: 2.6356 | Learning Rate: 0.000982 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 661/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 662/12542 | Batch Loss: 2.0601 | Learning Rate: 0.000982 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 663/12542 | Batch Loss: 1.1450 | Learning Rate: 0.000982 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 664/12542 | Batch Loss: 1.1588 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 665/12542 | Batch Loss: 0.6527 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 666/12542 | Batch Loss: 2.0272 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 667/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 668/12542 | Batch Loss: 1.0555 | Learning Rate: 0.000982 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 669/12542 | Batch Loss: 2.5298 | Learning Rate: 0.000982 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 670/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000982 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 671/12542 | Batch Loss: 1.0398 | Learning Rate: 0.000982 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 672/12542 | Batch Loss: 1.2300 | Learning Rate: 0.000982 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 673/12542 | Batch Loss: 1.2088 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 674/12542 | Batch Loss: 0.9886 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 675/12542 | Batch Loss: 1.4645 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 676/12542 | Batch Loss: 0.7675 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 677/12542 | Batch Loss: 1.0214 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 678/12542 | Batch Loss: 0.9567 | Learning Rate: 0.000982 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 679/12542 | Batch Loss: 2.2403 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 680/12542 | Batch Loss: 0.7930 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 681/12542 | Batch Loss: 2.1600 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 682/12542 | Batch Loss: 1.6014 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 683/12542 | Batch Loss: 3.0642 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 684/12542 | Batch Loss: 1.4270 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 685/12542 | Batch Loss: 1.7040 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 686/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 687/12542 | Batch Loss: 0.9272 | Learning Rate: 0.000982 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 688/12542 | Batch Loss: 1.1537 | Learning Rate: 0.000982 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 689/12542 | Batch Loss: 1.4987 | Learning Rate: 0.000982 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 690/12542 | Batch Loss: 1.6621 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 691/12542 | Batch Loss: 2.0595 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 692/12542 | Batch Loss: 1.1306 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 693/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000982 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 694/12542 | Batch Loss: 1.5114 | Learning Rate: 0.000982 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 695/12542 | Batch Loss: 2.1274 | Learning Rate: 0.000982 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 696/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000982 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 697/12542 | Batch Loss: 1.2801 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 698/12542 | Batch Loss: 2.1109 | Learning Rate: 0.000981 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 699/12542 | Batch Loss: 1.4718 | Learning Rate: 0.000981 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 700/12542 | Batch Loss: 2.3514 | Learning Rate: 0.000981 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 701/12542 | Batch Loss: 0.8927 | Learning Rate: 0.000981 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 702/12542 | Batch Loss: 0.6534 | Learning Rate: 0.000981 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 703/12542 | Batch Loss: 1.9890 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 704/12542 | Batch Loss: 0.6164 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 705/12542 | Batch Loss: 1.6409 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 706/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 707/12542 | Batch Loss: 1.3985 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 708/12542 | Batch Loss: 1.2656 | Learning Rate: 0.000981 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 709/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000981 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 710/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000981 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 711/12542 | Batch Loss: 1.0362 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 712/12542 | Batch Loss: 2.1792 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 713/12542 | Batch Loss: 1.1231 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 714/12542 | Batch Loss: 1.1134 | Learning Rate: 0.000981 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 715/12542 | Batch Loss: 1.9266 | Learning Rate: 0.000981 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 716/12542 | Batch Loss: 0.9823 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 717/12542 | Batch Loss: 2.1188 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 718/12542 | Batch Loss: 0.9599 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 719/12542 | Batch Loss: 1.1997 | Learning Rate: 0.000981 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 720/12542 | Batch Loss: 0.5317 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 721/12542 | Batch Loss: 2.2579 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 722/12542 | Batch Loss: 1.2425 | Learning Rate: 0.000981 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 723/12542 | Batch Loss: 0.9988 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 724/12542 | Batch Loss: 1.5247 | Learning Rate: 0.000981 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 725/12542 | Batch Loss: 2.3299 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 726/12542 | Batch Loss: 1.9705 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 727/12542 | Batch Loss: 0.8924 | Learning Rate: 0.000981 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 728/12542 | Batch Loss: 1.2905 | Learning Rate: 0.000981 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 729/12542 | Batch Loss: 0.8093 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 730/12542 | Batch Loss: 1.3746 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 731/12542 | Batch Loss: 1.2216 | Learning Rate: 0.000981 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 732/12542 | Batch Loss: 3.7818 | Learning Rate: 0.000981 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 733/12542 | Batch Loss: 2.1245 | Learning Rate: 0.000981 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 734/12542 | Batch Loss: 1.1597 | Learning Rate: 0.000980 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 735/12542 | Batch Loss: 1.6771 | Learning Rate: 0.000980 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 736/12542 | Batch Loss: 2.3586 | Learning Rate: 0.000980 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 737/12542 | Batch Loss: 1.2142 | Learning Rate: 0.000980 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 738/12542 | Batch Loss: 1.8714 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 739/12542 | Batch Loss: 1.8121 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 740/12542 | Batch Loss: 0.9757 | Learning Rate: 0.000980 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 741/12542 | Batch Loss: 1.2624 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 742/12542 | Batch Loss: 1.4453 | Learning Rate: 0.000980 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 743/12542 | Batch Loss: 0.9483 | Learning Rate: 0.000980 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 744/12542 | Batch Loss: 1.3787 | Learning Rate: 0.000980 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 745/12542 | Batch Loss: 2.0893 | Learning Rate: 0.000980 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 746/12542 | Batch Loss: 2.3289 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 747/12542 | Batch Loss: 1.3570 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 748/12542 | Batch Loss: 1.7261 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 749/12542 | Batch Loss: 0.7539 | Learning Rate: 0.000980 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 750/12542 | Batch Loss: 1.4171 | Learning Rate: 0.000980 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 751/12542 | Batch Loss: 1.5576 | Learning Rate: 0.000980 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 752/12542 | Batch Loss: 1.2016 | Learning Rate: 0.000980 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 753/12542 | Batch Loss: 2.0345 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 754/12542 | Batch Loss: 0.8001 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 755/12542 | Batch Loss: 0.8748 | Learning Rate: 0.000980 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 756/12542 | Batch Loss: 0.7260 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 757/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 758/12542 | Batch Loss: 2.1834 | Learning Rate: 0.000980 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 759/12542 | Batch Loss: 1.9533 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 760/12542 | Batch Loss: 2.0713 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 761/12542 | Batch Loss: 2.7541 | Learning Rate: 0.000980 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 762/12542 | Batch Loss: 0.7834 | Learning Rate: 0.000980 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 763/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000980 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 764/12542 | Batch Loss: 1.0692 | Learning Rate: 0.000980 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 765/12542 | Batch Loss: 2.7808 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 766/12542 | Batch Loss: 1.8172 | Learning Rate: 0.000980 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 767/12542 | Batch Loss: 0.6902 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 768/12542 | Batch Loss: 1.2382 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 769/12542 | Batch Loss: 1.3027 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 770/12542 | Batch Loss: 1.0375 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 771/12542 | Batch Loss: 1.5224 | Learning Rate: 0.000980 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 772/12542 | Batch Loss: 1.0702 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 773/12542 | Batch Loss: 2.0979 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 774/12542 | Batch Loss: 2.0819 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 775/12542 | Batch Loss: 0.6341 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 776/12542 | Batch Loss: 1.7331 | Learning Rate: 0.000979 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 777/12542 | Batch Loss: 0.7449 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 778/12542 | Batch Loss: 1.5160 | Learning Rate: 0.000979 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 779/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 780/12542 | Batch Loss: 2.3400 | Learning Rate: 0.000979 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 781/12542 | Batch Loss: 1.3852 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 782/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 783/12542 | Batch Loss: 1.4881 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 784/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 785/12542 | Batch Loss: 1.2541 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 786/12542 | Batch Loss: 1.1277 | Learning Rate: 0.000979 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 787/12542 | Batch Loss: 1.1188 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 788/12542 | Batch Loss: 0.7829 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 789/12542 | Batch Loss: 1.3213 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 790/12542 | Batch Loss: 2.1979 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 791/12542 | Batch Loss: 2.0843 | Learning Rate: 0.000979 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 792/12542 | Batch Loss: 1.3593 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 793/12542 | Batch Loss: 1.8762 | Learning Rate: 0.000979 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 794/12542 | Batch Loss: 1.8185 | Learning Rate: 0.000979 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 795/12542 | Batch Loss: 1.1599 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 796/12542 | Batch Loss: 1.7212 | Learning Rate: 0.000979 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 797/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000979 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 798/12542 | Batch Loss: 1.5746 | Learning Rate: 0.000979 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 799/12542 | Batch Loss: 1.7560 | Learning Rate: 0.000979 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 800/12542 | Batch Loss: 1.1756 | Learning Rate: 0.000979 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 801/12542 | Batch Loss: 0.4621 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 802/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 803/12542 | Batch Loss: 2.8595 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 804/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 805/12542 | Batch Loss: 1.3437 | Learning Rate: 0.000979 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 806/12542 | Batch Loss: 1.4536 | Learning Rate: 0.000979 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 807/12542 | Batch Loss: 2.1459 | Learning Rate: 0.000979 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 808/12542 | Batch Loss: 1.6873 | Learning Rate: 0.000979 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 809/12542 | Batch Loss: 1.6051 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 810/12542 | Batch Loss: 1.5600 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 811/12542 | Batch Loss: 1.9537 | Learning Rate: 0.000978 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 812/12542 | Batch Loss: 1.0930 | Learning Rate: 0.000978 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 813/12542 | Batch Loss: 1.5204 | Learning Rate: 0.000978 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 814/12542 | Batch Loss: 1.4435 | Learning Rate: 0.000978 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 815/12542 | Batch Loss: 0.6619 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 816/12542 | Batch Loss: 1.7987 | Learning Rate: 0.000978 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 817/12542 | Batch Loss: 2.2290 | Learning Rate: 0.000978 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 818/12542 | Batch Loss: 4.0524 | Learning Rate: 0.000978 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 819/12542 | Batch Loss: 0.7476 | Learning Rate: 0.000978 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 820/12542 | Batch Loss: 0.7573 | Learning Rate: 0.000978 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 821/12542 | Batch Loss: 3.1046 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 822/12542 | Batch Loss: 0.9400 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 823/12542 | Batch Loss: 2.5067 | Learning Rate: 0.000978 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 824/12542 | Batch Loss: 0.8127 | Learning Rate: 0.000978 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 825/12542 | Batch Loss: 1.3919 | Learning Rate: 0.000978 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 826/12542 | Batch Loss: 2.4704 | Learning Rate: 0.000978 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 827/12542 | Batch Loss: 1.4978 | Learning Rate: 0.000978 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 828/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000978 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 829/12542 | Batch Loss: 1.1924 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 830/12542 | Batch Loss: 0.9463 | Learning Rate: 0.000978 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 831/12542 | Batch Loss: 1.1794 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 832/12542 | Batch Loss: 1.7507 | Learning Rate: 0.000978 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 833/12542 | Batch Loss: 0.9867 | Learning Rate: 0.000978 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 834/12542 | Batch Loss: 1.5965 | Learning Rate: 0.000978 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 835/12542 | Batch Loss: 1.8277 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 836/12542 | Batch Loss: 1.6732 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 837/12542 | Batch Loss: 1.1810 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 838/12542 | Batch Loss: 2.3703 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 839/12542 | Batch Loss: 1.0649 | Learning Rate: 0.000978 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 840/12542 | Batch Loss: 1.4268 | Learning Rate: 0.000978 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 841/12542 | Batch Loss: 1.2288 | Learning Rate: 0.000978 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 842/12542 | Batch Loss: 1.3071 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 843/12542 | Batch Loss: 2.3204 | Learning Rate: 0.000978 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 844/12542 | Batch Loss: 2.2849 | Learning Rate: 0.000978 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 845/12542 | Batch Loss: 1.5916 | Learning Rate: 0.000978 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 846/12542 | Batch Loss: 1.2189 | Learning Rate: 0.000978 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 847/12542 | Batch Loss: 1.4350 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 848/12542 | Batch Loss: 1.4646 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 849/12542 | Batch Loss: 1.7028 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 850/12542 | Batch Loss: 2.8052 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 851/12542 | Batch Loss: 0.9134 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 852/12542 | Batch Loss: 1.3820 | Learning Rate: 0.000977 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 853/12542 | Batch Loss: 1.2247 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 854/12542 | Batch Loss: 0.9718 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 855/12542 | Batch Loss: 1.3595 | Learning Rate: 0.000977 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 856/12542 | Batch Loss: 1.7028 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 857/12542 | Batch Loss: 1.1211 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 858/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 859/12542 | Batch Loss: 0.8192 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 860/12542 | Batch Loss: 1.2421 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 861/12542 | Batch Loss: 1.5031 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 862/12542 | Batch Loss: 1.4221 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 863/12542 | Batch Loss: 1.6826 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 864/12542 | Batch Loss: 1.1995 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 865/12542 | Batch Loss: 2.2655 | Learning Rate: 0.000977 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 866/12542 | Batch Loss: 1.9549 | Learning Rate: 0.000977 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 867/12542 | Batch Loss: 2.1503 | Learning Rate: 0.000977 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 868/12542 | Batch Loss: 3.7212 | Learning Rate: 0.000977 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 869/12542 | Batch Loss: 1.1482 | Learning Rate: 0.000977 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 870/12542 | Batch Loss: 0.9376 | Learning Rate: 0.000977 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 871/12542 | Batch Loss: 1.4073 | Learning Rate: 0.000977 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 872/12542 | Batch Loss: 0.9031 | Learning Rate: 0.000977 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 873/12542 | Batch Loss: 0.7309 | Learning Rate: 0.000977 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 874/12542 | Batch Loss: 2.1977 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 875/12542 | Batch Loss: 0.7452 | Learning Rate: 0.000977 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 876/12542 | Batch Loss: 1.1908 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 877/12542 | Batch Loss: 1.7865 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 878/12542 | Batch Loss: 1.4488 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 879/12542 | Batch Loss: 0.4904 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 880/12542 | Batch Loss: 1.2965 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 881/12542 | Batch Loss: 1.5503 | Learning Rate: 0.000977 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 882/12542 | Batch Loss: 2.1488 | Learning Rate: 0.000977 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 883/12542 | Batch Loss: 1.1185 | Learning Rate: 0.000977 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 884/12542 | Batch Loss: 1.6232 | Learning Rate: 0.000977 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 885/12542 | Batch Loss: 1.7390 | Learning Rate: 0.000976 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 886/12542 | Batch Loss: 1.6136 | Learning Rate: 0.000976 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 887/12542 | Batch Loss: 1.1088 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 888/12542 | Batch Loss: 3.2732 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 889/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 890/12542 | Batch Loss: 2.2336 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 891/12542 | Batch Loss: 1.8540 | Learning Rate: 0.000976 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 892/12542 | Batch Loss: 1.1233 | Learning Rate: 0.000976 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 893/12542 | Batch Loss: 2.0606 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 894/12542 | Batch Loss: 0.5773 | Learning Rate: 0.000976 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 895/12542 | Batch Loss: 0.7442 | Learning Rate: 0.000976 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 896/12542 | Batch Loss: 1.8705 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 897/12542 | Batch Loss: 1.1769 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 898/12542 | Batch Loss: 3.2293 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 899/12542 | Batch Loss: 0.6739 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 900/12542 | Batch Loss: 1.1715 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 901/12542 | Batch Loss: 1.1573 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 902/12542 | Batch Loss: 1.6569 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 903/12542 | Batch Loss: 1.5385 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 904/12542 | Batch Loss: 1.2418 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 905/12542 | Batch Loss: 0.9002 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 906/12542 | Batch Loss: 2.1837 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 907/12542 | Batch Loss: 2.0315 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 908/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 909/12542 | Batch Loss: 1.8762 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 910/12542 | Batch Loss: 1.4862 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 911/12542 | Batch Loss: 0.6997 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 912/12542 | Batch Loss: 1.2091 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 913/12542 | Batch Loss: 1.9091 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 914/12542 | Batch Loss: 1.2603 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 915/12542 | Batch Loss: 2.1655 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 916/12542 | Batch Loss: 1.8060 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 917/12542 | Batch Loss: 2.1043 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 918/12542 | Batch Loss: 1.6197 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 919/12542 | Batch Loss: 0.8669 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 920/12542 | Batch Loss: 1.2041 | Learning Rate: 0.000976 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 921/12542 | Batch Loss: 0.9457 | Learning Rate: 0.000976 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 922/12542 | Batch Loss: 0.6518 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 923/12542 | Batch Loss: 1.9164 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 924/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000975 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 925/12542 | Batch Loss: 0.7265 | Learning Rate: 0.000975 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 926/12542 | Batch Loss: 1.2895 | Learning Rate: 0.000975 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 927/12542 | Batch Loss: 0.7215 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 928/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 929/12542 | Batch Loss: 1.4841 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 930/12542 | Batch Loss: 1.2999 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 931/12542 | Batch Loss: 1.7302 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 932/12542 | Batch Loss: 1.4536 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 933/12542 | Batch Loss: 0.9500 | Learning Rate: 0.000975 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 934/12542 | Batch Loss: 1.1996 | Learning Rate: 0.000975 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 935/12542 | Batch Loss: 1.5458 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 936/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 937/12542 | Batch Loss: 2.4515 | Learning Rate: 0.000975 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 938/12542 | Batch Loss: 1.0451 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 939/12542 | Batch Loss: 2.0238 | Learning Rate: 0.000975 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 940/12542 | Batch Loss: 0.5997 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 941/12542 | Batch Loss: 0.9261 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 942/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000975 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 943/12542 | Batch Loss: 0.7521 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 944/12542 | Batch Loss: 1.5910 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 945/12542 | Batch Loss: 1.8538 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 946/12542 | Batch Loss: 1.1958 | Learning Rate: 0.000975 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 947/12542 | Batch Loss: 1.7935 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 948/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000975 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 949/12542 | Batch Loss: 1.0943 | Learning Rate: 0.000975 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 950/12542 | Batch Loss: 1.3875 | Learning Rate: 0.000975 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 951/12542 | Batch Loss: 0.4463 | Learning Rate: 0.000975 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 952/12542 | Batch Loss: 2.1455 | Learning Rate: 0.000975 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 953/12542 | Batch Loss: 1.3754 | Learning Rate: 0.000975 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 954/12542 | Batch Loss: 1.6936 | Learning Rate: 0.000975 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 955/12542 | Batch Loss: 2.5709 | Learning Rate: 0.000975 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 956/12542 | Batch Loss: 2.0631 | Learning Rate: 0.000975 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 957/12542 | Batch Loss: 2.7728 | Learning Rate: 0.000975 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 958/12542 | Batch Loss: 2.1349 | Learning Rate: 0.000975 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 959/12542 | Batch Loss: 1.5427 | Learning Rate: 0.000975 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 960/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000974 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 961/12542 | Batch Loss: 1.9304 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 962/12542 | Batch Loss: 0.8269 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 963/12542 | Batch Loss: 1.2334 | Learning Rate: 0.000974 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 964/12542 | Batch Loss: 1.9739 | Learning Rate: 0.000974 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 965/12542 | Batch Loss: 1.2037 | Learning Rate: 0.000974 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 966/12542 | Batch Loss: 0.7389 | Learning Rate: 0.000974 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 967/12542 | Batch Loss: 0.4298 | Learning Rate: 0.000974 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 968/12542 | Batch Loss: 0.9923 | Learning Rate: 0.000974 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 969/12542 | Batch Loss: 1.0607 | Learning Rate: 0.000974 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 970/12542 | Batch Loss: 1.7341 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 971/12542 | Batch Loss: 1.3229 | Learning Rate: 0.000974 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 972/12542 | Batch Loss: 1.9482 | Learning Rate: 0.000974 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 973/12542 | Batch Loss: 0.9692 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 974/12542 | Batch Loss: 4.0674 | Learning Rate: 0.000974 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 975/12542 | Batch Loss: 1.4759 | Learning Rate: 0.000974 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 976/12542 | Batch Loss: 0.8938 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 977/12542 | Batch Loss: 1.3910 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 978/12542 | Batch Loss: 1.4095 | Learning Rate: 0.000974 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 979/12542 | Batch Loss: 1.7738 | Learning Rate: 0.000974 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 980/12542 | Batch Loss: 2.1592 | Learning Rate: 0.000974 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 981/12542 | Batch Loss: 0.5531 | Learning Rate: 0.000974 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 982/12542 | Batch Loss: 0.8604 | Learning Rate: 0.000974 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 983/12542 | Batch Loss: 2.5801 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 984/12542 | Batch Loss: 0.9750 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 985/12542 | Batch Loss: 1.5543 | Learning Rate: 0.000974 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 986/12542 | Batch Loss: 0.7732 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 987/12542 | Batch Loss: 1.8273 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 988/12542 | Batch Loss: 1.2071 | Learning Rate: 0.000974 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 989/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000974 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 990/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 991/12542 | Batch Loss: 1.6701 | Learning Rate: 0.000974 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 992/12542 | Batch Loss: 1.0621 | Learning Rate: 0.000974 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 993/12542 | Batch Loss: 1.1135 | Learning Rate: 0.000974 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 994/12542 | Batch Loss: 1.4433 | Learning Rate: 0.000974 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 995/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000974 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 996/12542 | Batch Loss: 1.7535 | Learning Rate: 0.000974 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 997/12542 | Batch Loss: 1.7510 | Learning Rate: 0.000974 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 998/12542 | Batch Loss: 1.4159 | Learning Rate: 0.000973 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 999/12542 | Batch Loss: 1.6933 | Learning Rate: 0.000973 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1000/12542 | Batch Loss: 2.1650 | Learning Rate: 0.000973 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1001/12542 | Batch Loss: 2.5762 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1002/12542 | Batch Loss: 1.6503 | Learning Rate: 0.000973 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1003/12542 | Batch Loss: 2.7944 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1004/12542 | Batch Loss: 1.9666 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1005/12542 | Batch Loss: 1.8941 | Learning Rate: 0.000973 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1006/12542 | Batch Loss: 0.9635 | Learning Rate: 0.000973 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1007/12542 | Batch Loss: 2.7218 | Learning Rate: 0.000973 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1008/12542 | Batch Loss: 1.0620 | Learning Rate: 0.000973 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1009/12542 | Batch Loss: 2.0008 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1010/12542 | Batch Loss: 2.3861 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1011/12542 | Batch Loss: 1.1148 | Learning Rate: 0.000973 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1012/12542 | Batch Loss: 1.8443 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1013/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000973 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1014/12542 | Batch Loss: 3.5444 | Learning Rate: 0.000973 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1015/12542 | Batch Loss: 1.0387 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1016/12542 | Batch Loss: 1.2633 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1017/12542 | Batch Loss: 1.0934 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1018/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1019/12542 | Batch Loss: 1.8761 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1020/12542 | Batch Loss: 0.9918 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1021/12542 | Batch Loss: 1.3361 | Learning Rate: 0.000973 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1022/12542 | Batch Loss: 1.6044 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1023/12542 | Batch Loss: 1.6387 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1024/12542 | Batch Loss: 1.6092 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1025/12542 | Batch Loss: 1.5685 | Learning Rate: 0.000973 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1026/12542 | Batch Loss: 0.6983 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1027/12542 | Batch Loss: 1.3812 | Learning Rate: 0.000973 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1028/12542 | Batch Loss: 0.8501 | Learning Rate: 0.000973 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1029/12542 | Batch Loss: 0.5734 | Learning Rate: 0.000973 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1030/12542 | Batch Loss: 2.7825 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1031/12542 | Batch Loss: 2.2913 | Learning Rate: 0.000973 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1032/12542 | Batch Loss: 0.6518 | Learning Rate: 0.000973 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1033/12542 | Batch Loss: 1.4505 | Learning Rate: 0.000973 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1034/12542 | Batch Loss: 0.6821 | Learning Rate: 0.000973 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1035/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000972 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1036/12542 | Batch Loss: 1.8604 | Learning Rate: 0.000972 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1037/12542 | Batch Loss: 2.0150 | Learning Rate: 0.000972 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1038/12542 | Batch Loss: 1.4652 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1039/12542 | Batch Loss: 1.5005 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1040/12542 | Batch Loss: 1.9732 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1041/12542 | Batch Loss: 1.0832 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1042/12542 | Batch Loss: 3.2217 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1043/12542 | Batch Loss: 1.7122 | Learning Rate: 0.000972 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1044/12542 | Batch Loss: 0.8869 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1045/12542 | Batch Loss: 1.8249 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1046/12542 | Batch Loss: 0.9471 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1047/12542 | Batch Loss: 2.4931 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1048/12542 | Batch Loss: 3.2682 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1049/12542 | Batch Loss: 1.3103 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1050/12542 | Batch Loss: 1.2308 | Learning Rate: 0.000972 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1051/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000972 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1052/12542 | Batch Loss: 1.2821 | Learning Rate: 0.000972 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1053/12542 | Batch Loss: 0.8029 | Learning Rate: 0.000972 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1054/12542 | Batch Loss: 1.6821 | Learning Rate: 0.000972 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1055/12542 | Batch Loss: 2.1055 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1056/12542 | Batch Loss: 1.8886 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1057/12542 | Batch Loss: 0.7146 | Learning Rate: 0.000972 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1058/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1059/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000972 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1060/12542 | Batch Loss: 1.8415 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1061/12542 | Batch Loss: 1.7740 | Learning Rate: 0.000972 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1062/12542 | Batch Loss: 1.7944 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1063/12542 | Batch Loss: 1.4736 | Learning Rate: 0.000972 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1064/12542 | Batch Loss: 0.9475 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1065/12542 | Batch Loss: 0.7438 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1066/12542 | Batch Loss: 3.0213 | Learning Rate: 0.000972 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1067/12542 | Batch Loss: 0.6438 | Learning Rate: 0.000972 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1068/12542 | Batch Loss: 2.0481 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1069/12542 | Batch Loss: 0.9454 | Learning Rate: 0.000972 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1070/12542 | Batch Loss: 0.8139 | Learning Rate: 0.000972 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1071/12542 | Batch Loss: 0.8643 | Learning Rate: 0.000972 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1072/12542 | Batch Loss: 1.9779 | Learning Rate: 0.000972 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1073/12542 | Batch Loss: 0.9196 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1074/12542 | Batch Loss: 1.1153 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1075/12542 | Batch Loss: 1.8719 | Learning Rate: 0.000971 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1076/12542 | Batch Loss: 1.7160 | Learning Rate: 0.000971 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1077/12542 | Batch Loss: 0.9949 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1078/12542 | Batch Loss: 2.1783 | Learning Rate: 0.000971 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1079/12542 | Batch Loss: 2.1181 | Learning Rate: 0.000971 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1080/12542 | Batch Loss: 1.9099 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1081/12542 | Batch Loss: 2.2537 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1082/12542 | Batch Loss: 1.6539 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1083/12542 | Batch Loss: 1.3456 | Learning Rate: 0.000971 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1084/12542 | Batch Loss: 2.5701 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1085/12542 | Batch Loss: 1.3864 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1086/12542 | Batch Loss: 0.5107 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1087/12542 | Batch Loss: 1.2470 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1088/12542 | Batch Loss: 0.4589 | Learning Rate: 0.000971 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1089/12542 | Batch Loss: 2.5119 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1090/12542 | Batch Loss: 1.0136 | Learning Rate: 0.000971 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1091/12542 | Batch Loss: 1.2709 | Learning Rate: 0.000971 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1092/12542 | Batch Loss: 1.9448 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1093/12542 | Batch Loss: 1.4002 | Learning Rate: 0.000971 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1094/12542 | Batch Loss: 1.0590 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1095/12542 | Batch Loss: 1.4553 | Learning Rate: 0.000971 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1096/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000971 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1097/12542 | Batch Loss: 1.3923 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1098/12542 | Batch Loss: 2.2637 | Learning Rate: 0.000971 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1099/12542 | Batch Loss: 1.1314 | Learning Rate: 0.000971 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1100/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000971 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1101/12542 | Batch Loss: 1.6017 | Learning Rate: 0.000971 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1102/12542 | Batch Loss: 1.5217 | Learning Rate: 0.000971 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1103/12542 | Batch Loss: 1.5021 | Learning Rate: 0.000971 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1104/12542 | Batch Loss: 1.4960 | Learning Rate: 0.000971 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1105/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1106/12542 | Batch Loss: 0.7587 | Learning Rate: 0.000971 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1107/12542 | Batch Loss: 2.2573 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1108/12542 | Batch Loss: 0.9111 | Learning Rate: 0.000971 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1109/12542 | Batch Loss: 1.0545 | Learning Rate: 0.000971 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1110/12542 | Batch Loss: 1.2449 | Learning Rate: 0.000970 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1111/12542 | Batch Loss: 1.6246 | Learning Rate: 0.000970 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1112/12542 | Batch Loss: 1.2980 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1113/12542 | Batch Loss: 1.0688 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1114/12542 | Batch Loss: 1.5986 | Learning Rate: 0.000970 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1115/12542 | Batch Loss: 1.5922 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1116/12542 | Batch Loss: 1.1326 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1117/12542 | Batch Loss: 1.6287 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1118/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1119/12542 | Batch Loss: 1.3005 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1120/12542 | Batch Loss: 2.4950 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1121/12542 | Batch Loss: 0.7388 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1122/12542 | Batch Loss: 1.1636 | Learning Rate: 0.000970 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1123/12542 | Batch Loss: 2.4798 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1124/12542 | Batch Loss: 0.7277 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1125/12542 | Batch Loss: 1.8844 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1126/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000970 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1127/12542 | Batch Loss: 1.3148 | Learning Rate: 0.000970 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1128/12542 | Batch Loss: 1.1116 | Learning Rate: 0.000970 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1129/12542 | Batch Loss: 0.7241 | Learning Rate: 0.000970 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1130/12542 | Batch Loss: 1.4609 | Learning Rate: 0.000970 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1131/12542 | Batch Loss: 1.0483 | Learning Rate: 0.000970 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1132/12542 | Batch Loss: 2.1050 | Learning Rate: 0.000970 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1133/12542 | Batch Loss: 1.3013 | Learning Rate: 0.000970 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1134/12542 | Batch Loss: 1.9089 | Learning Rate: 0.000970 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1135/12542 | Batch Loss: 0.6339 | Learning Rate: 0.000970 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1136/12542 | Batch Loss: 1.2735 | Learning Rate: 0.000970 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1137/12542 | Batch Loss: 1.9310 | Learning Rate: 0.000970 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1138/12542 | Batch Loss: 1.8896 | Learning Rate: 0.000970 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1139/12542 | Batch Loss: 1.6259 | Learning Rate: 0.000970 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1140/12542 | Batch Loss: 1.9325 | Learning Rate: 0.000970 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1141/12542 | Batch Loss: 0.7086 | Learning Rate: 0.000970 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1142/12542 | Batch Loss: 0.8854 | Learning Rate: 0.000970 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1143/12542 | Batch Loss: 0.9149 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1144/12542 | Batch Loss: 1.7862 | Learning Rate: 0.000970 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1145/12542 | Batch Loss: 1.2871 | Learning Rate: 0.000970 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1146/12542 | Batch Loss: 1.2644 | Learning Rate: 0.000970 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1147/12542 | Batch Loss: 1.8013 | Learning Rate: 0.000970 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1148/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000969 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1149/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1150/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1151/12542 | Batch Loss: 1.2652 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1152/12542 | Batch Loss: 1.6721 | Learning Rate: 0.000969 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1153/12542 | Batch Loss: 1.0063 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1154/12542 | Batch Loss: 1.2057 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1155/12542 | Batch Loss: 1.5370 | Learning Rate: 0.000969 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1156/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000969 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1157/12542 | Batch Loss: 2.4090 | Learning Rate: 0.000969 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1158/12542 | Batch Loss: 1.8758 | Learning Rate: 0.000969 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1159/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000969 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1160/12542 | Batch Loss: 1.8380 | Learning Rate: 0.000969 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1161/12542 | Batch Loss: 0.9604 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1162/12542 | Batch Loss: 1.0801 | Learning Rate: 0.000969 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1163/12542 | Batch Loss: 1.9853 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1164/12542 | Batch Loss: 2.7742 | Learning Rate: 0.000969 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1165/12542 | Batch Loss: 1.2924 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1166/12542 | Batch Loss: 1.1187 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1167/12542 | Batch Loss: 2.1079 | Learning Rate: 0.000969 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1168/12542 | Batch Loss: 1.1192 | Learning Rate: 0.000969 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1169/12542 | Batch Loss: 1.3483 | Learning Rate: 0.000969 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1170/12542 | Batch Loss: 0.9580 | Learning Rate: 0.000969 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1171/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000969 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1172/12542 | Batch Loss: 2.1040 | Learning Rate: 0.000969 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1173/12542 | Batch Loss: 1.1588 | Learning Rate: 0.000969 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1174/12542 | Batch Loss: 1.6016 | Learning Rate: 0.000969 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1175/12542 | Batch Loss: 2.4475 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1176/12542 | Batch Loss: 0.9663 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1177/12542 | Batch Loss: 0.4928 | Learning Rate: 0.000969 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1178/12542 | Batch Loss: 2.2116 | Learning Rate: 0.000969 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1179/12542 | Batch Loss: 1.1645 | Learning Rate: 0.000969 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1180/12542 | Batch Loss: 2.1369 | Learning Rate: 0.000969 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1181/12542 | Batch Loss: 2.8291 | Learning Rate: 0.000969 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1182/12542 | Batch Loss: 1.4230 | Learning Rate: 0.000969 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1183/12542 | Batch Loss: 1.6481 | Learning Rate: 0.000969 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1184/12542 | Batch Loss: 1.3426 | Learning Rate: 0.000969 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1185/12542 | Batch Loss: 1.5262 | Learning Rate: 0.000969 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1186/12542 | Batch Loss: 0.9012 | Learning Rate: 0.000968 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1187/12542 | Batch Loss: 2.2594 | Learning Rate: 0.000968 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1188/12542 | Batch Loss: 2.1097 | Learning Rate: 0.000968 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1189/12542 | Batch Loss: 0.9492 | Learning Rate: 0.000968 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1190/12542 | Batch Loss: 1.1570 | Learning Rate: 0.000968 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1191/12542 | Batch Loss: 2.3180 | Learning Rate: 0.000968 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1192/12542 | Batch Loss: 1.6894 | Learning Rate: 0.000968 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1193/12542 | Batch Loss: 0.9569 | Learning Rate: 0.000968 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1194/12542 | Batch Loss: 0.7106 | Learning Rate: 0.000968 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1195/12542 | Batch Loss: 1.5954 | Learning Rate: 0.000968 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1196/12542 | Batch Loss: 1.2027 | Learning Rate: 0.000968 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1197/12542 | Batch Loss: 2.5435 | Learning Rate: 0.000968 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1198/12542 | Batch Loss: 1.6733 | Learning Rate: 0.000968 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1199/12542 | Batch Loss: 1.4863 | Learning Rate: 0.000968 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1200/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000968 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1201/12542 | Batch Loss: 2.3348 | Learning Rate: 0.000968 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1202/12542 | Batch Loss: 0.9560 | Learning Rate: 0.000968 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1203/12542 | Batch Loss: 0.9601 | Learning Rate: 0.000968 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1204/12542 | Batch Loss: 1.3738 | Learning Rate: 0.000968 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1205/12542 | Batch Loss: 1.5932 | Learning Rate: 0.000968 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1206/12542 | Batch Loss: 1.3181 | Learning Rate: 0.000968 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1207/12542 | Batch Loss: 0.7639 | Learning Rate: 0.000968 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1208/12542 | Batch Loss: 1.6396 | Learning Rate: 0.000968 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1209/12542 | Batch Loss: 1.3031 | Learning Rate: 0.000968 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1210/12542 | Batch Loss: 1.7204 | Learning Rate: 0.000968 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1211/12542 | Batch Loss: 2.0250 | Learning Rate: 0.000968 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1212/12542 | Batch Loss: 1.4461 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1213/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1214/12542 | Batch Loss: 1.4954 | Learning Rate: 0.000968 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1215/12542 | Batch Loss: 2.0798 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1216/12542 | Batch Loss: 1.4790 | Learning Rate: 0.000968 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1217/12542 | Batch Loss: 1.1684 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1218/12542 | Batch Loss: 1.4451 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1219/12542 | Batch Loss: 1.1319 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1220/12542 | Batch Loss: 2.6054 | Learning Rate: 0.000968 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1221/12542 | Batch Loss: 2.1542 | Learning Rate: 0.000968 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1222/12542 | Batch Loss: 1.0208 | Learning Rate: 0.000968 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1223/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000967 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1224/12542 | Batch Loss: 1.1227 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1225/12542 | Batch Loss: 1.5354 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1226/12542 | Batch Loss: 1.7985 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1227/12542 | Batch Loss: 0.5979 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1228/12542 | Batch Loss: 0.7537 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1229/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1230/12542 | Batch Loss: 1.0492 | Learning Rate: 0.000967 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1231/12542 | Batch Loss: 1.8999 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1232/12542 | Batch Loss: 0.7480 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1233/12542 | Batch Loss: 2.4897 | Learning Rate: 0.000967 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1234/12542 | Batch Loss: 0.8264 | Learning Rate: 0.000967 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1235/12542 | Batch Loss: 1.2361 | Learning Rate: 0.000967 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1236/12542 | Batch Loss: 1.3006 | Learning Rate: 0.000967 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1237/12542 | Batch Loss: 1.6166 | Learning Rate: 0.000967 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1238/12542 | Batch Loss: 1.0439 | Learning Rate: 0.000967 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1239/12542 | Batch Loss: 1.0239 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1240/12542 | Batch Loss: 1.5369 | Learning Rate: 0.000967 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1241/12542 | Batch Loss: 1.4690 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1242/12542 | Batch Loss: 1.0186 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1243/12542 | Batch Loss: 0.8389 | Learning Rate: 0.000967 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1244/12542 | Batch Loss: 2.8070 | Learning Rate: 0.000967 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1245/12542 | Batch Loss: 0.5897 | Learning Rate: 0.000967 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1246/12542 | Batch Loss: 2.3983 | Learning Rate: 0.000967 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1247/12542 | Batch Loss: 1.7507 | Learning Rate: 0.000967 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1248/12542 | Batch Loss: 0.7554 | Learning Rate: 0.000967 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1249/12542 | Batch Loss: 1.5710 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1250/12542 | Batch Loss: 1.3621 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1251/12542 | Batch Loss: 2.3847 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1252/12542 | Batch Loss: 2.2036 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1253/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000967 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1254/12542 | Batch Loss: 0.7830 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1255/12542 | Batch Loss: 0.9794 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1256/12542 | Batch Loss: 1.9355 | Learning Rate: 0.000967 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1257/12542 | Batch Loss: 1.2662 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1258/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1259/12542 | Batch Loss: 1.9726 | Learning Rate: 0.000967 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1260/12542 | Batch Loss: 1.1226 | Learning Rate: 0.000967 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1261/12542 | Batch Loss: 1.6942 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1262/12542 | Batch Loss: 1.0216 | Learning Rate: 0.000966 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1263/12542 | Batch Loss: 1.1681 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1264/12542 | Batch Loss: 1.2195 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1265/12542 | Batch Loss: 0.6380 | Learning Rate: 0.000966 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1266/12542 | Batch Loss: 0.9571 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1267/12542 | Batch Loss: 1.3258 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1268/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1269/12542 | Batch Loss: 1.5916 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1270/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1271/12542 | Batch Loss: 1.5978 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1272/12542 | Batch Loss: 0.8492 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1273/12542 | Batch Loss: 0.8106 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1274/12542 | Batch Loss: 1.4270 | Learning Rate: 0.000966 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1275/12542 | Batch Loss: 0.6837 | Learning Rate: 0.000966 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1276/12542 | Batch Loss: 0.6875 | Learning Rate: 0.000966 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1277/12542 | Batch Loss: 0.8195 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1278/12542 | Batch Loss: 2.4688 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1279/12542 | Batch Loss: 1.0065 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1280/12542 | Batch Loss: 0.6310 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1281/12542 | Batch Loss: 1.2068 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1282/12542 | Batch Loss: 1.5540 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1283/12542 | Batch Loss: 1.6310 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1284/12542 | Batch Loss: 1.6166 | Learning Rate: 0.000966 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1285/12542 | Batch Loss: 0.7939 | Learning Rate: 0.000966 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1286/12542 | Batch Loss: 1.2419 | Learning Rate: 0.000966 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1287/12542 | Batch Loss: 1.5223 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1288/12542 | Batch Loss: 0.6915 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1289/12542 | Batch Loss: 1.2497 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1290/12542 | Batch Loss: 0.6901 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1291/12542 | Batch Loss: 1.2608 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1292/12542 | Batch Loss: 0.9543 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1293/12542 | Batch Loss: 1.7131 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1294/12542 | Batch Loss: 1.4827 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1295/12542 | Batch Loss: 1.4884 | Learning Rate: 0.000966 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1296/12542 | Batch Loss: 0.6150 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1297/12542 | Batch Loss: 1.1841 | Learning Rate: 0.000966 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1298/12542 | Batch Loss: 1.1519 | Learning Rate: 0.000966 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1299/12542 | Batch Loss: 1.0499 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1300/12542 | Batch Loss: 1.4307 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1301/12542 | Batch Loss: 0.5346 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1302/12542 | Batch Loss: 0.6955 | Learning Rate: 0.000965 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1303/12542 | Batch Loss: 1.3079 | Learning Rate: 0.000965 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1304/12542 | Batch Loss: 0.5934 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1305/12542 | Batch Loss: 1.0271 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1306/12542 | Batch Loss: 1.4270 | Learning Rate: 0.000965 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1307/12542 | Batch Loss: 0.6088 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1308/12542 | Batch Loss: 1.7093 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1309/12542 | Batch Loss: 2.2300 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1310/12542 | Batch Loss: 2.0937 | Learning Rate: 0.000965 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1311/12542 | Batch Loss: 2.3617 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1312/12542 | Batch Loss: 1.1884 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1313/12542 | Batch Loss: 1.9053 | Learning Rate: 0.000965 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1314/12542 | Batch Loss: 1.1614 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1315/12542 | Batch Loss: 1.7828 | Learning Rate: 0.000965 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1316/12542 | Batch Loss: 1.7498 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1317/12542 | Batch Loss: 1.7276 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1318/12542 | Batch Loss: 1.6646 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1319/12542 | Batch Loss: 0.4952 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1320/12542 | Batch Loss: 1.4261 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1321/12542 | Batch Loss: 1.3377 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1322/12542 | Batch Loss: 1.3554 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1323/12542 | Batch Loss: 2.1343 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1324/12542 | Batch Loss: 1.7421 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1325/12542 | Batch Loss: 1.6106 | Learning Rate: 0.000965 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1326/12542 | Batch Loss: 1.3521 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1327/12542 | Batch Loss: 1.0654 | Learning Rate: 0.000965 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1328/12542 | Batch Loss: 2.4998 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1329/12542 | Batch Loss: 1.0283 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1330/12542 | Batch Loss: 1.0228 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1331/12542 | Batch Loss: 1.1126 | Learning Rate: 0.000965 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1332/12542 | Batch Loss: 2.4428 | Learning Rate: 0.000965 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1333/12542 | Batch Loss: 1.4983 | Learning Rate: 0.000965 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1334/12542 | Batch Loss: 0.9988 | Learning Rate: 0.000965 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1335/12542 | Batch Loss: 0.7512 | Learning Rate: 0.000965 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1336/12542 | Batch Loss: 1.1111 | Learning Rate: 0.000964 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1337/12542 | Batch Loss: 1.2254 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1338/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000964 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1339/12542 | Batch Loss: 1.6098 | Learning Rate: 0.000964 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1340/12542 | Batch Loss: 2.3656 | Learning Rate: 0.000964 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1341/12542 | Batch Loss: 1.6868 | Learning Rate: 0.000964 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1342/12542 | Batch Loss: 0.8821 | Learning Rate: 0.000964 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1343/12542 | Batch Loss: 0.9359 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1344/12542 | Batch Loss: 0.5835 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1345/12542 | Batch Loss: 0.7325 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1346/12542 | Batch Loss: 2.1849 | Learning Rate: 0.000964 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1347/12542 | Batch Loss: 1.9638 | Learning Rate: 0.000964 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1348/12542 | Batch Loss: 1.5192 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1349/12542 | Batch Loss: 1.4979 | Learning Rate: 0.000964 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 1350/12542 | Batch Loss: 1.7670 | Learning Rate: 0.000964 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1351/12542 | Batch Loss: 0.9387 | Learning Rate: 0.000964 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1352/12542 | Batch Loss: 0.4311 | Learning Rate: 0.000964 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1353/12542 | Batch Loss: 1.2630 | Learning Rate: 0.000964 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1354/12542 | Batch Loss: 0.9980 | Learning Rate: 0.000964 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1355/12542 | Batch Loss: 1.5408 | Learning Rate: 0.000964 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1356/12542 | Batch Loss: 1.0243 | Learning Rate: 0.000964 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1357/12542 | Batch Loss: 1.7446 | Learning Rate: 0.000964 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1358/12542 | Batch Loss: 1.6229 | Learning Rate: 0.000964 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1359/12542 | Batch Loss: 2.2893 | Learning Rate: 0.000964 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1360/12542 | Batch Loss: 2.5743 | Learning Rate: 0.000964 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1361/12542 | Batch Loss: 1.2680 | Learning Rate: 0.000964 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1362/12542 | Batch Loss: 1.3010 | Learning Rate: 0.000964 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1363/12542 | Batch Loss: 1.6191 | Learning Rate: 0.000964 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1364/12542 | Batch Loss: 2.3437 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1365/12542 | Batch Loss: 0.6597 | Learning Rate: 0.000964 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1366/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1367/12542 | Batch Loss: 0.8076 | Learning Rate: 0.000964 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1368/12542 | Batch Loss: 1.3387 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1369/12542 | Batch Loss: 0.8369 | Learning Rate: 0.000964 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1370/12542 | Batch Loss: 3.6507 | Learning Rate: 0.000964 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1371/12542 | Batch Loss: 1.4990 | Learning Rate: 0.000964 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1372/12542 | Batch Loss: 1.8203 | Learning Rate: 0.000964 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1373/12542 | Batch Loss: 0.9839 | Learning Rate: 0.000964 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1374/12542 | Batch Loss: 1.0951 | Learning Rate: 0.000963 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1375/12542 | Batch Loss: 1.4318 | Learning Rate: 0.000963 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1376/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000963 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1377/12542 | Batch Loss: 0.8591 | Learning Rate: 0.000963 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1378/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1379/12542 | Batch Loss: 0.6700 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1380/12542 | Batch Loss: 1.0099 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1381/12542 | Batch Loss: 1.9418 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1382/12542 | Batch Loss: 0.7924 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1383/12542 | Batch Loss: 1.6134 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1384/12542 | Batch Loss: 1.1551 | Learning Rate: 0.000963 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1385/12542 | Batch Loss: 1.9907 | Learning Rate: 0.000963 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1386/12542 | Batch Loss: 0.7967 | Learning Rate: 0.000963 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1387/12542 | Batch Loss: 1.0248 | Learning Rate: 0.000963 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1388/12542 | Batch Loss: 2.2213 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1389/12542 | Batch Loss: 1.8094 | Learning Rate: 0.000963 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1390/12542 | Batch Loss: 1.2790 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1391/12542 | Batch Loss: 0.7307 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1392/12542 | Batch Loss: 1.7761 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1393/12542 | Batch Loss: 1.1153 | Learning Rate: 0.000963 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1394/12542 | Batch Loss: 0.8874 | Learning Rate: 0.000963 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1395/12542 | Batch Loss: 0.4524 | Learning Rate: 0.000963 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1396/12542 | Batch Loss: 0.6932 | Learning Rate: 0.000963 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1397/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000963 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1398/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1399/12542 | Batch Loss: 0.8318 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1400/12542 | Batch Loss: 3.1642 | Learning Rate: 0.000963 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 1401/12542 | Batch Loss: 0.9424 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1402/12542 | Batch Loss: 2.0618 | Learning Rate: 0.000963 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1403/12542 | Batch Loss: 1.6217 | Learning Rate: 0.000963 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1404/12542 | Batch Loss: 1.1371 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1405/12542 | Batch Loss: 0.9304 | Learning Rate: 0.000963 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1406/12542 | Batch Loss: 1.2849 | Learning Rate: 0.000963 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1407/12542 | Batch Loss: 1.1859 | Learning Rate: 0.000963 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1408/12542 | Batch Loss: 1.1829 | Learning Rate: 0.000963 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1409/12542 | Batch Loss: 2.0974 | Learning Rate: 0.000963 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1410/12542 | Batch Loss: 1.2753 | Learning Rate: 0.000963 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1411/12542 | Batch Loss: 2.2676 | Learning Rate: 0.000962 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1412/12542 | Batch Loss: 3.0407 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1413/12542 | Batch Loss: 0.9640 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1414/12542 | Batch Loss: 1.5467 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1415/12542 | Batch Loss: 1.3420 | Learning Rate: 0.000962 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1416/12542 | Batch Loss: 0.9946 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1417/12542 | Batch Loss: 0.8188 | Learning Rate: 0.000962 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1418/12542 | Batch Loss: 2.3651 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1419/12542 | Batch Loss: 1.9791 | Learning Rate: 0.000962 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1420/12542 | Batch Loss: 1.9267 | Learning Rate: 0.000962 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1421/12542 | Batch Loss: 1.9074 | Learning Rate: 0.000962 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1422/12542 | Batch Loss: 1.3134 | Learning Rate: 0.000962 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 1423/12542 | Batch Loss: 1.9440 | Learning Rate: 0.000962 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1424/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1425/12542 | Batch Loss: 1.2013 | Learning Rate: 0.000962 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1426/12542 | Batch Loss: 1.0121 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1427/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1428/12542 | Batch Loss: 0.9774 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1429/12542 | Batch Loss: 1.6690 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1430/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1431/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000962 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1432/12542 | Batch Loss: 1.3204 | Learning Rate: 0.000962 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1433/12542 | Batch Loss: 1.6294 | Learning Rate: 0.000962 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1434/12542 | Batch Loss: 1.4366 | Learning Rate: 0.000962 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1435/12542 | Batch Loss: 2.2456 | Learning Rate: 0.000962 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1436/12542 | Batch Loss: 2.4738 | Learning Rate: 0.000962 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1437/12542 | Batch Loss: 1.2387 | Learning Rate: 0.000962 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1438/12542 | Batch Loss: 2.1939 | Learning Rate: 0.000962 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1439/12542 | Batch Loss: 1.4380 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1440/12542 | Batch Loss: 1.0948 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1441/12542 | Batch Loss: 1.8905 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1442/12542 | Batch Loss: 1.5682 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1443/12542 | Batch Loss: 2.3231 | Learning Rate: 0.000962 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1444/12542 | Batch Loss: 1.0019 | Learning Rate: 0.000962 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1445/12542 | Batch Loss: 1.7088 | Learning Rate: 0.000962 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1446/12542 | Batch Loss: 1.0872 | Learning Rate: 0.000962 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1447/12542 | Batch Loss: 0.9319 | Learning Rate: 0.000962 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1448/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000962 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1449/12542 | Batch Loss: 2.3119 | Learning Rate: 0.000961 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1450/12542 | Batch Loss: 2.8159 | Learning Rate: 0.000961 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1451/12542 | Batch Loss: 2.1173 | Learning Rate: 0.000961 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1452/12542 | Batch Loss: 2.1452 | Learning Rate: 0.000961 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1453/12542 | Batch Loss: 2.4971 | Learning Rate: 0.000961 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1454/12542 | Batch Loss: 2.1661 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1455/12542 | Batch Loss: 2.4343 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1456/12542 | Batch Loss: 1.4129 | Learning Rate: 0.000961 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1457/12542 | Batch Loss: 0.9966 | Learning Rate: 0.000961 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1458/12542 | Batch Loss: 0.9265 | Learning Rate: 0.000961 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1459/12542 | Batch Loss: 2.2991 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1460/12542 | Batch Loss: 3.0098 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1461/12542 | Batch Loss: 3.2694 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1462/12542 | Batch Loss: 1.4794 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1463/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1464/12542 | Batch Loss: 2.4008 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1465/12542 | Batch Loss: 3.9426 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1466/12542 | Batch Loss: 1.3150 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1467/12542 | Batch Loss: 1.2634 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1468/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1469/12542 | Batch Loss: 0.7869 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1470/12542 | Batch Loss: 1.3594 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1471/12542 | Batch Loss: 1.3616 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1472/12542 | Batch Loss: 1.2780 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1473/12542 | Batch Loss: 1.7765 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1474/12542 | Batch Loss: 2.1962 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1475/12542 | Batch Loss: 1.1631 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1476/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1477/12542 | Batch Loss: 0.5165 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1478/12542 | Batch Loss: 1.4484 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1479/12542 | Batch Loss: 2.8884 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1480/12542 | Batch Loss: 0.6238 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1481/12542 | Batch Loss: 1.1685 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1482/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1483/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1484/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000961 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1485/12542 | Batch Loss: 2.3957 | Learning Rate: 0.000961 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1486/12542 | Batch Loss: 1.1444 | Learning Rate: 0.000961 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1487/12542 | Batch Loss: 0.9323 | Learning Rate: 0.000960 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1488/12542 | Batch Loss: 1.8639 | Learning Rate: 0.000960 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1489/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000960 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1490/12542 | Batch Loss: 1.4110 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1491/12542 | Batch Loss: 1.5154 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1492/12542 | Batch Loss: 0.9401 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1493/12542 | Batch Loss: 1.4961 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1494/12542 | Batch Loss: 1.8418 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1495/12542 | Batch Loss: 0.8052 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1496/12542 | Batch Loss: 1.5171 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1497/12542 | Batch Loss: 0.5733 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1498/12542 | Batch Loss: 0.7932 | Learning Rate: 0.000960 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1499/12542 | Batch Loss: 1.9194 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1500/12542 | Batch Loss: 1.7444 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1501/12542 | Batch Loss: 2.3194 | Learning Rate: 0.000960 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1502/12542 | Batch Loss: 2.2648 | Learning Rate: 0.000960 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1503/12542 | Batch Loss: 1.9362 | Learning Rate: 0.000960 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1504/12542 | Batch Loss: 1.0698 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1505/12542 | Batch Loss: 0.7846 | Learning Rate: 0.000960 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1506/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1507/12542 | Batch Loss: 2.5733 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1508/12542 | Batch Loss: 1.2396 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1509/12542 | Batch Loss: 1.5002 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1510/12542 | Batch Loss: 3.3022 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1511/12542 | Batch Loss: 1.8116 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1512/12542 | Batch Loss: 1.0402 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1513/12542 | Batch Loss: 1.3276 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1514/12542 | Batch Loss: 1.9910 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1515/12542 | Batch Loss: 1.4239 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1516/12542 | Batch Loss: 1.5840 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1517/12542 | Batch Loss: 1.7294 | Learning Rate: 0.000960 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1518/12542 | Batch Loss: 2.1263 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1519/12542 | Batch Loss: 0.9686 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1520/12542 | Batch Loss: 2.2682 | Learning Rate: 0.000960 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1521/12542 | Batch Loss: 1.9559 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1522/12542 | Batch Loss: 0.9141 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1523/12542 | Batch Loss: 0.8324 | Learning Rate: 0.000960 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1524/12542 | Batch Loss: 1.3526 | Learning Rate: 0.000959 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1525/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1526/12542 | Batch Loss: 1.1646 | Learning Rate: 0.000959 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1527/12542 | Batch Loss: 1.2247 | Learning Rate: 0.000959 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1528/12542 | Batch Loss: 1.7299 | Learning Rate: 0.000959 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1529/12542 | Batch Loss: 0.8857 | Learning Rate: 0.000959 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1530/12542 | Batch Loss: 2.4452 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1531/12542 | Batch Loss: 0.8775 | Learning Rate: 0.000959 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1532/12542 | Batch Loss: 1.5572 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1533/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1534/12542 | Batch Loss: 1.6600 | Learning Rate: 0.000959 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1535/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000959 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1536/12542 | Batch Loss: 0.9856 | Learning Rate: 0.000959 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1537/12542 | Batch Loss: 0.8753 | Learning Rate: 0.000959 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1538/12542 | Batch Loss: 1.5754 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1539/12542 | Batch Loss: 1.7294 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1540/12542 | Batch Loss: 2.2133 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1541/12542 | Batch Loss: 2.3153 | Learning Rate: 0.000959 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1542/12542 | Batch Loss: 1.4366 | Learning Rate: 0.000959 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1543/12542 | Batch Loss: 1.4319 | Learning Rate: 0.000959 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1544/12542 | Batch Loss: 2.0958 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1545/12542 | Batch Loss: 1.7508 | Learning Rate: 0.000959 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1546/12542 | Batch Loss: 2.6082 | Learning Rate: 0.000959 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1547/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000959 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1548/12542 | Batch Loss: 1.4303 | Learning Rate: 0.000959 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1549/12542 | Batch Loss: 1.5482 | Learning Rate: 0.000959 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1550/12542 | Batch Loss: 1.3748 | Learning Rate: 0.000959 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1551/12542 | Batch Loss: 1.6647 | Learning Rate: 0.000959 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1552/12542 | Batch Loss: 0.6999 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1553/12542 | Batch Loss: 2.0828 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1554/12542 | Batch Loss: 1.1063 | Learning Rate: 0.000959 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1555/12542 | Batch Loss: 1.3403 | Learning Rate: 0.000959 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1556/12542 | Batch Loss: 0.8744 | Learning Rate: 0.000959 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1557/12542 | Batch Loss: 1.8553 | Learning Rate: 0.000959 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1558/12542 | Batch Loss: 0.6962 | Learning Rate: 0.000959 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1559/12542 | Batch Loss: 1.3982 | Learning Rate: 0.000959 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1560/12542 | Batch Loss: 1.1608 | Learning Rate: 0.000959 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1561/12542 | Batch Loss: 1.1473 | Learning Rate: 0.000959 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1562/12542 | Batch Loss: 0.6541 | Learning Rate: 0.000958 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1563/12542 | Batch Loss: 0.7358 | Learning Rate: 0.000958 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1564/12542 | Batch Loss: 0.9198 | Learning Rate: 0.000958 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1565/12542 | Batch Loss: 1.0771 | Learning Rate: 0.000958 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1566/12542 | Batch Loss: 1.0650 | Learning Rate: 0.000958 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1567/12542 | Batch Loss: 1.1573 | Learning Rate: 0.000958 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1568/12542 | Batch Loss: 0.7015 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1569/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000958 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1570/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000958 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1571/12542 | Batch Loss: 2.0010 | Learning Rate: 0.000958 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1572/12542 | Batch Loss: 1.0527 | Learning Rate: 0.000958 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1573/12542 | Batch Loss: 2.4692 | Learning Rate: 0.000958 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1574/12542 | Batch Loss: 2.3661 | Learning Rate: 0.000958 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1575/12542 | Batch Loss: 0.8473 | Learning Rate: 0.000958 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1576/12542 | Batch Loss: 1.3533 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1577/12542 | Batch Loss: 1.7546 | Learning Rate: 0.000958 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1578/12542 | Batch Loss: 1.5443 | Learning Rate: 0.000958 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1579/12542 | Batch Loss: 1.1847 | Learning Rate: 0.000958 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1580/12542 | Batch Loss: 2.0914 | Learning Rate: 0.000958 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1581/12542 | Batch Loss: 1.6260 | Learning Rate: 0.000958 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1582/12542 | Batch Loss: 0.6668 | Learning Rate: 0.000958 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1583/12542 | Batch Loss: 1.6677 | Learning Rate: 0.000958 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1584/12542 | Batch Loss: 1.3260 | Learning Rate: 0.000958 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1585/12542 | Batch Loss: 0.7740 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1586/12542 | Batch Loss: 0.4935 | Learning Rate: 0.000958 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1587/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000958 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1588/12542 | Batch Loss: 1.2261 | Learning Rate: 0.000958 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1589/12542 | Batch Loss: 1.9165 | Learning Rate: 0.000958 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1590/12542 | Batch Loss: 1.4413 | Learning Rate: 0.000958 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1591/12542 | Batch Loss: 1.0094 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1592/12542 | Batch Loss: 0.9187 | Learning Rate: 0.000958 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1593/12542 | Batch Loss: 1.1435 | Learning Rate: 0.000958 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1594/12542 | Batch Loss: 0.8788 | Learning Rate: 0.000958 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1595/12542 | Batch Loss: 1.7193 | Learning Rate: 0.000958 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1596/12542 | Batch Loss: 1.8957 | Learning Rate: 0.000958 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1597/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1598/12542 | Batch Loss: 2.5037 | Learning Rate: 0.000958 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1599/12542 | Batch Loss: 1.4659 | Learning Rate: 0.000958 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1600/12542 | Batch Loss: 2.6154 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1601/12542 | Batch Loss: 1.3034 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1602/12542 | Batch Loss: 1.0642 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1603/12542 | Batch Loss: 1.9418 | Learning Rate: 0.000957 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1604/12542 | Batch Loss: 1.1280 | Learning Rate: 0.000957 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1605/12542 | Batch Loss: 1.1273 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1606/12542 | Batch Loss: 0.5060 | Learning Rate: 0.000957 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1607/12542 | Batch Loss: 0.8762 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1608/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1609/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1610/12542 | Batch Loss: 2.1443 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1611/12542 | Batch Loss: 1.5609 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1612/12542 | Batch Loss: 1.5150 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1613/12542 | Batch Loss: 1.3056 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1614/12542 | Batch Loss: 1.3121 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1615/12542 | Batch Loss: 1.2325 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1616/12542 | Batch Loss: 1.3102 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1617/12542 | Batch Loss: 1.3401 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1618/12542 | Batch Loss: 1.2812 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1619/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1620/12542 | Batch Loss: 1.3552 | Learning Rate: 0.000957 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1621/12542 | Batch Loss: 2.0593 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1622/12542 | Batch Loss: 1.7648 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1623/12542 | Batch Loss: 1.0468 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1624/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1625/12542 | Batch Loss: 0.9833 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1626/12542 | Batch Loss: 1.9408 | Learning Rate: 0.000957 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1627/12542 | Batch Loss: 1.4184 | Learning Rate: 0.000957 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1628/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000957 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1629/12542 | Batch Loss: 0.7279 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1630/12542 | Batch Loss: 2.1522 | Learning Rate: 0.000957 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1631/12542 | Batch Loss: 1.2085 | Learning Rate: 0.000957 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1632/12542 | Batch Loss: 0.9334 | Learning Rate: 0.000957 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1633/12542 | Batch Loss: 0.6057 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1634/12542 | Batch Loss: 1.3000 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1635/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1636/12542 | Batch Loss: 1.3086 | Learning Rate: 0.000957 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1637/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1638/12542 | Batch Loss: 1.8448 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1639/12542 | Batch Loss: 0.6938 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1640/12542 | Batch Loss: 1.4954 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1641/12542 | Batch Loss: 1.7200 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1642/12542 | Batch Loss: 1.2480 | Learning Rate: 0.000956 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1643/12542 | Batch Loss: 0.8060 | Learning Rate: 0.000956 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1644/12542 | Batch Loss: 0.7718 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1645/12542 | Batch Loss: 0.9861 | Learning Rate: 0.000956 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1646/12542 | Batch Loss: 0.7619 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1647/12542 | Batch Loss: 0.7728 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1648/12542 | Batch Loss: 1.6436 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1649/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1650/12542 | Batch Loss: 1.1949 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1651/12542 | Batch Loss: 1.7678 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1652/12542 | Batch Loss: 1.7704 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1653/12542 | Batch Loss: 1.5572 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1654/12542 | Batch Loss: 0.8589 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1655/12542 | Batch Loss: 1.0628 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1656/12542 | Batch Loss: 1.1630 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1657/12542 | Batch Loss: 2.5362 | Learning Rate: 0.000956 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1658/12542 | Batch Loss: 1.0479 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1659/12542 | Batch Loss: 1.2554 | Learning Rate: 0.000956 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1660/12542 | Batch Loss: 1.1496 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1661/12542 | Batch Loss: 0.9116 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1662/12542 | Batch Loss: 1.0951 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1663/12542 | Batch Loss: 1.5877 | Learning Rate: 0.000956 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1664/12542 | Batch Loss: 1.3256 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1665/12542 | Batch Loss: 1.5275 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1666/12542 | Batch Loss: 1.6274 | Learning Rate: 0.000956 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1667/12542 | Batch Loss: 1.0243 | Learning Rate: 0.000956 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1668/12542 | Batch Loss: 0.9223 | Learning Rate: 0.000956 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1669/12542 | Batch Loss: 0.9251 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1670/12542 | Batch Loss: 1.1242 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1671/12542 | Batch Loss: 0.8263 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1672/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000956 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1673/12542 | Batch Loss: 1.7989 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1674/12542 | Batch Loss: 1.4986 | Learning Rate: 0.000956 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1675/12542 | Batch Loss: 0.8354 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1676/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1677/12542 | Batch Loss: 2.8597 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1678/12542 | Batch Loss: 0.7390 | Learning Rate: 0.000955 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1679/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000955 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1680/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1681/12542 | Batch Loss: 1.1098 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1682/12542 | Batch Loss: 0.6137 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1683/12542 | Batch Loss: 0.8551 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1684/12542 | Batch Loss: 2.6180 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1685/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1686/12542 | Batch Loss: 0.6474 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1687/12542 | Batch Loss: 0.7272 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1688/12542 | Batch Loss: 1.5840 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1689/12542 | Batch Loss: 1.6604 | Learning Rate: 0.000955 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1690/12542 | Batch Loss: 1.0004 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1691/12542 | Batch Loss: 1.1361 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1692/12542 | Batch Loss: 1.1768 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1693/12542 | Batch Loss: 1.6924 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1694/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1695/12542 | Batch Loss: 0.8168 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1696/12542 | Batch Loss: 0.9659 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1697/12542 | Batch Loss: 1.3758 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1698/12542 | Batch Loss: 1.2502 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1699/12542 | Batch Loss: 1.2872 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1700/12542 | Batch Loss: 0.8075 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1701/12542 | Batch Loss: 0.7798 | Learning Rate: 0.000955 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1702/12542 | Batch Loss: 1.4817 | Learning Rate: 0.000955 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1703/12542 | Batch Loss: 0.7123 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1704/12542 | Batch Loss: 0.7569 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1705/12542 | Batch Loss: 1.8485 | Learning Rate: 0.000955 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1706/12542 | Batch Loss: 0.7373 | Learning Rate: 0.000955 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1707/12542 | Batch Loss: 1.3642 | Learning Rate: 0.000955 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1708/12542 | Batch Loss: 2.1957 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1709/12542 | Batch Loss: 0.8701 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1710/12542 | Batch Loss: 0.7503 | Learning Rate: 0.000955 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1711/12542 | Batch Loss: 0.6351 | Learning Rate: 0.000955 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1712/12542 | Batch Loss: 2.3152 | Learning Rate: 0.000954 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1713/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1714/12542 | Batch Loss: 1.2301 | Learning Rate: 0.000954 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1715/12542 | Batch Loss: 1.0877 | Learning Rate: 0.000954 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1716/12542 | Batch Loss: 1.8632 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1717/12542 | Batch Loss: 1.6650 | Learning Rate: 0.000954 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1718/12542 | Batch Loss: 1.5906 | Learning Rate: 0.000954 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1719/12542 | Batch Loss: 1.1381 | Learning Rate: 0.000954 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1720/12542 | Batch Loss: 1.9261 | Learning Rate: 0.000954 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1721/12542 | Batch Loss: 0.9741 | Learning Rate: 0.000954 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1722/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1723/12542 | Batch Loss: 2.0909 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1724/12542 | Batch Loss: 1.9350 | Learning Rate: 0.000954 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1725/12542 | Batch Loss: 2.7602 | Learning Rate: 0.000954 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1726/12542 | Batch Loss: 1.8837 | Learning Rate: 0.000954 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1727/12542 | Batch Loss: 1.1231 | Learning Rate: 0.000954 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1728/12542 | Batch Loss: 0.9975 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1729/12542 | Batch Loss: 1.3753 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1730/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1731/12542 | Batch Loss: 0.6162 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1732/12542 | Batch Loss: 3.9396 | Learning Rate: 0.000954 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1733/12542 | Batch Loss: 1.8359 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1734/12542 | Batch Loss: 0.9249 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1735/12542 | Batch Loss: 1.8989 | Learning Rate: 0.000954 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1736/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000954 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1737/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000954 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1738/12542 | Batch Loss: 0.5631 | Learning Rate: 0.000954 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1739/12542 | Batch Loss: 2.2162 | Learning Rate: 0.000954 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1740/12542 | Batch Loss: 2.4468 | Learning Rate: 0.000954 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1741/12542 | Batch Loss: 0.8467 | Learning Rate: 0.000954 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1742/12542 | Batch Loss: 1.7275 | Learning Rate: 0.000954 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1743/12542 | Batch Loss: 1.5386 | Learning Rate: 0.000954 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1744/12542 | Batch Loss: 0.5327 | Learning Rate: 0.000954 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1745/12542 | Batch Loss: 1.0590 | Learning Rate: 0.000954 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1746/12542 | Batch Loss: 1.2177 | Learning Rate: 0.000954 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1747/12542 | Batch Loss: 1.6301 | Learning Rate: 0.000954 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1748/12542 | Batch Loss: 2.8496 | Learning Rate: 0.000954 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1749/12542 | Batch Loss: 0.8313 | Learning Rate: 0.000954 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1750/12542 | Batch Loss: 0.9061 | Learning Rate: 0.000953 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1751/12542 | Batch Loss: 1.5470 | Learning Rate: 0.000953 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1752/12542 | Batch Loss: 1.2281 | Learning Rate: 0.000953 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1753/12542 | Batch Loss: 1.3833 | Learning Rate: 0.000953 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1754/12542 | Batch Loss: 1.0235 | Learning Rate: 0.000953 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1755/12542 | Batch Loss: 1.3831 | Learning Rate: 0.000953 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1756/12542 | Batch Loss: 2.5002 | Learning Rate: 0.000953 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1757/12542 | Batch Loss: 0.4543 | Learning Rate: 0.000953 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1758/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000953 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1759/12542 | Batch Loss: 0.5872 | Learning Rate: 0.000953 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1760/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000953 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1761/12542 | Batch Loss: 2.0438 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1762/12542 | Batch Loss: 3.8153 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1763/12542 | Batch Loss: 0.9975 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1764/12542 | Batch Loss: 1.3715 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1765/12542 | Batch Loss: 2.2695 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1766/12542 | Batch Loss: 1.5531 | Learning Rate: 0.000953 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1767/12542 | Batch Loss: 1.2947 | Learning Rate: 0.000953 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1768/12542 | Batch Loss: 1.2728 | Learning Rate: 0.000953 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1769/12542 | Batch Loss: 1.9554 | Learning Rate: 0.000953 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 1770/12542 | Batch Loss: 0.9033 | Learning Rate: 0.000953 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1771/12542 | Batch Loss: 0.7865 | Learning Rate: 0.000953 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1772/12542 | Batch Loss: 3.1595 | Learning Rate: 0.000953 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1773/12542 | Batch Loss: 2.4550 | Learning Rate: 0.000953 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1774/12542 | Batch Loss: 2.2662 | Learning Rate: 0.000953 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1775/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000953 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1776/12542 | Batch Loss: 2.6712 | Learning Rate: 0.000953 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1777/12542 | Batch Loss: 2.3534 | Learning Rate: 0.000953 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1778/12542 | Batch Loss: 1.1762 | Learning Rate: 0.000953 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1779/12542 | Batch Loss: 1.8350 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1780/12542 | Batch Loss: 0.8044 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1781/12542 | Batch Loss: 1.2440 | Learning Rate: 0.000953 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1782/12542 | Batch Loss: 1.3208 | Learning Rate: 0.000953 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1783/12542 | Batch Loss: 2.0840 | Learning Rate: 0.000953 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1784/12542 | Batch Loss: 1.9050 | Learning Rate: 0.000953 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1785/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000953 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 1786/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000953 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1787/12542 | Batch Loss: 2.3722 | Learning Rate: 0.000953 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1788/12542 | Batch Loss: 0.6616 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1789/12542 | Batch Loss: 1.2632 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1790/12542 | Batch Loss: 2.0890 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1791/12542 | Batch Loss: 1.4006 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1792/12542 | Batch Loss: 1.4246 | Learning Rate: 0.000952 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1793/12542 | Batch Loss: 2.0136 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1794/12542 | Batch Loss: 1.7971 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1795/12542 | Batch Loss: 2.0033 | Learning Rate: 0.000952 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1796/12542 | Batch Loss: 1.0469 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1797/12542 | Batch Loss: 0.8257 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1798/12542 | Batch Loss: 0.7026 | Learning Rate: 0.000952 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1799/12542 | Batch Loss: 1.4567 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1800/12542 | Batch Loss: 1.7890 | Learning Rate: 0.000952 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1801/12542 | Batch Loss: 1.0671 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1802/12542 | Batch Loss: 1.0342 | Learning Rate: 0.000952 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1803/12542 | Batch Loss: 0.7997 | Learning Rate: 0.000952 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1804/12542 | Batch Loss: 2.3431 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1805/12542 | Batch Loss: 1.9994 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1806/12542 | Batch Loss: 1.1519 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1807/12542 | Batch Loss: 1.6199 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1808/12542 | Batch Loss: 1.4588 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1809/12542 | Batch Loss: 0.9540 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1810/12542 | Batch Loss: 0.9253 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1811/12542 | Batch Loss: 0.7417 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1812/12542 | Batch Loss: 1.5424 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1813/12542 | Batch Loss: 0.5816 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1814/12542 | Batch Loss: 0.9466 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1815/12542 | Batch Loss: 1.0495 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1816/12542 | Batch Loss: 0.7424 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1817/12542 | Batch Loss: 3.8709 | Learning Rate: 0.000952 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1818/12542 | Batch Loss: 2.0038 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1819/12542 | Batch Loss: 1.0641 | Learning Rate: 0.000952 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1820/12542 | Batch Loss: 0.6701 | Learning Rate: 0.000952 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1821/12542 | Batch Loss: 0.7126 | Learning Rate: 0.000952 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1822/12542 | Batch Loss: 2.1965 | Learning Rate: 0.000952 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1823/12542 | Batch Loss: 0.9366 | Learning Rate: 0.000952 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1824/12542 | Batch Loss: 2.2785 | Learning Rate: 0.000952 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1825/12542 | Batch Loss: 1.0483 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1826/12542 | Batch Loss: 1.1599 | Learning Rate: 0.000951 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1827/12542 | Batch Loss: 0.7125 | Learning Rate: 0.000951 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1828/12542 | Batch Loss: 0.9244 | Learning Rate: 0.000951 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1829/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000951 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1830/12542 | Batch Loss: 1.4859 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1831/12542 | Batch Loss: 0.6789 | Learning Rate: 0.000951 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1832/12542 | Batch Loss: 0.9913 | Learning Rate: 0.000951 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1833/12542 | Batch Loss: 1.7753 | Learning Rate: 0.000951 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1834/12542 | Batch Loss: 1.8237 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1835/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000951 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1836/12542 | Batch Loss: 1.8488 | Learning Rate: 0.000951 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1837/12542 | Batch Loss: 2.1258 | Learning Rate: 0.000951 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1838/12542 | Batch Loss: 3.5107 | Learning Rate: 0.000951 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 1839/12542 | Batch Loss: 0.7165 | Learning Rate: 0.000951 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1840/12542 | Batch Loss: 1.0459 | Learning Rate: 0.000951 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1841/12542 | Batch Loss: 0.8573 | Learning Rate: 0.000951 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1842/12542 | Batch Loss: 1.6791 | Learning Rate: 0.000951 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1843/12542 | Batch Loss: 2.5349 | Learning Rate: 0.000951 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1844/12542 | Batch Loss: 0.9005 | Learning Rate: 0.000951 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1845/12542 | Batch Loss: 1.3182 | Learning Rate: 0.000951 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1846/12542 | Batch Loss: 1.4081 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1847/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000951 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1848/12542 | Batch Loss: 1.8056 | Learning Rate: 0.000951 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1849/12542 | Batch Loss: 1.0022 | Learning Rate: 0.000951 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1850/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000951 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1851/12542 | Batch Loss: 2.5184 | Learning Rate: 0.000951 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1852/12542 | Batch Loss: 2.4129 | Learning Rate: 0.000951 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1853/12542 | Batch Loss: 1.2982 | Learning Rate: 0.000951 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1854/12542 | Batch Loss: 0.8986 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1855/12542 | Batch Loss: 2.0856 | Learning Rate: 0.000951 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1856/12542 | Batch Loss: 3.4978 | Learning Rate: 0.000951 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1857/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000951 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1858/12542 | Batch Loss: 1.2296 | Learning Rate: 0.000951 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1859/12542 | Batch Loss: 0.9305 | Learning Rate: 0.000951 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1860/12542 | Batch Loss: 1.3671 | Learning Rate: 0.000951 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1861/12542 | Batch Loss: 1.3617 | Learning Rate: 0.000951 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1862/12542 | Batch Loss: 0.9201 | Learning Rate: 0.000951 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1863/12542 | Batch Loss: 0.4808 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1864/12542 | Batch Loss: 1.8084 | Learning Rate: 0.000950 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1865/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1866/12542 | Batch Loss: 1.2954 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1867/12542 | Batch Loss: 1.9437 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1868/12542 | Batch Loss: 1.6837 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1869/12542 | Batch Loss: 2.1359 | Learning Rate: 0.000950 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1870/12542 | Batch Loss: 1.4251 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1871/12542 | Batch Loss: 1.9208 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1872/12542 | Batch Loss: 1.4074 | Learning Rate: 0.000950 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1873/12542 | Batch Loss: 2.3641 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1874/12542 | Batch Loss: 1.0475 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1875/12542 | Batch Loss: 1.8675 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1876/12542 | Batch Loss: 1.5290 | Learning Rate: 0.000950 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1877/12542 | Batch Loss: 1.0557 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1878/12542 | Batch Loss: 1.4541 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1879/12542 | Batch Loss: 0.7566 | Learning Rate: 0.000950 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1880/12542 | Batch Loss: 1.7553 | Learning Rate: 0.000950 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1881/12542 | Batch Loss: 1.2173 | Learning Rate: 0.000950 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1882/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1883/12542 | Batch Loss: 2.9957 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1884/12542 | Batch Loss: 2.7522 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1885/12542 | Batch Loss: 1.1916 | Learning Rate: 0.000950 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1886/12542 | Batch Loss: 0.8968 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1887/12542 | Batch Loss: 2.2445 | Learning Rate: 0.000950 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1888/12542 | Batch Loss: 1.1556 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1889/12542 | Batch Loss: 1.5927 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1890/12542 | Batch Loss: 2.5089 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1891/12542 | Batch Loss: 2.4871 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1892/12542 | Batch Loss: 0.8904 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1893/12542 | Batch Loss: 1.7015 | Learning Rate: 0.000950 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1894/12542 | Batch Loss: 4.2973 | Learning Rate: 0.000950 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1895/12542 | Batch Loss: 1.6490 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1896/12542 | Batch Loss: 1.6754 | Learning Rate: 0.000950 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1897/12542 | Batch Loss: 0.9376 | Learning Rate: 0.000950 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1898/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000950 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1899/12542 | Batch Loss: 0.9676 | Learning Rate: 0.000950 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1900/12542 | Batch Loss: 1.3121 | Learning Rate: 0.000950 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1901/12542 | Batch Loss: 1.2072 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1902/12542 | Batch Loss: 1.3140 | Learning Rate: 0.000949 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1903/12542 | Batch Loss: 1.4704 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1904/12542 | Batch Loss: 3.0201 | Learning Rate: 0.000949 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1905/12542 | Batch Loss: 1.4559 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1906/12542 | Batch Loss: 1.5653 | Learning Rate: 0.000949 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1907/12542 | Batch Loss: 1.3802 | Learning Rate: 0.000949 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1908/12542 | Batch Loss: 0.8939 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1909/12542 | Batch Loss: 2.3293 | Learning Rate: 0.000949 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1910/12542 | Batch Loss: 0.7391 | Learning Rate: 0.000949 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1911/12542 | Batch Loss: 2.0955 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1912/12542 | Batch Loss: 1.2863 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1913/12542 | Batch Loss: 0.9650 | Learning Rate: 0.000949 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1914/12542 | Batch Loss: 3.7670 | Learning Rate: 0.000949 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1915/12542 | Batch Loss: 0.9793 | Learning Rate: 0.000949 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 1916/12542 | Batch Loss: 1.9416 | Learning Rate: 0.000949 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1917/12542 | Batch Loss: 0.7677 | Learning Rate: 0.000949 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1918/12542 | Batch Loss: 1.4534 | Learning Rate: 0.000949 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1919/12542 | Batch Loss: 0.5743 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1920/12542 | Batch Loss: 0.8524 | Learning Rate: 0.000949 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1921/12542 | Batch Loss: 1.0545 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1922/12542 | Batch Loss: 1.5114 | Learning Rate: 0.000949 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1923/12542 | Batch Loss: 2.3996 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1924/12542 | Batch Loss: 0.8663 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1925/12542 | Batch Loss: 1.5479 | Learning Rate: 0.000949 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1926/12542 | Batch Loss: 0.9637 | Learning Rate: 0.000949 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1927/12542 | Batch Loss: 0.8173 | Learning Rate: 0.000949 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1928/12542 | Batch Loss: 0.8703 | Learning Rate: 0.000949 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1929/12542 | Batch Loss: 1.2121 | Learning Rate: 0.000949 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1930/12542 | Batch Loss: 1.2214 | Learning Rate: 0.000949 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1931/12542 | Batch Loss: 0.9561 | Learning Rate: 0.000949 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1932/12542 | Batch Loss: 1.4585 | Learning Rate: 0.000949 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1933/12542 | Batch Loss: 1.1660 | Learning Rate: 0.000949 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1934/12542 | Batch Loss: 0.9316 | Learning Rate: 0.000949 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 1935/12542 | Batch Loss: 1.7705 | Learning Rate: 0.000949 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 1936/12542 | Batch Loss: 2.7456 | Learning Rate: 0.000949 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1937/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000949 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1938/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1939/12542 | Batch Loss: 1.3128 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1940/12542 | Batch Loss: 0.9334 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1941/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000948 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1942/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1943/12542 | Batch Loss: 1.1844 | Learning Rate: 0.000948 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1944/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1945/12542 | Batch Loss: 2.2127 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1946/12542 | Batch Loss: 1.9035 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1947/12542 | Batch Loss: 1.9156 | Learning Rate: 0.000948 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1948/12542 | Batch Loss: 1.1829 | Learning Rate: 0.000948 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1949/12542 | Batch Loss: 1.9234 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1950/12542 | Batch Loss: 0.8178 | Learning Rate: 0.000948 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1951/12542 | Batch Loss: 1.4471 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1952/12542 | Batch Loss: 1.7215 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1953/12542 | Batch Loss: 1.3172 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1954/12542 | Batch Loss: 0.6745 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1955/12542 | Batch Loss: 2.2905 | Learning Rate: 0.000948 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1956/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000948 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1957/12542 | Batch Loss: 2.0320 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1958/12542 | Batch Loss: 0.9625 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1959/12542 | Batch Loss: 1.6451 | Learning Rate: 0.000948 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1960/12542 | Batch Loss: 1.6167 | Learning Rate: 0.000948 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1961/12542 | Batch Loss: 0.7546 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1962/12542 | Batch Loss: 0.8850 | Learning Rate: 0.000948 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1963/12542 | Batch Loss: 0.5970 | Learning Rate: 0.000948 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1964/12542 | Batch Loss: 1.0568 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1965/12542 | Batch Loss: 1.2115 | Learning Rate: 0.000948 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1966/12542 | Batch Loss: 2.1161 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1967/12542 | Batch Loss: 1.5745 | Learning Rate: 0.000948 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1968/12542 | Batch Loss: 1.1346 | Learning Rate: 0.000948 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 1969/12542 | Batch Loss: 1.5641 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1970/12542 | Batch Loss: 0.7419 | Learning Rate: 0.000948 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1971/12542 | Batch Loss: 1.5447 | Learning Rate: 0.000948 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1972/12542 | Batch Loss: 0.6513 | Learning Rate: 0.000948 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1973/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000948 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1974/12542 | Batch Loss: 1.5769 | Learning Rate: 0.000948 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1975/12542 | Batch Loss: 1.6029 | Learning Rate: 0.000948 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1976/12542 | Batch Loss: 2.6387 | Learning Rate: 0.000947 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1977/12542 | Batch Loss: 1.0823 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1978/12542 | Batch Loss: 1.8989 | Learning Rate: 0.000947 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1979/12542 | Batch Loss: 0.9100 | Learning Rate: 0.000947 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1980/12542 | Batch Loss: 2.6492 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1981/12542 | Batch Loss: 1.6397 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1982/12542 | Batch Loss: 0.9354 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1983/12542 | Batch Loss: 1.1750 | Learning Rate: 0.000947 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1984/12542 | Batch Loss: 2.6946 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1985/12542 | Batch Loss: 1.5624 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1986/12542 | Batch Loss: 1.8663 | Learning Rate: 0.000947 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 1987/12542 | Batch Loss: 1.1503 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1988/12542 | Batch Loss: 1.2322 | Learning Rate: 0.000947 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1989/12542 | Batch Loss: 1.1803 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1990/12542 | Batch Loss: 1.1990 | Learning Rate: 0.000947 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1991/12542 | Batch Loss: 0.8097 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 1992/12542 | Batch Loss: 1.5882 | Learning Rate: 0.000947 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 1993/12542 | Batch Loss: 2.0550 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1994/12542 | Batch Loss: 0.5625 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 1995/12542 | Batch Loss: 1.0110 | Learning Rate: 0.000947 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 1996/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000947 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 1997/12542 | Batch Loss: 1.0201 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 1998/12542 | Batch Loss: 1.8772 | Learning Rate: 0.000947 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 1999/12542 | Batch Loss: 0.8176 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2000/12542 | Batch Loss: 1.2979 | Learning Rate: 0.000947 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2001/12542 | Batch Loss: 1.0833 | Learning Rate: 0.000947 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2002/12542 | Batch Loss: 0.9217 | Learning Rate: 0.000947 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2003/12542 | Batch Loss: 1.2393 | Learning Rate: 0.000947 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2004/12542 | Batch Loss: 1.4339 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2005/12542 | Batch Loss: 0.7723 | Learning Rate: 0.000947 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2006/12542 | Batch Loss: 1.1455 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2007/12542 | Batch Loss: 1.5168 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2008/12542 | Batch Loss: 0.9291 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2009/12542 | Batch Loss: 0.9983 | Learning Rate: 0.000947 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2010/12542 | Batch Loss: 1.8517 | Learning Rate: 0.000947 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2011/12542 | Batch Loss: 3.1605 | Learning Rate: 0.000947 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2012/12542 | Batch Loss: 1.4853 | Learning Rate: 0.000947 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2013/12542 | Batch Loss: 1.1507 | Learning Rate: 0.000946 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2014/12542 | Batch Loss: 1.2039 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2015/12542 | Batch Loss: 1.8482 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2016/12542 | Batch Loss: 1.2633 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2017/12542 | Batch Loss: 0.9332 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2018/12542 | Batch Loss: 1.1922 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2019/12542 | Batch Loss: 0.8257 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2020/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2021/12542 | Batch Loss: 1.4204 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2022/12542 | Batch Loss: 2.8968 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2023/12542 | Batch Loss: 1.0839 | Learning Rate: 0.000946 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2024/12542 | Batch Loss: 1.6449 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2025/12542 | Batch Loss: 1.2818 | Learning Rate: 0.000946 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2026/12542 | Batch Loss: 1.0585 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2027/12542 | Batch Loss: 1.8656 | Learning Rate: 0.000946 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2028/12542 | Batch Loss: 1.1759 | Learning Rate: 0.000946 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2029/12542 | Batch Loss: 0.7178 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2030/12542 | Batch Loss: 2.1492 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2031/12542 | Batch Loss: 1.7207 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2032/12542 | Batch Loss: 1.9059 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2033/12542 | Batch Loss: 1.5265 | Learning Rate: 0.000946 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2034/12542 | Batch Loss: 1.7565 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2035/12542 | Batch Loss: 0.9049 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2036/12542 | Batch Loss: 1.2788 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2037/12542 | Batch Loss: 0.9316 | Learning Rate: 0.000946 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2038/12542 | Batch Loss: 0.7818 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2039/12542 | Batch Loss: 4.0958 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2040/12542 | Batch Loss: 3.4774 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2041/12542 | Batch Loss: 3.4570 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2042/12542 | Batch Loss: 1.3586 | Learning Rate: 0.000946 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2043/12542 | Batch Loss: 1.7110 | Learning Rate: 0.000946 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2044/12542 | Batch Loss: 1.4889 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2045/12542 | Batch Loss: 1.1870 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2046/12542 | Batch Loss: 1.5905 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2047/12542 | Batch Loss: 1.4777 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2048/12542 | Batch Loss: 0.8678 | Learning Rate: 0.000946 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2049/12542 | Batch Loss: 1.1203 | Learning Rate: 0.000946 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2050/12542 | Batch Loss: 1.5831 | Learning Rate: 0.000946 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2051/12542 | Batch Loss: 0.7459 | Learning Rate: 0.000945 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2052/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000945 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2053/12542 | Batch Loss: 1.7935 | Learning Rate: 0.000945 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2054/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000945 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2055/12542 | Batch Loss: 1.3521 | Learning Rate: 0.000945 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2056/12542 | Batch Loss: 2.4923 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2057/12542 | Batch Loss: 1.6905 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2058/12542 | Batch Loss: 1.1973 | Learning Rate: 0.000945 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2059/12542 | Batch Loss: 0.8198 | Learning Rate: 0.000945 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2060/12542 | Batch Loss: 1.4329 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2061/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000945 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2062/12542 | Batch Loss: 1.2012 | Learning Rate: 0.000945 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2063/12542 | Batch Loss: 0.8204 | Learning Rate: 0.000945 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2064/12542 | Batch Loss: 1.3018 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2065/12542 | Batch Loss: 3.0132 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2066/12542 | Batch Loss: 1.2702 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2067/12542 | Batch Loss: 0.8403 | Learning Rate: 0.000945 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2068/12542 | Batch Loss: 1.2947 | Learning Rate: 0.000945 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2069/12542 | Batch Loss: 2.3050 | Learning Rate: 0.000945 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2070/12542 | Batch Loss: 1.4089 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2071/12542 | Batch Loss: 1.6614 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2072/12542 | Batch Loss: 2.6828 | Learning Rate: 0.000945 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2073/12542 | Batch Loss: 1.4830 | Learning Rate: 0.000945 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2074/12542 | Batch Loss: 1.4630 | Learning Rate: 0.000945 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2075/12542 | Batch Loss: 1.4024 | Learning Rate: 0.000945 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2076/12542 | Batch Loss: 1.8261 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2077/12542 | Batch Loss: 1.0040 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2078/12542 | Batch Loss: 2.3580 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2079/12542 | Batch Loss: 1.1295 | Learning Rate: 0.000945 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2080/12542 | Batch Loss: 1.2400 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2081/12542 | Batch Loss: 1.1430 | Learning Rate: 0.000945 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2082/12542 | Batch Loss: 1.2049 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2083/12542 | Batch Loss: 0.9423 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2084/12542 | Batch Loss: 1.2339 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2085/12542 | Batch Loss: 2.6010 | Learning Rate: 0.000945 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2086/12542 | Batch Loss: 3.3860 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2087/12542 | Batch Loss: 2.9980 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2088/12542 | Batch Loss: 1.2776 | Learning Rate: 0.000945 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2089/12542 | Batch Loss: 1.7387 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2090/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2091/12542 | Batch Loss: 3.0386 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2092/12542 | Batch Loss: 1.3159 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2093/12542 | Batch Loss: 2.4331 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2094/12542 | Batch Loss: 2.2359 | Learning Rate: 0.000944 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2095/12542 | Batch Loss: 0.8411 | Learning Rate: 0.000944 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2096/12542 | Batch Loss: 1.5003 | Learning Rate: 0.000944 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2097/12542 | Batch Loss: 1.4484 | Learning Rate: 0.000944 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2098/12542 | Batch Loss: 0.7090 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2099/12542 | Batch Loss: 0.8353 | Learning Rate: 0.000944 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2100/12542 | Batch Loss: 0.7930 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2101/12542 | Batch Loss: 2.0387 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2102/12542 | Batch Loss: 2.1161 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2103/12542 | Batch Loss: 0.7866 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2104/12542 | Batch Loss: 0.4286 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2105/12542 | Batch Loss: 1.6295 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2106/12542 | Batch Loss: 1.0525 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2107/12542 | Batch Loss: 1.9590 | Learning Rate: 0.000944 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2108/12542 | Batch Loss: 1.1997 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2109/12542 | Batch Loss: 1.6752 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2110/12542 | Batch Loss: 1.0530 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2111/12542 | Batch Loss: 1.6325 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2112/12542 | Batch Loss: 3.0446 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2113/12542 | Batch Loss: 0.9556 | Learning Rate: 0.000944 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2114/12542 | Batch Loss: 1.1253 | Learning Rate: 0.000944 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2115/12542 | Batch Loss: 1.3234 | Learning Rate: 0.000944 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2116/12542 | Batch Loss: 1.5841 | Learning Rate: 0.000944 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2117/12542 | Batch Loss: 1.1026 | Learning Rate: 0.000944 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2118/12542 | Batch Loss: 2.2983 | Learning Rate: 0.000944 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2119/12542 | Batch Loss: 1.1195 | Learning Rate: 0.000944 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2120/12542 | Batch Loss: 2.2829 | Learning Rate: 0.000944 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2121/12542 | Batch Loss: 1.1031 | Learning Rate: 0.000944 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2122/12542 | Batch Loss: 1.2479 | Learning Rate: 0.000944 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2123/12542 | Batch Loss: 1.8679 | Learning Rate: 0.000944 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2124/12542 | Batch Loss: 0.5446 | Learning Rate: 0.000944 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2125/12542 | Batch Loss: 1.8858 | Learning Rate: 0.000944 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2126/12542 | Batch Loss: 2.3689 | Learning Rate: 0.000943 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2127/12542 | Batch Loss: 1.9019 | Learning Rate: 0.000943 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2128/12542 | Batch Loss: 0.9187 | Learning Rate: 0.000943 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2129/12542 | Batch Loss: 1.1002 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2130/12542 | Batch Loss: 1.2215 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2131/12542 | Batch Loss: 0.8945 | Learning Rate: 0.000943 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2132/12542 | Batch Loss: 1.7554 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2133/12542 | Batch Loss: 0.8045 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2134/12542 | Batch Loss: 0.7515 | Learning Rate: 0.000943 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2135/12542 | Batch Loss: 2.3233 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2136/12542 | Batch Loss: 2.7393 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2137/12542 | Batch Loss: 2.0451 | Learning Rate: 0.000943 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2138/12542 | Batch Loss: 1.6485 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2139/12542 | Batch Loss: 1.0479 | Learning Rate: 0.000943 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2140/12542 | Batch Loss: 1.7008 | Learning Rate: 0.000943 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2141/12542 | Batch Loss: 0.7004 | Learning Rate: 0.000943 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2142/12542 | Batch Loss: 0.7815 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2143/12542 | Batch Loss: 0.8212 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2144/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2145/12542 | Batch Loss: 1.7958 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2146/12542 | Batch Loss: 3.1676 | Learning Rate: 0.000943 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2147/12542 | Batch Loss: 1.6153 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2148/12542 | Batch Loss: 0.8416 | Learning Rate: 0.000943 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2149/12542 | Batch Loss: 0.8728 | Learning Rate: 0.000943 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2150/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2151/12542 | Batch Loss: 1.8633 | Learning Rate: 0.000943 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2152/12542 | Batch Loss: 1.6143 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2153/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2154/12542 | Batch Loss: 0.5676 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2155/12542 | Batch Loss: 1.8311 | Learning Rate: 0.000943 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2156/12542 | Batch Loss: 1.3680 | Learning Rate: 0.000943 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2157/12542 | Batch Loss: 2.5965 | Learning Rate: 0.000943 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2158/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000943 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2159/12542 | Batch Loss: 1.2183 | Learning Rate: 0.000943 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2160/12542 | Batch Loss: 1.1396 | Learning Rate: 0.000943 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2161/12542 | Batch Loss: 2.4003 | Learning Rate: 0.000943 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2162/12542 | Batch Loss: 1.4800 | Learning Rate: 0.000943 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2163/12542 | Batch Loss: 1.2027 | Learning Rate: 0.000943 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2164/12542 | Batch Loss: 0.7238 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2165/12542 | Batch Loss: 0.6046 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2166/12542 | Batch Loss: 1.4544 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2167/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2168/12542 | Batch Loss: 0.9716 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2169/12542 | Batch Loss: 0.9954 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2170/12542 | Batch Loss: 2.3216 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2171/12542 | Batch Loss: 0.9726 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2172/12542 | Batch Loss: 1.9497 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2173/12542 | Batch Loss: 1.1945 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2174/12542 | Batch Loss: 1.3239 | Learning Rate: 0.000942 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2175/12542 | Batch Loss: 2.1022 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2176/12542 | Batch Loss: 1.6126 | Learning Rate: 0.000942 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2177/12542 | Batch Loss: 1.3320 | Learning Rate: 0.000942 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2178/12542 | Batch Loss: 0.8941 | Learning Rate: 0.000942 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2179/12542 | Batch Loss: 1.5878 | Learning Rate: 0.000942 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2180/12542 | Batch Loss: 1.7359 | Learning Rate: 0.000942 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2181/12542 | Batch Loss: 1.5496 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2182/12542 | Batch Loss: 0.8249 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2183/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2184/12542 | Batch Loss: 2.2567 | Learning Rate: 0.000942 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2185/12542 | Batch Loss: 0.9859 | Learning Rate: 0.000942 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2186/12542 | Batch Loss: 0.5977 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2187/12542 | Batch Loss: 1.8852 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2188/12542 | Batch Loss: 2.6124 | Learning Rate: 0.000942 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2189/12542 | Batch Loss: 1.8346 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2190/12542 | Batch Loss: 0.6438 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2191/12542 | Batch Loss: 1.2044 | Learning Rate: 0.000942 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2192/12542 | Batch Loss: 2.1028 | Learning Rate: 0.000942 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2193/12542 | Batch Loss: 0.9914 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2194/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2195/12542 | Batch Loss: 1.5446 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2196/12542 | Batch Loss: 2.5181 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2197/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000942 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2198/12542 | Batch Loss: 1.1206 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2199/12542 | Batch Loss: 1.6406 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2200/12542 | Batch Loss: 0.6292 | Learning Rate: 0.000942 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2201/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000942 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2202/12542 | Batch Loss: 1.7377 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2203/12542 | Batch Loss: 0.6733 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2204/12542 | Batch Loss: 2.0640 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2205/12542 | Batch Loss: 1.8666 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2206/12542 | Batch Loss: 1.4107 | Learning Rate: 0.000941 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2207/12542 | Batch Loss: 1.3766 | Learning Rate: 0.000941 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2208/12542 | Batch Loss: 1.2710 | Learning Rate: 0.000941 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2209/12542 | Batch Loss: 0.6569 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2210/12542 | Batch Loss: 1.2289 | Learning Rate: 0.000941 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2211/12542 | Batch Loss: 0.6547 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2212/12542 | Batch Loss: 1.4861 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2213/12542 | Batch Loss: 0.5900 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2214/12542 | Batch Loss: 1.8450 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2215/12542 | Batch Loss: 0.9270 | Learning Rate: 0.000941 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2216/12542 | Batch Loss: 1.3550 | Learning Rate: 0.000941 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2217/12542 | Batch Loss: 0.8742 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2218/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000941 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2219/12542 | Batch Loss: 1.8001 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2220/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2221/12542 | Batch Loss: 2.0389 | Learning Rate: 0.000941 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2222/12542 | Batch Loss: 0.5973 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2223/12542 | Batch Loss: 1.0798 | Learning Rate: 0.000941 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2224/12542 | Batch Loss: 1.1355 | Learning Rate: 0.000941 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2225/12542 | Batch Loss: 0.7489 | Learning Rate: 0.000941 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2226/12542 | Batch Loss: 2.4026 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2227/12542 | Batch Loss: 1.6199 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2228/12542 | Batch Loss: 1.4119 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2229/12542 | Batch Loss: 2.9433 | Learning Rate: 0.000941 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2230/12542 | Batch Loss: 1.7380 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2231/12542 | Batch Loss: 1.3848 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2232/12542 | Batch Loss: 2.3879 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2233/12542 | Batch Loss: 1.3594 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2234/12542 | Batch Loss: 1.5061 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2235/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000941 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2236/12542 | Batch Loss: 1.7173 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2237/12542 | Batch Loss: 1.1179 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2238/12542 | Batch Loss: 1.5503 | Learning Rate: 0.000941 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2239/12542 | Batch Loss: 1.3984 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2240/12542 | Batch Loss: 0.7645 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2241/12542 | Batch Loss: 1.7844 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2242/12542 | Batch Loss: 2.0400 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2243/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2244/12542 | Batch Loss: 2.2627 | Learning Rate: 0.000940 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2245/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2246/12542 | Batch Loss: 1.5232 | Learning Rate: 0.000940 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2247/12542 | Batch Loss: 1.6733 | Learning Rate: 0.000940 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2248/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000940 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2249/12542 | Batch Loss: 1.0406 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2250/12542 | Batch Loss: 1.2369 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2251/12542 | Batch Loss: 2.1007 | Learning Rate: 0.000940 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2252/12542 | Batch Loss: 2.2647 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2253/12542 | Batch Loss: 1.0780 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2254/12542 | Batch Loss: 2.9642 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2255/12542 | Batch Loss: 0.7932 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2256/12542 | Batch Loss: 0.7703 | Learning Rate: 0.000940 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2257/12542 | Batch Loss: 1.8613 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2258/12542 | Batch Loss: 1.4069 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2259/12542 | Batch Loss: 1.1071 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2260/12542 | Batch Loss: 0.9496 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2261/12542 | Batch Loss: 1.3645 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2262/12542 | Batch Loss: 3.6743 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2263/12542 | Batch Loss: 0.6553 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2264/12542 | Batch Loss: 0.7965 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2265/12542 | Batch Loss: 1.7326 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2266/12542 | Batch Loss: 1.8909 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2267/12542 | Batch Loss: 2.9014 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2268/12542 | Batch Loss: 1.8140 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2269/12542 | Batch Loss: 1.3459 | Learning Rate: 0.000940 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2270/12542 | Batch Loss: 2.6033 | Learning Rate: 0.000940 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2271/12542 | Batch Loss: 1.3216 | Learning Rate: 0.000940 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2272/12542 | Batch Loss: 0.9083 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2273/12542 | Batch Loss: 0.7868 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2274/12542 | Batch Loss: 1.7912 | Learning Rate: 0.000940 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2275/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000940 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2276/12542 | Batch Loss: 2.3521 | Learning Rate: 0.000940 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2277/12542 | Batch Loss: 1.4456 | Learning Rate: 0.000939 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2278/12542 | Batch Loss: 2.0468 | Learning Rate: 0.000939 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2279/12542 | Batch Loss: 1.4125 | Learning Rate: 0.000939 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2280/12542 | Batch Loss: 0.7952 | Learning Rate: 0.000939 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2281/12542 | Batch Loss: 1.2025 | Learning Rate: 0.000939 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2282/12542 | Batch Loss: 1.0489 | Learning Rate: 0.000939 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2283/12542 | Batch Loss: 2.3498 | Learning Rate: 0.000939 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2284/12542 | Batch Loss: 2.3465 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2285/12542 | Batch Loss: 1.0507 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2286/12542 | Batch Loss: 1.1113 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2287/12542 | Batch Loss: 1.3805 | Learning Rate: 0.000939 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2288/12542 | Batch Loss: 1.1572 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2289/12542 | Batch Loss: 1.0620 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2290/12542 | Batch Loss: 2.5014 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2291/12542 | Batch Loss: 1.2828 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2292/12542 | Batch Loss: 1.5457 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2293/12542 | Batch Loss: 0.6679 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2294/12542 | Batch Loss: 1.1943 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2295/12542 | Batch Loss: 0.7453 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2296/12542 | Batch Loss: 1.1859 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2297/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000939 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2298/12542 | Batch Loss: 4.9684 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2299/12542 | Batch Loss: 1.1621 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2300/12542 | Batch Loss: 1.0025 | Learning Rate: 0.000939 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2301/12542 | Batch Loss: 1.4026 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2302/12542 | Batch Loss: 1.5890 | Learning Rate: 0.000939 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2303/12542 | Batch Loss: 1.9424 | Learning Rate: 0.000939 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2304/12542 | Batch Loss: 1.8023 | Learning Rate: 0.000939 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2305/12542 | Batch Loss: 1.0853 | Learning Rate: 0.000939 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2306/12542 | Batch Loss: 0.9268 | Learning Rate: 0.000939 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2307/12542 | Batch Loss: 0.9099 | Learning Rate: 0.000939 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2308/12542 | Batch Loss: 2.0022 | Learning Rate: 0.000939 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2309/12542 | Batch Loss: 0.9387 | Learning Rate: 0.000939 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 2310/12542 | Batch Loss: 2.6811 | Learning Rate: 0.000939 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2311/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000939 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2312/12542 | Batch Loss: 1.4457 | Learning Rate: 0.000939 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2313/12542 | Batch Loss: 2.4702 | Learning Rate: 0.000939 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2314/12542 | Batch Loss: 1.0479 | Learning Rate: 0.000938 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2315/12542 | Batch Loss: 1.6828 | Learning Rate: 0.000938 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 2316/12542 | Batch Loss: 0.8335 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2317/12542 | Batch Loss: 1.4033 | Learning Rate: 0.000938 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2318/12542 | Batch Loss: 0.6300 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2319/12542 | Batch Loss: 1.9550 | Learning Rate: 0.000938 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2320/12542 | Batch Loss: 1.0391 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2321/12542 | Batch Loss: 2.4409 | Learning Rate: 0.000938 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2322/12542 | Batch Loss: 1.6458 | Learning Rate: 0.000938 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2323/12542 | Batch Loss: 1.4151 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2324/12542 | Batch Loss: 1.3694 | Learning Rate: 0.000938 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2325/12542 | Batch Loss: 2.2526 | Learning Rate: 0.000938 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2326/12542 | Batch Loss: 2.6327 | Learning Rate: 0.000938 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2327/12542 | Batch Loss: 1.2108 | Learning Rate: 0.000938 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2328/12542 | Batch Loss: 1.6685 | Learning Rate: 0.000938 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2329/12542 | Batch Loss: 0.9930 | Learning Rate: 0.000938 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2330/12542 | Batch Loss: 1.4116 | Learning Rate: 0.000938 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2331/12542 | Batch Loss: 1.6065 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2332/12542 | Batch Loss: 1.5522 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2333/12542 | Batch Loss: 1.8295 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2334/12542 | Batch Loss: 0.8395 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2335/12542 | Batch Loss: 1.2188 | Learning Rate: 0.000938 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2336/12542 | Batch Loss: 2.0378 | Learning Rate: 0.000938 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2337/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000938 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2338/12542 | Batch Loss: 1.3140 | Learning Rate: 0.000938 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2339/12542 | Batch Loss: 1.4543 | Learning Rate: 0.000938 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2340/12542 | Batch Loss: 1.3076 | Learning Rate: 0.000938 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2341/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2342/12542 | Batch Loss: 2.5009 | Learning Rate: 0.000938 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2343/12542 | Batch Loss: 1.5214 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2344/12542 | Batch Loss: 3.5733 | Learning Rate: 0.000938 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2345/12542 | Batch Loss: 1.0791 | Learning Rate: 0.000938 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2346/12542 | Batch Loss: 1.0696 | Learning Rate: 0.000938 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2347/12542 | Batch Loss: 1.3071 | Learning Rate: 0.000938 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2348/12542 | Batch Loss: 0.8137 | Learning Rate: 0.000938 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2349/12542 | Batch Loss: 1.8466 | Learning Rate: 0.000938 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2350/12542 | Batch Loss: 1.1156 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2351/12542 | Batch Loss: 2.6361 | Learning Rate: 0.000938 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2352/12542 | Batch Loss: 0.8696 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2353/12542 | Batch Loss: 1.5067 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2354/12542 | Batch Loss: 0.8290 | Learning Rate: 0.000937 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2355/12542 | Batch Loss: 2.0565 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2356/12542 | Batch Loss: 1.6334 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2357/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2358/12542 | Batch Loss: 1.4278 | Learning Rate: 0.000937 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2359/12542 | Batch Loss: 2.2431 | Learning Rate: 0.000937 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 2360/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000937 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2361/12542 | Batch Loss: 1.0326 | Learning Rate: 0.000937 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2362/12542 | Batch Loss: 2.1964 | Learning Rate: 0.000937 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2363/12542 | Batch Loss: 1.5755 | Learning Rate: 0.000937 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2364/12542 | Batch Loss: 0.7220 | Learning Rate: 0.000937 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2365/12542 | Batch Loss: 1.2649 | Learning Rate: 0.000937 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2366/12542 | Batch Loss: 1.9841 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2367/12542 | Batch Loss: 0.6424 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2368/12542 | Batch Loss: 1.2811 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2369/12542 | Batch Loss: 1.8823 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2370/12542 | Batch Loss: 1.9525 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2371/12542 | Batch Loss: 2.1746 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2372/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2373/12542 | Batch Loss: 0.9252 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2374/12542 | Batch Loss: 1.1488 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2375/12542 | Batch Loss: 2.9765 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2376/12542 | Batch Loss: 2.3507 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2377/12542 | Batch Loss: 1.8372 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2378/12542 | Batch Loss: 1.3041 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2379/12542 | Batch Loss: 1.7798 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2380/12542 | Batch Loss: 0.5253 | Learning Rate: 0.000937 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2381/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2382/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2383/12542 | Batch Loss: 1.3329 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2384/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000937 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2385/12542 | Batch Loss: 0.5419 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2386/12542 | Batch Loss: 1.1017 | Learning Rate: 0.000937 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2387/12542 | Batch Loss: 2.0339 | Learning Rate: 0.000937 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2388/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000937 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2389/12542 | Batch Loss: 0.5714 | Learning Rate: 0.000937 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2390/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2391/12542 | Batch Loss: 1.9234 | Learning Rate: 0.000936 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2392/12542 | Batch Loss: 1.6229 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2393/12542 | Batch Loss: 1.4804 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2394/12542 | Batch Loss: 1.5731 | Learning Rate: 0.000936 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2395/12542 | Batch Loss: 0.9916 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2396/12542 | Batch Loss: 1.3751 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2397/12542 | Batch Loss: 1.9131 | Learning Rate: 0.000936 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2398/12542 | Batch Loss: 0.7855 | Learning Rate: 0.000936 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2399/12542 | Batch Loss: 1.2683 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2400/12542 | Batch Loss: 0.4632 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2401/12542 | Batch Loss: 2.1789 | Learning Rate: 0.000936 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 2402/12542 | Batch Loss: 1.5764 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2403/12542 | Batch Loss: 1.2432 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2404/12542 | Batch Loss: 1.0755 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2405/12542 | Batch Loss: 1.9001 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2406/12542 | Batch Loss: 1.3322 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2407/12542 | Batch Loss: 1.0926 | Learning Rate: 0.000936 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2408/12542 | Batch Loss: 0.8934 | Learning Rate: 0.000936 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2409/12542 | Batch Loss: 0.9162 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2410/12542 | Batch Loss: 1.2422 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2411/12542 | Batch Loss: 2.2471 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2412/12542 | Batch Loss: 6.0825 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2413/12542 | Batch Loss: 1.6278 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2414/12542 | Batch Loss: 0.9700 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2415/12542 | Batch Loss: 1.3164 | Learning Rate: 0.000936 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2416/12542 | Batch Loss: 1.4707 | Learning Rate: 0.000936 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2417/12542 | Batch Loss: 2.5795 | Learning Rate: 0.000936 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2418/12542 | Batch Loss: 1.7762 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2419/12542 | Batch Loss: 0.8672 | Learning Rate: 0.000936 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2420/12542 | Batch Loss: 1.2295 | Learning Rate: 0.000936 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2421/12542 | Batch Loss: 1.6447 | Learning Rate: 0.000936 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2422/12542 | Batch Loss: 1.5390 | Learning Rate: 0.000936 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2423/12542 | Batch Loss: 0.5336 | Learning Rate: 0.000936 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 2424/12542 | Batch Loss: 0.8527 | Learning Rate: 0.000936 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2425/12542 | Batch Loss: 1.9976 | Learning Rate: 0.000936 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2426/12542 | Batch Loss: 1.1002 | Learning Rate: 0.000936 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2427/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000935 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2428/12542 | Batch Loss: 2.5418 | Learning Rate: 0.000935 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2429/12542 | Batch Loss: 1.0190 | Learning Rate: 0.000935 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2430/12542 | Batch Loss: 1.3909 | Learning Rate: 0.000935 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2431/12542 | Batch Loss: 1.9057 | Learning Rate: 0.000935 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2432/12542 | Batch Loss: 1.8161 | Learning Rate: 0.000935 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2433/12542 | Batch Loss: 2.3247 | Learning Rate: 0.000935 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2434/12542 | Batch Loss: 1.9804 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2435/12542 | Batch Loss: 1.1664 | Learning Rate: 0.000935 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2436/12542 | Batch Loss: 1.4836 | Learning Rate: 0.000935 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2437/12542 | Batch Loss: 1.8892 | Learning Rate: 0.000935 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2438/12542 | Batch Loss: 1.2255 | Learning Rate: 0.000935 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2439/12542 | Batch Loss: 1.2334 | Learning Rate: 0.000935 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2440/12542 | Batch Loss: 0.9477 | Learning Rate: 0.000935 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2441/12542 | Batch Loss: 1.3609 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2442/12542 | Batch Loss: 1.5335 | Learning Rate: 0.000935 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2443/12542 | Batch Loss: 0.5859 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2444/12542 | Batch Loss: 2.1437 | Learning Rate: 0.000935 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2445/12542 | Batch Loss: 0.9336 | Learning Rate: 0.000935 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2446/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2447/12542 | Batch Loss: 2.0164 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2448/12542 | Batch Loss: 0.9151 | Learning Rate: 0.000935 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2449/12542 | Batch Loss: 2.0856 | Learning Rate: 0.000935 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2450/12542 | Batch Loss: 1.3592 | Learning Rate: 0.000935 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2451/12542 | Batch Loss: 0.9267 | Learning Rate: 0.000935 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2452/12542 | Batch Loss: 1.0042 | Learning Rate: 0.000935 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2453/12542 | Batch Loss: 0.8144 | Learning Rate: 0.000935 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2454/12542 | Batch Loss: 1.3759 | Learning Rate: 0.000935 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2455/12542 | Batch Loss: 1.9811 | Learning Rate: 0.000935 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2456/12542 | Batch Loss: 0.8439 | Learning Rate: 0.000935 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2457/12542 | Batch Loss: 1.6803 | Learning Rate: 0.000935 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2458/12542 | Batch Loss: 1.8594 | Learning Rate: 0.000935 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2459/12542 | Batch Loss: 1.1590 | Learning Rate: 0.000935 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2460/12542 | Batch Loss: 0.8831 | Learning Rate: 0.000935 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2461/12542 | Batch Loss: 1.4745 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2462/12542 | Batch Loss: 4.3286 | Learning Rate: 0.000935 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2463/12542 | Batch Loss: 0.7878 | Learning Rate: 0.000935 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2464/12542 | Batch Loss: 1.9663 | Learning Rate: 0.000935 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2465/12542 | Batch Loss: 0.9885 | Learning Rate: 0.000934 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2466/12542 | Batch Loss: 1.3382 | Learning Rate: 0.000934 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2467/12542 | Batch Loss: 1.1984 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2468/12542 | Batch Loss: 1.2599 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2469/12542 | Batch Loss: 1.7644 | Learning Rate: 0.000934 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2470/12542 | Batch Loss: 1.2308 | Learning Rate: 0.000934 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2471/12542 | Batch Loss: 2.2814 | Learning Rate: 0.000934 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2472/12542 | Batch Loss: 2.6217 | Learning Rate: 0.000934 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2473/12542 | Batch Loss: 1.4499 | Learning Rate: 0.000934 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2474/12542 | Batch Loss: 1.1776 | Learning Rate: 0.000934 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2475/12542 | Batch Loss: 1.7981 | Learning Rate: 0.000934 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2476/12542 | Batch Loss: 1.6323 | Learning Rate: 0.000934 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2477/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2478/12542 | Batch Loss: 1.6455 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2479/12542 | Batch Loss: 0.9068 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2480/12542 | Batch Loss: 0.9283 | Learning Rate: 0.000934 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2481/12542 | Batch Loss: 1.3368 | Learning Rate: 0.000934 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2482/12542 | Batch Loss: 1.6326 | Learning Rate: 0.000934 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2483/12542 | Batch Loss: 3.1376 | Learning Rate: 0.000934 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2484/12542 | Batch Loss: 2.2358 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2485/12542 | Batch Loss: 2.3510 | Learning Rate: 0.000934 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2486/12542 | Batch Loss: 1.7946 | Learning Rate: 0.000934 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2487/12542 | Batch Loss: 0.7752 | Learning Rate: 0.000934 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2488/12542 | Batch Loss: 1.6780 | Learning Rate: 0.000934 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2489/12542 | Batch Loss: 0.9503 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2490/12542 | Batch Loss: 1.4033 | Learning Rate: 0.000934 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2491/12542 | Batch Loss: 1.4804 | Learning Rate: 0.000934 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2492/12542 | Batch Loss: 1.4179 | Learning Rate: 0.000934 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2493/12542 | Batch Loss: 1.3439 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2494/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000934 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2495/12542 | Batch Loss: 1.0991 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2496/12542 | Batch Loss: 1.1992 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2497/12542 | Batch Loss: 1.1555 | Learning Rate: 0.000934 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2498/12542 | Batch Loss: 1.0287 | Learning Rate: 0.000934 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2499/12542 | Batch Loss: 1.1914 | Learning Rate: 0.000934 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2500/12542 | Batch Loss: 1.7084 | Learning Rate: 0.000934 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2501/12542 | Batch Loss: 1.7906 | Learning Rate: 0.000934 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2502/12542 | Batch Loss: 1.3247 | Learning Rate: 0.000934 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2503/12542 | Batch Loss: 1.0980 | Learning Rate: 0.000933 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2504/12542 | Batch Loss: 0.6487 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2505/12542 | Batch Loss: 2.0591 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2506/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2507/12542 | Batch Loss: 0.8535 | Learning Rate: 0.000933 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2508/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000933 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2509/12542 | Batch Loss: 0.9166 | Learning Rate: 0.000933 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2510/12542 | Batch Loss: 1.1067 | Learning Rate: 0.000933 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2511/12542 | Batch Loss: 1.4441 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2512/12542 | Batch Loss: 3.3139 | Learning Rate: 0.000933 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2513/12542 | Batch Loss: 1.9510 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2514/12542 | Batch Loss: 0.7344 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2515/12542 | Batch Loss: 1.2212 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2516/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000933 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2517/12542 | Batch Loss: 1.4914 | Learning Rate: 0.000933 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2518/12542 | Batch Loss: 1.6586 | Learning Rate: 0.000933 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2519/12542 | Batch Loss: 1.4956 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2520/12542 | Batch Loss: 1.2335 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2521/12542 | Batch Loss: 1.3955 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2522/12542 | Batch Loss: 1.4523 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2523/12542 | Batch Loss: 1.5738 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2524/12542 | Batch Loss: 0.7401 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2525/12542 | Batch Loss: 1.0249 | Learning Rate: 0.000933 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2526/12542 | Batch Loss: 1.9240 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2527/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2528/12542 | Batch Loss: 1.5013 | Learning Rate: 0.000933 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2529/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000933 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2530/12542 | Batch Loss: 2.0943 | Learning Rate: 0.000933 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2531/12542 | Batch Loss: 1.0575 | Learning Rate: 0.000933 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2532/12542 | Batch Loss: 1.0154 | Learning Rate: 0.000933 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2533/12542 | Batch Loss: 1.3222 | Learning Rate: 0.000933 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2534/12542 | Batch Loss: 1.5737 | Learning Rate: 0.000933 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2535/12542 | Batch Loss: 2.3287 | Learning Rate: 0.000933 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2536/12542 | Batch Loss: 2.1944 | Learning Rate: 0.000933 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2537/12542 | Batch Loss: 0.7095 | Learning Rate: 0.000933 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2538/12542 | Batch Loss: 1.0763 | Learning Rate: 0.000933 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2539/12542 | Batch Loss: 1.9111 | Learning Rate: 0.000933 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2540/12542 | Batch Loss: 2.1621 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2541/12542 | Batch Loss: 1.3982 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2542/12542 | Batch Loss: 1.2523 | Learning Rate: 0.000932 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2543/12542 | Batch Loss: 2.4333 | Learning Rate: 0.000932 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2544/12542 | Batch Loss: 1.0574 | Learning Rate: 0.000932 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2545/12542 | Batch Loss: 0.5696 | Learning Rate: 0.000932 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2546/12542 | Batch Loss: 0.9662 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2547/12542 | Batch Loss: 1.3180 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2548/12542 | Batch Loss: 0.4519 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2549/12542 | Batch Loss: 0.8183 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2550/12542 | Batch Loss: 1.3033 | Learning Rate: 0.000932 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2551/12542 | Batch Loss: 2.4451 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2552/12542 | Batch Loss: 0.8183 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2553/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000932 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2554/12542 | Batch Loss: 2.0666 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2555/12542 | Batch Loss: 1.3005 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2556/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2557/12542 | Batch Loss: 1.5335 | Learning Rate: 0.000932 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2558/12542 | Batch Loss: 0.9691 | Learning Rate: 0.000932 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2559/12542 | Batch Loss: 1.1095 | Learning Rate: 0.000932 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2560/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000932 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2561/12542 | Batch Loss: 0.6454 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2562/12542 | Batch Loss: 1.0904 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2563/12542 | Batch Loss: 1.1284 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2564/12542 | Batch Loss: 0.5242 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2565/12542 | Batch Loss: 0.8518 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2566/12542 | Batch Loss: 1.4348 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2567/12542 | Batch Loss: 1.5722 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2568/12542 | Batch Loss: 1.0783 | Learning Rate: 0.000932 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2569/12542 | Batch Loss: 1.6089 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2570/12542 | Batch Loss: 1.8886 | Learning Rate: 0.000932 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2571/12542 | Batch Loss: 1.0066 | Learning Rate: 0.000932 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2572/12542 | Batch Loss: 1.3766 | Learning Rate: 0.000932 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2573/12542 | Batch Loss: 1.7818 | Learning Rate: 0.000932 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2574/12542 | Batch Loss: 2.6475 | Learning Rate: 0.000932 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2575/12542 | Batch Loss: 1.9629 | Learning Rate: 0.000932 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2576/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000932 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2577/12542 | Batch Loss: 2.5584 | Learning Rate: 0.000932 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2578/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2579/12542 | Batch Loss: 1.1887 | Learning Rate: 0.000931 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2580/12542 | Batch Loss: 1.3194 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2581/12542 | Batch Loss: 1.9947 | Learning Rate: 0.000931 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2582/12542 | Batch Loss: 1.3020 | Learning Rate: 0.000931 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2583/12542 | Batch Loss: 1.2695 | Learning Rate: 0.000931 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2584/12542 | Batch Loss: 1.9141 | Learning Rate: 0.000931 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2585/12542 | Batch Loss: 0.8508 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2586/12542 | Batch Loss: 1.3042 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2587/12542 | Batch Loss: 3.2238 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2588/12542 | Batch Loss: 1.6597 | Learning Rate: 0.000931 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2589/12542 | Batch Loss: 1.7771 | Learning Rate: 0.000931 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2590/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000931 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2591/12542 | Batch Loss: 1.0920 | Learning Rate: 0.000931 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2592/12542 | Batch Loss: 0.7039 | Learning Rate: 0.000931 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2593/12542 | Batch Loss: 2.3909 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2594/12542 | Batch Loss: 1.0770 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2595/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000931 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2596/12542 | Batch Loss: 1.3750 | Learning Rate: 0.000931 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2597/12542 | Batch Loss: 0.8079 | Learning Rate: 0.000931 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2598/12542 | Batch Loss: 1.5804 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2599/12542 | Batch Loss: 2.0764 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2600/12542 | Batch Loss: 1.6809 | Learning Rate: 0.000931 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2601/12542 | Batch Loss: 1.5450 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2602/12542 | Batch Loss: 2.1098 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2603/12542 | Batch Loss: 1.4346 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2604/12542 | Batch Loss: 0.8592 | Learning Rate: 0.000931 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2605/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2606/12542 | Batch Loss: 1.9572 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2607/12542 | Batch Loss: 1.4332 | Learning Rate: 0.000931 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2608/12542 | Batch Loss: 1.7537 | Learning Rate: 0.000931 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2609/12542 | Batch Loss: 0.5742 | Learning Rate: 0.000931 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2610/12542 | Batch Loss: 3.8382 | Learning Rate: 0.000931 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2611/12542 | Batch Loss: 1.1287 | Learning Rate: 0.000931 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2612/12542 | Batch Loss: 1.0285 | Learning Rate: 0.000931 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2613/12542 | Batch Loss: 0.7040 | Learning Rate: 0.000931 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2614/12542 | Batch Loss: 1.0595 | Learning Rate: 0.000931 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2615/12542 | Batch Loss: 1.9133 | Learning Rate: 0.000931 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2616/12542 | Batch Loss: 1.2986 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2617/12542 | Batch Loss: 0.9048 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2618/12542 | Batch Loss: 2.2616 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2619/12542 | Batch Loss: 1.2936 | Learning Rate: 0.000930 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2620/12542 | Batch Loss: 0.9118 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2621/12542 | Batch Loss: 1.6023 | Learning Rate: 0.000930 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2622/12542 | Batch Loss: 3.2891 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2623/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2624/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2625/12542 | Batch Loss: 1.7974 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2626/12542 | Batch Loss: 1.2236 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2627/12542 | Batch Loss: 1.1904 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2628/12542 | Batch Loss: 1.4058 | Learning Rate: 0.000930 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2629/12542 | Batch Loss: 1.6619 | Learning Rate: 0.000930 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2630/12542 | Batch Loss: 2.8364 | Learning Rate: 0.000930 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2631/12542 | Batch Loss: 1.3218 | Learning Rate: 0.000930 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2632/12542 | Batch Loss: 1.1767 | Learning Rate: 0.000930 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2633/12542 | Batch Loss: 0.6439 | Learning Rate: 0.000930 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2634/12542 | Batch Loss: 1.8036 | Learning Rate: 0.000930 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2635/12542 | Batch Loss: 2.2706 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2636/12542 | Batch Loss: 0.8995 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2637/12542 | Batch Loss: 1.2237 | Learning Rate: 0.000930 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2638/12542 | Batch Loss: 0.7093 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2639/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2640/12542 | Batch Loss: 0.6791 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2641/12542 | Batch Loss: 1.6518 | Learning Rate: 0.000930 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2642/12542 | Batch Loss: 1.6737 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2643/12542 | Batch Loss: 1.6877 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2644/12542 | Batch Loss: 3.0611 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2645/12542 | Batch Loss: 0.9051 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2646/12542 | Batch Loss: 0.4867 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2647/12542 | Batch Loss: 0.7723 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2648/12542 | Batch Loss: 1.2303 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2649/12542 | Batch Loss: 1.2796 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2650/12542 | Batch Loss: 1.9181 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2651/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2652/12542 | Batch Loss: 1.3061 | Learning Rate: 0.000930 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2653/12542 | Batch Loss: 0.8711 | Learning Rate: 0.000929 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2654/12542 | Batch Loss: 4.4262 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2655/12542 | Batch Loss: 2.1761 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2656/12542 | Batch Loss: 1.8936 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2657/12542 | Batch Loss: 1.2170 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2658/12542 | Batch Loss: 1.5249 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2659/12542 | Batch Loss: 1.6721 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2660/12542 | Batch Loss: 2.0579 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2661/12542 | Batch Loss: 0.9782 | Learning Rate: 0.000929 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2662/12542 | Batch Loss: 1.9966 | Learning Rate: 0.000929 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2663/12542 | Batch Loss: 1.7792 | Learning Rate: 0.000929 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2664/12542 | Batch Loss: 1.8965 | Learning Rate: 0.000929 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 2665/12542 | Batch Loss: 0.5130 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2666/12542 | Batch Loss: 1.0788 | Learning Rate: 0.000929 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2667/12542 | Batch Loss: 1.6002 | Learning Rate: 0.000929 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2668/12542 | Batch Loss: 0.9585 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2669/12542 | Batch Loss: 1.6059 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2670/12542 | Batch Loss: 2.5417 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2671/12542 | Batch Loss: 1.3491 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2672/12542 | Batch Loss: 1.2627 | Learning Rate: 0.000929 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2673/12542 | Batch Loss: 0.9725 | Learning Rate: 0.000929 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2674/12542 | Batch Loss: 0.9052 | Learning Rate: 0.000929 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2675/12542 | Batch Loss: 1.0864 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2676/12542 | Batch Loss: 1.7972 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2677/12542 | Batch Loss: 1.2798 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2678/12542 | Batch Loss: 1.0484 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2679/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2680/12542 | Batch Loss: 0.5954 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2681/12542 | Batch Loss: 0.7350 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2682/12542 | Batch Loss: 1.1365 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2683/12542 | Batch Loss: 0.6528 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2684/12542 | Batch Loss: 1.5602 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2685/12542 | Batch Loss: 2.2720 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2686/12542 | Batch Loss: 1.1063 | Learning Rate: 0.000929 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2687/12542 | Batch Loss: 1.0818 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2688/12542 | Batch Loss: 0.7438 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2689/12542 | Batch Loss: 0.7548 | Learning Rate: 0.000929 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2690/12542 | Batch Loss: 0.5644 | Learning Rate: 0.000929 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2691/12542 | Batch Loss: 1.5342 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2692/12542 | Batch Loss: 1.3165 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2693/12542 | Batch Loss: 1.0620 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2694/12542 | Batch Loss: 0.7041 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2695/12542 | Batch Loss: 2.1802 | Learning Rate: 0.000928 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 2696/12542 | Batch Loss: 1.4268 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2697/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000928 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2698/12542 | Batch Loss: 0.7847 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2699/12542 | Batch Loss: 1.1395 | Learning Rate: 0.000928 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2700/12542 | Batch Loss: 1.4488 | Learning Rate: 0.000928 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2701/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000928 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2702/12542 | Batch Loss: 1.6380 | Learning Rate: 0.000928 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2703/12542 | Batch Loss: 1.3597 | Learning Rate: 0.000928 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2704/12542 | Batch Loss: 1.7510 | Learning Rate: 0.000928 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2705/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000928 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2706/12542 | Batch Loss: 1.0499 | Learning Rate: 0.000928 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2707/12542 | Batch Loss: 1.7221 | Learning Rate: 0.000928 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2708/12542 | Batch Loss: 3.5535 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2709/12542 | Batch Loss: 1.9226 | Learning Rate: 0.000928 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2710/12542 | Batch Loss: 1.5696 | Learning Rate: 0.000928 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2711/12542 | Batch Loss: 1.9789 | Learning Rate: 0.000928 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2712/12542 | Batch Loss: 1.6376 | Learning Rate: 0.000928 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2713/12542 | Batch Loss: 1.1260 | Learning Rate: 0.000928 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2714/12542 | Batch Loss: 1.6418 | Learning Rate: 0.000928 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2715/12542 | Batch Loss: 1.3770 | Learning Rate: 0.000928 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2716/12542 | Batch Loss: 0.9924 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2717/12542 | Batch Loss: 1.0357 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2718/12542 | Batch Loss: 1.8515 | Learning Rate: 0.000928 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2719/12542 | Batch Loss: 1.4117 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2720/12542 | Batch Loss: 1.2708 | Learning Rate: 0.000928 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2721/12542 | Batch Loss: 2.0856 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2722/12542 | Batch Loss: 1.9052 | Learning Rate: 0.000928 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2723/12542 | Batch Loss: 1.0051 | Learning Rate: 0.000928 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2724/12542 | Batch Loss: 1.3516 | Learning Rate: 0.000928 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2725/12542 | Batch Loss: 1.9780 | Learning Rate: 0.000928 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2726/12542 | Batch Loss: 1.5466 | Learning Rate: 0.000928 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2727/12542 | Batch Loss: 1.2771 | Learning Rate: 0.000928 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2728/12542 | Batch Loss: 1.6819 | Learning Rate: 0.000927 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2729/12542 | Batch Loss: 1.9669 | Learning Rate: 0.000927 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2730/12542 | Batch Loss: 0.7895 | Learning Rate: 0.000927 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2731/12542 | Batch Loss: 0.8117 | Learning Rate: 0.000927 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2732/12542 | Batch Loss: 2.1238 | Learning Rate: 0.000927 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2733/12542 | Batch Loss: 1.1793 | Learning Rate: 0.000927 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2734/12542 | Batch Loss: 1.6263 | Learning Rate: 0.000927 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2735/12542 | Batch Loss: 1.2752 | Learning Rate: 0.000927 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2736/12542 | Batch Loss: 2.0432 | Learning Rate: 0.000927 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2737/12542 | Batch Loss: 1.8712 | Learning Rate: 0.000927 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2738/12542 | Batch Loss: 0.7117 | Learning Rate: 0.000927 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2739/12542 | Batch Loss: 0.8595 | Learning Rate: 0.000927 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2740/12542 | Batch Loss: 1.2052 | Learning Rate: 0.000927 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2741/12542 | Batch Loss: 0.9274 | Learning Rate: 0.000927 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2742/12542 | Batch Loss: 2.1766 | Learning Rate: 0.000927 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2743/12542 | Batch Loss: 2.3926 | Learning Rate: 0.000927 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2744/12542 | Batch Loss: 0.5708 | Learning Rate: 0.000927 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2745/12542 | Batch Loss: 0.6047 | Learning Rate: 0.000927 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2746/12542 | Batch Loss: 1.4037 | Learning Rate: 0.000927 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 2747/12542 | Batch Loss: 2.0504 | Learning Rate: 0.000927 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2748/12542 | Batch Loss: 0.5358 | Learning Rate: 0.000927 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2749/12542 | Batch Loss: 2.3083 | Learning Rate: 0.000927 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2750/12542 | Batch Loss: 1.2623 | Learning Rate: 0.000927 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2751/12542 | Batch Loss: 2.0568 | Learning Rate: 0.000927 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2752/12542 | Batch Loss: 0.6696 | Learning Rate: 0.000927 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2753/12542 | Batch Loss: 1.8524 | Learning Rate: 0.000927 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2754/12542 | Batch Loss: 1.9043 | Learning Rate: 0.000927 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2755/12542 | Batch Loss: 1.6654 | Learning Rate: 0.000927 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2756/12542 | Batch Loss: 2.0556 | Learning Rate: 0.000927 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2757/12542 | Batch Loss: 0.9786 | Learning Rate: 0.000927 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2758/12542 | Batch Loss: 0.8618 | Learning Rate: 0.000927 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2759/12542 | Batch Loss: 1.7663 | Learning Rate: 0.000927 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2760/12542 | Batch Loss: 1.4300 | Learning Rate: 0.000927 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2761/12542 | Batch Loss: 1.6821 | Learning Rate: 0.000927 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2762/12542 | Batch Loss: 2.3753 | Learning Rate: 0.000927 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2763/12542 | Batch Loss: 1.7044 | Learning Rate: 0.000927 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2764/12542 | Batch Loss: 1.8154 | Learning Rate: 0.000927 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2765/12542 | Batch Loss: 1.6423 | Learning Rate: 0.000927 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2766/12542 | Batch Loss: 0.7011 | Learning Rate: 0.000926 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2767/12542 | Batch Loss: 1.7048 | Learning Rate: 0.000926 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2768/12542 | Batch Loss: 2.8598 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2769/12542 | Batch Loss: 0.9892 | Learning Rate: 0.000926 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2770/12542 | Batch Loss: 2.0688 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2771/12542 | Batch Loss: 1.7393 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2772/12542 | Batch Loss: 2.2626 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2773/12542 | Batch Loss: 1.3566 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2774/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2775/12542 | Batch Loss: 1.2859 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2776/12542 | Batch Loss: 1.0625 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2777/12542 | Batch Loss: 1.2182 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2778/12542 | Batch Loss: 1.5876 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2779/12542 | Batch Loss: 2.0303 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2780/12542 | Batch Loss: 2.3223 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2781/12542 | Batch Loss: 1.1243 | Learning Rate: 0.000926 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2782/12542 | Batch Loss: 1.1246 | Learning Rate: 0.000926 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 2783/12542 | Batch Loss: 0.9202 | Learning Rate: 0.000926 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2784/12542 | Batch Loss: 3.4055 | Learning Rate: 0.000926 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2785/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2786/12542 | Batch Loss: 1.0210 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2787/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2788/12542 | Batch Loss: 1.3875 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2789/12542 | Batch Loss: 1.3245 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2790/12542 | Batch Loss: 1.7442 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2791/12542 | Batch Loss: 1.3311 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2792/12542 | Batch Loss: 1.9821 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2793/12542 | Batch Loss: 0.9340 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2794/12542 | Batch Loss: 2.1994 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2795/12542 | Batch Loss: 1.5858 | Learning Rate: 0.000926 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2796/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000926 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2797/12542 | Batch Loss: 0.8105 | Learning Rate: 0.000926 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2798/12542 | Batch Loss: 1.4303 | Learning Rate: 0.000926 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2799/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000926 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2800/12542 | Batch Loss: 1.3874 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2801/12542 | Batch Loss: 1.8934 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2802/12542 | Batch Loss: 1.9753 | Learning Rate: 0.000926 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2803/12542 | Batch Loss: 1.5614 | Learning Rate: 0.000926 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2804/12542 | Batch Loss: 0.7523 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2805/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000925 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2806/12542 | Batch Loss: 1.2948 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2807/12542 | Batch Loss: 1.4684 | Learning Rate: 0.000925 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2808/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000925 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2809/12542 | Batch Loss: 2.4849 | Learning Rate: 0.000925 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2810/12542 | Batch Loss: 1.2775 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2811/12542 | Batch Loss: 1.2892 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2812/12542 | Batch Loss: 2.0183 | Learning Rate: 0.000925 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2813/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2814/12542 | Batch Loss: 3.2005 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2815/12542 | Batch Loss: 1.1709 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2816/12542 | Batch Loss: 1.2693 | Learning Rate: 0.000925 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2817/12542 | Batch Loss: 2.1103 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2818/12542 | Batch Loss: 1.1526 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2819/12542 | Batch Loss: 1.0038 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2820/12542 | Batch Loss: 1.4837 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2821/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2822/12542 | Batch Loss: 1.3611 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2823/12542 | Batch Loss: 1.1350 | Learning Rate: 0.000925 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2824/12542 | Batch Loss: 2.9504 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2825/12542 | Batch Loss: 2.1467 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2826/12542 | Batch Loss: 1.7153 | Learning Rate: 0.000925 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2827/12542 | Batch Loss: 1.9421 | Learning Rate: 0.000925 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2828/12542 | Batch Loss: 1.6369 | Learning Rate: 0.000925 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2829/12542 | Batch Loss: 1.5986 | Learning Rate: 0.000925 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2830/12542 | Batch Loss: 1.1834 | Learning Rate: 0.000925 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2831/12542 | Batch Loss: 1.2425 | Learning Rate: 0.000925 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2832/12542 | Batch Loss: 1.3963 | Learning Rate: 0.000925 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2833/12542 | Batch Loss: 2.2792 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2834/12542 | Batch Loss: 1.2491 | Learning Rate: 0.000925 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2835/12542 | Batch Loss: 1.9136 | Learning Rate: 0.000925 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2836/12542 | Batch Loss: 2.7485 | Learning Rate: 0.000925 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2837/12542 | Batch Loss: 1.6734 | Learning Rate: 0.000925 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2838/12542 | Batch Loss: 0.6401 | Learning Rate: 0.000925 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2839/12542 | Batch Loss: 1.3811 | Learning Rate: 0.000925 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2840/12542 | Batch Loss: 0.7148 | Learning Rate: 0.000925 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2841/12542 | Batch Loss: 1.1069 | Learning Rate: 0.000924 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2842/12542 | Batch Loss: 1.2074 | Learning Rate: 0.000924 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2843/12542 | Batch Loss: 2.2697 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2844/12542 | Batch Loss: 1.0898 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2845/12542 | Batch Loss: 2.1561 | Learning Rate: 0.000924 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2846/12542 | Batch Loss: 0.5962 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2847/12542 | Batch Loss: 0.8954 | Learning Rate: 0.000924 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2848/12542 | Batch Loss: 1.7778 | Learning Rate: 0.000924 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2849/12542 | Batch Loss: 1.1394 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2850/12542 | Batch Loss: 2.7819 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2851/12542 | Batch Loss: 1.1712 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2852/12542 | Batch Loss: 1.7041 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2853/12542 | Batch Loss: 1.2252 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2854/12542 | Batch Loss: 2.2132 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2855/12542 | Batch Loss: 2.6990 | Learning Rate: 0.000924 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2856/12542 | Batch Loss: 1.6546 | Learning Rate: 0.000924 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2857/12542 | Batch Loss: 0.8814 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2858/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2859/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2860/12542 | Batch Loss: 1.3401 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2861/12542 | Batch Loss: 1.0911 | Learning Rate: 0.000924 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2862/12542 | Batch Loss: 1.3650 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2863/12542 | Batch Loss: 1.5263 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2864/12542 | Batch Loss: 0.4234 | Learning Rate: 0.000924 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2865/12542 | Batch Loss: 1.4914 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2866/12542 | Batch Loss: 0.9906 | Learning Rate: 0.000924 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2867/12542 | Batch Loss: 1.5367 | Learning Rate: 0.000924 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2868/12542 | Batch Loss: 2.4950 | Learning Rate: 0.000924 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2869/12542 | Batch Loss: 0.8733 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2870/12542 | Batch Loss: 1.7491 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2871/12542 | Batch Loss: 1.4818 | Learning Rate: 0.000924 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2872/12542 | Batch Loss: 1.2858 | Learning Rate: 0.000924 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2873/12542 | Batch Loss: 0.8538 | Learning Rate: 0.000924 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2874/12542 | Batch Loss: 3.0338 | Learning Rate: 0.000924 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2875/12542 | Batch Loss: 1.4440 | Learning Rate: 0.000924 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2876/12542 | Batch Loss: 1.3875 | Learning Rate: 0.000924 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2877/12542 | Batch Loss: 1.6710 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2878/12542 | Batch Loss: 4.9998 | Learning Rate: 0.000924 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2879/12542 | Batch Loss: 0.8497 | Learning Rate: 0.000923 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2880/12542 | Batch Loss: 1.0949 | Learning Rate: 0.000923 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2881/12542 | Batch Loss: 1.1025 | Learning Rate: 0.000923 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2882/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000923 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2883/12542 | Batch Loss: 2.9296 | Learning Rate: 0.000923 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2884/12542 | Batch Loss: 2.6634 | Learning Rate: 0.000923 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2885/12542 | Batch Loss: 4.0578 | Learning Rate: 0.000923 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2886/12542 | Batch Loss: 0.8343 | Learning Rate: 0.000923 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2887/12542 | Batch Loss: 1.2805 | Learning Rate: 0.000923 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2888/12542 | Batch Loss: 1.9533 | Learning Rate: 0.000923 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2889/12542 | Batch Loss: 1.1624 | Learning Rate: 0.000923 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 2890/12542 | Batch Loss: 1.1927 | Learning Rate: 0.000923 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2891/12542 | Batch Loss: 0.7217 | Learning Rate: 0.000923 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 2892/12542 | Batch Loss: 1.4991 | Learning Rate: 0.000923 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2893/12542 | Batch Loss: 1.5695 | Learning Rate: 0.000923 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2894/12542 | Batch Loss: 1.8385 | Learning Rate: 0.000923 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2895/12542 | Batch Loss: 0.9251 | Learning Rate: 0.000923 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2896/12542 | Batch Loss: 1.3506 | Learning Rate: 0.000923 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2897/12542 | Batch Loss: 1.9006 | Learning Rate: 0.000923 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2898/12542 | Batch Loss: 2.1419 | Learning Rate: 0.000923 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2899/12542 | Batch Loss: 0.8790 | Learning Rate: 0.000923 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2900/12542 | Batch Loss: 1.3437 | Learning Rate: 0.000923 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2901/12542 | Batch Loss: 1.4065 | Learning Rate: 0.000923 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2902/12542 | Batch Loss: 2.1389 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2903/12542 | Batch Loss: 1.1375 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2904/12542 | Batch Loss: 1.2151 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2905/12542 | Batch Loss: 0.5508 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2906/12542 | Batch Loss: 0.9443 | Learning Rate: 0.000923 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2907/12542 | Batch Loss: 0.5864 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2908/12542 | Batch Loss: 1.8662 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2909/12542 | Batch Loss: 2.0090 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2910/12542 | Batch Loss: 1.4065 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2911/12542 | Batch Loss: 0.5265 | Learning Rate: 0.000923 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2912/12542 | Batch Loss: 0.5165 | Learning Rate: 0.000923 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2913/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000923 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2914/12542 | Batch Loss: 1.2352 | Learning Rate: 0.000923 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2915/12542 | Batch Loss: 0.6578 | Learning Rate: 0.000923 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2916/12542 | Batch Loss: 0.6184 | Learning Rate: 0.000923 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2917/12542 | Batch Loss: 1.3794 | Learning Rate: 0.000922 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2918/12542 | Batch Loss: 1.8498 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2919/12542 | Batch Loss: 2.8455 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2920/12542 | Batch Loss: 0.8005 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2921/12542 | Batch Loss: 0.6675 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2922/12542 | Batch Loss: 0.6407 | Learning Rate: 0.000922 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2923/12542 | Batch Loss: 1.7412 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2924/12542 | Batch Loss: 1.2721 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2925/12542 | Batch Loss: 1.0703 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2926/12542 | Batch Loss: 2.9811 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2927/12542 | Batch Loss: 1.4122 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2928/12542 | Batch Loss: 1.3981 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2929/12542 | Batch Loss: 1.2403 | Learning Rate: 0.000922 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2930/12542 | Batch Loss: 1.1267 | Learning Rate: 0.000922 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2931/12542 | Batch Loss: 1.7287 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2932/12542 | Batch Loss: 1.7034 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2933/12542 | Batch Loss: 0.8244 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2934/12542 | Batch Loss: 4.1570 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2935/12542 | Batch Loss: 1.5572 | Learning Rate: 0.000922 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2936/12542 | Batch Loss: 1.1980 | Learning Rate: 0.000922 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 2937/12542 | Batch Loss: 2.0061 | Learning Rate: 0.000922 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2938/12542 | Batch Loss: 1.4901 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2939/12542 | Batch Loss: 2.0559 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2940/12542 | Batch Loss: 2.1066 | Learning Rate: 0.000922 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2941/12542 | Batch Loss: 0.6799 | Learning Rate: 0.000922 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2942/12542 | Batch Loss: 0.8508 | Learning Rate: 0.000922 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 2943/12542 | Batch Loss: 2.1152 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2944/12542 | Batch Loss: 0.4639 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2945/12542 | Batch Loss: 0.9637 | Learning Rate: 0.000922 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2946/12542 | Batch Loss: 1.9217 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2947/12542 | Batch Loss: 1.1299 | Learning Rate: 0.000922 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2948/12542 | Batch Loss: 2.3603 | Learning Rate: 0.000922 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2949/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000922 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2950/12542 | Batch Loss: 2.1112 | Learning Rate: 0.000922 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2951/12542 | Batch Loss: 1.4594 | Learning Rate: 0.000922 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2952/12542 | Batch Loss: 0.8842 | Learning Rate: 0.000922 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2953/12542 | Batch Loss: 1.2140 | Learning Rate: 0.000922 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2954/12542 | Batch Loss: 1.1507 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2955/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2956/12542 | Batch Loss: 2.1197 | Learning Rate: 0.000921 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2957/12542 | Batch Loss: 1.2424 | Learning Rate: 0.000921 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 2958/12542 | Batch Loss: 1.0592 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2959/12542 | Batch Loss: 1.9709 | Learning Rate: 0.000921 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2960/12542 | Batch Loss: 2.0744 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2961/12542 | Batch Loss: 0.6651 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2962/12542 | Batch Loss: 0.7605 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2963/12542 | Batch Loss: 1.1922 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2964/12542 | Batch Loss: 0.8351 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2965/12542 | Batch Loss: 2.3796 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2966/12542 | Batch Loss: 2.4305 | Learning Rate: 0.000921 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2967/12542 | Batch Loss: 1.0278 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2968/12542 | Batch Loss: 0.8808 | Learning Rate: 0.000921 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2969/12542 | Batch Loss: 0.8693 | Learning Rate: 0.000921 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 2970/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2971/12542 | Batch Loss: 1.2302 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2972/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2973/12542 | Batch Loss: 1.2404 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2974/12542 | Batch Loss: 1.1266 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2975/12542 | Batch Loss: 0.9217 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2976/12542 | Batch Loss: 1.5290 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2977/12542 | Batch Loss: 0.9688 | Learning Rate: 0.000921 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2978/12542 | Batch Loss: 1.4379 | Learning Rate: 0.000921 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2979/12542 | Batch Loss: 0.8659 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2980/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2981/12542 | Batch Loss: 3.1036 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2982/12542 | Batch Loss: 1.3172 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2983/12542 | Batch Loss: 1.3195 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2984/12542 | Batch Loss: 0.8646 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2985/12542 | Batch Loss: 1.3493 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2986/12542 | Batch Loss: 1.7160 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2987/12542 | Batch Loss: 1.1987 | Learning Rate: 0.000921 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2988/12542 | Batch Loss: 1.5964 | Learning Rate: 0.000921 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2989/12542 | Batch Loss: 1.9620 | Learning Rate: 0.000921 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2990/12542 | Batch Loss: 1.8574 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2991/12542 | Batch Loss: 0.9953 | Learning Rate: 0.000921 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2992/12542 | Batch Loss: 1.3216 | Learning Rate: 0.000920 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 2993/12542 | Batch Loss: 0.9123 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 2994/12542 | Batch Loss: 0.7987 | Learning Rate: 0.000920 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 2995/12542 | Batch Loss: 3.2036 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2996/12542 | Batch Loss: 1.9550 | Learning Rate: 0.000920 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 2997/12542 | Batch Loss: 0.8513 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 2998/12542 | Batch Loss: 0.8979 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 2999/12542 | Batch Loss: 1.1265 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3000/12542 | Batch Loss: 0.6686 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3001/12542 | Batch Loss: 1.9304 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3002/12542 | Batch Loss: 1.3366 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3003/12542 | Batch Loss: 1.2809 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3004/12542 | Batch Loss: 2.1858 | Learning Rate: 0.000920 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3005/12542 | Batch Loss: 1.4987 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3006/12542 | Batch Loss: 2.6359 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3007/12542 | Batch Loss: 1.9030 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3008/12542 | Batch Loss: 0.9943 | Learning Rate: 0.000920 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3009/12542 | Batch Loss: 0.6888 | Learning Rate: 0.000920 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3010/12542 | Batch Loss: 1.1092 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3011/12542 | Batch Loss: 1.5664 | Learning Rate: 0.000920 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3012/12542 | Batch Loss: 0.7623 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3013/12542 | Batch Loss: 0.8618 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3014/12542 | Batch Loss: 0.9425 | Learning Rate: 0.000920 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3015/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000920 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3016/12542 | Batch Loss: 0.5500 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3017/12542 | Batch Loss: 0.7157 | Learning Rate: 0.000920 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3018/12542 | Batch Loss: 1.5044 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3019/12542 | Batch Loss: 0.7128 | Learning Rate: 0.000920 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3020/12542 | Batch Loss: 2.3805 | Learning Rate: 0.000920 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3021/12542 | Batch Loss: 0.9316 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3022/12542 | Batch Loss: 2.2600 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3023/12542 | Batch Loss: 0.8060 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3024/12542 | Batch Loss: 2.2004 | Learning Rate: 0.000920 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3025/12542 | Batch Loss: 1.2247 | Learning Rate: 0.000920 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3026/12542 | Batch Loss: 0.8140 | Learning Rate: 0.000920 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3027/12542 | Batch Loss: 2.5673 | Learning Rate: 0.000920 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3028/12542 | Batch Loss: 1.0113 | Learning Rate: 0.000920 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3029/12542 | Batch Loss: 1.3404 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3030/12542 | Batch Loss: 0.9155 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3031/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3032/12542 | Batch Loss: 0.6721 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3033/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000919 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3034/12542 | Batch Loss: 1.7571 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3035/12542 | Batch Loss: 0.9735 | Learning Rate: 0.000919 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3036/12542 | Batch Loss: 1.2638 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3037/12542 | Batch Loss: 0.5291 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3038/12542 | Batch Loss: 2.8628 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3039/12542 | Batch Loss: 0.8247 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3040/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3041/12542 | Batch Loss: 2.8752 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3042/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3043/12542 | Batch Loss: 1.1128 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3044/12542 | Batch Loss: 1.6842 | Learning Rate: 0.000919 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3045/12542 | Batch Loss: 1.2329 | Learning Rate: 0.000919 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3046/12542 | Batch Loss: 1.6272 | Learning Rate: 0.000919 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3047/12542 | Batch Loss: 2.0229 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3048/12542 | Batch Loss: 1.5270 | Learning Rate: 0.000919 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3049/12542 | Batch Loss: 0.6905 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3050/12542 | Batch Loss: 1.8653 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3051/12542 | Batch Loss: 3.7278 | Learning Rate: 0.000919 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3052/12542 | Batch Loss: 1.5457 | Learning Rate: 0.000919 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3053/12542 | Batch Loss: 1.1288 | Learning Rate: 0.000919 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3054/12542 | Batch Loss: 1.2669 | Learning Rate: 0.000919 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3055/12542 | Batch Loss: 1.7190 | Learning Rate: 0.000919 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3056/12542 | Batch Loss: 1.3263 | Learning Rate: 0.000919 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3057/12542 | Batch Loss: 1.5470 | Learning Rate: 0.000919 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3058/12542 | Batch Loss: 0.8988 | Learning Rate: 0.000919 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3059/12542 | Batch Loss: 1.2774 | Learning Rate: 0.000919 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3060/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000919 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3061/12542 | Batch Loss: 1.1742 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3062/12542 | Batch Loss: 0.4575 | Learning Rate: 0.000919 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3063/12542 | Batch Loss: 1.6620 | Learning Rate: 0.000919 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3064/12542 | Batch Loss: 1.5361 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3065/12542 | Batch Loss: 3.5144 | Learning Rate: 0.000919 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3066/12542 | Batch Loss: 2.2632 | Learning Rate: 0.000919 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3067/12542 | Batch Loss: 0.8575 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3068/12542 | Batch Loss: 1.3852 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3069/12542 | Batch Loss: 0.9878 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3070/12542 | Batch Loss: 1.6293 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3071/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3072/12542 | Batch Loss: 2.4917 | Learning Rate: 0.000918 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3073/12542 | Batch Loss: 1.0396 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3074/12542 | Batch Loss: 1.3264 | Learning Rate: 0.000918 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3075/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3076/12542 | Batch Loss: 0.9440 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3077/12542 | Batch Loss: 1.4886 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3078/12542 | Batch Loss: 1.9923 | Learning Rate: 0.000918 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3079/12542 | Batch Loss: 3.4124 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3080/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3081/12542 | Batch Loss: 1.6751 | Learning Rate: 0.000918 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3082/12542 | Batch Loss: 0.8603 | Learning Rate: 0.000918 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3083/12542 | Batch Loss: 1.2144 | Learning Rate: 0.000918 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3084/12542 | Batch Loss: 1.8068 | Learning Rate: 0.000918 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3085/12542 | Batch Loss: 2.4008 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3086/12542 | Batch Loss: 1.4780 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3087/12542 | Batch Loss: 1.0659 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3088/12542 | Batch Loss: 0.8879 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3089/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3090/12542 | Batch Loss: 1.5044 | Learning Rate: 0.000918 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3091/12542 | Batch Loss: 1.8277 | Learning Rate: 0.000918 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3092/12542 | Batch Loss: 1.3418 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3093/12542 | Batch Loss: 1.3261 | Learning Rate: 0.000918 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3094/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000918 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3095/12542 | Batch Loss: 1.0571 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3096/12542 | Batch Loss: 0.6441 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3097/12542 | Batch Loss: 0.8744 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3098/12542 | Batch Loss: 1.2133 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3099/12542 | Batch Loss: 2.0564 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3100/12542 | Batch Loss: 2.1224 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3101/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000918 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3102/12542 | Batch Loss: 1.6582 | Learning Rate: 0.000918 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3103/12542 | Batch Loss: 0.8733 | Learning Rate: 0.000918 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3104/12542 | Batch Loss: 1.1803 | Learning Rate: 0.000918 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3105/12542 | Batch Loss: 1.1232 | Learning Rate: 0.000917 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3106/12542 | Batch Loss: 1.0092 | Learning Rate: 0.000917 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3107/12542 | Batch Loss: 1.2906 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3108/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000917 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3109/12542 | Batch Loss: 1.4455 | Learning Rate: 0.000917 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3110/12542 | Batch Loss: 1.5096 | Learning Rate: 0.000917 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3111/12542 | Batch Loss: 2.4941 | Learning Rate: 0.000917 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3112/12542 | Batch Loss: 1.1255 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3113/12542 | Batch Loss: 1.0871 | Learning Rate: 0.000917 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3114/12542 | Batch Loss: 1.2422 | Learning Rate: 0.000917 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3115/12542 | Batch Loss: 2.4441 | Learning Rate: 0.000917 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3116/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3117/12542 | Batch Loss: 1.7274 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3118/12542 | Batch Loss: 0.9680 | Learning Rate: 0.000917 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3119/12542 | Batch Loss: 1.7587 | Learning Rate: 0.000917 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3120/12542 | Batch Loss: 1.2630 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3121/12542 | Batch Loss: 0.5862 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3122/12542 | Batch Loss: 1.6494 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3123/12542 | Batch Loss: 0.6520 | Learning Rate: 0.000917 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3124/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3125/12542 | Batch Loss: 1.6185 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3126/12542 | Batch Loss: 0.5875 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3127/12542 | Batch Loss: 0.8126 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3128/12542 | Batch Loss: 1.3496 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3129/12542 | Batch Loss: 0.9295 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3130/12542 | Batch Loss: 4.5515 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3131/12542 | Batch Loss: 1.6517 | Learning Rate: 0.000917 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3132/12542 | Batch Loss: 1.3339 | Learning Rate: 0.000917 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3133/12542 | Batch Loss: 1.4878 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3134/12542 | Batch Loss: 2.0237 | Learning Rate: 0.000917 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3135/12542 | Batch Loss: 1.5144 | Learning Rate: 0.000917 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3136/12542 | Batch Loss: 1.7897 | Learning Rate: 0.000917 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3137/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000917 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3138/12542 | Batch Loss: 1.2310 | Learning Rate: 0.000917 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3139/12542 | Batch Loss: 2.2671 | Learning Rate: 0.000917 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3140/12542 | Batch Loss: 1.6164 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3141/12542 | Batch Loss: 1.2167 | Learning Rate: 0.000917 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3142/12542 | Batch Loss: 1.8927 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3143/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000916 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3144/12542 | Batch Loss: 0.8300 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3145/12542 | Batch Loss: 0.5951 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3146/12542 | Batch Loss: 1.4164 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3147/12542 | Batch Loss: 1.0537 | Learning Rate: 0.000916 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3148/12542 | Batch Loss: 1.5124 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3149/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3150/12542 | Batch Loss: 1.1918 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3151/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3152/12542 | Batch Loss: 0.5839 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3153/12542 | Batch Loss: 0.7999 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3154/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3155/12542 | Batch Loss: 2.2453 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3156/12542 | Batch Loss: 0.7322 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3157/12542 | Batch Loss: 1.4333 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3158/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3159/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3160/12542 | Batch Loss: 0.8709 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3161/12542 | Batch Loss: 1.2018 | Learning Rate: 0.000916 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3162/12542 | Batch Loss: 1.8198 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3163/12542 | Batch Loss: 1.0815 | Learning Rate: 0.000916 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 3164/12542 | Batch Loss: 1.8938 | Learning Rate: 0.000916 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3165/12542 | Batch Loss: 2.7738 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3166/12542 | Batch Loss: 1.8921 | Learning Rate: 0.000916 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3167/12542 | Batch Loss: 1.4140 | Learning Rate: 0.000916 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3168/12542 | Batch Loss: 1.2111 | Learning Rate: 0.000916 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3169/12542 | Batch Loss: 0.8159 | Learning Rate: 0.000916 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3170/12542 | Batch Loss: 0.8698 | Learning Rate: 0.000916 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3171/12542 | Batch Loss: 0.7626 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3172/12542 | Batch Loss: 1.7065 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3173/12542 | Batch Loss: 0.8050 | Learning Rate: 0.000916 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3174/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3175/12542 | Batch Loss: 2.4366 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3176/12542 | Batch Loss: 1.1842 | Learning Rate: 0.000916 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3177/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3178/12542 | Batch Loss: 2.1640 | Learning Rate: 0.000916 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3179/12542 | Batch Loss: 1.9094 | Learning Rate: 0.000916 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3180/12542 | Batch Loss: 0.9405 | Learning Rate: 0.000915 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3181/12542 | Batch Loss: 1.1804 | Learning Rate: 0.000915 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3182/12542 | Batch Loss: 1.3775 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3183/12542 | Batch Loss: 0.9479 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3184/12542 | Batch Loss: 2.6005 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3185/12542 | Batch Loss: 1.6242 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3186/12542 | Batch Loss: 1.0730 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3187/12542 | Batch Loss: 1.1741 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3188/12542 | Batch Loss: 1.0116 | Learning Rate: 0.000915 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3189/12542 | Batch Loss: 0.8674 | Learning Rate: 0.000915 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3190/12542 | Batch Loss: 1.6494 | Learning Rate: 0.000915 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3191/12542 | Batch Loss: 1.8542 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3192/12542 | Batch Loss: 2.4121 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3193/12542 | Batch Loss: 1.0993 | Learning Rate: 0.000915 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3194/12542 | Batch Loss: 0.5906 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3195/12542 | Batch Loss: 1.1336 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3196/12542 | Batch Loss: 0.9314 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3197/12542 | Batch Loss: 1.5980 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3198/12542 | Batch Loss: 1.4501 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3199/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3200/12542 | Batch Loss: 1.0547 | Learning Rate: 0.000915 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3201/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000915 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3202/12542 | Batch Loss: 0.7968 | Learning Rate: 0.000915 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3203/12542 | Batch Loss: 1.4428 | Learning Rate: 0.000915 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3204/12542 | Batch Loss: 1.3268 | Learning Rate: 0.000915 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3205/12542 | Batch Loss: 1.7648 | Learning Rate: 0.000915 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3206/12542 | Batch Loss: 3.1202 | Learning Rate: 0.000915 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3207/12542 | Batch Loss: 0.7878 | Learning Rate: 0.000915 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3208/12542 | Batch Loss: 1.5316 | Learning Rate: 0.000915 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3209/12542 | Batch Loss: 1.3705 | Learning Rate: 0.000915 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3210/12542 | Batch Loss: 1.0432 | Learning Rate: 0.000915 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3211/12542 | Batch Loss: 0.9237 | Learning Rate: 0.000915 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3212/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000915 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3213/12542 | Batch Loss: 1.1057 | Learning Rate: 0.000915 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3214/12542 | Batch Loss: 1.4046 | Learning Rate: 0.000915 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3215/12542 | Batch Loss: 1.9789 | Learning Rate: 0.000915 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3216/12542 | Batch Loss: 0.9859 | Learning Rate: 0.000915 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3217/12542 | Batch Loss: 0.7259 | Learning Rate: 0.000915 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3218/12542 | Batch Loss: 2.0806 | Learning Rate: 0.000914 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3219/12542 | Batch Loss: 1.3695 | Learning Rate: 0.000914 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3220/12542 | Batch Loss: 1.9717 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3221/12542 | Batch Loss: 3.3659 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3222/12542 | Batch Loss: 1.4467 | Learning Rate: 0.000914 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3223/12542 | Batch Loss: 1.4314 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3224/12542 | Batch Loss: 3.1718 | Learning Rate: 0.000914 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3225/12542 | Batch Loss: 1.0914 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3226/12542 | Batch Loss: 1.6708 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3227/12542 | Batch Loss: 1.1875 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3228/12542 | Batch Loss: 0.8101 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3229/12542 | Batch Loss: 3.6892 | Learning Rate: 0.000914 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3230/12542 | Batch Loss: 0.9795 | Learning Rate: 0.000914 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3231/12542 | Batch Loss: 2.1303 | Learning Rate: 0.000914 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3232/12542 | Batch Loss: 1.9662 | Learning Rate: 0.000914 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3233/12542 | Batch Loss: 3.3445 | Learning Rate: 0.000914 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3234/12542 | Batch Loss: 1.6928 | Learning Rate: 0.000914 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3235/12542 | Batch Loss: 0.8386 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3236/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3237/12542 | Batch Loss: 1.4895 | Learning Rate: 0.000914 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3238/12542 | Batch Loss: 1.4087 | Learning Rate: 0.000914 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3239/12542 | Batch Loss: 1.0035 | Learning Rate: 0.000914 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3240/12542 | Batch Loss: 0.7446 | Learning Rate: 0.000914 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3241/12542 | Batch Loss: 1.7041 | Learning Rate: 0.000914 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3242/12542 | Batch Loss: 1.8363 | Learning Rate: 0.000914 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3243/12542 | Batch Loss: 1.2301 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3244/12542 | Batch Loss: 1.4504 | Learning Rate: 0.000914 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3245/12542 | Batch Loss: 1.8140 | Learning Rate: 0.000914 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3246/12542 | Batch Loss: 1.5991 | Learning Rate: 0.000914 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3247/12542 | Batch Loss: 1.4990 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3248/12542 | Batch Loss: 0.7612 | Learning Rate: 0.000914 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3249/12542 | Batch Loss: 1.0925 | Learning Rate: 0.000914 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3250/12542 | Batch Loss: 2.7298 | Learning Rate: 0.000914 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3251/12542 | Batch Loss: 1.0422 | Learning Rate: 0.000914 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3252/12542 | Batch Loss: 0.6971 | Learning Rate: 0.000914 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3253/12542 | Batch Loss: 0.6353 | Learning Rate: 0.000914 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3254/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000914 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3255/12542 | Batch Loss: 1.5584 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3256/12542 | Batch Loss: 0.5564 | Learning Rate: 0.000913 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3257/12542 | Batch Loss: 0.7519 | Learning Rate: 0.000913 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3258/12542 | Batch Loss: 0.3358 | Learning Rate: 0.000913 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3259/12542 | Batch Loss: 0.8221 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3260/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3261/12542 | Batch Loss: 0.8562 | Learning Rate: 0.000913 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3262/12542 | Batch Loss: 0.7809 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3263/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000913 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3264/12542 | Batch Loss: 1.2489 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3265/12542 | Batch Loss: 2.0715 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3266/12542 | Batch Loss: 0.7585 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3267/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000913 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3268/12542 | Batch Loss: 1.4101 | Learning Rate: 0.000913 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3269/12542 | Batch Loss: 1.5503 | Learning Rate: 0.000913 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3270/12542 | Batch Loss: 1.4148 | Learning Rate: 0.000913 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3271/12542 | Batch Loss: 0.7855 | Learning Rate: 0.000913 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3272/12542 | Batch Loss: 1.5750 | Learning Rate: 0.000913 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3273/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3274/12542 | Batch Loss: 1.4683 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3275/12542 | Batch Loss: 0.9693 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3276/12542 | Batch Loss: 2.2673 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3277/12542 | Batch Loss: 1.0081 | Learning Rate: 0.000913 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3278/12542 | Batch Loss: 1.4349 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3279/12542 | Batch Loss: 1.9779 | Learning Rate: 0.000913 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3280/12542 | Batch Loss: 1.5435 | Learning Rate: 0.000913 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3281/12542 | Batch Loss: 1.4021 | Learning Rate: 0.000913 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3282/12542 | Batch Loss: 0.4960 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3283/12542 | Batch Loss: 1.4631 | Learning Rate: 0.000913 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3284/12542 | Batch Loss: 1.4127 | Learning Rate: 0.000913 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3285/12542 | Batch Loss: 0.7751 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3286/12542 | Batch Loss: 0.6838 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3287/12542 | Batch Loss: 2.3191 | Learning Rate: 0.000913 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3288/12542 | Batch Loss: 1.4101 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3289/12542 | Batch Loss: 1.0834 | Learning Rate: 0.000913 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3290/12542 | Batch Loss: 1.5179 | Learning Rate: 0.000913 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3291/12542 | Batch Loss: 0.7183 | Learning Rate: 0.000913 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3292/12542 | Batch Loss: 1.5940 | Learning Rate: 0.000913 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3293/12542 | Batch Loss: 1.6242 | Learning Rate: 0.000912 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3294/12542 | Batch Loss: 0.7895 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3295/12542 | Batch Loss: 0.8419 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3296/12542 | Batch Loss: 1.8396 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3297/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3298/12542 | Batch Loss: 1.0739 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3299/12542 | Batch Loss: 1.5198 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3300/12542 | Batch Loss: 0.8223 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3301/12542 | Batch Loss: 1.3767 | Learning Rate: 0.000912 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3302/12542 | Batch Loss: 1.4931 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3303/12542 | Batch Loss: 0.6511 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3304/12542 | Batch Loss: 1.4929 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3305/12542 | Batch Loss: 1.2201 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3306/12542 | Batch Loss: 0.9680 | Learning Rate: 0.000912 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3307/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3308/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000912 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3309/12542 | Batch Loss: 1.8034 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3310/12542 | Batch Loss: 0.9676 | Learning Rate: 0.000912 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3311/12542 | Batch Loss: 0.5893 | Learning Rate: 0.000912 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3312/12542 | Batch Loss: 0.5620 | Learning Rate: 0.000912 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3313/12542 | Batch Loss: 1.8599 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3314/12542 | Batch Loss: 2.4106 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3315/12542 | Batch Loss: 1.1558 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3316/12542 | Batch Loss: 1.5062 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3317/12542 | Batch Loss: 2.3839 | Learning Rate: 0.000912 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3318/12542 | Batch Loss: 1.3307 | Learning Rate: 0.000912 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3319/12542 | Batch Loss: 1.7853 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3320/12542 | Batch Loss: 0.7501 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3321/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000912 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3322/12542 | Batch Loss: 1.3494 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3323/12542 | Batch Loss: 0.7599 | Learning Rate: 0.000912 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3324/12542 | Batch Loss: 1.4451 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3325/12542 | Batch Loss: 3.1247 | Learning Rate: 0.000912 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3326/12542 | Batch Loss: 1.4465 | Learning Rate: 0.000912 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3327/12542 | Batch Loss: 1.8648 | Learning Rate: 0.000912 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3328/12542 | Batch Loss: 1.5125 | Learning Rate: 0.000912 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3329/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000912 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3330/12542 | Batch Loss: 1.4970 | Learning Rate: 0.000911 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3331/12542 | Batch Loss: 0.7913 | Learning Rate: 0.000911 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3332/12542 | Batch Loss: 1.0779 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3333/12542 | Batch Loss: 2.1269 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3334/12542 | Batch Loss: 1.2547 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3335/12542 | Batch Loss: 0.9939 | Learning Rate: 0.000911 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3336/12542 | Batch Loss: 1.2664 | Learning Rate: 0.000911 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3337/12542 | Batch Loss: 1.9192 | Learning Rate: 0.000911 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3338/12542 | Batch Loss: 0.7725 | Learning Rate: 0.000911 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3339/12542 | Batch Loss: 1.4328 | Learning Rate: 0.000911 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3340/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000911 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3341/12542 | Batch Loss: 2.0151 | Learning Rate: 0.000911 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3342/12542 | Batch Loss: 1.2107 | Learning Rate: 0.000911 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3343/12542 | Batch Loss: 1.0226 | Learning Rate: 0.000911 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3344/12542 | Batch Loss: 1.2063 | Learning Rate: 0.000911 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3345/12542 | Batch Loss: 2.5659 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3346/12542 | Batch Loss: 1.6123 | Learning Rate: 0.000911 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3347/12542 | Batch Loss: 1.9094 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3348/12542 | Batch Loss: 1.0729 | Learning Rate: 0.000911 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3349/12542 | Batch Loss: 1.9457 | Learning Rate: 0.000911 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3350/12542 | Batch Loss: 2.0876 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3351/12542 | Batch Loss: 1.0007 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3352/12542 | Batch Loss: 1.5307 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3353/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3354/12542 | Batch Loss: 2.3492 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3355/12542 | Batch Loss: 1.0621 | Learning Rate: 0.000911 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3356/12542 | Batch Loss: 0.8769 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3357/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3358/12542 | Batch Loss: 2.8124 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3359/12542 | Batch Loss: 1.2503 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3360/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3361/12542 | Batch Loss: 1.5271 | Learning Rate: 0.000911 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3362/12542 | Batch Loss: 0.8859 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3363/12542 | Batch Loss: 1.2457 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3364/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000911 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3365/12542 | Batch Loss: 0.9756 | Learning Rate: 0.000911 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3366/12542 | Batch Loss: 1.3080 | Learning Rate: 0.000911 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3367/12542 | Batch Loss: 1.6026 | Learning Rate: 0.000911 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3368/12542 | Batch Loss: 1.4296 | Learning Rate: 0.000910 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3369/12542 | Batch Loss: 1.5745 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3370/12542 | Batch Loss: 0.6710 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3371/12542 | Batch Loss: 1.2498 | Learning Rate: 0.000910 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3372/12542 | Batch Loss: 2.9401 | Learning Rate: 0.000910 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3373/12542 | Batch Loss: 0.7286 | Learning Rate: 0.000910 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3374/12542 | Batch Loss: 1.7559 | Learning Rate: 0.000910 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3375/12542 | Batch Loss: 1.6501 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3376/12542 | Batch Loss: 1.8728 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3377/12542 | Batch Loss: 1.3206 | Learning Rate: 0.000910 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3378/12542 | Batch Loss: 0.8730 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3379/12542 | Batch Loss: 0.9434 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3380/12542 | Batch Loss: 0.4067 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3381/12542 | Batch Loss: 0.4569 | Learning Rate: 0.000910 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3382/12542 | Batch Loss: 2.3803 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3383/12542 | Batch Loss: 1.9639 | Learning Rate: 0.000910 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3384/12542 | Batch Loss: 1.4918 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3385/12542 | Batch Loss: 1.9568 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3386/12542 | Batch Loss: 2.1196 | Learning Rate: 0.000910 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3387/12542 | Batch Loss: 1.4393 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3388/12542 | Batch Loss: 1.4739 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3389/12542 | Batch Loss: 2.8036 | Learning Rate: 0.000910 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3390/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000910 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3391/12542 | Batch Loss: 1.1568 | Learning Rate: 0.000910 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3392/12542 | Batch Loss: 1.9949 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3393/12542 | Batch Loss: 2.6954 | Learning Rate: 0.000910 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3394/12542 | Batch Loss: 1.3484 | Learning Rate: 0.000910 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3395/12542 | Batch Loss: 1.1867 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3396/12542 | Batch Loss: 1.2318 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3397/12542 | Batch Loss: 1.2559 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3398/12542 | Batch Loss: 1.6866 | Learning Rate: 0.000910 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3399/12542 | Batch Loss: 2.1125 | Learning Rate: 0.000910 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3400/12542 | Batch Loss: 2.9964 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3401/12542 | Batch Loss: 0.8881 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3402/12542 | Batch Loss: 2.8683 | Learning Rate: 0.000910 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3403/12542 | Batch Loss: 0.6592 | Learning Rate: 0.000910 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3404/12542 | Batch Loss: 2.9528 | Learning Rate: 0.000910 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3405/12542 | Batch Loss: 1.6418 | Learning Rate: 0.000910 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3406/12542 | Batch Loss: 0.9753 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3407/12542 | Batch Loss: 1.3457 | Learning Rate: 0.000909 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3408/12542 | Batch Loss: 1.9393 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3409/12542 | Batch Loss: 1.6171 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3410/12542 | Batch Loss: 1.8648 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3411/12542 | Batch Loss: 1.4010 | Learning Rate: 0.000909 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3412/12542 | Batch Loss: 0.6434 | Learning Rate: 0.000909 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3413/12542 | Batch Loss: 1.2409 | Learning Rate: 0.000909 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3414/12542 | Batch Loss: 1.5092 | Learning Rate: 0.000909 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3415/12542 | Batch Loss: 0.8216 | Learning Rate: 0.000909 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3416/12542 | Batch Loss: 2.2345 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3417/12542 | Batch Loss: 2.4022 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3418/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3419/12542 | Batch Loss: 1.3408 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3420/12542 | Batch Loss: 1.0459 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3421/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3422/12542 | Batch Loss: 1.3499 | Learning Rate: 0.000909 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3423/12542 | Batch Loss: 2.3860 | Learning Rate: 0.000909 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3424/12542 | Batch Loss: 2.7937 | Learning Rate: 0.000909 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3425/12542 | Batch Loss: 0.8453 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3426/12542 | Batch Loss: 1.0079 | Learning Rate: 0.000909 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3427/12542 | Batch Loss: 0.7841 | Learning Rate: 0.000909 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 3428/12542 | Batch Loss: 3.3990 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3429/12542 | Batch Loss: 1.2651 | Learning Rate: 0.000909 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3430/12542 | Batch Loss: 2.0397 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3431/12542 | Batch Loss: 1.2410 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3432/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3433/12542 | Batch Loss: 0.6052 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3434/12542 | Batch Loss: 0.9621 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3435/12542 | Batch Loss: 0.7056 | Learning Rate: 0.000909 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3436/12542 | Batch Loss: 0.7662 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3437/12542 | Batch Loss: 1.5213 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3438/12542 | Batch Loss: 2.0040 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3439/12542 | Batch Loss: 1.0600 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3440/12542 | Batch Loss: 0.5181 | Learning Rate: 0.000909 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3441/12542 | Batch Loss: 1.6172 | Learning Rate: 0.000909 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3442/12542 | Batch Loss: 1.9040 | Learning Rate: 0.000909 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3443/12542 | Batch Loss: 1.8006 | Learning Rate: 0.000908 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3444/12542 | Batch Loss: 0.5875 | Learning Rate: 0.000908 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3445/12542 | Batch Loss: 1.0843 | Learning Rate: 0.000908 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3446/12542 | Batch Loss: 0.9079 | Learning Rate: 0.000908 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3447/12542 | Batch Loss: 0.6471 | Learning Rate: 0.000908 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3448/12542 | Batch Loss: 2.0807 | Learning Rate: 0.000908 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3449/12542 | Batch Loss: 1.4580 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3450/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000908 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3451/12542 | Batch Loss: 1.5633 | Learning Rate: 0.000908 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3452/12542 | Batch Loss: 1.1009 | Learning Rate: 0.000908 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3453/12542 | Batch Loss: 1.1768 | Learning Rate: 0.000908 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3454/12542 | Batch Loss: 3.2636 | Learning Rate: 0.000908 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3455/12542 | Batch Loss: 0.8014 | Learning Rate: 0.000908 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3456/12542 | Batch Loss: 1.6748 | Learning Rate: 0.000908 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3457/12542 | Batch Loss: 1.7071 | Learning Rate: 0.000908 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3458/12542 | Batch Loss: 1.6302 | Learning Rate: 0.000908 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3459/12542 | Batch Loss: 1.0908 | Learning Rate: 0.000908 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3460/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3461/12542 | Batch Loss: 1.3674 | Learning Rate: 0.000908 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3462/12542 | Batch Loss: 0.8150 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3463/12542 | Batch Loss: 0.8003 | Learning Rate: 0.000908 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3464/12542 | Batch Loss: 1.0901 | Learning Rate: 0.000908 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3465/12542 | Batch Loss: 1.8430 | Learning Rate: 0.000908 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3466/12542 | Batch Loss: 2.3765 | Learning Rate: 0.000908 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3467/12542 | Batch Loss: 1.6986 | Learning Rate: 0.000908 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3468/12542 | Batch Loss: 1.8471 | Learning Rate: 0.000908 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3469/12542 | Batch Loss: 1.6832 | Learning Rate: 0.000908 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3470/12542 | Batch Loss: 0.7526 | Learning Rate: 0.000908 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3471/12542 | Batch Loss: 1.4631 | Learning Rate: 0.000908 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3472/12542 | Batch Loss: 1.0926 | Learning Rate: 0.000908 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3473/12542 | Batch Loss: 1.3021 | Learning Rate: 0.000908 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3474/12542 | Batch Loss: 1.0895 | Learning Rate: 0.000908 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3475/12542 | Batch Loss: 2.3813 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3476/12542 | Batch Loss: 1.2094 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3477/12542 | Batch Loss: 0.8079 | Learning Rate: 0.000908 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3478/12542 | Batch Loss: 1.8807 | Learning Rate: 0.000908 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3479/12542 | Batch Loss: 0.9478 | Learning Rate: 0.000908 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3480/12542 | Batch Loss: 0.9594 | Learning Rate: 0.000908 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3481/12542 | Batch Loss: 1.0318 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3482/12542 | Batch Loss: 1.4918 | Learning Rate: 0.000907 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3483/12542 | Batch Loss: 1.3005 | Learning Rate: 0.000907 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3484/12542 | Batch Loss: 1.2458 | Learning Rate: 0.000907 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3485/12542 | Batch Loss: 0.8658 | Learning Rate: 0.000907 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3486/12542 | Batch Loss: 2.0973 | Learning Rate: 0.000907 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3487/12542 | Batch Loss: 1.2892 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3488/12542 | Batch Loss: 0.6643 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3489/12542 | Batch Loss: 1.2023 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3490/12542 | Batch Loss: 1.3825 | Learning Rate: 0.000907 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3491/12542 | Batch Loss: 1.9198 | Learning Rate: 0.000907 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3492/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3493/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3494/12542 | Batch Loss: 3.4639 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3495/12542 | Batch Loss: 1.0509 | Learning Rate: 0.000907 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3496/12542 | Batch Loss: 1.3211 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3497/12542 | Batch Loss: 2.0838 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3498/12542 | Batch Loss: 1.5098 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3499/12542 | Batch Loss: 1.5712 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3500/12542 | Batch Loss: 1.9128 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3501/12542 | Batch Loss: 1.6753 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3502/12542 | Batch Loss: 2.6223 | Learning Rate: 0.000907 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3503/12542 | Batch Loss: 1.3562 | Learning Rate: 0.000907 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3504/12542 | Batch Loss: 0.8021 | Learning Rate: 0.000907 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3505/12542 | Batch Loss: 1.4174 | Learning Rate: 0.000907 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3506/12542 | Batch Loss: 1.2780 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3507/12542 | Batch Loss: 0.5134 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3508/12542 | Batch Loss: 2.4267 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3509/12542 | Batch Loss: 1.3402 | Learning Rate: 0.000907 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3510/12542 | Batch Loss: 0.6175 | Learning Rate: 0.000907 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3511/12542 | Batch Loss: 1.0790 | Learning Rate: 0.000907 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3512/12542 | Batch Loss: 1.4535 | Learning Rate: 0.000907 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3513/12542 | Batch Loss: 1.7131 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3514/12542 | Batch Loss: 1.7594 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3515/12542 | Batch Loss: 1.1453 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3516/12542 | Batch Loss: 0.9018 | Learning Rate: 0.000907 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3517/12542 | Batch Loss: 0.7576 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3518/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000907 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3519/12542 | Batch Loss: 1.7734 | Learning Rate: 0.000906 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3520/12542 | Batch Loss: 1.2545 | Learning Rate: 0.000906 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3521/12542 | Batch Loss: 1.0399 | Learning Rate: 0.000906 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3522/12542 | Batch Loss: 0.8167 | Learning Rate: 0.000906 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3523/12542 | Batch Loss: 2.1553 | Learning Rate: 0.000906 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3524/12542 | Batch Loss: 1.4252 | Learning Rate: 0.000906 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3525/12542 | Batch Loss: 2.1619 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3526/12542 | Batch Loss: 1.1849 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3527/12542 | Batch Loss: 0.8208 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3528/12542 | Batch Loss: 0.3914 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3529/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3530/12542 | Batch Loss: 1.4657 | Learning Rate: 0.000906 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3531/12542 | Batch Loss: 0.7475 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3532/12542 | Batch Loss: 1.0309 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3533/12542 | Batch Loss: 1.5520 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3534/12542 | Batch Loss: 0.9392 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3535/12542 | Batch Loss: 0.8774 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3536/12542 | Batch Loss: 3.2990 | Learning Rate: 0.000906 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3537/12542 | Batch Loss: 1.1747 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3538/12542 | Batch Loss: 0.9355 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3539/12542 | Batch Loss: 0.8995 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3540/12542 | Batch Loss: 0.8972 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3541/12542 | Batch Loss: 0.7299 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3542/12542 | Batch Loss: 0.6054 | Learning Rate: 0.000906 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3543/12542 | Batch Loss: 0.8904 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3544/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3545/12542 | Batch Loss: 1.9948 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3546/12542 | Batch Loss: 0.9354 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3547/12542 | Batch Loss: 0.6108 | Learning Rate: 0.000906 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3548/12542 | Batch Loss: 2.1909 | Learning Rate: 0.000906 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3549/12542 | Batch Loss: 2.6422 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3550/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3551/12542 | Batch Loss: 3.5571 | Learning Rate: 0.000906 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3552/12542 | Batch Loss: 1.5650 | Learning Rate: 0.000906 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3553/12542 | Batch Loss: 1.2708 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3554/12542 | Batch Loss: 2.0181 | Learning Rate: 0.000906 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3555/12542 | Batch Loss: 1.4094 | Learning Rate: 0.000906 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3556/12542 | Batch Loss: 0.9174 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3557/12542 | Batch Loss: 1.1511 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3558/12542 | Batch Loss: 1.3553 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3559/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3560/12542 | Batch Loss: 2.2146 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3561/12542 | Batch Loss: 1.3424 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3562/12542 | Batch Loss: 1.1104 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3563/12542 | Batch Loss: 1.8592 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3564/12542 | Batch Loss: 1.0074 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3565/12542 | Batch Loss: 1.0349 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3566/12542 | Batch Loss: 1.2397 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3567/12542 | Batch Loss: 1.2738 | Learning Rate: 0.000905 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3568/12542 | Batch Loss: 1.7904 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3569/12542 | Batch Loss: 1.4357 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3570/12542 | Batch Loss: 1.4936 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3571/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3572/12542 | Batch Loss: 1.6143 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3573/12542 | Batch Loss: 2.6473 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3574/12542 | Batch Loss: 0.8253 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3575/12542 | Batch Loss: 2.4989 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3576/12542 | Batch Loss: 1.1648 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3577/12542 | Batch Loss: 3.3811 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3578/12542 | Batch Loss: 1.4070 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3579/12542 | Batch Loss: 1.6947 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3580/12542 | Batch Loss: 2.2527 | Learning Rate: 0.000905 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3581/12542 | Batch Loss: 0.8656 | Learning Rate: 0.000905 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3582/12542 | Batch Loss: 1.3604 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3583/12542 | Batch Loss: 1.2388 | Learning Rate: 0.000905 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3584/12542 | Batch Loss: 1.6840 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3585/12542 | Batch Loss: 0.9246 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3586/12542 | Batch Loss: 1.4981 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3587/12542 | Batch Loss: 1.2934 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3588/12542 | Batch Loss: 1.7735 | Learning Rate: 0.000905 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3589/12542 | Batch Loss: 1.8993 | Learning Rate: 0.000905 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3590/12542 | Batch Loss: 1.0960 | Learning Rate: 0.000905 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3591/12542 | Batch Loss: 0.5509 | Learning Rate: 0.000905 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3592/12542 | Batch Loss: 1.2480 | Learning Rate: 0.000905 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3593/12542 | Batch Loss: 0.8263 | Learning Rate: 0.000905 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3594/12542 | Batch Loss: 1.4863 | Learning Rate: 0.000904 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3595/12542 | Batch Loss: 0.8524 | Learning Rate: 0.000904 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3596/12542 | Batch Loss: 1.0287 | Learning Rate: 0.000904 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3597/12542 | Batch Loss: 1.4794 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3598/12542 | Batch Loss: 1.2343 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3599/12542 | Batch Loss: 1.6025 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3600/12542 | Batch Loss: 0.9745 | Learning Rate: 0.000904 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3601/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000904 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3602/12542 | Batch Loss: 1.0433 | Learning Rate: 0.000904 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3603/12542 | Batch Loss: 2.0702 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3604/12542 | Batch Loss: 0.8419 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3605/12542 | Batch Loss: 0.6845 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3606/12542 | Batch Loss: 0.5991 | Learning Rate: 0.000904 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3607/12542 | Batch Loss: 2.3163 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3608/12542 | Batch Loss: 1.3190 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3609/12542 | Batch Loss: 0.8825 | Learning Rate: 0.000904 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3610/12542 | Batch Loss: 3.1516 | Learning Rate: 0.000904 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3611/12542 | Batch Loss: 1.5999 | Learning Rate: 0.000904 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3612/12542 | Batch Loss: 1.2948 | Learning Rate: 0.000904 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3613/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000904 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3614/12542 | Batch Loss: 1.9121 | Learning Rate: 0.000904 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3615/12542 | Batch Loss: 0.6605 | Learning Rate: 0.000904 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3616/12542 | Batch Loss: 1.7794 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3617/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3618/12542 | Batch Loss: 2.4008 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3619/12542 | Batch Loss: 0.8285 | Learning Rate: 0.000904 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3620/12542 | Batch Loss: 2.7939 | Learning Rate: 0.000904 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3621/12542 | Batch Loss: 1.1457 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3622/12542 | Batch Loss: 1.9858 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3623/12542 | Batch Loss: 1.7321 | Learning Rate: 0.000904 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3624/12542 | Batch Loss: 0.7529 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3625/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000904 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3626/12542 | Batch Loss: 1.2289 | Learning Rate: 0.000904 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3627/12542 | Batch Loss: 1.0363 | Learning Rate: 0.000904 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3628/12542 | Batch Loss: 2.0406 | Learning Rate: 0.000904 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3629/12542 | Batch Loss: 1.4710 | Learning Rate: 0.000904 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3630/12542 | Batch Loss: 1.3385 | Learning Rate: 0.000904 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3631/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000903 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3632/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000903 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3633/12542 | Batch Loss: 1.1648 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3634/12542 | Batch Loss: 2.0052 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3635/12542 | Batch Loss: 0.7333 | Learning Rate: 0.000903 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3636/12542 | Batch Loss: 2.6668 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3637/12542 | Batch Loss: 1.9276 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3638/12542 | Batch Loss: 1.4869 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3639/12542 | Batch Loss: 2.6406 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3640/12542 | Batch Loss: 1.7233 | Learning Rate: 0.000903 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3641/12542 | Batch Loss: 1.6987 | Learning Rate: 0.000903 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3642/12542 | Batch Loss: 0.4782 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3643/12542 | Batch Loss: 0.6710 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3644/12542 | Batch Loss: 1.5117 | Learning Rate: 0.000903 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3645/12542 | Batch Loss: 1.1987 | Learning Rate: 0.000903 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3646/12542 | Batch Loss: 0.9266 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3647/12542 | Batch Loss: 1.0531 | Learning Rate: 0.000903 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3648/12542 | Batch Loss: 2.3810 | Learning Rate: 0.000903 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3649/12542 | Batch Loss: 1.2480 | Learning Rate: 0.000903 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3650/12542 | Batch Loss: 1.0848 | Learning Rate: 0.000903 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3651/12542 | Batch Loss: 2.2329 | Learning Rate: 0.000903 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3652/12542 | Batch Loss: 1.2110 | Learning Rate: 0.000903 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3653/12542 | Batch Loss: 0.9226 | Learning Rate: 0.000903 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3654/12542 | Batch Loss: 1.5354 | Learning Rate: 0.000903 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3655/12542 | Batch Loss: 1.5785 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3656/12542 | Batch Loss: 1.0190 | Learning Rate: 0.000903 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3657/12542 | Batch Loss: 0.7832 | Learning Rate: 0.000903 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3658/12542 | Batch Loss: 1.1587 | Learning Rate: 0.000903 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3659/12542 | Batch Loss: 1.3584 | Learning Rate: 0.000903 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3660/12542 | Batch Loss: 0.9930 | Learning Rate: 0.000903 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3661/12542 | Batch Loss: 1.1157 | Learning Rate: 0.000903 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3662/12542 | Batch Loss: 0.8503 | Learning Rate: 0.000903 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3663/12542 | Batch Loss: 3.3450 | Learning Rate: 0.000903 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3664/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000903 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3665/12542 | Batch Loss: 1.8196 | Learning Rate: 0.000903 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3666/12542 | Batch Loss: 1.4734 | Learning Rate: 0.000903 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3667/12542 | Batch Loss: 1.0039 | Learning Rate: 0.000903 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3668/12542 | Batch Loss: 1.0855 | Learning Rate: 0.000903 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3669/12542 | Batch Loss: 1.5214 | Learning Rate: 0.000902 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3670/12542 | Batch Loss: 1.0850 | Learning Rate: 0.000902 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3671/12542 | Batch Loss: 1.9146 | Learning Rate: 0.000902 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3672/12542 | Batch Loss: 2.2253 | Learning Rate: 0.000902 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3673/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000902 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3674/12542 | Batch Loss: 1.5769 | Learning Rate: 0.000902 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3675/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3676/12542 | Batch Loss: 1.5043 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3677/12542 | Batch Loss: 0.4121 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3678/12542 | Batch Loss: 1.0936 | Learning Rate: 0.000902 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3679/12542 | Batch Loss: 1.2625 | Learning Rate: 0.000902 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3680/12542 | Batch Loss: 1.5236 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3681/12542 | Batch Loss: 0.8377 | Learning Rate: 0.000902 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3682/12542 | Batch Loss: 0.7662 | Learning Rate: 0.000902 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3683/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000902 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3684/12542 | Batch Loss: 1.1501 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3685/12542 | Batch Loss: 2.1400 | Learning Rate: 0.000902 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3686/12542 | Batch Loss: 0.7573 | Learning Rate: 0.000902 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3687/12542 | Batch Loss: 1.9658 | Learning Rate: 0.000902 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3688/12542 | Batch Loss: 1.8411 | Learning Rate: 0.000902 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3689/12542 | Batch Loss: 0.7667 | Learning Rate: 0.000902 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3690/12542 | Batch Loss: 2.3253 | Learning Rate: 0.000902 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3691/12542 | Batch Loss: 1.8605 | Learning Rate: 0.000902 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3692/12542 | Batch Loss: 1.6315 | Learning Rate: 0.000902 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3693/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000902 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3694/12542 | Batch Loss: 0.8303 | Learning Rate: 0.000902 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3695/12542 | Batch Loss: 1.0534 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3696/12542 | Batch Loss: 1.3214 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3697/12542 | Batch Loss: 1.4941 | Learning Rate: 0.000902 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3698/12542 | Batch Loss: 1.8451 | Learning Rate: 0.000902 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3699/12542 | Batch Loss: 1.0998 | Learning Rate: 0.000902 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3700/12542 | Batch Loss: 2.3347 | Learning Rate: 0.000902 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3701/12542 | Batch Loss: 1.4179 | Learning Rate: 0.000902 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3702/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000902 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3703/12542 | Batch Loss: 1.3225 | Learning Rate: 0.000902 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3704/12542 | Batch Loss: 2.0497 | Learning Rate: 0.000902 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3705/12542 | Batch Loss: 1.0182 | Learning Rate: 0.000902 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3706/12542 | Batch Loss: 2.4304 | Learning Rate: 0.000902 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3707/12542 | Batch Loss: 0.8898 | Learning Rate: 0.000901 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3708/12542 | Batch Loss: 0.8598 | Learning Rate: 0.000901 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3709/12542 | Batch Loss: 0.8338 | Learning Rate: 0.000901 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3710/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000901 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3711/12542 | Batch Loss: 1.1646 | Learning Rate: 0.000901 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3712/12542 | Batch Loss: 1.4201 | Learning Rate: 0.000901 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3713/12542 | Batch Loss: 1.7147 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3714/12542 | Batch Loss: 1.1857 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3715/12542 | Batch Loss: 1.0645 | Learning Rate: 0.000901 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3716/12542 | Batch Loss: 1.2357 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3717/12542 | Batch Loss: 0.7814 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3718/12542 | Batch Loss: 1.4564 | Learning Rate: 0.000901 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3719/12542 | Batch Loss: 1.4166 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3720/12542 | Batch Loss: 0.7048 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3721/12542 | Batch Loss: 1.1539 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3722/12542 | Batch Loss: 4.5385 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3723/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3724/12542 | Batch Loss: 2.5333 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3725/12542 | Batch Loss: 1.0806 | Learning Rate: 0.000901 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3726/12542 | Batch Loss: 1.1030 | Learning Rate: 0.000901 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3727/12542 | Batch Loss: 1.3477 | Learning Rate: 0.000901 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3728/12542 | Batch Loss: 1.3604 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3729/12542 | Batch Loss: 0.8457 | Learning Rate: 0.000901 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3730/12542 | Batch Loss: 1.5227 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3731/12542 | Batch Loss: 1.0570 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3732/12542 | Batch Loss: 2.5664 | Learning Rate: 0.000901 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3733/12542 | Batch Loss: 2.0803 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3734/12542 | Batch Loss: 1.1088 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3735/12542 | Batch Loss: 1.1838 | Learning Rate: 0.000901 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3736/12542 | Batch Loss: 0.8658 | Learning Rate: 0.000901 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3737/12542 | Batch Loss: 2.9321 | Learning Rate: 0.000901 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3738/12542 | Batch Loss: 1.1214 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3739/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3740/12542 | Batch Loss: 1.3275 | Learning Rate: 0.000901 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3741/12542 | Batch Loss: 1.5218 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3742/12542 | Batch Loss: 1.8529 | Learning Rate: 0.000901 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3743/12542 | Batch Loss: 2.2736 | Learning Rate: 0.000901 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3744/12542 | Batch Loss: 1.4040 | Learning Rate: 0.000900 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3745/12542 | Batch Loss: 1.5525 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3746/12542 | Batch Loss: 0.7512 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3747/12542 | Batch Loss: 1.0627 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3748/12542 | Batch Loss: 2.7588 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3749/12542 | Batch Loss: 2.4843 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3750/12542 | Batch Loss: 0.6609 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3751/12542 | Batch Loss: 1.7710 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3752/12542 | Batch Loss: 1.8792 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3753/12542 | Batch Loss: 1.6135 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3754/12542 | Batch Loss: 1.1849 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3755/12542 | Batch Loss: 0.9409 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3756/12542 | Batch Loss: 0.6867 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3757/12542 | Batch Loss: 1.1680 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3758/12542 | Batch Loss: 1.0319 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3759/12542 | Batch Loss: 1.4540 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3760/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3761/12542 | Batch Loss: 1.2602 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3762/12542 | Batch Loss: 1.3588 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3763/12542 | Batch Loss: 1.0791 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3764/12542 | Batch Loss: 3.0537 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3765/12542 | Batch Loss: 2.3520 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3766/12542 | Batch Loss: 2.0234 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3767/12542 | Batch Loss: 1.1781 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3768/12542 | Batch Loss: 1.2580 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3769/12542 | Batch Loss: 1.2933 | Learning Rate: 0.000900 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3770/12542 | Batch Loss: 1.4396 | Learning Rate: 0.000900 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3771/12542 | Batch Loss: 1.5271 | Learning Rate: 0.000900 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3772/12542 | Batch Loss: 1.1517 | Learning Rate: 0.000900 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3773/12542 | Batch Loss: 0.9196 | Learning Rate: 0.000900 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3774/12542 | Batch Loss: 1.7477 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3775/12542 | Batch Loss: 1.4022 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3776/12542 | Batch Loss: 1.0978 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3777/12542 | Batch Loss: 0.8750 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3778/12542 | Batch Loss: 1.0293 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3779/12542 | Batch Loss: 0.7634 | Learning Rate: 0.000900 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3780/12542 | Batch Loss: 1.6417 | Learning Rate: 0.000900 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3781/12542 | Batch Loss: 2.3931 | Learning Rate: 0.000900 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3782/12542 | Batch Loss: 0.6378 | Learning Rate: 0.000899 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3783/12542 | Batch Loss: 1.2674 | Learning Rate: 0.000899 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3784/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000899 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3785/12542 | Batch Loss: 1.3796 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3786/12542 | Batch Loss: 2.1397 | Learning Rate: 0.000899 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3787/12542 | Batch Loss: 1.2362 | Learning Rate: 0.000899 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 3788/12542 | Batch Loss: 1.3329 | Learning Rate: 0.000899 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3789/12542 | Batch Loss: 1.6364 | Learning Rate: 0.000899 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3790/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000899 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3791/12542 | Batch Loss: 0.5841 | Learning Rate: 0.000899 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3792/12542 | Batch Loss: 1.5275 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3793/12542 | Batch Loss: 1.6217 | Learning Rate: 0.000899 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3794/12542 | Batch Loss: 0.5837 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3795/12542 | Batch Loss: 0.3905 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3796/12542 | Batch Loss: 1.4022 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3797/12542 | Batch Loss: 3.0617 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3798/12542 | Batch Loss: 1.2581 | Learning Rate: 0.000899 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3799/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3800/12542 | Batch Loss: 1.8453 | Learning Rate: 0.000899 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3801/12542 | Batch Loss: 3.6198 | Learning Rate: 0.000899 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3802/12542 | Batch Loss: 1.0702 | Learning Rate: 0.000899 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3803/12542 | Batch Loss: 1.1852 | Learning Rate: 0.000899 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3804/12542 | Batch Loss: 0.9325 | Learning Rate: 0.000899 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3805/12542 | Batch Loss: 0.7651 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3806/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000899 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3807/12542 | Batch Loss: 0.9370 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3808/12542 | Batch Loss: 1.9881 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3809/12542 | Batch Loss: 1.3797 | Learning Rate: 0.000899 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3810/12542 | Batch Loss: 1.6805 | Learning Rate: 0.000899 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3811/12542 | Batch Loss: 0.9738 | Learning Rate: 0.000899 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 3812/12542 | Batch Loss: 1.0076 | Learning Rate: 0.000899 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3813/12542 | Batch Loss: 2.6774 | Learning Rate: 0.000899 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3814/12542 | Batch Loss: 2.8307 | Learning Rate: 0.000899 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3815/12542 | Batch Loss: 1.1016 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3816/12542 | Batch Loss: 0.7013 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3817/12542 | Batch Loss: 1.0610 | Learning Rate: 0.000899 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3818/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000899 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3819/12542 | Batch Loss: 1.7526 | Learning Rate: 0.000899 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3820/12542 | Batch Loss: 1.7514 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3821/12542 | Batch Loss: 0.9870 | Learning Rate: 0.000898 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3822/12542 | Batch Loss: 1.2774 | Learning Rate: 0.000898 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3823/12542 | Batch Loss: 0.7718 | Learning Rate: 0.000898 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3824/12542 | Batch Loss: 1.2023 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3825/12542 | Batch Loss: 1.1725 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3826/12542 | Batch Loss: 0.9010 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3827/12542 | Batch Loss: 1.3133 | Learning Rate: 0.000898 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3828/12542 | Batch Loss: 1.7800 | Learning Rate: 0.000898 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3829/12542 | Batch Loss: 1.7283 | Learning Rate: 0.000898 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3830/12542 | Batch Loss: 0.8408 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3831/12542 | Batch Loss: 0.8705 | Learning Rate: 0.000898 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3832/12542 | Batch Loss: 1.3379 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3833/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3834/12542 | Batch Loss: 0.9814 | Learning Rate: 0.000898 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 3835/12542 | Batch Loss: 2.4111 | Learning Rate: 0.000898 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3836/12542 | Batch Loss: 2.5774 | Learning Rate: 0.000898 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3837/12542 | Batch Loss: 2.5226 | Learning Rate: 0.000898 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3838/12542 | Batch Loss: 1.4336 | Learning Rate: 0.000898 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3839/12542 | Batch Loss: 1.6361 | Learning Rate: 0.000898 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3840/12542 | Batch Loss: 0.6860 | Learning Rate: 0.000898 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3841/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000898 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3842/12542 | Batch Loss: 1.2184 | Learning Rate: 0.000898 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3843/12542 | Batch Loss: 0.9904 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3844/12542 | Batch Loss: 1.8727 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3845/12542 | Batch Loss: 1.4192 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3846/12542 | Batch Loss: 1.8822 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3847/12542 | Batch Loss: 0.8543 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3848/12542 | Batch Loss: 1.7950 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3849/12542 | Batch Loss: 0.8204 | Learning Rate: 0.000898 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3850/12542 | Batch Loss: 0.8351 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3851/12542 | Batch Loss: 1.3326 | Learning Rate: 0.000898 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3852/12542 | Batch Loss: 2.0169 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3853/12542 | Batch Loss: 1.3348 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3854/12542 | Batch Loss: 1.0195 | Learning Rate: 0.000898 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3855/12542 | Batch Loss: 0.7717 | Learning Rate: 0.000898 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3856/12542 | Batch Loss: 1.8976 | Learning Rate: 0.000898 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3857/12542 | Batch Loss: 1.3898 | Learning Rate: 0.000897 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3858/12542 | Batch Loss: 1.7350 | Learning Rate: 0.000897 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3859/12542 | Batch Loss: 1.0138 | Learning Rate: 0.000897 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 3860/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000897 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3861/12542 | Batch Loss: 1.5496 | Learning Rate: 0.000897 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3862/12542 | Batch Loss: 1.6336 | Learning Rate: 0.000897 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3863/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000897 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3864/12542 | Batch Loss: 0.4628 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3865/12542 | Batch Loss: 0.5619 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3866/12542 | Batch Loss: 0.6745 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3867/12542 | Batch Loss: 0.6233 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3868/12542 | Batch Loss: 2.8537 | Learning Rate: 0.000897 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3869/12542 | Batch Loss: 0.7212 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3870/12542 | Batch Loss: 2.6966 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3871/12542 | Batch Loss: 1.5088 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3872/12542 | Batch Loss: 1.3131 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3873/12542 | Batch Loss: 0.8441 | Learning Rate: 0.000897 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3874/12542 | Batch Loss: 1.4325 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3875/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3876/12542 | Batch Loss: 0.9043 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3877/12542 | Batch Loss: 1.5732 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3878/12542 | Batch Loss: 1.2872 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3879/12542 | Batch Loss: 1.2777 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3880/12542 | Batch Loss: 3.4561 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3881/12542 | Batch Loss: 1.9631 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3882/12542 | Batch Loss: 1.4219 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3883/12542 | Batch Loss: 1.9401 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3884/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3885/12542 | Batch Loss: 2.1348 | Learning Rate: 0.000897 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3886/12542 | Batch Loss: 0.9028 | Learning Rate: 0.000897 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3887/12542 | Batch Loss: 1.1699 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3888/12542 | Batch Loss: 1.4183 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3889/12542 | Batch Loss: 1.9372 | Learning Rate: 0.000897 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3890/12542 | Batch Loss: 1.4303 | Learning Rate: 0.000897 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3891/12542 | Batch Loss: 1.1019 | Learning Rate: 0.000897 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3892/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3893/12542 | Batch Loss: 1.4355 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3894/12542 | Batch Loss: 1.4664 | Learning Rate: 0.000897 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3895/12542 | Batch Loss: 1.7126 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3896/12542 | Batch Loss: 2.2194 | Learning Rate: 0.000896 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3897/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3898/12542 | Batch Loss: 1.1373 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3899/12542 | Batch Loss: 3.0478 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3900/12542 | Batch Loss: 1.0869 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3901/12542 | Batch Loss: 1.2441 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3902/12542 | Batch Loss: 1.2392 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3903/12542 | Batch Loss: 0.9399 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3904/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3905/12542 | Batch Loss: 0.9623 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3906/12542 | Batch Loss: 0.8531 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3907/12542 | Batch Loss: 1.5960 | Learning Rate: 0.000896 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3908/12542 | Batch Loss: 1.3947 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3909/12542 | Batch Loss: 1.4972 | Learning Rate: 0.000896 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3910/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3911/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000896 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3912/12542 | Batch Loss: 1.3308 | Learning Rate: 0.000896 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3913/12542 | Batch Loss: 0.8065 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3914/12542 | Batch Loss: 1.1488 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3915/12542 | Batch Loss: 0.8786 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3916/12542 | Batch Loss: 2.2609 | Learning Rate: 0.000896 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3917/12542 | Batch Loss: 2.1244 | Learning Rate: 0.000896 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3918/12542 | Batch Loss: 1.0102 | Learning Rate: 0.000896 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3919/12542 | Batch Loss: 1.6264 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3920/12542 | Batch Loss: 1.2376 | Learning Rate: 0.000896 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3921/12542 | Batch Loss: 0.8162 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3922/12542 | Batch Loss: 1.9992 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3923/12542 | Batch Loss: 1.5442 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3924/12542 | Batch Loss: 0.5852 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3925/12542 | Batch Loss: 1.0197 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3926/12542 | Batch Loss: 0.7779 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3927/12542 | Batch Loss: 0.7879 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3928/12542 | Batch Loss: 0.6892 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3929/12542 | Batch Loss: 0.7383 | Learning Rate: 0.000896 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3930/12542 | Batch Loss: 1.3829 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3931/12542 | Batch Loss: 0.8702 | Learning Rate: 0.000896 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3932/12542 | Batch Loss: 2.0536 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3933/12542 | Batch Loss: 1.1651 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3934/12542 | Batch Loss: 0.9889 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3935/12542 | Batch Loss: 1.5281 | Learning Rate: 0.000895 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3936/12542 | Batch Loss: 0.7542 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3937/12542 | Batch Loss: 0.5746 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3938/12542 | Batch Loss: 2.5089 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3939/12542 | Batch Loss: 1.5124 | Learning Rate: 0.000895 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3940/12542 | Batch Loss: 0.7634 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3941/12542 | Batch Loss: 0.8517 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3942/12542 | Batch Loss: 0.8314 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3943/12542 | Batch Loss: 1.7238 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3944/12542 | Batch Loss: 2.1540 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3945/12542 | Batch Loss: 0.8558 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3946/12542 | Batch Loss: 2.4430 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3947/12542 | Batch Loss: 2.0414 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3948/12542 | Batch Loss: 0.9263 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3949/12542 | Batch Loss: 1.1443 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3950/12542 | Batch Loss: 1.7753 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3951/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3952/12542 | Batch Loss: 1.7199 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3953/12542 | Batch Loss: 1.4365 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3954/12542 | Batch Loss: 3.5466 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3955/12542 | Batch Loss: 1.0839 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3956/12542 | Batch Loss: 0.7877 | Learning Rate: 0.000895 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3957/12542 | Batch Loss: 1.6173 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3958/12542 | Batch Loss: 2.2934 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3959/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3960/12542 | Batch Loss: 1.3567 | Learning Rate: 0.000895 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3961/12542 | Batch Loss: 1.4224 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3962/12542 | Batch Loss: 1.7978 | Learning Rate: 0.000895 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3963/12542 | Batch Loss: 0.5595 | Learning Rate: 0.000895 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3964/12542 | Batch Loss: 2.8735 | Learning Rate: 0.000895 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3965/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000895 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 3966/12542 | Batch Loss: 1.8147 | Learning Rate: 0.000895 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 3967/12542 | Batch Loss: 1.1705 | Learning Rate: 0.000895 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3968/12542 | Batch Loss: 0.9993 | Learning Rate: 0.000895 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 3969/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000895 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3970/12542 | Batch Loss: 1.5784 | Learning Rate: 0.000894 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3971/12542 | Batch Loss: 1.4561 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3972/12542 | Batch Loss: 0.7647 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3973/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3974/12542 | Batch Loss: 0.8569 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3975/12542 | Batch Loss: 1.4782 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3976/12542 | Batch Loss: 1.4101 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3977/12542 | Batch Loss: 1.3202 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3978/12542 | Batch Loss: 1.1822 | Learning Rate: 0.000894 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3979/12542 | Batch Loss: 0.7831 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3980/12542 | Batch Loss: 2.4296 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3981/12542 | Batch Loss: 1.0551 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3982/12542 | Batch Loss: 3.5495 | Learning Rate: 0.000894 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3983/12542 | Batch Loss: 0.9555 | Learning Rate: 0.000894 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3984/12542 | Batch Loss: 0.5752 | Learning Rate: 0.000894 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 3985/12542 | Batch Loss: 0.9007 | Learning Rate: 0.000894 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 3986/12542 | Batch Loss: 0.6342 | Learning Rate: 0.000894 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 3987/12542 | Batch Loss: 3.0961 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3988/12542 | Batch Loss: 1.4994 | Learning Rate: 0.000894 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3989/12542 | Batch Loss: 1.4543 | Learning Rate: 0.000894 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 3990/12542 | Batch Loss: 0.8877 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3991/12542 | Batch Loss: 1.0763 | Learning Rate: 0.000894 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 3992/12542 | Batch Loss: 0.9093 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3993/12542 | Batch Loss: 1.6390 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3994/12542 | Batch Loss: 1.6253 | Learning Rate: 0.000894 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3995/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 3996/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 3997/12542 | Batch Loss: 0.6469 | Learning Rate: 0.000894 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3998/12542 | Batch Loss: 1.4611 | Learning Rate: 0.000894 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 3999/12542 | Batch Loss: 0.3270 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4000/12542 | Batch Loss: 0.9042 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4001/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4002/12542 | Batch Loss: 3.4688 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4003/12542 | Batch Loss: 1.0038 | Learning Rate: 0.000894 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4004/12542 | Batch Loss: 2.4663 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4005/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000894 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4006/12542 | Batch Loss: 1.0766 | Learning Rate: 0.000894 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4007/12542 | Batch Loss: 1.4358 | Learning Rate: 0.000894 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4008/12542 | Batch Loss: 1.8710 | Learning Rate: 0.000893 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4009/12542 | Batch Loss: 1.4439 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4010/12542 | Batch Loss: 2.0944 | Learning Rate: 0.000893 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 4011/12542 | Batch Loss: 1.2999 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4012/12542 | Batch Loss: 1.3245 | Learning Rate: 0.000893 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 4013/12542 | Batch Loss: 1.2408 | Learning Rate: 0.000893 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4014/12542 | Batch Loss: 1.5432 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4015/12542 | Batch Loss: 0.7113 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4016/12542 | Batch Loss: 0.6266 | Learning Rate: 0.000893 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4017/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000893 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4018/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000893 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4019/12542 | Batch Loss: 0.6585 | Learning Rate: 0.000893 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4020/12542 | Batch Loss: 0.7859 | Learning Rate: 0.000893 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4021/12542 | Batch Loss: 1.3474 | Learning Rate: 0.000893 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4022/12542 | Batch Loss: 1.6468 | Learning Rate: 0.000893 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4023/12542 | Batch Loss: 1.4452 | Learning Rate: 0.000893 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4024/12542 | Batch Loss: 1.3862 | Learning Rate: 0.000893 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4025/12542 | Batch Loss: 0.9398 | Learning Rate: 0.000893 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4026/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000893 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4027/12542 | Batch Loss: 1.0768 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4028/12542 | Batch Loss: 2.8825 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4029/12542 | Batch Loss: 1.0486 | Learning Rate: 0.000893 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4030/12542 | Batch Loss: 1.6235 | Learning Rate: 0.000893 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4031/12542 | Batch Loss: 0.5271 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4032/12542 | Batch Loss: 1.0904 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4033/12542 | Batch Loss: 2.5088 | Learning Rate: 0.000893 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4034/12542 | Batch Loss: 0.7581 | Learning Rate: 0.000893 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4035/12542 | Batch Loss: 1.0352 | Learning Rate: 0.000893 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4036/12542 | Batch Loss: 0.4621 | Learning Rate: 0.000893 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4037/12542 | Batch Loss: 0.8622 | Learning Rate: 0.000893 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 4038/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000893 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4039/12542 | Batch Loss: 1.3634 | Learning Rate: 0.000893 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 4040/12542 | Batch Loss: 1.2304 | Learning Rate: 0.000893 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4041/12542 | Batch Loss: 1.4473 | Learning Rate: 0.000893 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4042/12542 | Batch Loss: 1.8958 | Learning Rate: 0.000893 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4043/12542 | Batch Loss: 1.1957 | Learning Rate: 0.000893 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4044/12542 | Batch Loss: 3.1997 | Learning Rate: 0.000893 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4045/12542 | Batch Loss: 1.2784 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4046/12542 | Batch Loss: 1.3639 | Learning Rate: 0.000892 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4047/12542 | Batch Loss: 1.5858 | Learning Rate: 0.000892 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4048/12542 | Batch Loss: 1.1575 | Learning Rate: 0.000892 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 4049/12542 | Batch Loss: 1.1633 | Learning Rate: 0.000892 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4050/12542 | Batch Loss: 0.8969 | Learning Rate: 0.000892 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4051/12542 | Batch Loss: 1.0947 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4052/12542 | Batch Loss: 1.1732 | Learning Rate: 0.000892 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4053/12542 | Batch Loss: 0.9827 | Learning Rate: 0.000892 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4054/12542 | Batch Loss: 1.7166 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4055/12542 | Batch Loss: 1.5828 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4056/12542 | Batch Loss: 2.3423 | Learning Rate: 0.000892 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4057/12542 | Batch Loss: 2.3916 | Learning Rate: 0.000892 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4058/12542 | Batch Loss: 0.7811 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4059/12542 | Batch Loss: 0.8297 | Learning Rate: 0.000892 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4060/12542 | Batch Loss: 2.8571 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4061/12542 | Batch Loss: 1.5496 | Learning Rate: 0.000892 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4062/12542 | Batch Loss: 2.0383 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4063/12542 | Batch Loss: 1.4850 | Learning Rate: 0.000892 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4064/12542 | Batch Loss: 2.0032 | Learning Rate: 0.000892 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4065/12542 | Batch Loss: 0.5165 | Learning Rate: 0.000892 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4066/12542 | Batch Loss: 1.4618 | Learning Rate: 0.000892 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4067/12542 | Batch Loss: 2.7456 | Learning Rate: 0.000892 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4068/12542 | Batch Loss: 1.4459 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4069/12542 | Batch Loss: 0.8317 | Learning Rate: 0.000892 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4070/12542 | Batch Loss: 1.2843 | Learning Rate: 0.000892 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4071/12542 | Batch Loss: 0.6385 | Learning Rate: 0.000892 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4072/12542 | Batch Loss: 1.5745 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4073/12542 | Batch Loss: 1.1065 | Learning Rate: 0.000892 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4074/12542 | Batch Loss: 1.7920 | Learning Rate: 0.000892 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4075/12542 | Batch Loss: 1.9500 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4076/12542 | Batch Loss: 1.1957 | Learning Rate: 0.000892 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4077/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000892 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4078/12542 | Batch Loss: 0.4299 | Learning Rate: 0.000892 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4079/12542 | Batch Loss: 2.3194 | Learning Rate: 0.000892 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4080/12542 | Batch Loss: 1.3185 | Learning Rate: 0.000892 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4081/12542 | Batch Loss: 0.9883 | Learning Rate: 0.000892 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4082/12542 | Batch Loss: 1.6821 | Learning Rate: 0.000892 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4083/12542 | Batch Loss: 1.6011 | Learning Rate: 0.000891 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4084/12542 | Batch Loss: 3.5048 | Learning Rate: 0.000891 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 4085/12542 | Batch Loss: 1.7913 | Learning Rate: 0.000891 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4086/12542 | Batch Loss: 2.1187 | Learning Rate: 0.000891 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4087/12542 | Batch Loss: 1.8358 | Learning Rate: 0.000891 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4088/12542 | Batch Loss: 1.9282 | Learning Rate: 0.000891 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4089/12542 | Batch Loss: 1.4042 | Learning Rate: 0.000891 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4090/12542 | Batch Loss: 0.9036 | Learning Rate: 0.000891 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4091/12542 | Batch Loss: 0.5644 | Learning Rate: 0.000891 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4092/12542 | Batch Loss: 0.6185 | Learning Rate: 0.000891 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4093/12542 | Batch Loss: 0.8506 | Learning Rate: 0.000891 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4094/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000891 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4095/12542 | Batch Loss: 1.6474 | Learning Rate: 0.000891 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4096/12542 | Batch Loss: 1.4235 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4097/12542 | Batch Loss: 0.8673 | Learning Rate: 0.000891 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4098/12542 | Batch Loss: 1.8563 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4099/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000891 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4100/12542 | Batch Loss: 1.1809 | Learning Rate: 0.000891 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4101/12542 | Batch Loss: 0.6817 | Learning Rate: 0.000891 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4102/12542 | Batch Loss: 3.0283 | Learning Rate: 0.000891 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4103/12542 | Batch Loss: 0.7553 | Learning Rate: 0.000891 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4104/12542 | Batch Loss: 1.0415 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4105/12542 | Batch Loss: 1.1345 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4106/12542 | Batch Loss: 1.5280 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4107/12542 | Batch Loss: 1.8164 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4108/12542 | Batch Loss: 1.4803 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4109/12542 | Batch Loss: 1.6696 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4110/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4111/12542 | Batch Loss: 0.9755 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4112/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4113/12542 | Batch Loss: 1.3797 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4114/12542 | Batch Loss: 0.9063 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4115/12542 | Batch Loss: 1.8886 | Learning Rate: 0.000891 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4116/12542 | Batch Loss: 0.9406 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4117/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000891 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4118/12542 | Batch Loss: 0.6927 | Learning Rate: 0.000891 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4119/12542 | Batch Loss: 0.5962 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4120/12542 | Batch Loss: 3.7607 | Learning Rate: 0.000891 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4121/12542 | Batch Loss: 0.8609 | Learning Rate: 0.000890 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4122/12542 | Batch Loss: 1.8104 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4123/12542 | Batch Loss: 1.7527 | Learning Rate: 0.000890 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4124/12542 | Batch Loss: 0.8991 | Learning Rate: 0.000890 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4125/12542 | Batch Loss: 1.8743 | Learning Rate: 0.000890 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4126/12542 | Batch Loss: 2.0785 | Learning Rate: 0.000890 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4127/12542 | Batch Loss: 1.1651 | Learning Rate: 0.000890 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4128/12542 | Batch Loss: 1.4406 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4129/12542 | Batch Loss: 0.9545 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4130/12542 | Batch Loss: 2.3775 | Learning Rate: 0.000890 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4131/12542 | Batch Loss: 1.6868 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4132/12542 | Batch Loss: 1.7523 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4133/12542 | Batch Loss: 0.7233 | Learning Rate: 0.000890 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4134/12542 | Batch Loss: 1.6047 | Learning Rate: 0.000890 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4135/12542 | Batch Loss: 0.9337 | Learning Rate: 0.000890 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4136/12542 | Batch Loss: 0.8718 | Learning Rate: 0.000890 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4137/12542 | Batch Loss: 1.3800 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4138/12542 | Batch Loss: 1.6551 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4139/12542 | Batch Loss: 1.6795 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4140/12542 | Batch Loss: 2.5257 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4141/12542 | Batch Loss: 0.7043 | Learning Rate: 0.000890 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4142/12542 | Batch Loss: 1.2475 | Learning Rate: 0.000890 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4143/12542 | Batch Loss: 0.6532 | Learning Rate: 0.000890 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4144/12542 | Batch Loss: 2.1037 | Learning Rate: 0.000890 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4145/12542 | Batch Loss: 1.3886 | Learning Rate: 0.000890 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4146/12542 | Batch Loss: 0.8845 | Learning Rate: 0.000890 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4147/12542 | Batch Loss: 0.7656 | Learning Rate: 0.000890 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4148/12542 | Batch Loss: 1.5010 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4149/12542 | Batch Loss: 1.4506 | Learning Rate: 0.000890 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4150/12542 | Batch Loss: 1.5659 | Learning Rate: 0.000890 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4151/12542 | Batch Loss: 1.1004 | Learning Rate: 0.000890 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4152/12542 | Batch Loss: 1.8771 | Learning Rate: 0.000890 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4153/12542 | Batch Loss: 1.3747 | Learning Rate: 0.000890 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4154/12542 | Batch Loss: 0.9286 | Learning Rate: 0.000890 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4155/12542 | Batch Loss: 0.8872 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4156/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000890 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4157/12542 | Batch Loss: 2.7433 | Learning Rate: 0.000890 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4158/12542 | Batch Loss: 1.2653 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4159/12542 | Batch Loss: 1.3700 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4160/12542 | Batch Loss: 0.8349 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4161/12542 | Batch Loss: 1.8051 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4162/12542 | Batch Loss: 1.7669 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4163/12542 | Batch Loss: 1.3277 | Learning Rate: 0.000889 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4164/12542 | Batch Loss: 1.1776 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4165/12542 | Batch Loss: 0.8291 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4166/12542 | Batch Loss: 1.5712 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4167/12542 | Batch Loss: 1.4231 | Learning Rate: 0.000889 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4168/12542 | Batch Loss: 0.7590 | Learning Rate: 0.000889 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4169/12542 | Batch Loss: 1.1881 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4170/12542 | Batch Loss: 0.9550 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4171/12542 | Batch Loss: 1.7494 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4172/12542 | Batch Loss: 0.9705 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4173/12542 | Batch Loss: 2.0110 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4174/12542 | Batch Loss: 2.0326 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4175/12542 | Batch Loss: 0.9279 | Learning Rate: 0.000889 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4176/12542 | Batch Loss: 1.2931 | Learning Rate: 0.000889 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4177/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000889 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4178/12542 | Batch Loss: 1.4492 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4179/12542 | Batch Loss: 0.9585 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4180/12542 | Batch Loss: 2.8164 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4181/12542 | Batch Loss: 1.2025 | Learning Rate: 0.000889 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4182/12542 | Batch Loss: 1.9558 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4183/12542 | Batch Loss: 2.2065 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4184/12542 | Batch Loss: 0.7449 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4185/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4186/12542 | Batch Loss: 1.9232 | Learning Rate: 0.000889 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4187/12542 | Batch Loss: 1.6908 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4188/12542 | Batch Loss: 2.0280 | Learning Rate: 0.000889 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4189/12542 | Batch Loss: 1.3237 | Learning Rate: 0.000889 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4190/12542 | Batch Loss: 2.0196 | Learning Rate: 0.000889 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4191/12542 | Batch Loss: 1.7301 | Learning Rate: 0.000889 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4192/12542 | Batch Loss: 2.4516 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4193/12542 | Batch Loss: 1.6276 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4194/12542 | Batch Loss: 3.5305 | Learning Rate: 0.000889 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4195/12542 | Batch Loss: 0.8168 | Learning Rate: 0.000889 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4196/12542 | Batch Loss: 1.1464 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4197/12542 | Batch Loss: 1.8706 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4198/12542 | Batch Loss: 2.2206 | Learning Rate: 0.000888 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4199/12542 | Batch Loss: 1.1776 | Learning Rate: 0.000888 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4200/12542 | Batch Loss: 0.9491 | Learning Rate: 0.000888 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4201/12542 | Batch Loss: 1.6238 | Learning Rate: 0.000888 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4202/12542 | Batch Loss: 1.5333 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4203/12542 | Batch Loss: 1.3155 | Learning Rate: 0.000888 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4204/12542 | Batch Loss: 0.5607 | Learning Rate: 0.000888 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4205/12542 | Batch Loss: 1.5097 | Learning Rate: 0.000888 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4206/12542 | Batch Loss: 2.5025 | Learning Rate: 0.000888 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4207/12542 | Batch Loss: 1.1426 | Learning Rate: 0.000888 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4208/12542 | Batch Loss: 1.1985 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4209/12542 | Batch Loss: 0.9232 | Learning Rate: 0.000888 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4210/12542 | Batch Loss: 1.3033 | Learning Rate: 0.000888 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4211/12542 | Batch Loss: 1.2242 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4212/12542 | Batch Loss: 0.7557 | Learning Rate: 0.000888 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4213/12542 | Batch Loss: 1.6819 | Learning Rate: 0.000888 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4214/12542 | Batch Loss: 2.0718 | Learning Rate: 0.000888 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4215/12542 | Batch Loss: 1.0493 | Learning Rate: 0.000888 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4216/12542 | Batch Loss: 0.8940 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4217/12542 | Batch Loss: 0.8590 | Learning Rate: 0.000888 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4218/12542 | Batch Loss: 1.4192 | Learning Rate: 0.000888 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 4219/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4220/12542 | Batch Loss: 1.2992 | Learning Rate: 0.000888 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4221/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4222/12542 | Batch Loss: 1.5150 | Learning Rate: 0.000888 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4223/12542 | Batch Loss: 0.5642 | Learning Rate: 0.000888 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4224/12542 | Batch Loss: 1.5976 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4225/12542 | Batch Loss: 0.7396 | Learning Rate: 0.000888 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4226/12542 | Batch Loss: 2.4180 | Learning Rate: 0.000888 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4227/12542 | Batch Loss: 1.5611 | Learning Rate: 0.000888 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4228/12542 | Batch Loss: 1.0189 | Learning Rate: 0.000888 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4229/12542 | Batch Loss: 1.6909 | Learning Rate: 0.000888 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4230/12542 | Batch Loss: 1.0711 | Learning Rate: 0.000888 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4231/12542 | Batch Loss: 1.6871 | Learning Rate: 0.000888 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4232/12542 | Batch Loss: 1.4101 | Learning Rate: 0.000888 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4233/12542 | Batch Loss: 1.1484 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4234/12542 | Batch Loss: 2.4106 | Learning Rate: 0.000887 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4235/12542 | Batch Loss: 0.7670 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4236/12542 | Batch Loss: 1.0952 | Learning Rate: 0.000887 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4237/12542 | Batch Loss: 0.6972 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4238/12542 | Batch Loss: 1.9196 | Learning Rate: 0.000887 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4239/12542 | Batch Loss: 0.9353 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4240/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4241/12542 | Batch Loss: 1.6164 | Learning Rate: 0.000887 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4242/12542 | Batch Loss: 2.1467 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4243/12542 | Batch Loss: 1.6120 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4244/12542 | Batch Loss: 3.1223 | Learning Rate: 0.000887 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4245/12542 | Batch Loss: 0.4964 | Learning Rate: 0.000887 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4246/12542 | Batch Loss: 1.0335 | Learning Rate: 0.000887 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4247/12542 | Batch Loss: 1.6112 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4248/12542 | Batch Loss: 1.4446 | Learning Rate: 0.000887 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4249/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4250/12542 | Batch Loss: 1.5449 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4251/12542 | Batch Loss: 0.8154 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4252/12542 | Batch Loss: 1.4367 | Learning Rate: 0.000887 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4253/12542 | Batch Loss: 1.0386 | Learning Rate: 0.000887 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4254/12542 | Batch Loss: 0.9398 | Learning Rate: 0.000887 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4255/12542 | Batch Loss: 1.9171 | Learning Rate: 0.000887 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4256/12542 | Batch Loss: 2.6582 | Learning Rate: 0.000887 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4257/12542 | Batch Loss: 1.7490 | Learning Rate: 0.000887 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4258/12542 | Batch Loss: 0.7593 | Learning Rate: 0.000887 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4259/12542 | Batch Loss: 1.2981 | Learning Rate: 0.000887 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4260/12542 | Batch Loss: 1.4102 | Learning Rate: 0.000887 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4261/12542 | Batch Loss: 0.7287 | Learning Rate: 0.000887 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4262/12542 | Batch Loss: 1.5016 | Learning Rate: 0.000887 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4263/12542 | Batch Loss: 0.8756 | Learning Rate: 0.000887 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4264/12542 | Batch Loss: 1.1922 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4265/12542 | Batch Loss: 0.8440 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4266/12542 | Batch Loss: 2.0489 | Learning Rate: 0.000887 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4267/12542 | Batch Loss: 1.2788 | Learning Rate: 0.000887 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4268/12542 | Batch Loss: 1.7441 | Learning Rate: 0.000887 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4269/12542 | Batch Loss: 1.9249 | Learning Rate: 0.000887 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4270/12542 | Batch Loss: 1.2838 | Learning Rate: 0.000887 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4271/12542 | Batch Loss: 1.3692 | Learning Rate: 0.000886 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4272/12542 | Batch Loss: 1.5568 | Learning Rate: 0.000886 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4273/12542 | Batch Loss: 1.3228 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4274/12542 | Batch Loss: 0.6289 | Learning Rate: 0.000886 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4275/12542 | Batch Loss: 0.8823 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4276/12542 | Batch Loss: 2.6189 | Learning Rate: 0.000886 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4277/12542 | Batch Loss: 1.1957 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4278/12542 | Batch Loss: 1.3167 | Learning Rate: 0.000886 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4279/12542 | Batch Loss: 1.2747 | Learning Rate: 0.000886 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4280/12542 | Batch Loss: 1.1839 | Learning Rate: 0.000886 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4281/12542 | Batch Loss: 3.2137 | Learning Rate: 0.000886 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4282/12542 | Batch Loss: 1.4092 | Learning Rate: 0.000886 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4283/12542 | Batch Loss: 1.8120 | Learning Rate: 0.000886 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4284/12542 | Batch Loss: 1.7293 | Learning Rate: 0.000886 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4285/12542 | Batch Loss: 0.9818 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4286/12542 | Batch Loss: 0.9893 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4287/12542 | Batch Loss: 1.5600 | Learning Rate: 0.000886 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4288/12542 | Batch Loss: 0.9450 | Learning Rate: 0.000886 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4289/12542 | Batch Loss: 2.2185 | Learning Rate: 0.000886 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4290/12542 | Batch Loss: 0.7066 | Learning Rate: 0.000886 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4291/12542 | Batch Loss: 1.7056 | Learning Rate: 0.000886 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4292/12542 | Batch Loss: 3.1136 | Learning Rate: 0.000886 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4293/12542 | Batch Loss: 2.2041 | Learning Rate: 0.000886 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4294/12542 | Batch Loss: 1.5013 | Learning Rate: 0.000886 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4295/12542 | Batch Loss: 0.8065 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4296/12542 | Batch Loss: 1.1287 | Learning Rate: 0.000886 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4297/12542 | Batch Loss: 1.8689 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4298/12542 | Batch Loss: 1.7385 | Learning Rate: 0.000886 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4299/12542 | Batch Loss: 0.8687 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4300/12542 | Batch Loss: 1.2350 | Learning Rate: 0.000886 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4301/12542 | Batch Loss: 1.5695 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4302/12542 | Batch Loss: 0.9389 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4303/12542 | Batch Loss: 0.5289 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4304/12542 | Batch Loss: 3.6681 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4305/12542 | Batch Loss: 1.2881 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4306/12542 | Batch Loss: 0.7443 | Learning Rate: 0.000886 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4307/12542 | Batch Loss: 2.4370 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4308/12542 | Batch Loss: 1.1623 | Learning Rate: 0.000886 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4309/12542 | Batch Loss: 1.3076 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4310/12542 | Batch Loss: 2.1917 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4311/12542 | Batch Loss: 1.9244 | Learning Rate: 0.000885 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4312/12542 | Batch Loss: 0.6903 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4313/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4314/12542 | Batch Loss: 1.4646 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4315/12542 | Batch Loss: 1.3430 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4316/12542 | Batch Loss: 0.9458 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4317/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4318/12542 | Batch Loss: 2.0904 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4319/12542 | Batch Loss: 1.2504 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4320/12542 | Batch Loss: 0.6302 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4321/12542 | Batch Loss: 1.1336 | Learning Rate: 0.000885 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4322/12542 | Batch Loss: 1.7636 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4323/12542 | Batch Loss: 1.1391 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4324/12542 | Batch Loss: 0.6995 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4325/12542 | Batch Loss: 1.3936 | Learning Rate: 0.000885 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4326/12542 | Batch Loss: 1.3206 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4327/12542 | Batch Loss: 1.8604 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4328/12542 | Batch Loss: 0.6355 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4329/12542 | Batch Loss: 0.7340 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4330/12542 | Batch Loss: 3.3062 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4331/12542 | Batch Loss: 1.6921 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4332/12542 | Batch Loss: 0.6792 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4333/12542 | Batch Loss: 0.9639 | Learning Rate: 0.000885 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4334/12542 | Batch Loss: 1.3078 | Learning Rate: 0.000885 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4335/12542 | Batch Loss: 0.9760 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4336/12542 | Batch Loss: 1.4203 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4337/12542 | Batch Loss: 1.3578 | Learning Rate: 0.000885 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4338/12542 | Batch Loss: 0.6296 | Learning Rate: 0.000885 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4339/12542 | Batch Loss: 2.0797 | Learning Rate: 0.000885 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 4340/12542 | Batch Loss: 1.4360 | Learning Rate: 0.000885 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4341/12542 | Batch Loss: 0.8306 | Learning Rate: 0.000885 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4342/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000885 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4343/12542 | Batch Loss: 1.1098 | Learning Rate: 0.000885 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4344/12542 | Batch Loss: 1.5914 | Learning Rate: 0.000885 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4345/12542 | Batch Loss: 0.5688 | Learning Rate: 0.000885 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4346/12542 | Batch Loss: 0.7615 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4347/12542 | Batch Loss: 1.0326 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4348/12542 | Batch Loss: 1.8262 | Learning Rate: 0.000884 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 4349/12542 | Batch Loss: 1.2131 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4350/12542 | Batch Loss: 0.8832 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4351/12542 | Batch Loss: 2.5304 | Learning Rate: 0.000884 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4352/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000884 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4353/12542 | Batch Loss: 1.6727 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4354/12542 | Batch Loss: 1.7871 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4355/12542 | Batch Loss: 2.8326 | Learning Rate: 0.000884 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4356/12542 | Batch Loss: 2.5225 | Learning Rate: 0.000884 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4357/12542 | Batch Loss: 0.7560 | Learning Rate: 0.000884 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4358/12542 | Batch Loss: 1.4495 | Learning Rate: 0.000884 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4359/12542 | Batch Loss: 0.4520 | Learning Rate: 0.000884 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4360/12542 | Batch Loss: 1.1548 | Learning Rate: 0.000884 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4361/12542 | Batch Loss: 0.6967 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4362/12542 | Batch Loss: 1.1055 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4363/12542 | Batch Loss: 2.5643 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4364/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000884 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4365/12542 | Batch Loss: 1.9958 | Learning Rate: 0.000884 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4366/12542 | Batch Loss: 3.8227 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4367/12542 | Batch Loss: 2.3569 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4368/12542 | Batch Loss: 0.8720 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4369/12542 | Batch Loss: 0.8726 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4370/12542 | Batch Loss: 2.6141 | Learning Rate: 0.000884 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4371/12542 | Batch Loss: 1.4983 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4372/12542 | Batch Loss: 1.4420 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4373/12542 | Batch Loss: 1.9581 | Learning Rate: 0.000884 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4374/12542 | Batch Loss: 1.0981 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4375/12542 | Batch Loss: 1.2371 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4376/12542 | Batch Loss: 1.3832 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4377/12542 | Batch Loss: 0.9244 | Learning Rate: 0.000884 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4378/12542 | Batch Loss: 0.7718 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4379/12542 | Batch Loss: 1.3956 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4380/12542 | Batch Loss: 1.9673 | Learning Rate: 0.000884 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4381/12542 | Batch Loss: 1.3548 | Learning Rate: 0.000884 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4382/12542 | Batch Loss: 0.9083 | Learning Rate: 0.000884 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4383/12542 | Batch Loss: 1.3132 | Learning Rate: 0.000884 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4384/12542 | Batch Loss: 1.1274 | Learning Rate: 0.000883 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4385/12542 | Batch Loss: 0.8378 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4386/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000883 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4387/12542 | Batch Loss: 1.8246 | Learning Rate: 0.000883 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4388/12542 | Batch Loss: 0.6218 | Learning Rate: 0.000883 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4389/12542 | Batch Loss: 2.2531 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4390/12542 | Batch Loss: 0.4636 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4391/12542 | Batch Loss: 1.1797 | Learning Rate: 0.000883 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4392/12542 | Batch Loss: 1.1570 | Learning Rate: 0.000883 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4393/12542 | Batch Loss: 1.5523 | Learning Rate: 0.000883 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4394/12542 | Batch Loss: 1.4332 | Learning Rate: 0.000883 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4395/12542 | Batch Loss: 2.1113 | Learning Rate: 0.000883 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4396/12542 | Batch Loss: 1.8211 | Learning Rate: 0.000883 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4397/12542 | Batch Loss: 0.9684 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4398/12542 | Batch Loss: 1.7684 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4399/12542 | Batch Loss: 0.8565 | Learning Rate: 0.000883 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4400/12542 | Batch Loss: 0.8431 | Learning Rate: 0.000883 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4401/12542 | Batch Loss: 2.2938 | Learning Rate: 0.000883 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4402/12542 | Batch Loss: 0.9252 | Learning Rate: 0.000883 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4403/12542 | Batch Loss: 2.2317 | Learning Rate: 0.000883 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4404/12542 | Batch Loss: 0.7580 | Learning Rate: 0.000883 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4405/12542 | Batch Loss: 2.3668 | Learning Rate: 0.000883 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4406/12542 | Batch Loss: 1.1796 | Learning Rate: 0.000883 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4407/12542 | Batch Loss: 1.3627 | Learning Rate: 0.000883 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4408/12542 | Batch Loss: 1.8761 | Learning Rate: 0.000883 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4409/12542 | Batch Loss: 1.0270 | Learning Rate: 0.000883 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4410/12542 | Batch Loss: 1.5315 | Learning Rate: 0.000883 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4411/12542 | Batch Loss: 1.3623 | Learning Rate: 0.000883 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4412/12542 | Batch Loss: 1.1866 | Learning Rate: 0.000883 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4413/12542 | Batch Loss: 1.1575 | Learning Rate: 0.000883 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4414/12542 | Batch Loss: 1.6275 | Learning Rate: 0.000883 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4415/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000883 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4416/12542 | Batch Loss: 2.6833 | Learning Rate: 0.000883 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4417/12542 | Batch Loss: 0.9774 | Learning Rate: 0.000883 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4418/12542 | Batch Loss: 1.0600 | Learning Rate: 0.000883 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4419/12542 | Batch Loss: 0.7585 | Learning Rate: 0.000883 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4420/12542 | Batch Loss: 0.8437 | Learning Rate: 0.000883 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4421/12542 | Batch Loss: 1.8496 | Learning Rate: 0.000883 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4422/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4423/12542 | Batch Loss: 1.4313 | Learning Rate: 0.000882 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4424/12542 | Batch Loss: 2.9782 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4425/12542 | Batch Loss: 1.3389 | Learning Rate: 0.000882 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4426/12542 | Batch Loss: 0.8405 | Learning Rate: 0.000882 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4427/12542 | Batch Loss: 2.1265 | Learning Rate: 0.000882 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4428/12542 | Batch Loss: 1.1822 | Learning Rate: 0.000882 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4429/12542 | Batch Loss: 3.3777 | Learning Rate: 0.000882 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4430/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000882 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4431/12542 | Batch Loss: 0.6285 | Learning Rate: 0.000882 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4432/12542 | Batch Loss: 0.9256 | Learning Rate: 0.000882 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4433/12542 | Batch Loss: 1.8007 | Learning Rate: 0.000882 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4434/12542 | Batch Loss: 1.2207 | Learning Rate: 0.000882 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4435/12542 | Batch Loss: 1.9805 | Learning Rate: 0.000882 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4436/12542 | Batch Loss: 1.5630 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4437/12542 | Batch Loss: 1.4323 | Learning Rate: 0.000882 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4438/12542 | Batch Loss: 1.9340 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4439/12542 | Batch Loss: 1.3888 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4440/12542 | Batch Loss: 1.0291 | Learning Rate: 0.000882 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4441/12542 | Batch Loss: 0.9331 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4442/12542 | Batch Loss: 1.6703 | Learning Rate: 0.000882 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4443/12542 | Batch Loss: 1.8266 | Learning Rate: 0.000882 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4444/12542 | Batch Loss: 0.5791 | Learning Rate: 0.000882 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4445/12542 | Batch Loss: 1.4772 | Learning Rate: 0.000882 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4446/12542 | Batch Loss: 1.1101 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4447/12542 | Batch Loss: 1.0193 | Learning Rate: 0.000882 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4448/12542 | Batch Loss: 0.6315 | Learning Rate: 0.000882 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4449/12542 | Batch Loss: 2.2318 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4450/12542 | Batch Loss: 2.0503 | Learning Rate: 0.000882 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4451/12542 | Batch Loss: 1.7996 | Learning Rate: 0.000882 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4452/12542 | Batch Loss: 2.1756 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4453/12542 | Batch Loss: 2.0115 | Learning Rate: 0.000882 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4454/12542 | Batch Loss: 1.7121 | Learning Rate: 0.000882 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4455/12542 | Batch Loss: 1.8309 | Learning Rate: 0.000882 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4456/12542 | Batch Loss: 2.1856 | Learning Rate: 0.000882 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4457/12542 | Batch Loss: 1.3297 | Learning Rate: 0.000882 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4458/12542 | Batch Loss: 1.2280 | Learning Rate: 0.000882 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4459/12542 | Batch Loss: 1.6534 | Learning Rate: 0.000881 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4460/12542 | Batch Loss: 1.4194 | Learning Rate: 0.000881 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4461/12542 | Batch Loss: 0.6879 | Learning Rate: 0.000881 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4462/12542 | Batch Loss: 1.3548 | Learning Rate: 0.000881 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4463/12542 | Batch Loss: 2.8700 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4464/12542 | Batch Loss: 0.7844 | Learning Rate: 0.000881 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4465/12542 | Batch Loss: 2.1616 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4466/12542 | Batch Loss: 1.8827 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4467/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4468/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4469/12542 | Batch Loss: 1.0328 | Learning Rate: 0.000881 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4470/12542 | Batch Loss: 1.3882 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4471/12542 | Batch Loss: 1.2472 | Learning Rate: 0.000881 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4472/12542 | Batch Loss: 1.4702 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4473/12542 | Batch Loss: 2.0166 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4474/12542 | Batch Loss: 1.3413 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4475/12542 | Batch Loss: 1.0228 | Learning Rate: 0.000881 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4476/12542 | Batch Loss: 1.3253 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4477/12542 | Batch Loss: 0.9213 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4478/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4479/12542 | Batch Loss: 1.6753 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4480/12542 | Batch Loss: 0.4737 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4481/12542 | Batch Loss: 1.5473 | Learning Rate: 0.000881 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4482/12542 | Batch Loss: 1.0007 | Learning Rate: 0.000881 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4483/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000881 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4484/12542 | Batch Loss: 1.2103 | Learning Rate: 0.000881 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4485/12542 | Batch Loss: 2.0364 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4486/12542 | Batch Loss: 1.7688 | Learning Rate: 0.000881 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4487/12542 | Batch Loss: 1.6170 | Learning Rate: 0.000881 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4488/12542 | Batch Loss: 1.4840 | Learning Rate: 0.000881 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4489/12542 | Batch Loss: 1.4714 | Learning Rate: 0.000881 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4490/12542 | Batch Loss: 1.5453 | Learning Rate: 0.000881 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4491/12542 | Batch Loss: 0.9846 | Learning Rate: 0.000881 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4492/12542 | Batch Loss: 2.5321 | Learning Rate: 0.000881 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4493/12542 | Batch Loss: 2.1993 | Learning Rate: 0.000881 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4494/12542 | Batch Loss: 1.6305 | Learning Rate: 0.000881 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4495/12542 | Batch Loss: 1.5263 | Learning Rate: 0.000881 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4496/12542 | Batch Loss: 0.4607 | Learning Rate: 0.000881 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4497/12542 | Batch Loss: 0.8688 | Learning Rate: 0.000880 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4498/12542 | Batch Loss: 1.3070 | Learning Rate: 0.000880 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4499/12542 | Batch Loss: 1.0113 | Learning Rate: 0.000880 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4500/12542 | Batch Loss: 1.8073 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4501/12542 | Batch Loss: 1.7267 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4502/12542 | Batch Loss: 1.4280 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4503/12542 | Batch Loss: 1.1072 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4504/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4505/12542 | Batch Loss: 0.5437 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4506/12542 | Batch Loss: 1.6181 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4507/12542 | Batch Loss: 1.3088 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4508/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000880 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4509/12542 | Batch Loss: 0.9232 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4510/12542 | Batch Loss: 0.5507 | Learning Rate: 0.000880 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4511/12542 | Batch Loss: 0.9313 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4512/12542 | Batch Loss: 0.8334 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4513/12542 | Batch Loss: 1.7306 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4514/12542 | Batch Loss: 1.3902 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4515/12542 | Batch Loss: 0.7189 | Learning Rate: 0.000880 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4516/12542 | Batch Loss: 1.1992 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4517/12542 | Batch Loss: 1.2118 | Learning Rate: 0.000880 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4518/12542 | Batch Loss: 2.1460 | Learning Rate: 0.000880 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4519/12542 | Batch Loss: 4.0189 | Learning Rate: 0.000880 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4520/12542 | Batch Loss: 0.7893 | Learning Rate: 0.000880 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4521/12542 | Batch Loss: 1.0511 | Learning Rate: 0.000880 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4522/12542 | Batch Loss: 1.3398 | Learning Rate: 0.000880 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4523/12542 | Batch Loss: 1.8593 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4524/12542 | Batch Loss: 1.2558 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4525/12542 | Batch Loss: 0.8872 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4526/12542 | Batch Loss: 1.2525 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4527/12542 | Batch Loss: 1.3079 | Learning Rate: 0.000880 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4528/12542 | Batch Loss: 2.0073 | Learning Rate: 0.000880 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4529/12542 | Batch Loss: 1.5777 | Learning Rate: 0.000880 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4530/12542 | Batch Loss: 0.8979 | Learning Rate: 0.000880 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4531/12542 | Batch Loss: 1.6359 | Learning Rate: 0.000880 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4532/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000880 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4533/12542 | Batch Loss: 3.1932 | Learning Rate: 0.000880 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4534/12542 | Batch Loss: 1.0541 | Learning Rate: 0.000879 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4535/12542 | Batch Loss: 1.8039 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4536/12542 | Batch Loss: 1.9313 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4537/12542 | Batch Loss: 2.0494 | Learning Rate: 0.000879 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4538/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000879 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4539/12542 | Batch Loss: 1.5196 | Learning Rate: 0.000879 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4540/12542 | Batch Loss: 0.8628 | Learning Rate: 0.000879 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4541/12542 | Batch Loss: 1.4376 | Learning Rate: 0.000879 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4542/12542 | Batch Loss: 0.5579 | Learning Rate: 0.000879 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4543/12542 | Batch Loss: 1.2043 | Learning Rate: 0.000879 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4544/12542 | Batch Loss: 1.1772 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4545/12542 | Batch Loss: 1.8436 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4546/12542 | Batch Loss: 2.3846 | Learning Rate: 0.000879 | Batch Time: 0.54s\n",
      "Epoch 1 | Step 4547/12542 | Batch Loss: 1.5523 | Learning Rate: 0.000879 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4548/12542 | Batch Loss: 1.1937 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4549/12542 | Batch Loss: 1.6034 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4550/12542 | Batch Loss: 1.3959 | Learning Rate: 0.000879 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4551/12542 | Batch Loss: 1.7031 | Learning Rate: 0.000879 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4552/12542 | Batch Loss: 1.0800 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4553/12542 | Batch Loss: 0.6321 | Learning Rate: 0.000879 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4554/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000879 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4555/12542 | Batch Loss: 1.1916 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4556/12542 | Batch Loss: 1.7083 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4557/12542 | Batch Loss: 2.0245 | Learning Rate: 0.000879 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4558/12542 | Batch Loss: 1.8766 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4559/12542 | Batch Loss: 0.9219 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4560/12542 | Batch Loss: 0.4039 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4561/12542 | Batch Loss: 1.8023 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4562/12542 | Batch Loss: 1.3626 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4563/12542 | Batch Loss: 1.0425 | Learning Rate: 0.000879 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4564/12542 | Batch Loss: 1.5210 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4565/12542 | Batch Loss: 0.4785 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4566/12542 | Batch Loss: 2.0439 | Learning Rate: 0.000879 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4567/12542 | Batch Loss: 1.3753 | Learning Rate: 0.000879 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4568/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000879 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4569/12542 | Batch Loss: 0.8999 | Learning Rate: 0.000879 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4570/12542 | Batch Loss: 1.1040 | Learning Rate: 0.000879 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4571/12542 | Batch Loss: 1.3670 | Learning Rate: 0.000879 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4572/12542 | Batch Loss: 2.3577 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4573/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000878 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4574/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4575/12542 | Batch Loss: 1.9930 | Learning Rate: 0.000878 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4576/12542 | Batch Loss: 0.8161 | Learning Rate: 0.000878 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4577/12542 | Batch Loss: 0.5758 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4578/12542 | Batch Loss: 1.2694 | Learning Rate: 0.000878 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 4579/12542 | Batch Loss: 3.8517 | Learning Rate: 0.000878 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4580/12542 | Batch Loss: 0.9951 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4581/12542 | Batch Loss: 2.6273 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4582/12542 | Batch Loss: 2.7727 | Learning Rate: 0.000878 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4583/12542 | Batch Loss: 1.7291 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4584/12542 | Batch Loss: 2.0176 | Learning Rate: 0.000878 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4585/12542 | Batch Loss: 1.2551 | Learning Rate: 0.000878 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4586/12542 | Batch Loss: 0.8279 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4587/12542 | Batch Loss: 1.5257 | Learning Rate: 0.000878 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4588/12542 | Batch Loss: 1.4859 | Learning Rate: 0.000878 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4589/12542 | Batch Loss: 1.1788 | Learning Rate: 0.000878 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4590/12542 | Batch Loss: 1.2654 | Learning Rate: 0.000878 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4591/12542 | Batch Loss: 1.8055 | Learning Rate: 0.000878 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4592/12542 | Batch Loss: 0.6973 | Learning Rate: 0.000878 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4593/12542 | Batch Loss: 0.9395 | Learning Rate: 0.000878 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4594/12542 | Batch Loss: 2.2074 | Learning Rate: 0.000878 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4595/12542 | Batch Loss: 1.6711 | Learning Rate: 0.000878 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4596/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000878 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4597/12542 | Batch Loss: 1.0822 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4598/12542 | Batch Loss: 1.5351 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4599/12542 | Batch Loss: 2.0371 | Learning Rate: 0.000878 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4600/12542 | Batch Loss: 1.4927 | Learning Rate: 0.000878 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4601/12542 | Batch Loss: 1.3120 | Learning Rate: 0.000878 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4602/12542 | Batch Loss: 1.9872 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4603/12542 | Batch Loss: 1.2830 | Learning Rate: 0.000878 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4604/12542 | Batch Loss: 1.1006 | Learning Rate: 0.000878 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4605/12542 | Batch Loss: 1.2596 | Learning Rate: 0.000878 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4606/12542 | Batch Loss: 1.0830 | Learning Rate: 0.000878 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4607/12542 | Batch Loss: 1.9676 | Learning Rate: 0.000878 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4608/12542 | Batch Loss: 1.8012 | Learning Rate: 0.000878 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4609/12542 | Batch Loss: 2.5094 | Learning Rate: 0.000878 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4610/12542 | Batch Loss: 1.8407 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4611/12542 | Batch Loss: 0.6111 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4612/12542 | Batch Loss: 0.7237 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4613/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000877 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4614/12542 | Batch Loss: 2.6297 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4615/12542 | Batch Loss: 1.9448 | Learning Rate: 0.000877 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 4616/12542 | Batch Loss: 0.6135 | Learning Rate: 0.000877 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4617/12542 | Batch Loss: 0.8422 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4618/12542 | Batch Loss: 0.8743 | Learning Rate: 0.000877 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4619/12542 | Batch Loss: 0.6255 | Learning Rate: 0.000877 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4620/12542 | Batch Loss: 2.7792 | Learning Rate: 0.000877 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4621/12542 | Batch Loss: 0.8677 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4622/12542 | Batch Loss: 1.0922 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4623/12542 | Batch Loss: 0.7160 | Learning Rate: 0.000877 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4624/12542 | Batch Loss: 1.4769 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4625/12542 | Batch Loss: 1.5531 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4626/12542 | Batch Loss: 3.4680 | Learning Rate: 0.000877 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4627/12542 | Batch Loss: 2.4790 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4628/12542 | Batch Loss: 0.6638 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4629/12542 | Batch Loss: 2.3067 | Learning Rate: 0.000877 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4630/12542 | Batch Loss: 0.9571 | Learning Rate: 0.000877 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4631/12542 | Batch Loss: 0.8055 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4632/12542 | Batch Loss: 0.9572 | Learning Rate: 0.000877 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4633/12542 | Batch Loss: 1.3763 | Learning Rate: 0.000877 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4634/12542 | Batch Loss: 1.3107 | Learning Rate: 0.000877 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4635/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000877 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4636/12542 | Batch Loss: 1.2539 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4637/12542 | Batch Loss: 2.3610 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4638/12542 | Batch Loss: 1.4863 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4639/12542 | Batch Loss: 0.9366 | Learning Rate: 0.000877 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4640/12542 | Batch Loss: 0.9010 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4641/12542 | Batch Loss: 1.6755 | Learning Rate: 0.000877 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4642/12542 | Batch Loss: 1.3205 | Learning Rate: 0.000877 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4643/12542 | Batch Loss: 1.3984 | Learning Rate: 0.000877 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4644/12542 | Batch Loss: 1.7387 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4645/12542 | Batch Loss: 1.3680 | Learning Rate: 0.000877 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4646/12542 | Batch Loss: 0.6826 | Learning Rate: 0.000877 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4647/12542 | Batch Loss: 0.6845 | Learning Rate: 0.000876 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4648/12542 | Batch Loss: 1.5372 | Learning Rate: 0.000876 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4649/12542 | Batch Loss: 1.5347 | Learning Rate: 0.000876 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4650/12542 | Batch Loss: 1.2605 | Learning Rate: 0.000876 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4651/12542 | Batch Loss: 1.5887 | Learning Rate: 0.000876 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4652/12542 | Batch Loss: 1.3244 | Learning Rate: 0.000876 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4653/12542 | Batch Loss: 1.0080 | Learning Rate: 0.000876 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4654/12542 | Batch Loss: 1.1207 | Learning Rate: 0.000876 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4655/12542 | Batch Loss: 0.9531 | Learning Rate: 0.000876 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4656/12542 | Batch Loss: 0.5245 | Learning Rate: 0.000876 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4657/12542 | Batch Loss: 1.1711 | Learning Rate: 0.000876 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4658/12542 | Batch Loss: 1.3276 | Learning Rate: 0.000876 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4659/12542 | Batch Loss: 1.2372 | Learning Rate: 0.000876 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4660/12542 | Batch Loss: 0.7469 | Learning Rate: 0.000876 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4661/12542 | Batch Loss: 0.9826 | Learning Rate: 0.000876 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4662/12542 | Batch Loss: 0.7150 | Learning Rate: 0.000876 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4663/12542 | Batch Loss: 0.6043 | Learning Rate: 0.000876 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4664/12542 | Batch Loss: 1.1491 | Learning Rate: 0.000876 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4665/12542 | Batch Loss: 0.4850 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4666/12542 | Batch Loss: 1.8498 | Learning Rate: 0.000876 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4667/12542 | Batch Loss: 4.1213 | Learning Rate: 0.000876 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4668/12542 | Batch Loss: 1.2697 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4669/12542 | Batch Loss: 2.0701 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4670/12542 | Batch Loss: 1.4696 | Learning Rate: 0.000876 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4671/12542 | Batch Loss: 0.8895 | Learning Rate: 0.000876 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4672/12542 | Batch Loss: 2.2343 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4673/12542 | Batch Loss: 1.0710 | Learning Rate: 0.000876 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4674/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000876 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4675/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4676/12542 | Batch Loss: 1.5096 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4677/12542 | Batch Loss: 1.2563 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4678/12542 | Batch Loss: 1.5788 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4679/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000876 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4680/12542 | Batch Loss: 2.4856 | Learning Rate: 0.000876 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4681/12542 | Batch Loss: 2.2647 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4682/12542 | Batch Loss: 1.6282 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4683/12542 | Batch Loss: 1.8872 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4684/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000876 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4685/12542 | Batch Loss: 1.5293 | Learning Rate: 0.000875 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4686/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000875 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4687/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4688/12542 | Batch Loss: 2.1796 | Learning Rate: 0.000875 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4689/12542 | Batch Loss: 2.5448 | Learning Rate: 0.000875 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4690/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000875 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4691/12542 | Batch Loss: 1.6947 | Learning Rate: 0.000875 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4692/12542 | Batch Loss: 2.2208 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4693/12542 | Batch Loss: 1.8861 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4694/12542 | Batch Loss: 0.4702 | Learning Rate: 0.000875 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4695/12542 | Batch Loss: 1.7399 | Learning Rate: 0.000875 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4696/12542 | Batch Loss: 1.2704 | Learning Rate: 0.000875 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4697/12542 | Batch Loss: 0.8626 | Learning Rate: 0.000875 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4698/12542 | Batch Loss: 1.1965 | Learning Rate: 0.000875 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4699/12542 | Batch Loss: 0.8354 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4700/12542 | Batch Loss: 0.7086 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4701/12542 | Batch Loss: 1.6400 | Learning Rate: 0.000875 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4702/12542 | Batch Loss: 0.6124 | Learning Rate: 0.000875 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4703/12542 | Batch Loss: 1.4783 | Learning Rate: 0.000875 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4704/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000875 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4705/12542 | Batch Loss: 0.6956 | Learning Rate: 0.000875 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4706/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000875 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4707/12542 | Batch Loss: 1.5866 | Learning Rate: 0.000875 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4708/12542 | Batch Loss: 2.8609 | Learning Rate: 0.000875 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4709/12542 | Batch Loss: 1.2888 | Learning Rate: 0.000875 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4710/12542 | Batch Loss: 1.7831 | Learning Rate: 0.000875 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4711/12542 | Batch Loss: 1.7838 | Learning Rate: 0.000875 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4712/12542 | Batch Loss: 1.4306 | Learning Rate: 0.000875 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4713/12542 | Batch Loss: 1.0415 | Learning Rate: 0.000875 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4714/12542 | Batch Loss: 2.7909 | Learning Rate: 0.000875 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4715/12542 | Batch Loss: 0.6599 | Learning Rate: 0.000875 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4716/12542 | Batch Loss: 2.8880 | Learning Rate: 0.000875 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4717/12542 | Batch Loss: 1.5000 | Learning Rate: 0.000875 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4718/12542 | Batch Loss: 0.8608 | Learning Rate: 0.000875 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4719/12542 | Batch Loss: 2.4909 | Learning Rate: 0.000875 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4720/12542 | Batch Loss: 0.5341 | Learning Rate: 0.000875 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4721/12542 | Batch Loss: 3.5901 | Learning Rate: 0.000875 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4722/12542 | Batch Loss: 1.1020 | Learning Rate: 0.000875 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4723/12542 | Batch Loss: 1.5624 | Learning Rate: 0.000874 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4724/12542 | Batch Loss: 1.3972 | Learning Rate: 0.000874 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4725/12542 | Batch Loss: 0.8998 | Learning Rate: 0.000874 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4726/12542 | Batch Loss: 1.1568 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4727/12542 | Batch Loss: 1.7758 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4728/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000874 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4729/12542 | Batch Loss: 1.6402 | Learning Rate: 0.000874 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4730/12542 | Batch Loss: 1.2152 | Learning Rate: 0.000874 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4731/12542 | Batch Loss: 1.4215 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4732/12542 | Batch Loss: 1.2939 | Learning Rate: 0.000874 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4733/12542 | Batch Loss: 2.0538 | Learning Rate: 0.000874 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4734/12542 | Batch Loss: 3.0836 | Learning Rate: 0.000874 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4735/12542 | Batch Loss: 1.5219 | Learning Rate: 0.000874 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4736/12542 | Batch Loss: 0.5448 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4737/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000874 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4738/12542 | Batch Loss: 1.5171 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4739/12542 | Batch Loss: 1.5270 | Learning Rate: 0.000874 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4740/12542 | Batch Loss: 1.6662 | Learning Rate: 0.000874 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4741/12542 | Batch Loss: 1.0293 | Learning Rate: 0.000874 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4742/12542 | Batch Loss: 0.9963 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4743/12542 | Batch Loss: 0.8779 | Learning Rate: 0.000874 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4744/12542 | Batch Loss: 1.6719 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4745/12542 | Batch Loss: 1.5641 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4746/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000874 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4747/12542 | Batch Loss: 1.2098 | Learning Rate: 0.000874 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4748/12542 | Batch Loss: 0.9421 | Learning Rate: 0.000874 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4749/12542 | Batch Loss: 1.0073 | Learning Rate: 0.000874 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4750/12542 | Batch Loss: 1.0453 | Learning Rate: 0.000874 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4751/12542 | Batch Loss: 1.3720 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4752/12542 | Batch Loss: 1.3730 | Learning Rate: 0.000874 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4753/12542 | Batch Loss: 1.2091 | Learning Rate: 0.000874 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4754/12542 | Batch Loss: 1.3077 | Learning Rate: 0.000874 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4755/12542 | Batch Loss: 0.8014 | Learning Rate: 0.000874 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4756/12542 | Batch Loss: 2.6288 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4757/12542 | Batch Loss: 0.7575 | Learning Rate: 0.000874 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4758/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000874 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4759/12542 | Batch Loss: 1.3342 | Learning Rate: 0.000874 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4760/12542 | Batch Loss: 0.7992 | Learning Rate: 0.000873 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4761/12542 | Batch Loss: 2.8126 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4762/12542 | Batch Loss: 2.4038 | Learning Rate: 0.000873 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4763/12542 | Batch Loss: 2.1273 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4764/12542 | Batch Loss: 1.7643 | Learning Rate: 0.000873 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4765/12542 | Batch Loss: 1.6378 | Learning Rate: 0.000873 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4766/12542 | Batch Loss: 3.1840 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4767/12542 | Batch Loss: 1.0643 | Learning Rate: 0.000873 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4768/12542 | Batch Loss: 1.1071 | Learning Rate: 0.000873 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4769/12542 | Batch Loss: 2.6001 | Learning Rate: 0.000873 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4770/12542 | Batch Loss: 1.5149 | Learning Rate: 0.000873 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4771/12542 | Batch Loss: 1.7437 | Learning Rate: 0.000873 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4772/12542 | Batch Loss: 2.3362 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4773/12542 | Batch Loss: 1.2565 | Learning Rate: 0.000873 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4774/12542 | Batch Loss: 1.8410 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4775/12542 | Batch Loss: 2.1643 | Learning Rate: 0.000873 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4776/12542 | Batch Loss: 1.0130 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4777/12542 | Batch Loss: 1.4532 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4778/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000873 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4779/12542 | Batch Loss: 1.8118 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4780/12542 | Batch Loss: 0.6598 | Learning Rate: 0.000873 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4781/12542 | Batch Loss: 1.3817 | Learning Rate: 0.000873 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4782/12542 | Batch Loss: 1.5381 | Learning Rate: 0.000873 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4783/12542 | Batch Loss: 0.8660 | Learning Rate: 0.000873 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4784/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4785/12542 | Batch Loss: 1.6721 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4786/12542 | Batch Loss: 2.8267 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4787/12542 | Batch Loss: 1.6472 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4788/12542 | Batch Loss: 1.2450 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4789/12542 | Batch Loss: 1.1231 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4790/12542 | Batch Loss: 3.4616 | Learning Rate: 0.000873 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4791/12542 | Batch Loss: 0.9592 | Learning Rate: 0.000873 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4792/12542 | Batch Loss: 0.9591 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4793/12542 | Batch Loss: 0.8676 | Learning Rate: 0.000873 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4794/12542 | Batch Loss: 1.3157 | Learning Rate: 0.000873 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4795/12542 | Batch Loss: 1.6119 | Learning Rate: 0.000873 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4796/12542 | Batch Loss: 1.5849 | Learning Rate: 0.000873 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4797/12542 | Batch Loss: 0.6222 | Learning Rate: 0.000873 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4798/12542 | Batch Loss: 1.4826 | Learning Rate: 0.000872 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4799/12542 | Batch Loss: 1.0645 | Learning Rate: 0.000872 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4800/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000872 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4801/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4802/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4803/12542 | Batch Loss: 0.8050 | Learning Rate: 0.000872 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4804/12542 | Batch Loss: 0.5917 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4805/12542 | Batch Loss: 1.6741 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4806/12542 | Batch Loss: 0.5865 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4807/12542 | Batch Loss: 0.6452 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4808/12542 | Batch Loss: 0.8379 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4809/12542 | Batch Loss: 1.1849 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4810/12542 | Batch Loss: 0.9713 | Learning Rate: 0.000872 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4811/12542 | Batch Loss: 2.1156 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4812/12542 | Batch Loss: 0.4750 | Learning Rate: 0.000872 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4813/12542 | Batch Loss: 0.9500 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4814/12542 | Batch Loss: 1.2565 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4815/12542 | Batch Loss: 1.7033 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4816/12542 | Batch Loss: 1.5051 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4817/12542 | Batch Loss: 2.1766 | Learning Rate: 0.000872 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4818/12542 | Batch Loss: 0.9555 | Learning Rate: 0.000872 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4819/12542 | Batch Loss: 1.5490 | Learning Rate: 0.000872 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4820/12542 | Batch Loss: 1.6490 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4821/12542 | Batch Loss: 1.1722 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4822/12542 | Batch Loss: 1.4041 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4823/12542 | Batch Loss: 1.5537 | Learning Rate: 0.000872 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4824/12542 | Batch Loss: 1.2082 | Learning Rate: 0.000872 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4825/12542 | Batch Loss: 1.5232 | Learning Rate: 0.000872 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4826/12542 | Batch Loss: 0.9443 | Learning Rate: 0.000872 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4827/12542 | Batch Loss: 0.7069 | Learning Rate: 0.000872 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4828/12542 | Batch Loss: 1.4152 | Learning Rate: 0.000872 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4829/12542 | Batch Loss: 1.7206 | Learning Rate: 0.000872 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4830/12542 | Batch Loss: 0.6905 | Learning Rate: 0.000872 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4831/12542 | Batch Loss: 1.7096 | Learning Rate: 0.000872 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4832/12542 | Batch Loss: 2.5570 | Learning Rate: 0.000872 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4833/12542 | Batch Loss: 1.3609 | Learning Rate: 0.000872 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4834/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000872 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4835/12542 | Batch Loss: 1.2159 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4836/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4837/12542 | Batch Loss: 0.6339 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4838/12542 | Batch Loss: 0.9109 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4839/12542 | Batch Loss: 1.0218 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4840/12542 | Batch Loss: 1.3209 | Learning Rate: 0.000871 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4841/12542 | Batch Loss: 1.5923 | Learning Rate: 0.000871 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4842/12542 | Batch Loss: 0.4394 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4843/12542 | Batch Loss: 1.9644 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4844/12542 | Batch Loss: 1.6394 | Learning Rate: 0.000871 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4845/12542 | Batch Loss: 1.4378 | Learning Rate: 0.000871 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4846/12542 | Batch Loss: 0.8170 | Learning Rate: 0.000871 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4847/12542 | Batch Loss: 1.5082 | Learning Rate: 0.000871 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4848/12542 | Batch Loss: 2.7490 | Learning Rate: 0.000871 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4849/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000871 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4850/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000871 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4851/12542 | Batch Loss: 1.0745 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4852/12542 | Batch Loss: 1.6485 | Learning Rate: 0.000871 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4853/12542 | Batch Loss: 1.9953 | Learning Rate: 0.000871 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4854/12542 | Batch Loss: 0.6480 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4855/12542 | Batch Loss: 2.1754 | Learning Rate: 0.000871 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4856/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4857/12542 | Batch Loss: 1.6695 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4858/12542 | Batch Loss: 1.4387 | Learning Rate: 0.000871 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4859/12542 | Batch Loss: 1.0822 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4860/12542 | Batch Loss: 0.8161 | Learning Rate: 0.000871 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4861/12542 | Batch Loss: 2.4565 | Learning Rate: 0.000871 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4862/12542 | Batch Loss: 1.1902 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4863/12542 | Batch Loss: 1.5246 | Learning Rate: 0.000871 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4864/12542 | Batch Loss: 1.7840 | Learning Rate: 0.000871 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4865/12542 | Batch Loss: 0.8220 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4866/12542 | Batch Loss: 1.7158 | Learning Rate: 0.000871 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4867/12542 | Batch Loss: 2.5553 | Learning Rate: 0.000871 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4868/12542 | Batch Loss: 1.5965 | Learning Rate: 0.000871 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4869/12542 | Batch Loss: 0.9243 | Learning Rate: 0.000871 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4870/12542 | Batch Loss: 1.2085 | Learning Rate: 0.000871 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4871/12542 | Batch Loss: 1.3705 | Learning Rate: 0.000871 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4872/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000871 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4873/12542 | Batch Loss: 0.5225 | Learning Rate: 0.000870 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4874/12542 | Batch Loss: 2.2553 | Learning Rate: 0.000870 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4875/12542 | Batch Loss: 1.1911 | Learning Rate: 0.000870 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4876/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000870 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4877/12542 | Batch Loss: 1.5561 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4878/12542 | Batch Loss: 1.9239 | Learning Rate: 0.000870 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4879/12542 | Batch Loss: 0.6895 | Learning Rate: 0.000870 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4880/12542 | Batch Loss: 1.2690 | Learning Rate: 0.000870 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4881/12542 | Batch Loss: 0.5625 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4882/12542 | Batch Loss: 1.5008 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4883/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000870 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4884/12542 | Batch Loss: 0.4269 | Learning Rate: 0.000870 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4885/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000870 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4886/12542 | Batch Loss: 0.7981 | Learning Rate: 0.000870 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4887/12542 | Batch Loss: 1.4284 | Learning Rate: 0.000870 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4888/12542 | Batch Loss: 1.3029 | Learning Rate: 0.000870 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4889/12542 | Batch Loss: 0.9954 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4890/12542 | Batch Loss: 0.3032 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4891/12542 | Batch Loss: 1.0688 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4892/12542 | Batch Loss: 1.1823 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4893/12542 | Batch Loss: 0.8138 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4894/12542 | Batch Loss: 1.4256 | Learning Rate: 0.000870 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4895/12542 | Batch Loss: 1.6608 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4896/12542 | Batch Loss: 1.5762 | Learning Rate: 0.000870 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4897/12542 | Batch Loss: 1.9761 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4898/12542 | Batch Loss: 0.4478 | Learning Rate: 0.000870 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4899/12542 | Batch Loss: 0.6451 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4900/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4901/12542 | Batch Loss: 1.2632 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4902/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4903/12542 | Batch Loss: 2.8921 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4904/12542 | Batch Loss: 0.8036 | Learning Rate: 0.000870 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4905/12542 | Batch Loss: 1.5417 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4906/12542 | Batch Loss: 2.0738 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4907/12542 | Batch Loss: 1.4889 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4908/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000870 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4909/12542 | Batch Loss: 1.4033 | Learning Rate: 0.000870 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4910/12542 | Batch Loss: 1.9370 | Learning Rate: 0.000870 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4911/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4912/12542 | Batch Loss: 1.7395 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4913/12542 | Batch Loss: 2.1178 | Learning Rate: 0.000869 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4914/12542 | Batch Loss: 1.5187 | Learning Rate: 0.000869 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4915/12542 | Batch Loss: 0.6703 | Learning Rate: 0.000869 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4916/12542 | Batch Loss: 1.0491 | Learning Rate: 0.000869 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4917/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4918/12542 | Batch Loss: 1.6618 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4919/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000869 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4920/12542 | Batch Loss: 1.0165 | Learning Rate: 0.000869 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4921/12542 | Batch Loss: 2.4123 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4922/12542 | Batch Loss: 1.7473 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4923/12542 | Batch Loss: 1.6100 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4924/12542 | Batch Loss: 0.4705 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4925/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4926/12542 | Batch Loss: 1.7130 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4927/12542 | Batch Loss: 1.0008 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4928/12542 | Batch Loss: 2.2722 | Learning Rate: 0.000869 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4929/12542 | Batch Loss: 0.6944 | Learning Rate: 0.000869 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4930/12542 | Batch Loss: 1.4488 | Learning Rate: 0.000869 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4931/12542 | Batch Loss: 0.8708 | Learning Rate: 0.000869 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4932/12542 | Batch Loss: 1.5171 | Learning Rate: 0.000869 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 4933/12542 | Batch Loss: 1.1225 | Learning Rate: 0.000869 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4934/12542 | Batch Loss: 1.8577 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4935/12542 | Batch Loss: 0.8097 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4936/12542 | Batch Loss: 0.9470 | Learning Rate: 0.000869 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4937/12542 | Batch Loss: 0.7917 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4938/12542 | Batch Loss: 2.3106 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4939/12542 | Batch Loss: 0.4754 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4940/12542 | Batch Loss: 1.3652 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4941/12542 | Batch Loss: 1.8193 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4942/12542 | Batch Loss: 1.1258 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4943/12542 | Batch Loss: 1.3222 | Learning Rate: 0.000869 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4944/12542 | Batch Loss: 2.3579 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4945/12542 | Batch Loss: 1.2286 | Learning Rate: 0.000869 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 4946/12542 | Batch Loss: 0.9660 | Learning Rate: 0.000869 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4947/12542 | Batch Loss: 0.7404 | Learning Rate: 0.000869 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4948/12542 | Batch Loss: 1.8227 | Learning Rate: 0.000868 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4949/12542 | Batch Loss: 0.9935 | Learning Rate: 0.000868 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4950/12542 | Batch Loss: 1.8187 | Learning Rate: 0.000868 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4951/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4952/12542 | Batch Loss: 1.1094 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4953/12542 | Batch Loss: 1.0452 | Learning Rate: 0.000868 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4954/12542 | Batch Loss: 1.2846 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4955/12542 | Batch Loss: 1.9983 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4956/12542 | Batch Loss: 2.6599 | Learning Rate: 0.000868 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4957/12542 | Batch Loss: 1.5017 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4958/12542 | Batch Loss: 2.9325 | Learning Rate: 0.000868 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4959/12542 | Batch Loss: 0.9582 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4960/12542 | Batch Loss: 2.1239 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4961/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000868 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4962/12542 | Batch Loss: 2.4008 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4963/12542 | Batch Loss: 1.9374 | Learning Rate: 0.000868 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4964/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000868 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4965/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000868 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4966/12542 | Batch Loss: 1.7563 | Learning Rate: 0.000868 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4967/12542 | Batch Loss: 0.7673 | Learning Rate: 0.000868 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4968/12542 | Batch Loss: 0.7277 | Learning Rate: 0.000868 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4969/12542 | Batch Loss: 2.3804 | Learning Rate: 0.000868 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 4970/12542 | Batch Loss: 1.8970 | Learning Rate: 0.000868 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4971/12542 | Batch Loss: 1.4073 | Learning Rate: 0.000868 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4972/12542 | Batch Loss: 2.2378 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4973/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000868 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4974/12542 | Batch Loss: 1.6221 | Learning Rate: 0.000868 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4975/12542 | Batch Loss: 1.1699 | Learning Rate: 0.000868 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4976/12542 | Batch Loss: 2.5678 | Learning Rate: 0.000868 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4977/12542 | Batch Loss: 1.7763 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4978/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000868 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4979/12542 | Batch Loss: 2.2892 | Learning Rate: 0.000868 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4980/12542 | Batch Loss: 0.9193 | Learning Rate: 0.000868 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4981/12542 | Batch Loss: 2.0677 | Learning Rate: 0.000868 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4982/12542 | Batch Loss: 0.4433 | Learning Rate: 0.000868 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4983/12542 | Batch Loss: 1.2328 | Learning Rate: 0.000868 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4984/12542 | Batch Loss: 3.1866 | Learning Rate: 0.000868 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4985/12542 | Batch Loss: 1.8647 | Learning Rate: 0.000868 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4986/12542 | Batch Loss: 1.8586 | Learning Rate: 0.000867 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4987/12542 | Batch Loss: 0.9053 | Learning Rate: 0.000867 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 4988/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000867 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4989/12542 | Batch Loss: 1.8773 | Learning Rate: 0.000867 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 4990/12542 | Batch Loss: 0.7663 | Learning Rate: 0.000867 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4991/12542 | Batch Loss: 1.1633 | Learning Rate: 0.000867 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 4992/12542 | Batch Loss: 1.4901 | Learning Rate: 0.000867 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 4993/12542 | Batch Loss: 2.5942 | Learning Rate: 0.000867 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 4994/12542 | Batch Loss: 1.5649 | Learning Rate: 0.000867 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4995/12542 | Batch Loss: 1.0606 | Learning Rate: 0.000867 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 4996/12542 | Batch Loss: 0.8518 | Learning Rate: 0.000867 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 4997/12542 | Batch Loss: 1.0975 | Learning Rate: 0.000867 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 4998/12542 | Batch Loss: 1.0063 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 4999/12542 | Batch Loss: 1.7212 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5000/12542 | Batch Loss: 1.1366 | Learning Rate: 0.000867 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5001/12542 | Batch Loss: 1.5901 | Learning Rate: 0.000867 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5002/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000867 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5003/12542 | Batch Loss: 0.3590 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5004/12542 | Batch Loss: 0.9779 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5005/12542 | Batch Loss: 1.7633 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5006/12542 | Batch Loss: 0.9651 | Learning Rate: 0.000867 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5007/12542 | Batch Loss: 1.6107 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5008/12542 | Batch Loss: 1.3154 | Learning Rate: 0.000867 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5009/12542 | Batch Loss: 0.9625 | Learning Rate: 0.000867 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5010/12542 | Batch Loss: 1.3221 | Learning Rate: 0.000867 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5011/12542 | Batch Loss: 1.4816 | Learning Rate: 0.000867 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5012/12542 | Batch Loss: 1.2723 | Learning Rate: 0.000867 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5013/12542 | Batch Loss: 1.3251 | Learning Rate: 0.000867 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5014/12542 | Batch Loss: 1.2432 | Learning Rate: 0.000867 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5015/12542 | Batch Loss: 1.3605 | Learning Rate: 0.000867 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5016/12542 | Batch Loss: 1.3018 | Learning Rate: 0.000867 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5017/12542 | Batch Loss: 1.6977 | Learning Rate: 0.000867 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5018/12542 | Batch Loss: 0.7524 | Learning Rate: 0.000867 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5019/12542 | Batch Loss: 2.0605 | Learning Rate: 0.000867 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5020/12542 | Batch Loss: 0.8511 | Learning Rate: 0.000867 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5021/12542 | Batch Loss: 1.3314 | Learning Rate: 0.000867 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5022/12542 | Batch Loss: 1.0840 | Learning Rate: 0.000867 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5023/12542 | Batch Loss: 0.8239 | Learning Rate: 0.000867 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5024/12542 | Batch Loss: 1.5024 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5025/12542 | Batch Loss: 1.2533 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5026/12542 | Batch Loss: 1.9038 | Learning Rate: 0.000866 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5027/12542 | Batch Loss: 1.1030 | Learning Rate: 0.000866 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5028/12542 | Batch Loss: 1.2292 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5029/12542 | Batch Loss: 1.2622 | Learning Rate: 0.000866 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5030/12542 | Batch Loss: 0.9365 | Learning Rate: 0.000866 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5031/12542 | Batch Loss: 0.8196 | Learning Rate: 0.000866 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5032/12542 | Batch Loss: 0.8631 | Learning Rate: 0.000866 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5033/12542 | Batch Loss: 1.2980 | Learning Rate: 0.000866 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5034/12542 | Batch Loss: 1.2462 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5035/12542 | Batch Loss: 0.8561 | Learning Rate: 0.000866 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5036/12542 | Batch Loss: 3.5450 | Learning Rate: 0.000866 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5037/12542 | Batch Loss: 1.3265 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5038/12542 | Batch Loss: 0.3558 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5039/12542 | Batch Loss: 1.7547 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5040/12542 | Batch Loss: 1.5846 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5041/12542 | Batch Loss: 0.6804 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5042/12542 | Batch Loss: 1.6268 | Learning Rate: 0.000866 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5043/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5044/12542 | Batch Loss: 2.1362 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5045/12542 | Batch Loss: 1.0230 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5046/12542 | Batch Loss: 0.7124 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5047/12542 | Batch Loss: 0.6161 | Learning Rate: 0.000866 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5048/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5049/12542 | Batch Loss: 1.0904 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5050/12542 | Batch Loss: 1.7851 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5051/12542 | Batch Loss: 0.6686 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5052/12542 | Batch Loss: 1.2609 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5053/12542 | Batch Loss: 1.9590 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5054/12542 | Batch Loss: 1.7415 | Learning Rate: 0.000866 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5055/12542 | Batch Loss: 1.1037 | Learning Rate: 0.000866 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5056/12542 | Batch Loss: 0.6740 | Learning Rate: 0.000866 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5057/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000866 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5058/12542 | Batch Loss: 1.3905 | Learning Rate: 0.000866 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5059/12542 | Batch Loss: 1.0421 | Learning Rate: 0.000866 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5060/12542 | Batch Loss: 1.3399 | Learning Rate: 0.000866 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5061/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5062/12542 | Batch Loss: 0.7701 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5063/12542 | Batch Loss: 0.3626 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5064/12542 | Batch Loss: 0.9616 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5065/12542 | Batch Loss: 1.6299 | Learning Rate: 0.000865 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5066/12542 | Batch Loss: 1.9357 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5067/12542 | Batch Loss: 2.8547 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5068/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5069/12542 | Batch Loss: 0.6203 | Learning Rate: 0.000865 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5070/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5071/12542 | Batch Loss: 0.7058 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5072/12542 | Batch Loss: 1.1097 | Learning Rate: 0.000865 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5073/12542 | Batch Loss: 1.7149 | Learning Rate: 0.000865 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5074/12542 | Batch Loss: 1.1981 | Learning Rate: 0.000865 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5075/12542 | Batch Loss: 0.8975 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5076/12542 | Batch Loss: 3.1310 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5077/12542 | Batch Loss: 1.6387 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5078/12542 | Batch Loss: 0.8802 | Learning Rate: 0.000865 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5079/12542 | Batch Loss: 1.8940 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5080/12542 | Batch Loss: 1.1703 | Learning Rate: 0.000865 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5081/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000865 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5082/12542 | Batch Loss: 1.2157 | Learning Rate: 0.000865 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5083/12542 | Batch Loss: 0.8545 | Learning Rate: 0.000865 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5084/12542 | Batch Loss: 2.0313 | Learning Rate: 0.000865 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5085/12542 | Batch Loss: 1.9997 | Learning Rate: 0.000865 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5086/12542 | Batch Loss: 0.9407 | Learning Rate: 0.000865 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5087/12542 | Batch Loss: 0.6938 | Learning Rate: 0.000865 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5088/12542 | Batch Loss: 0.8395 | Learning Rate: 0.000865 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5089/12542 | Batch Loss: 0.9321 | Learning Rate: 0.000865 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5090/12542 | Batch Loss: 1.4146 | Learning Rate: 0.000865 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5091/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000865 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5092/12542 | Batch Loss: 1.0775 | Learning Rate: 0.000865 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5093/12542 | Batch Loss: 1.0830 | Learning Rate: 0.000865 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5094/12542 | Batch Loss: 1.7351 | Learning Rate: 0.000865 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5095/12542 | Batch Loss: 0.6608 | Learning Rate: 0.000865 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5096/12542 | Batch Loss: 1.3194 | Learning Rate: 0.000865 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5097/12542 | Batch Loss: 1.4506 | Learning Rate: 0.000865 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5098/12542 | Batch Loss: 1.1062 | Learning Rate: 0.000865 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5099/12542 | Batch Loss: 1.7694 | Learning Rate: 0.000864 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5100/12542 | Batch Loss: 2.6293 | Learning Rate: 0.000864 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5101/12542 | Batch Loss: 2.1464 | Learning Rate: 0.000864 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5102/12542 | Batch Loss: 1.7020 | Learning Rate: 0.000864 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5103/12542 | Batch Loss: 1.9985 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5104/12542 | Batch Loss: 0.9025 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5105/12542 | Batch Loss: 1.1947 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5106/12542 | Batch Loss: 1.6834 | Learning Rate: 0.000864 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5107/12542 | Batch Loss: 1.4419 | Learning Rate: 0.000864 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5108/12542 | Batch Loss: 0.6315 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5109/12542 | Batch Loss: 4.6088 | Learning Rate: 0.000864 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5110/12542 | Batch Loss: 2.3473 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5111/12542 | Batch Loss: 1.4183 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5112/12542 | Batch Loss: 1.3012 | Learning Rate: 0.000864 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5113/12542 | Batch Loss: 1.5282 | Learning Rate: 0.000864 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5114/12542 | Batch Loss: 1.3358 | Learning Rate: 0.000864 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5115/12542 | Batch Loss: 1.2898 | Learning Rate: 0.000864 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5116/12542 | Batch Loss: 1.1982 | Learning Rate: 0.000864 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5117/12542 | Batch Loss: 1.0506 | Learning Rate: 0.000864 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5118/12542 | Batch Loss: 0.6991 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5119/12542 | Batch Loss: 1.9041 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5120/12542 | Batch Loss: 1.1074 | Learning Rate: 0.000864 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5121/12542 | Batch Loss: 0.7435 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5122/12542 | Batch Loss: 3.1379 | Learning Rate: 0.000864 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5123/12542 | Batch Loss: 2.5289 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5124/12542 | Batch Loss: 1.3534 | Learning Rate: 0.000864 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5125/12542 | Batch Loss: 1.5887 | Learning Rate: 0.000864 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5126/12542 | Batch Loss: 1.4818 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5127/12542 | Batch Loss: 2.4714 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5128/12542 | Batch Loss: 1.1420 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5129/12542 | Batch Loss: 1.5025 | Learning Rate: 0.000864 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5130/12542 | Batch Loss: 1.1295 | Learning Rate: 0.000864 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5131/12542 | Batch Loss: 0.8820 | Learning Rate: 0.000864 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5132/12542 | Batch Loss: 2.9507 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5133/12542 | Batch Loss: 0.6980 | Learning Rate: 0.000864 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5134/12542 | Batch Loss: 1.6460 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5135/12542 | Batch Loss: 1.5846 | Learning Rate: 0.000864 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5136/12542 | Batch Loss: 1.3861 | Learning Rate: 0.000863 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5137/12542 | Batch Loss: 0.6413 | Learning Rate: 0.000863 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5138/12542 | Batch Loss: 1.4487 | Learning Rate: 0.000863 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5139/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000863 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5140/12542 | Batch Loss: 1.3106 | Learning Rate: 0.000863 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5141/12542 | Batch Loss: 2.8500 | Learning Rate: 0.000863 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5142/12542 | Batch Loss: 1.4841 | Learning Rate: 0.000863 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5143/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000863 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5144/12542 | Batch Loss: 0.5881 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5145/12542 | Batch Loss: 1.1340 | Learning Rate: 0.000863 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5146/12542 | Batch Loss: 2.2668 | Learning Rate: 0.000863 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5147/12542 | Batch Loss: 0.6892 | Learning Rate: 0.000863 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5148/12542 | Batch Loss: 0.9925 | Learning Rate: 0.000863 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5149/12542 | Batch Loss: 1.3567 | Learning Rate: 0.000863 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5150/12542 | Batch Loss: 1.9041 | Learning Rate: 0.000863 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5151/12542 | Batch Loss: 2.0273 | Learning Rate: 0.000863 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5152/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000863 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5153/12542 | Batch Loss: 1.1817 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5154/12542 | Batch Loss: 1.4427 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5155/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000863 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5156/12542 | Batch Loss: 1.3198 | Learning Rate: 0.000863 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5157/12542 | Batch Loss: 2.5217 | Learning Rate: 0.000863 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5158/12542 | Batch Loss: 1.7511 | Learning Rate: 0.000863 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5159/12542 | Batch Loss: 0.9794 | Learning Rate: 0.000863 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5160/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5161/12542 | Batch Loss: 1.2929 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5162/12542 | Batch Loss: 1.4991 | Learning Rate: 0.000863 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5163/12542 | Batch Loss: 2.0498 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5164/12542 | Batch Loss: 0.9074 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5165/12542 | Batch Loss: 1.1891 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5166/12542 | Batch Loss: 1.5091 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5167/12542 | Batch Loss: 1.1430 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5168/12542 | Batch Loss: 3.9557 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5169/12542 | Batch Loss: 1.1894 | Learning Rate: 0.000863 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5170/12542 | Batch Loss: 1.4861 | Learning Rate: 0.000863 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5171/12542 | Batch Loss: 1.7685 | Learning Rate: 0.000863 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5172/12542 | Batch Loss: 2.0581 | Learning Rate: 0.000863 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5173/12542 | Batch Loss: 1.0233 | Learning Rate: 0.000863 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5174/12542 | Batch Loss: 3.6929 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5175/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000862 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5176/12542 | Batch Loss: 1.5312 | Learning Rate: 0.000862 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5177/12542 | Batch Loss: 1.1880 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5178/12542 | Batch Loss: 2.0629 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5179/12542 | Batch Loss: 0.7410 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5180/12542 | Batch Loss: 1.4659 | Learning Rate: 0.000862 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5181/12542 | Batch Loss: 1.6133 | Learning Rate: 0.000862 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5182/12542 | Batch Loss: 3.0222 | Learning Rate: 0.000862 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5183/12542 | Batch Loss: 1.4703 | Learning Rate: 0.000862 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5184/12542 | Batch Loss: 2.0674 | Learning Rate: 0.000862 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5185/12542 | Batch Loss: 1.4019 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5186/12542 | Batch Loss: 0.5486 | Learning Rate: 0.000862 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5187/12542 | Batch Loss: 0.7664 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5188/12542 | Batch Loss: 1.1482 | Learning Rate: 0.000862 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5189/12542 | Batch Loss: 2.2509 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5190/12542 | Batch Loss: 1.0833 | Learning Rate: 0.000862 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5191/12542 | Batch Loss: 2.7442 | Learning Rate: 0.000862 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5192/12542 | Batch Loss: 0.7568 | Learning Rate: 0.000862 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5193/12542 | Batch Loss: 1.6576 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5194/12542 | Batch Loss: 1.7019 | Learning Rate: 0.000862 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5195/12542 | Batch Loss: 1.7782 | Learning Rate: 0.000862 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5196/12542 | Batch Loss: 1.6008 | Learning Rate: 0.000862 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5197/12542 | Batch Loss: 1.2904 | Learning Rate: 0.000862 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5198/12542 | Batch Loss: 0.8253 | Learning Rate: 0.000862 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5199/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000862 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5200/12542 | Batch Loss: 0.7969 | Learning Rate: 0.000862 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5201/12542 | Batch Loss: 1.8916 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5202/12542 | Batch Loss: 0.6644 | Learning Rate: 0.000862 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5203/12542 | Batch Loss: 0.5454 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5204/12542 | Batch Loss: 1.1583 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5205/12542 | Batch Loss: 0.3315 | Learning Rate: 0.000862 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5206/12542 | Batch Loss: 2.1595 | Learning Rate: 0.000862 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5207/12542 | Batch Loss: 3.1909 | Learning Rate: 0.000862 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5208/12542 | Batch Loss: 1.5358 | Learning Rate: 0.000862 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5209/12542 | Batch Loss: 2.5148 | Learning Rate: 0.000862 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5210/12542 | Batch Loss: 2.3623 | Learning Rate: 0.000862 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5211/12542 | Batch Loss: 0.5771 | Learning Rate: 0.000862 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5212/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000861 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5213/12542 | Batch Loss: 0.8729 | Learning Rate: 0.000861 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5214/12542 | Batch Loss: 1.8845 | Learning Rate: 0.000861 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5215/12542 | Batch Loss: 0.6663 | Learning Rate: 0.000861 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5216/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5217/12542 | Batch Loss: 0.6621 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5218/12542 | Batch Loss: 0.7279 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5219/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5220/12542 | Batch Loss: 0.6477 | Learning Rate: 0.000861 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5221/12542 | Batch Loss: 0.8625 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5222/12542 | Batch Loss: 0.6175 | Learning Rate: 0.000861 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5223/12542 | Batch Loss: 1.9348 | Learning Rate: 0.000861 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5224/12542 | Batch Loss: 1.0063 | Learning Rate: 0.000861 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5225/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000861 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5226/12542 | Batch Loss: 1.0511 | Learning Rate: 0.000861 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5227/12542 | Batch Loss: 2.8038 | Learning Rate: 0.000861 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5228/12542 | Batch Loss: 2.0882 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5229/12542 | Batch Loss: 1.3481 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5230/12542 | Batch Loss: 1.0613 | Learning Rate: 0.000861 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5231/12542 | Batch Loss: 0.7066 | Learning Rate: 0.000861 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5232/12542 | Batch Loss: 2.4108 | Learning Rate: 0.000861 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5233/12542 | Batch Loss: 1.3806 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5234/12542 | Batch Loss: 1.0375 | Learning Rate: 0.000861 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5235/12542 | Batch Loss: 1.5034 | Learning Rate: 0.000861 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5236/12542 | Batch Loss: 1.4109 | Learning Rate: 0.000861 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5237/12542 | Batch Loss: 1.8732 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5238/12542 | Batch Loss: 0.8694 | Learning Rate: 0.000861 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5239/12542 | Batch Loss: 1.2363 | Learning Rate: 0.000861 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5240/12542 | Batch Loss: 1.1659 | Learning Rate: 0.000861 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5241/12542 | Batch Loss: 0.3468 | Learning Rate: 0.000861 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5242/12542 | Batch Loss: 0.6304 | Learning Rate: 0.000861 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5243/12542 | Batch Loss: 0.9308 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5244/12542 | Batch Loss: 1.0674 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5245/12542 | Batch Loss: 1.5170 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5246/12542 | Batch Loss: 1.5453 | Learning Rate: 0.000861 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5247/12542 | Batch Loss: 0.9566 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5248/12542 | Batch Loss: 1.2985 | Learning Rate: 0.000861 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5249/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000860 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5250/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000860 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5251/12542 | Batch Loss: 0.7164 | Learning Rate: 0.000860 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5252/12542 | Batch Loss: 0.6604 | Learning Rate: 0.000860 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5253/12542 | Batch Loss: 1.0455 | Learning Rate: 0.000860 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5254/12542 | Batch Loss: 2.0673 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5255/12542 | Batch Loss: 1.3053 | Learning Rate: 0.000860 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5256/12542 | Batch Loss: 1.0045 | Learning Rate: 0.000860 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5257/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000860 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5258/12542 | Batch Loss: 1.2491 | Learning Rate: 0.000860 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5259/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000860 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5260/12542 | Batch Loss: 1.2636 | Learning Rate: 0.000860 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5261/12542 | Batch Loss: 1.9993 | Learning Rate: 0.000860 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5262/12542 | Batch Loss: 2.3544 | Learning Rate: 0.000860 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5263/12542 | Batch Loss: 0.7165 | Learning Rate: 0.000860 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5264/12542 | Batch Loss: 1.4000 | Learning Rate: 0.000860 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5265/12542 | Batch Loss: 1.8085 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5266/12542 | Batch Loss: 1.7379 | Learning Rate: 0.000860 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5267/12542 | Batch Loss: 1.3428 | Learning Rate: 0.000860 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5268/12542 | Batch Loss: 0.8457 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5269/12542 | Batch Loss: 1.0690 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5270/12542 | Batch Loss: 0.6267 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5271/12542 | Batch Loss: 1.1192 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5272/12542 | Batch Loss: 1.0361 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5273/12542 | Batch Loss: 1.3788 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5274/12542 | Batch Loss: 2.1074 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5275/12542 | Batch Loss: 0.7834 | Learning Rate: 0.000860 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5276/12542 | Batch Loss: 1.2123 | Learning Rate: 0.000860 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5277/12542 | Batch Loss: 0.6562 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5278/12542 | Batch Loss: 1.7022 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5279/12542 | Batch Loss: 2.1762 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5280/12542 | Batch Loss: 0.6454 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5281/12542 | Batch Loss: 0.5616 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5282/12542 | Batch Loss: 0.8102 | Learning Rate: 0.000860 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5283/12542 | Batch Loss: 1.2544 | Learning Rate: 0.000860 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5284/12542 | Batch Loss: 1.4442 | Learning Rate: 0.000860 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5285/12542 | Batch Loss: 1.6413 | Learning Rate: 0.000860 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5286/12542 | Batch Loss: 2.1632 | Learning Rate: 0.000860 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5287/12542 | Batch Loss: 1.4168 | Learning Rate: 0.000859 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5288/12542 | Batch Loss: 1.2993 | Learning Rate: 0.000859 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5289/12542 | Batch Loss: 0.9234 | Learning Rate: 0.000859 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5290/12542 | Batch Loss: 0.8213 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5291/12542 | Batch Loss: 1.1341 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5292/12542 | Batch Loss: 2.3825 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5293/12542 | Batch Loss: 0.7545 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5294/12542 | Batch Loss: 0.6753 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5295/12542 | Batch Loss: 1.0184 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5296/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5297/12542 | Batch Loss: 0.8474 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5298/12542 | Batch Loss: 3.8200 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5299/12542 | Batch Loss: 1.1677 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5300/12542 | Batch Loss: 1.8723 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5301/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5302/12542 | Batch Loss: 1.2202 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5303/12542 | Batch Loss: 0.7427 | Learning Rate: 0.000859 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5304/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000859 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5305/12542 | Batch Loss: 2.2605 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5306/12542 | Batch Loss: 1.2547 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5307/12542 | Batch Loss: 0.6462 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5308/12542 | Batch Loss: 0.9397 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5309/12542 | Batch Loss: 0.8428 | Learning Rate: 0.000859 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5310/12542 | Batch Loss: 1.5536 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5311/12542 | Batch Loss: 1.6797 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5312/12542 | Batch Loss: 0.8616 | Learning Rate: 0.000859 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5313/12542 | Batch Loss: 1.2177 | Learning Rate: 0.000859 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5314/12542 | Batch Loss: 1.9264 | Learning Rate: 0.000859 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5315/12542 | Batch Loss: 1.1523 | Learning Rate: 0.000859 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5316/12542 | Batch Loss: 1.1827 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5317/12542 | Batch Loss: 1.8982 | Learning Rate: 0.000859 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5318/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5319/12542 | Batch Loss: 1.3328 | Learning Rate: 0.000859 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5320/12542 | Batch Loss: 2.0822 | Learning Rate: 0.000859 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5321/12542 | Batch Loss: 0.4737 | Learning Rate: 0.000859 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5322/12542 | Batch Loss: 1.3511 | Learning Rate: 0.000859 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5323/12542 | Batch Loss: 0.9814 | Learning Rate: 0.000859 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5324/12542 | Batch Loss: 0.9236 | Learning Rate: 0.000859 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5325/12542 | Batch Loss: 0.4832 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5326/12542 | Batch Loss: 1.0435 | Learning Rate: 0.000858 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5327/12542 | Batch Loss: 2.0973 | Learning Rate: 0.000858 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5328/12542 | Batch Loss: 2.2164 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5329/12542 | Batch Loss: 1.1058 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5330/12542 | Batch Loss: 1.4733 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5331/12542 | Batch Loss: 1.3685 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5332/12542 | Batch Loss: 0.9089 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5333/12542 | Batch Loss: 1.9298 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5334/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5335/12542 | Batch Loss: 0.9487 | Learning Rate: 0.000858 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5336/12542 | Batch Loss: 0.9744 | Learning Rate: 0.000858 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5337/12542 | Batch Loss: 1.5093 | Learning Rate: 0.000858 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5338/12542 | Batch Loss: 1.6085 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5339/12542 | Batch Loss: 0.7816 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5340/12542 | Batch Loss: 1.9239 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5341/12542 | Batch Loss: 1.6394 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5342/12542 | Batch Loss: 1.4809 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5343/12542 | Batch Loss: 0.8872 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5344/12542 | Batch Loss: 1.9086 | Learning Rate: 0.000858 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5345/12542 | Batch Loss: 1.1127 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5346/12542 | Batch Loss: 1.6298 | Learning Rate: 0.000858 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5347/12542 | Batch Loss: 1.3193 | Learning Rate: 0.000858 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5348/12542 | Batch Loss: 1.1426 | Learning Rate: 0.000858 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5349/12542 | Batch Loss: 1.5705 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5350/12542 | Batch Loss: 0.9472 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5351/12542 | Batch Loss: 1.1084 | Learning Rate: 0.000858 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5352/12542 | Batch Loss: 0.8190 | Learning Rate: 0.000858 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5353/12542 | Batch Loss: 0.6754 | Learning Rate: 0.000858 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5354/12542 | Batch Loss: 1.3051 | Learning Rate: 0.000858 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5355/12542 | Batch Loss: 1.2278 | Learning Rate: 0.000858 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5356/12542 | Batch Loss: 0.9187 | Learning Rate: 0.000858 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5357/12542 | Batch Loss: 1.3121 | Learning Rate: 0.000858 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5358/12542 | Batch Loss: 0.7952 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5359/12542 | Batch Loss: 0.9363 | Learning Rate: 0.000858 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5360/12542 | Batch Loss: 1.6529 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5361/12542 | Batch Loss: 0.8750 | Learning Rate: 0.000858 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5362/12542 | Batch Loss: 1.3451 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5363/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5364/12542 | Batch Loss: 0.9159 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5365/12542 | Batch Loss: 1.4489 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5366/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5367/12542 | Batch Loss: 0.9345 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5368/12542 | Batch Loss: 0.7186 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5369/12542 | Batch Loss: 0.8312 | Learning Rate: 0.000857 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5370/12542 | Batch Loss: 3.7526 | Learning Rate: 0.000857 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5371/12542 | Batch Loss: 1.7399 | Learning Rate: 0.000857 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5372/12542 | Batch Loss: 1.2774 | Learning Rate: 0.000857 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5373/12542 | Batch Loss: 0.9088 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5374/12542 | Batch Loss: 0.8009 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5375/12542 | Batch Loss: 1.3352 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5376/12542 | Batch Loss: 0.7528 | Learning Rate: 0.000857 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5377/12542 | Batch Loss: 1.4997 | Learning Rate: 0.000857 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5378/12542 | Batch Loss: 1.6327 | Learning Rate: 0.000857 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5379/12542 | Batch Loss: 1.5638 | Learning Rate: 0.000857 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 5380/12542 | Batch Loss: 1.3711 | Learning Rate: 0.000857 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5381/12542 | Batch Loss: 0.8786 | Learning Rate: 0.000857 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5382/12542 | Batch Loss: 1.0255 | Learning Rate: 0.000857 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5383/12542 | Batch Loss: 1.2762 | Learning Rate: 0.000857 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5384/12542 | Batch Loss: 1.5863 | Learning Rate: 0.000857 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5385/12542 | Batch Loss: 2.2974 | Learning Rate: 0.000857 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5386/12542 | Batch Loss: 1.6223 | Learning Rate: 0.000857 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5387/12542 | Batch Loss: 1.4129 | Learning Rate: 0.000857 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5388/12542 | Batch Loss: 1.2740 | Learning Rate: 0.000857 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5389/12542 | Batch Loss: 1.9588 | Learning Rate: 0.000857 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5390/12542 | Batch Loss: 1.5940 | Learning Rate: 0.000857 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5391/12542 | Batch Loss: 2.6016 | Learning Rate: 0.000857 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5392/12542 | Batch Loss: 0.6731 | Learning Rate: 0.000857 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5393/12542 | Batch Loss: 2.2061 | Learning Rate: 0.000857 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5394/12542 | Batch Loss: 1.5101 | Learning Rate: 0.000857 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5395/12542 | Batch Loss: 1.8516 | Learning Rate: 0.000857 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5396/12542 | Batch Loss: 1.2618 | Learning Rate: 0.000857 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5397/12542 | Batch Loss: 1.4486 | Learning Rate: 0.000857 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5398/12542 | Batch Loss: 1.9729 | Learning Rate: 0.000857 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 5399/12542 | Batch Loss: 0.6529 | Learning Rate: 0.000857 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5400/12542 | Batch Loss: 1.2045 | Learning Rate: 0.000856 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5401/12542 | Batch Loss: 1.7655 | Learning Rate: 0.000856 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5402/12542 | Batch Loss: 0.7036 | Learning Rate: 0.000856 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5403/12542 | Batch Loss: 1.1563 | Learning Rate: 0.000856 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5404/12542 | Batch Loss: 0.8395 | Learning Rate: 0.000856 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5405/12542 | Batch Loss: 1.4557 | Learning Rate: 0.000856 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5406/12542 | Batch Loss: 1.2393 | Learning Rate: 0.000856 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5407/12542 | Batch Loss: 2.1232 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5408/12542 | Batch Loss: 1.5470 | Learning Rate: 0.000856 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5409/12542 | Batch Loss: 1.9714 | Learning Rate: 0.000856 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5410/12542 | Batch Loss: 0.8376 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5411/12542 | Batch Loss: 1.5066 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5412/12542 | Batch Loss: 2.0435 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5413/12542 | Batch Loss: 1.5614 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5414/12542 | Batch Loss: 1.9745 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5415/12542 | Batch Loss: 2.2737 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5416/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5417/12542 | Batch Loss: 0.6173 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5418/12542 | Batch Loss: 0.9125 | Learning Rate: 0.000856 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5419/12542 | Batch Loss: 1.9368 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5420/12542 | Batch Loss: 0.3448 | Learning Rate: 0.000856 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5421/12542 | Batch Loss: 1.9204 | Learning Rate: 0.000856 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5422/12542 | Batch Loss: 1.6576 | Learning Rate: 0.000856 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5423/12542 | Batch Loss: 0.7461 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5424/12542 | Batch Loss: 3.8029 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5425/12542 | Batch Loss: 0.8552 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5426/12542 | Batch Loss: 1.3979 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5427/12542 | Batch Loss: 1.8847 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5428/12542 | Batch Loss: 0.9402 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5429/12542 | Batch Loss: 1.2004 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5430/12542 | Batch Loss: 1.6302 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5431/12542 | Batch Loss: 1.2802 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5432/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5433/12542 | Batch Loss: 1.3107 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5434/12542 | Batch Loss: 1.0854 | Learning Rate: 0.000856 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5435/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5436/12542 | Batch Loss: 2.1387 | Learning Rate: 0.000856 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5437/12542 | Batch Loss: 1.7905 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5438/12542 | Batch Loss: 0.9568 | Learning Rate: 0.000855 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5439/12542 | Batch Loss: 1.3596 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5440/12542 | Batch Loss: 0.9324 | Learning Rate: 0.000855 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5441/12542 | Batch Loss: 1.5210 | Learning Rate: 0.000855 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5442/12542 | Batch Loss: 0.8752 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5443/12542 | Batch Loss: 0.8125 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5444/12542 | Batch Loss: 0.7840 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5445/12542 | Batch Loss: 1.4595 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5446/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5447/12542 | Batch Loss: 1.1924 | Learning Rate: 0.000855 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5448/12542 | Batch Loss: 1.4742 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5449/12542 | Batch Loss: 1.3458 | Learning Rate: 0.000855 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5450/12542 | Batch Loss: 1.9451 | Learning Rate: 0.000855 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5451/12542 | Batch Loss: 1.3982 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5452/12542 | Batch Loss: 1.7163 | Learning Rate: 0.000855 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5453/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5454/12542 | Batch Loss: 0.7383 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5455/12542 | Batch Loss: 0.7459 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5456/12542 | Batch Loss: 1.2500 | Learning Rate: 0.000855 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5457/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000855 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5458/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5459/12542 | Batch Loss: 0.8169 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5460/12542 | Batch Loss: 0.9603 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5461/12542 | Batch Loss: 1.7600 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5462/12542 | Batch Loss: 2.0654 | Learning Rate: 0.000855 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5463/12542 | Batch Loss: 3.1041 | Learning Rate: 0.000855 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5464/12542 | Batch Loss: 1.5225 | Learning Rate: 0.000855 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5465/12542 | Batch Loss: 0.4681 | Learning Rate: 0.000855 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5466/12542 | Batch Loss: 1.0412 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5467/12542 | Batch Loss: 1.4205 | Learning Rate: 0.000855 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5468/12542 | Batch Loss: 0.7250 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5469/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000855 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5470/12542 | Batch Loss: 1.4078 | Learning Rate: 0.000855 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5471/12542 | Batch Loss: 0.7655 | Learning Rate: 0.000855 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5472/12542 | Batch Loss: 1.1027 | Learning Rate: 0.000855 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5473/12542 | Batch Loss: 1.1999 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5474/12542 | Batch Loss: 0.7642 | Learning Rate: 0.000855 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5475/12542 | Batch Loss: 1.2205 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5476/12542 | Batch Loss: 0.8707 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5477/12542 | Batch Loss: 1.6512 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5478/12542 | Batch Loss: 0.8693 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5479/12542 | Batch Loss: 3.8299 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5480/12542 | Batch Loss: 1.8087 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5481/12542 | Batch Loss: 1.1221 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5482/12542 | Batch Loss: 1.0883 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5483/12542 | Batch Loss: 0.5370 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5484/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000854 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5485/12542 | Batch Loss: 1.3864 | Learning Rate: 0.000854 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5486/12542 | Batch Loss: 1.2801 | Learning Rate: 0.000854 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5487/12542 | Batch Loss: 3.3263 | Learning Rate: 0.000854 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5488/12542 | Batch Loss: 1.5935 | Learning Rate: 0.000854 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5489/12542 | Batch Loss: 0.5981 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5490/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5491/12542 | Batch Loss: 1.1501 | Learning Rate: 0.000854 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5492/12542 | Batch Loss: 1.7698 | Learning Rate: 0.000854 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5493/12542 | Batch Loss: 1.1708 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5494/12542 | Batch Loss: 0.9931 | Learning Rate: 0.000854 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5495/12542 | Batch Loss: 0.7618 | Learning Rate: 0.000854 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5496/12542 | Batch Loss: 2.2609 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5497/12542 | Batch Loss: 0.7578 | Learning Rate: 0.000854 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5498/12542 | Batch Loss: 0.9660 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5499/12542 | Batch Loss: 2.1381 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5500/12542 | Batch Loss: 1.2843 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5501/12542 | Batch Loss: 1.0917 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5502/12542 | Batch Loss: 1.8256 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5503/12542 | Batch Loss: 1.8897 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5504/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000854 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5505/12542 | Batch Loss: 1.2633 | Learning Rate: 0.000854 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5506/12542 | Batch Loss: 1.2143 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5507/12542 | Batch Loss: 1.4228 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5508/12542 | Batch Loss: 1.6109 | Learning Rate: 0.000854 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5509/12542 | Batch Loss: 0.6232 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5510/12542 | Batch Loss: 1.8420 | Learning Rate: 0.000854 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5511/12542 | Batch Loss: 0.5416 | Learning Rate: 0.000854 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5512/12542 | Batch Loss: 1.7662 | Learning Rate: 0.000854 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5513/12542 | Batch Loss: 1.2550 | Learning Rate: 0.000853 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5514/12542 | Batch Loss: 0.6494 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5515/12542 | Batch Loss: 1.3940 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5516/12542 | Batch Loss: 0.7884 | Learning Rate: 0.000853 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5517/12542 | Batch Loss: 1.7390 | Learning Rate: 0.000853 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5518/12542 | Batch Loss: 1.3718 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5519/12542 | Batch Loss: 1.5039 | Learning Rate: 0.000853 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5520/12542 | Batch Loss: 0.7356 | Learning Rate: 0.000853 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5521/12542 | Batch Loss: 1.0956 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5522/12542 | Batch Loss: 1.3327 | Learning Rate: 0.000853 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5523/12542 | Batch Loss: 1.0383 | Learning Rate: 0.000853 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5524/12542 | Batch Loss: 1.0930 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5525/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000853 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5526/12542 | Batch Loss: 2.2491 | Learning Rate: 0.000853 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5527/12542 | Batch Loss: 2.4081 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5528/12542 | Batch Loss: 2.0507 | Learning Rate: 0.000853 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5529/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5530/12542 | Batch Loss: 1.1466 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5531/12542 | Batch Loss: 1.5635 | Learning Rate: 0.000853 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5532/12542 | Batch Loss: 1.2346 | Learning Rate: 0.000853 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5533/12542 | Batch Loss: 0.9560 | Learning Rate: 0.000853 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5534/12542 | Batch Loss: 0.9237 | Learning Rate: 0.000853 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5535/12542 | Batch Loss: 1.4642 | Learning Rate: 0.000853 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5536/12542 | Batch Loss: 1.5668 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5537/12542 | Batch Loss: 1.7466 | Learning Rate: 0.000853 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5538/12542 | Batch Loss: 1.9609 | Learning Rate: 0.000853 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5539/12542 | Batch Loss: 1.7345 | Learning Rate: 0.000853 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5540/12542 | Batch Loss: 1.1357 | Learning Rate: 0.000853 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5541/12542 | Batch Loss: 0.6939 | Learning Rate: 0.000853 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 5542/12542 | Batch Loss: 1.2725 | Learning Rate: 0.000853 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5543/12542 | Batch Loss: 2.3540 | Learning Rate: 0.000853 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5544/12542 | Batch Loss: 1.1895 | Learning Rate: 0.000853 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5545/12542 | Batch Loss: 1.3759 | Learning Rate: 0.000853 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 5546/12542 | Batch Loss: 1.2152 | Learning Rate: 0.000853 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 5547/12542 | Batch Loss: 1.5428 | Learning Rate: 0.000853 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5548/12542 | Batch Loss: 1.4226 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5549/12542 | Batch Loss: 1.1368 | Learning Rate: 0.000853 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5550/12542 | Batch Loss: 1.7470 | Learning Rate: 0.000852 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5551/12542 | Batch Loss: 0.3966 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5552/12542 | Batch Loss: 1.2530 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5553/12542 | Batch Loss: 0.9605 | Learning Rate: 0.000852 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5554/12542 | Batch Loss: 0.9565 | Learning Rate: 0.000852 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5555/12542 | Batch Loss: 1.3266 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5556/12542 | Batch Loss: 2.7520 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5557/12542 | Batch Loss: 1.9533 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5558/12542 | Batch Loss: 1.6475 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5559/12542 | Batch Loss: 0.9601 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5560/12542 | Batch Loss: 1.5874 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5561/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000852 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5562/12542 | Batch Loss: 0.8685 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5563/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5564/12542 | Batch Loss: 1.1229 | Learning Rate: 0.000852 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5565/12542 | Batch Loss: 1.2389 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5566/12542 | Batch Loss: 2.2636 | Learning Rate: 0.000852 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5567/12542 | Batch Loss: 1.8414 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5568/12542 | Batch Loss: 1.0536 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5569/12542 | Batch Loss: 1.1652 | Learning Rate: 0.000852 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5570/12542 | Batch Loss: 0.9039 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5571/12542 | Batch Loss: 1.9374 | Learning Rate: 0.000852 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5572/12542 | Batch Loss: 1.9096 | Learning Rate: 0.000852 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5573/12542 | Batch Loss: 1.9115 | Learning Rate: 0.000852 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5574/12542 | Batch Loss: 0.8572 | Learning Rate: 0.000852 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5575/12542 | Batch Loss: 0.5157 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5576/12542 | Batch Loss: 1.0873 | Learning Rate: 0.000852 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5577/12542 | Batch Loss: 1.0421 | Learning Rate: 0.000852 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5578/12542 | Batch Loss: 1.6920 | Learning Rate: 0.000852 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5579/12542 | Batch Loss: 1.5891 | Learning Rate: 0.000852 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5580/12542 | Batch Loss: 1.8657 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5581/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000852 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5582/12542 | Batch Loss: 1.3553 | Learning Rate: 0.000852 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5583/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000852 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5584/12542 | Batch Loss: 0.4672 | Learning Rate: 0.000852 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5585/12542 | Batch Loss: 0.5605 | Learning Rate: 0.000852 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5586/12542 | Batch Loss: 0.7061 | Learning Rate: 0.000852 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5587/12542 | Batch Loss: 1.3574 | Learning Rate: 0.000852 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5588/12542 | Batch Loss: 1.2275 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5589/12542 | Batch Loss: 2.2974 | Learning Rate: 0.000851 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5590/12542 | Batch Loss: 0.5947 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5591/12542 | Batch Loss: 1.2268 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5592/12542 | Batch Loss: 0.8963 | Learning Rate: 0.000851 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5593/12542 | Batch Loss: 1.2298 | Learning Rate: 0.000851 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5594/12542 | Batch Loss: 1.0344 | Learning Rate: 0.000851 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5595/12542 | Batch Loss: 0.7978 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5596/12542 | Batch Loss: 0.5761 | Learning Rate: 0.000851 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5597/12542 | Batch Loss: 0.4409 | Learning Rate: 0.000851 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5598/12542 | Batch Loss: 3.3045 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5599/12542 | Batch Loss: 1.6694 | Learning Rate: 0.000851 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5600/12542 | Batch Loss: 0.8547 | Learning Rate: 0.000851 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5601/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000851 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5602/12542 | Batch Loss: 1.1944 | Learning Rate: 0.000851 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5603/12542 | Batch Loss: 1.3961 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5604/12542 | Batch Loss: 0.9479 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5605/12542 | Batch Loss: 1.6881 | Learning Rate: 0.000851 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5606/12542 | Batch Loss: 0.8836 | Learning Rate: 0.000851 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5607/12542 | Batch Loss: 0.7304 | Learning Rate: 0.000851 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5608/12542 | Batch Loss: 1.5298 | Learning Rate: 0.000851 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5609/12542 | Batch Loss: 0.6586 | Learning Rate: 0.000851 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5610/12542 | Batch Loss: 0.7534 | Learning Rate: 0.000851 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5611/12542 | Batch Loss: 1.7280 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5612/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5613/12542 | Batch Loss: 2.6236 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5614/12542 | Batch Loss: 1.5418 | Learning Rate: 0.000851 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5615/12542 | Batch Loss: 1.6798 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5616/12542 | Batch Loss: 1.1688 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5617/12542 | Batch Loss: 1.1029 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5618/12542 | Batch Loss: 0.8903 | Learning Rate: 0.000851 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5619/12542 | Batch Loss: 0.6489 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5620/12542 | Batch Loss: 0.7987 | Learning Rate: 0.000851 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5621/12542 | Batch Loss: 0.7521 | Learning Rate: 0.000851 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5622/12542 | Batch Loss: 1.5825 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5623/12542 | Batch Loss: 1.4572 | Learning Rate: 0.000851 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5624/12542 | Batch Loss: 1.1433 | Learning Rate: 0.000851 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5625/12542 | Batch Loss: 1.4487 | Learning Rate: 0.000851 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5626/12542 | Batch Loss: 2.4729 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5627/12542 | Batch Loss: 2.2534 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5628/12542 | Batch Loss: 1.2778 | Learning Rate: 0.000850 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5629/12542 | Batch Loss: 1.0966 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5630/12542 | Batch Loss: 1.6716 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5631/12542 | Batch Loss: 0.8652 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5632/12542 | Batch Loss: 0.6810 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5633/12542 | Batch Loss: 0.8521 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5634/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5635/12542 | Batch Loss: 1.5630 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5636/12542 | Batch Loss: 1.9789 | Learning Rate: 0.000850 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5637/12542 | Batch Loss: 2.0542 | Learning Rate: 0.000850 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5638/12542 | Batch Loss: 1.3459 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5639/12542 | Batch Loss: 1.0090 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5640/12542 | Batch Loss: 1.2258 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5641/12542 | Batch Loss: 0.7114 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5642/12542 | Batch Loss: 2.3337 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5643/12542 | Batch Loss: 1.1464 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5644/12542 | Batch Loss: 0.8629 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5645/12542 | Batch Loss: 2.1211 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5646/12542 | Batch Loss: 2.5422 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5647/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5648/12542 | Batch Loss: 1.8470 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5649/12542 | Batch Loss: 1.9003 | Learning Rate: 0.000850 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5650/12542 | Batch Loss: 0.9359 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5651/12542 | Batch Loss: 1.3030 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5652/12542 | Batch Loss: 0.9301 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5653/12542 | Batch Loss: 1.3981 | Learning Rate: 0.000850 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5654/12542 | Batch Loss: 1.4433 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5655/12542 | Batch Loss: 1.8895 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5656/12542 | Batch Loss: 2.7194 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5657/12542 | Batch Loss: 0.7143 | Learning Rate: 0.000850 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5658/12542 | Batch Loss: 1.5505 | Learning Rate: 0.000850 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5659/12542 | Batch Loss: 2.1574 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5660/12542 | Batch Loss: 3.2856 | Learning Rate: 0.000850 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5661/12542 | Batch Loss: 0.9738 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5662/12542 | Batch Loss: 1.0939 | Learning Rate: 0.000850 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5663/12542 | Batch Loss: 1.4780 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5664/12542 | Batch Loss: 0.8907 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5665/12542 | Batch Loss: 0.9889 | Learning Rate: 0.000849 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5666/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000849 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5667/12542 | Batch Loss: 0.9020 | Learning Rate: 0.000849 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5668/12542 | Batch Loss: 1.2619 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5669/12542 | Batch Loss: 2.1165 | Learning Rate: 0.000849 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5670/12542 | Batch Loss: 1.8913 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5671/12542 | Batch Loss: 0.2969 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5672/12542 | Batch Loss: 0.9957 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5673/12542 | Batch Loss: 0.9314 | Learning Rate: 0.000849 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5674/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5675/12542 | Batch Loss: 1.3021 | Learning Rate: 0.000849 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5676/12542 | Batch Loss: 1.8577 | Learning Rate: 0.000849 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5677/12542 | Batch Loss: 1.6800 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5678/12542 | Batch Loss: 1.9212 | Learning Rate: 0.000849 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5679/12542 | Batch Loss: 0.8582 | Learning Rate: 0.000849 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5680/12542 | Batch Loss: 1.1700 | Learning Rate: 0.000849 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5681/12542 | Batch Loss: 1.1378 | Learning Rate: 0.000849 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5682/12542 | Batch Loss: 3.1461 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5683/12542 | Batch Loss: 2.0941 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5684/12542 | Batch Loss: 1.3988 | Learning Rate: 0.000849 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5685/12542 | Batch Loss: 1.1543 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5686/12542 | Batch Loss: 1.1148 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5687/12542 | Batch Loss: 1.7035 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5688/12542 | Batch Loss: 0.4386 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5689/12542 | Batch Loss: 1.0729 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5690/12542 | Batch Loss: 0.7252 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5691/12542 | Batch Loss: 1.9031 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5692/12542 | Batch Loss: 1.4077 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5693/12542 | Batch Loss: 0.5483 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5694/12542 | Batch Loss: 1.7058 | Learning Rate: 0.000849 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5695/12542 | Batch Loss: 0.9619 | Learning Rate: 0.000849 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5696/12542 | Batch Loss: 3.1363 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5697/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000849 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5698/12542 | Batch Loss: 0.9846 | Learning Rate: 0.000849 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5699/12542 | Batch Loss: 3.1806 | Learning Rate: 0.000849 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5700/12542 | Batch Loss: 1.0647 | Learning Rate: 0.000849 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5701/12542 | Batch Loss: 2.5176 | Learning Rate: 0.000848 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5702/12542 | Batch Loss: 1.4624 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5703/12542 | Batch Loss: 0.9671 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5704/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000848 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5705/12542 | Batch Loss: 0.8814 | Learning Rate: 0.000848 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5706/12542 | Batch Loss: 1.4769 | Learning Rate: 0.000848 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5707/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000848 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5708/12542 | Batch Loss: 2.0517 | Learning Rate: 0.000848 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5709/12542 | Batch Loss: 1.5940 | Learning Rate: 0.000848 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5710/12542 | Batch Loss: 2.6255 | Learning Rate: 0.000848 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5711/12542 | Batch Loss: 1.3306 | Learning Rate: 0.000848 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5712/12542 | Batch Loss: 1.2554 | Learning Rate: 0.000848 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5713/12542 | Batch Loss: 1.4588 | Learning Rate: 0.000848 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5714/12542 | Batch Loss: 1.7913 | Learning Rate: 0.000848 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5715/12542 | Batch Loss: 0.8641 | Learning Rate: 0.000848 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5716/12542 | Batch Loss: 1.7619 | Learning Rate: 0.000848 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5717/12542 | Batch Loss: 1.5196 | Learning Rate: 0.000848 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5718/12542 | Batch Loss: 2.9899 | Learning Rate: 0.000848 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5719/12542 | Batch Loss: 2.1917 | Learning Rate: 0.000848 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5720/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5721/12542 | Batch Loss: 3.0549 | Learning Rate: 0.000848 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5722/12542 | Batch Loss: 1.5022 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5723/12542 | Batch Loss: 1.4752 | Learning Rate: 0.000848 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5724/12542 | Batch Loss: 1.8686 | Learning Rate: 0.000848 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5725/12542 | Batch Loss: 1.5550 | Learning Rate: 0.000848 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5726/12542 | Batch Loss: 2.5014 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5727/12542 | Batch Loss: 0.6610 | Learning Rate: 0.000848 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5728/12542 | Batch Loss: 1.1907 | Learning Rate: 0.000848 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5729/12542 | Batch Loss: 1.2814 | Learning Rate: 0.000848 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5730/12542 | Batch Loss: 1.0150 | Learning Rate: 0.000848 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5731/12542 | Batch Loss: 1.1063 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5732/12542 | Batch Loss: 1.5567 | Learning Rate: 0.000848 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5733/12542 | Batch Loss: 1.9026 | Learning Rate: 0.000848 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5734/12542 | Batch Loss: 2.1393 | Learning Rate: 0.000848 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5735/12542 | Batch Loss: 0.5179 | Learning Rate: 0.000848 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5736/12542 | Batch Loss: 1.9082 | Learning Rate: 0.000848 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5737/12542 | Batch Loss: 0.7051 | Learning Rate: 0.000848 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5738/12542 | Batch Loss: 0.5100 | Learning Rate: 0.000847 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5739/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000847 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5740/12542 | Batch Loss: 0.6832 | Learning Rate: 0.000847 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5741/12542 | Batch Loss: 1.4244 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5742/12542 | Batch Loss: 0.8809 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5743/12542 | Batch Loss: 1.4519 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5744/12542 | Batch Loss: 0.8234 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5745/12542 | Batch Loss: 0.7016 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5746/12542 | Batch Loss: 0.7519 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5747/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000847 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5748/12542 | Batch Loss: 1.1943 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5749/12542 | Batch Loss: 1.5103 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5750/12542 | Batch Loss: 0.8204 | Learning Rate: 0.000847 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5751/12542 | Batch Loss: 1.3638 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5752/12542 | Batch Loss: 0.5511 | Learning Rate: 0.000847 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5753/12542 | Batch Loss: 0.6790 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5754/12542 | Batch Loss: 2.1278 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5755/12542 | Batch Loss: 0.6752 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5756/12542 | Batch Loss: 1.2931 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5757/12542 | Batch Loss: 0.8536 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5758/12542 | Batch Loss: 1.0073 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5759/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5760/12542 | Batch Loss: 1.7085 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5761/12542 | Batch Loss: 0.7338 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5762/12542 | Batch Loss: 1.4574 | Learning Rate: 0.000847 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5763/12542 | Batch Loss: 0.6359 | Learning Rate: 0.000847 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 5764/12542 | Batch Loss: 0.7266 | Learning Rate: 0.000847 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 5765/12542 | Batch Loss: 1.7826 | Learning Rate: 0.000847 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5766/12542 | Batch Loss: 2.7526 | Learning Rate: 0.000847 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5767/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000847 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5768/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000847 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5769/12542 | Batch Loss: 0.5185 | Learning Rate: 0.000847 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5770/12542 | Batch Loss: 1.5493 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5771/12542 | Batch Loss: 1.1577 | Learning Rate: 0.000847 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5772/12542 | Batch Loss: 0.7653 | Learning Rate: 0.000847 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5773/12542 | Batch Loss: 1.1180 | Learning Rate: 0.000847 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5774/12542 | Batch Loss: 0.7600 | Learning Rate: 0.000847 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5775/12542 | Batch Loss: 1.7271 | Learning Rate: 0.000847 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5776/12542 | Batch Loss: 1.4460 | Learning Rate: 0.000846 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5777/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000846 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5778/12542 | Batch Loss: 2.2397 | Learning Rate: 0.000846 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5779/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000846 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5780/12542 | Batch Loss: 1.3009 | Learning Rate: 0.000846 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5781/12542 | Batch Loss: 0.5515 | Learning Rate: 0.000846 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5782/12542 | Batch Loss: 1.8276 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5783/12542 | Batch Loss: 1.3070 | Learning Rate: 0.000846 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5784/12542 | Batch Loss: 1.1619 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5785/12542 | Batch Loss: 2.0601 | Learning Rate: 0.000846 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5786/12542 | Batch Loss: 1.2615 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5787/12542 | Batch Loss: 2.3501 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5788/12542 | Batch Loss: 2.3160 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5789/12542 | Batch Loss: 1.0198 | Learning Rate: 0.000846 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5790/12542 | Batch Loss: 1.4827 | Learning Rate: 0.000846 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5791/12542 | Batch Loss: 0.5567 | Learning Rate: 0.000846 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5792/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000846 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5793/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5794/12542 | Batch Loss: 1.3066 | Learning Rate: 0.000846 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5795/12542 | Batch Loss: 0.7089 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5796/12542 | Batch Loss: 1.2513 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5797/12542 | Batch Loss: 1.7935 | Learning Rate: 0.000846 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5798/12542 | Batch Loss: 1.2522 | Learning Rate: 0.000846 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5799/12542 | Batch Loss: 1.0989 | Learning Rate: 0.000846 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5800/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000846 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5801/12542 | Batch Loss: 3.4387 | Learning Rate: 0.000846 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5802/12542 | Batch Loss: 1.0418 | Learning Rate: 0.000846 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5803/12542 | Batch Loss: 1.7087 | Learning Rate: 0.000846 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5804/12542 | Batch Loss: 1.1622 | Learning Rate: 0.000846 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5805/12542 | Batch Loss: 0.9951 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5806/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5807/12542 | Batch Loss: 2.4389 | Learning Rate: 0.000846 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5808/12542 | Batch Loss: 2.1286 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5809/12542 | Batch Loss: 1.6351 | Learning Rate: 0.000846 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5810/12542 | Batch Loss: 1.4828 | Learning Rate: 0.000846 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5811/12542 | Batch Loss: 3.0474 | Learning Rate: 0.000846 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5812/12542 | Batch Loss: 1.7351 | Learning Rate: 0.000846 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5813/12542 | Batch Loss: 1.3708 | Learning Rate: 0.000846 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5814/12542 | Batch Loss: 1.2996 | Learning Rate: 0.000845 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5815/12542 | Batch Loss: 0.9251 | Learning Rate: 0.000845 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5816/12542 | Batch Loss: 0.8474 | Learning Rate: 0.000845 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5817/12542 | Batch Loss: 2.1755 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5818/12542 | Batch Loss: 1.3465 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5819/12542 | Batch Loss: 0.8163 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5820/12542 | Batch Loss: 0.6739 | Learning Rate: 0.000845 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5821/12542 | Batch Loss: 1.2483 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5822/12542 | Batch Loss: 0.7494 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5823/12542 | Batch Loss: 1.6596 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5824/12542 | Batch Loss: 1.6265 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5825/12542 | Batch Loss: 1.9352 | Learning Rate: 0.000845 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5826/12542 | Batch Loss: 1.7216 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5827/12542 | Batch Loss: 1.2143 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5828/12542 | Batch Loss: 1.3007 | Learning Rate: 0.000845 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5829/12542 | Batch Loss: 0.7966 | Learning Rate: 0.000845 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5830/12542 | Batch Loss: 0.7912 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5831/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5832/12542 | Batch Loss: 0.8246 | Learning Rate: 0.000845 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5833/12542 | Batch Loss: 3.2220 | Learning Rate: 0.000845 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5834/12542 | Batch Loss: 1.0719 | Learning Rate: 0.000845 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5835/12542 | Batch Loss: 0.7221 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5836/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5837/12542 | Batch Loss: 1.0640 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5838/12542 | Batch Loss: 1.3464 | Learning Rate: 0.000845 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5839/12542 | Batch Loss: 0.8943 | Learning Rate: 0.000845 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5840/12542 | Batch Loss: 1.3526 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5841/12542 | Batch Loss: 1.1080 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5842/12542 | Batch Loss: 0.7893 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5843/12542 | Batch Loss: 0.8016 | Learning Rate: 0.000845 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5844/12542 | Batch Loss: 1.0331 | Learning Rate: 0.000845 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5845/12542 | Batch Loss: 3.2409 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5846/12542 | Batch Loss: 2.1306 | Learning Rate: 0.000845 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5847/12542 | Batch Loss: 1.2950 | Learning Rate: 0.000845 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5848/12542 | Batch Loss: 3.2805 | Learning Rate: 0.000845 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5849/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000845 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5850/12542 | Batch Loss: 1.3465 | Learning Rate: 0.000845 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5851/12542 | Batch Loss: 2.8258 | Learning Rate: 0.000844 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5852/12542 | Batch Loss: 0.6151 | Learning Rate: 0.000844 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5853/12542 | Batch Loss: 1.5784 | Learning Rate: 0.000844 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5854/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000844 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5855/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000844 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5856/12542 | Batch Loss: 1.5031 | Learning Rate: 0.000844 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5857/12542 | Batch Loss: 1.4514 | Learning Rate: 0.000844 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5858/12542 | Batch Loss: 0.7270 | Learning Rate: 0.000844 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5859/12542 | Batch Loss: 1.2637 | Learning Rate: 0.000844 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5860/12542 | Batch Loss: 1.9358 | Learning Rate: 0.000844 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5861/12542 | Batch Loss: 1.1736 | Learning Rate: 0.000844 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5862/12542 | Batch Loss: 1.3291 | Learning Rate: 0.000844 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5863/12542 | Batch Loss: 2.5915 | Learning Rate: 0.000844 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5864/12542 | Batch Loss: 1.5984 | Learning Rate: 0.000844 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5865/12542 | Batch Loss: 0.5616 | Learning Rate: 0.000844 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5866/12542 | Batch Loss: 2.3759 | Learning Rate: 0.000844 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5867/12542 | Batch Loss: 1.2045 | Learning Rate: 0.000844 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5868/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000844 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5869/12542 | Batch Loss: 1.0357 | Learning Rate: 0.000844 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5870/12542 | Batch Loss: 2.2279 | Learning Rate: 0.000844 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5871/12542 | Batch Loss: 1.1368 | Learning Rate: 0.000844 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5872/12542 | Batch Loss: 1.6732 | Learning Rate: 0.000844 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5873/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000844 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5874/12542 | Batch Loss: 1.1458 | Learning Rate: 0.000844 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5875/12542 | Batch Loss: 0.7357 | Learning Rate: 0.000844 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5876/12542 | Batch Loss: 1.6815 | Learning Rate: 0.000844 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5877/12542 | Batch Loss: 0.8414 | Learning Rate: 0.000844 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5878/12542 | Batch Loss: 1.0056 | Learning Rate: 0.000844 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5879/12542 | Batch Loss: 0.7471 | Learning Rate: 0.000844 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5880/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000844 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5881/12542 | Batch Loss: 0.8303 | Learning Rate: 0.000844 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5882/12542 | Batch Loss: 0.7712 | Learning Rate: 0.000844 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5883/12542 | Batch Loss: 1.2886 | Learning Rate: 0.000844 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5884/12542 | Batch Loss: 1.2972 | Learning Rate: 0.000844 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5885/12542 | Batch Loss: 1.4999 | Learning Rate: 0.000844 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5886/12542 | Batch Loss: 0.3863 | Learning Rate: 0.000844 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5887/12542 | Batch Loss: 0.9900 | Learning Rate: 0.000844 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5888/12542 | Batch Loss: 1.8562 | Learning Rate: 0.000844 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5889/12542 | Batch Loss: 2.2306 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5890/12542 | Batch Loss: 1.4875 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5891/12542 | Batch Loss: 0.9554 | Learning Rate: 0.000843 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5892/12542 | Batch Loss: 2.2019 | Learning Rate: 0.000843 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5893/12542 | Batch Loss: 1.6297 | Learning Rate: 0.000843 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5894/12542 | Batch Loss: 1.0172 | Learning Rate: 0.000843 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5895/12542 | Batch Loss: 2.4705 | Learning Rate: 0.000843 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5896/12542 | Batch Loss: 1.0922 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5897/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5898/12542 | Batch Loss: 1.4781 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5899/12542 | Batch Loss: 1.3834 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5900/12542 | Batch Loss: 0.6214 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5901/12542 | Batch Loss: 0.7515 | Learning Rate: 0.000843 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5902/12542 | Batch Loss: 1.8702 | Learning Rate: 0.000843 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5903/12542 | Batch Loss: 0.7701 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5904/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5905/12542 | Batch Loss: 1.4376 | Learning Rate: 0.000843 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5906/12542 | Batch Loss: 0.4241 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5907/12542 | Batch Loss: 1.5133 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5908/12542 | Batch Loss: 1.9380 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5909/12542 | Batch Loss: 2.0984 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5910/12542 | Batch Loss: 1.0175 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5911/12542 | Batch Loss: 2.3864 | Learning Rate: 0.000843 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5912/12542 | Batch Loss: 1.3839 | Learning Rate: 0.000843 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5913/12542 | Batch Loss: 1.8102 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5914/12542 | Batch Loss: 2.3543 | Learning Rate: 0.000843 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5915/12542 | Batch Loss: 0.7693 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5916/12542 | Batch Loss: 0.6831 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5917/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000843 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5918/12542 | Batch Loss: 1.1392 | Learning Rate: 0.000843 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5919/12542 | Batch Loss: 1.3359 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5920/12542 | Batch Loss: 1.0064 | Learning Rate: 0.000843 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5921/12542 | Batch Loss: 2.2430 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5922/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000843 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5923/12542 | Batch Loss: 1.4520 | Learning Rate: 0.000843 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5924/12542 | Batch Loss: 1.0858 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5925/12542 | Batch Loss: 1.0234 | Learning Rate: 0.000843 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5926/12542 | Batch Loss: 1.1132 | Learning Rate: 0.000843 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5927/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000842 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5928/12542 | Batch Loss: 2.0756 | Learning Rate: 0.000842 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5929/12542 | Batch Loss: 1.8231 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5930/12542 | Batch Loss: 0.3559 | Learning Rate: 0.000842 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5931/12542 | Batch Loss: 1.0144 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5932/12542 | Batch Loss: 1.7198 | Learning Rate: 0.000842 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5933/12542 | Batch Loss: 0.4959 | Learning Rate: 0.000842 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5934/12542 | Batch Loss: 2.3130 | Learning Rate: 0.000842 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 5935/12542 | Batch Loss: 2.4375 | Learning Rate: 0.000842 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5936/12542 | Batch Loss: 1.3560 | Learning Rate: 0.000842 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5937/12542 | Batch Loss: 1.2021 | Learning Rate: 0.000842 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5938/12542 | Batch Loss: 1.4373 | Learning Rate: 0.000842 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5939/12542 | Batch Loss: 2.0096 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5940/12542 | Batch Loss: 1.0047 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5941/12542 | Batch Loss: 1.2532 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5942/12542 | Batch Loss: 1.5641 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5943/12542 | Batch Loss: 0.9171 | Learning Rate: 0.000842 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5944/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000842 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5945/12542 | Batch Loss: 1.3355 | Learning Rate: 0.000842 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5946/12542 | Batch Loss: 1.8091 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5947/12542 | Batch Loss: 0.5387 | Learning Rate: 0.000842 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5948/12542 | Batch Loss: 2.3580 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5949/12542 | Batch Loss: 1.3343 | Learning Rate: 0.000842 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5950/12542 | Batch Loss: 0.9360 | Learning Rate: 0.000842 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5951/12542 | Batch Loss: 1.5231 | Learning Rate: 0.000842 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5952/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000842 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5953/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5954/12542 | Batch Loss: 1.0259 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5955/12542 | Batch Loss: 2.0262 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5956/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000842 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5957/12542 | Batch Loss: 1.6943 | Learning Rate: 0.000842 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5958/12542 | Batch Loss: 1.1991 | Learning Rate: 0.000842 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5959/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000842 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5960/12542 | Batch Loss: 2.7389 | Learning Rate: 0.000842 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5961/12542 | Batch Loss: 1.1841 | Learning Rate: 0.000842 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5962/12542 | Batch Loss: 2.0144 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5963/12542 | Batch Loss: 1.3232 | Learning Rate: 0.000842 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5964/12542 | Batch Loss: 0.8142 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5965/12542 | Batch Loss: 2.5103 | Learning Rate: 0.000841 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5966/12542 | Batch Loss: 1.2830 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5967/12542 | Batch Loss: 1.1636 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5968/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5969/12542 | Batch Loss: 0.8177 | Learning Rate: 0.000841 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 5970/12542 | Batch Loss: 0.7378 | Learning Rate: 0.000841 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 5971/12542 | Batch Loss: 2.6098 | Learning Rate: 0.000841 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5972/12542 | Batch Loss: 0.9860 | Learning Rate: 0.000841 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5973/12542 | Batch Loss: 1.4789 | Learning Rate: 0.000841 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 5974/12542 | Batch Loss: 1.1235 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5975/12542 | Batch Loss: 0.8074 | Learning Rate: 0.000841 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5976/12542 | Batch Loss: 0.8201 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5977/12542 | Batch Loss: 1.8061 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5978/12542 | Batch Loss: 0.7311 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5979/12542 | Batch Loss: 0.4692 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5980/12542 | Batch Loss: 1.9512 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5981/12542 | Batch Loss: 1.4553 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5982/12542 | Batch Loss: 1.9286 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5983/12542 | Batch Loss: 1.5118 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5984/12542 | Batch Loss: 1.5944 | Learning Rate: 0.000841 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5985/12542 | Batch Loss: 1.4703 | Learning Rate: 0.000841 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5986/12542 | Batch Loss: 1.0210 | Learning Rate: 0.000841 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 5987/12542 | Batch Loss: 0.7620 | Learning Rate: 0.000841 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 5988/12542 | Batch Loss: 1.1015 | Learning Rate: 0.000841 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 5989/12542 | Batch Loss: 1.8528 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 5990/12542 | Batch Loss: 1.2881 | Learning Rate: 0.000841 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 5991/12542 | Batch Loss: 0.9464 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5992/12542 | Batch Loss: 2.3993 | Learning Rate: 0.000841 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 5993/12542 | Batch Loss: 0.7557 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5994/12542 | Batch Loss: 1.0036 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5995/12542 | Batch Loss: 1.6886 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5996/12542 | Batch Loss: 1.4651 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 5997/12542 | Batch Loss: 0.7348 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5998/12542 | Batch Loss: 1.9457 | Learning Rate: 0.000841 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 5999/12542 | Batch Loss: 0.6836 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6000/12542 | Batch Loss: 1.3772 | Learning Rate: 0.000841 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6001/12542 | Batch Loss: 1.2744 | Learning Rate: 0.000841 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6002/12542 | Batch Loss: 0.5140 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6003/12542 | Batch Loss: 2.9456 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6004/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6005/12542 | Batch Loss: 0.7065 | Learning Rate: 0.000840 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6006/12542 | Batch Loss: 1.1581 | Learning Rate: 0.000840 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6007/12542 | Batch Loss: 1.8749 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6008/12542 | Batch Loss: 1.2792 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6009/12542 | Batch Loss: 1.7901 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6010/12542 | Batch Loss: 1.5692 | Learning Rate: 0.000840 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6011/12542 | Batch Loss: 1.1061 | Learning Rate: 0.000840 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6012/12542 | Batch Loss: 3.4966 | Learning Rate: 0.000840 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6013/12542 | Batch Loss: 1.2592 | Learning Rate: 0.000840 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6014/12542 | Batch Loss: 0.7911 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6015/12542 | Batch Loss: 1.3105 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6016/12542 | Batch Loss: 0.8277 | Learning Rate: 0.000840 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6017/12542 | Batch Loss: 1.9690 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6018/12542 | Batch Loss: 1.3009 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6019/12542 | Batch Loss: 1.5112 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6020/12542 | Batch Loss: 2.0303 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6021/12542 | Batch Loss: 1.1983 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6022/12542 | Batch Loss: 3.6037 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6023/12542 | Batch Loss: 2.3348 | Learning Rate: 0.000840 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6024/12542 | Batch Loss: 1.1220 | Learning Rate: 0.000840 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6025/12542 | Batch Loss: 1.0130 | Learning Rate: 0.000840 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6026/12542 | Batch Loss: 0.6708 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6027/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000840 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6028/12542 | Batch Loss: 2.2112 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6029/12542 | Batch Loss: 1.2147 | Learning Rate: 0.000840 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6030/12542 | Batch Loss: 0.9549 | Learning Rate: 0.000840 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6031/12542 | Batch Loss: 1.1904 | Learning Rate: 0.000840 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6032/12542 | Batch Loss: 0.6073 | Learning Rate: 0.000840 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6033/12542 | Batch Loss: 1.2750 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6034/12542 | Batch Loss: 1.2077 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6035/12542 | Batch Loss: 1.3655 | Learning Rate: 0.000840 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6036/12542 | Batch Loss: 1.7240 | Learning Rate: 0.000840 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6037/12542 | Batch Loss: 1.0367 | Learning Rate: 0.000840 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6038/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000840 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6039/12542 | Batch Loss: 1.4343 | Learning Rate: 0.000839 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6040/12542 | Batch Loss: 0.9072 | Learning Rate: 0.000839 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6041/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6042/12542 | Batch Loss: 1.3837 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6043/12542 | Batch Loss: 0.6081 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6044/12542 | Batch Loss: 1.4632 | Learning Rate: 0.000839 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6045/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6046/12542 | Batch Loss: 1.1104 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6047/12542 | Batch Loss: 3.0226 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6048/12542 | Batch Loss: 0.6905 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6049/12542 | Batch Loss: 1.1955 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6050/12542 | Batch Loss: 1.5076 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6051/12542 | Batch Loss: 0.6072 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6052/12542 | Batch Loss: 0.6020 | Learning Rate: 0.000839 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6053/12542 | Batch Loss: 2.5116 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6054/12542 | Batch Loss: 0.9888 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6055/12542 | Batch Loss: 0.7747 | Learning Rate: 0.000839 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6056/12542 | Batch Loss: 1.3529 | Learning Rate: 0.000839 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6057/12542 | Batch Loss: 0.6342 | Learning Rate: 0.000839 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6058/12542 | Batch Loss: 1.9085 | Learning Rate: 0.000839 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6059/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000839 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6060/12542 | Batch Loss: 1.4060 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6061/12542 | Batch Loss: 1.8646 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6062/12542 | Batch Loss: 1.4099 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6063/12542 | Batch Loss: 2.5342 | Learning Rate: 0.000839 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6064/12542 | Batch Loss: 0.4709 | Learning Rate: 0.000839 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6065/12542 | Batch Loss: 1.4761 | Learning Rate: 0.000839 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6066/12542 | Batch Loss: 1.3850 | Learning Rate: 0.000839 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6067/12542 | Batch Loss: 0.8049 | Learning Rate: 0.000839 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6068/12542 | Batch Loss: 1.2471 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6069/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6070/12542 | Batch Loss: 1.7034 | Learning Rate: 0.000839 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6071/12542 | Batch Loss: 1.1167 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6072/12542 | Batch Loss: 2.3915 | Learning Rate: 0.000839 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6073/12542 | Batch Loss: 1.1766 | Learning Rate: 0.000839 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6074/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000839 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6075/12542 | Batch Loss: 1.0628 | Learning Rate: 0.000839 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6076/12542 | Batch Loss: 2.1155 | Learning Rate: 0.000839 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6077/12542 | Batch Loss: 1.5056 | Learning Rate: 0.000838 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6078/12542 | Batch Loss: 1.3670 | Learning Rate: 0.000838 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6079/12542 | Batch Loss: 1.6085 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6080/12542 | Batch Loss: 1.6044 | Learning Rate: 0.000838 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6081/12542 | Batch Loss: 1.0544 | Learning Rate: 0.000838 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6082/12542 | Batch Loss: 1.9229 | Learning Rate: 0.000838 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6083/12542 | Batch Loss: 1.1749 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6084/12542 | Batch Loss: 2.2615 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6085/12542 | Batch Loss: 2.1316 | Learning Rate: 0.000838 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6086/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6087/12542 | Batch Loss: 1.4920 | Learning Rate: 0.000838 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6088/12542 | Batch Loss: 0.5301 | Learning Rate: 0.000838 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6089/12542 | Batch Loss: 1.7233 | Learning Rate: 0.000838 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6090/12542 | Batch Loss: 0.6606 | Learning Rate: 0.000838 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6091/12542 | Batch Loss: 0.5195 | Learning Rate: 0.000838 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6092/12542 | Batch Loss: 1.6700 | Learning Rate: 0.000838 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6093/12542 | Batch Loss: 1.7894 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6094/12542 | Batch Loss: 1.6173 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6095/12542 | Batch Loss: 1.0568 | Learning Rate: 0.000838 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6096/12542 | Batch Loss: 1.1003 | Learning Rate: 0.000838 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6097/12542 | Batch Loss: 1.5882 | Learning Rate: 0.000838 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6098/12542 | Batch Loss: 2.3872 | Learning Rate: 0.000838 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6099/12542 | Batch Loss: 1.2206 | Learning Rate: 0.000838 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6100/12542 | Batch Loss: 1.5509 | Learning Rate: 0.000838 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6101/12542 | Batch Loss: 1.4114 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6102/12542 | Batch Loss: 1.4539 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6103/12542 | Batch Loss: 1.3472 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6104/12542 | Batch Loss: 1.9356 | Learning Rate: 0.000838 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6105/12542 | Batch Loss: 0.6305 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6106/12542 | Batch Loss: 0.8917 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6107/12542 | Batch Loss: 0.7492 | Learning Rate: 0.000838 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6108/12542 | Batch Loss: 2.0197 | Learning Rate: 0.000838 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6109/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000838 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6110/12542 | Batch Loss: 1.7413 | Learning Rate: 0.000838 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6111/12542 | Batch Loss: 1.4650 | Learning Rate: 0.000838 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6112/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000838 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6113/12542 | Batch Loss: 1.0414 | Learning Rate: 0.000838 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6114/12542 | Batch Loss: 0.7531 | Learning Rate: 0.000838 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6115/12542 | Batch Loss: 1.6397 | Learning Rate: 0.000837 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6116/12542 | Batch Loss: 1.1886 | Learning Rate: 0.000837 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6117/12542 | Batch Loss: 0.9894 | Learning Rate: 0.000837 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6118/12542 | Batch Loss: 2.3450 | Learning Rate: 0.000837 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6119/12542 | Batch Loss: 0.6450 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6120/12542 | Batch Loss: 1.3885 | Learning Rate: 0.000837 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6121/12542 | Batch Loss: 0.7882 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6122/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000837 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6123/12542 | Batch Loss: 2.1834 | Learning Rate: 0.000837 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6124/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6125/12542 | Batch Loss: 1.2371 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6126/12542 | Batch Loss: 1.1178 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6127/12542 | Batch Loss: 1.5995 | Learning Rate: 0.000837 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6128/12542 | Batch Loss: 0.7639 | Learning Rate: 0.000837 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6129/12542 | Batch Loss: 0.9012 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6130/12542 | Batch Loss: 0.8666 | Learning Rate: 0.000837 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6131/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000837 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6132/12542 | Batch Loss: 1.0581 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6133/12542 | Batch Loss: 0.8313 | Learning Rate: 0.000837 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6134/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000837 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6135/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6136/12542 | Batch Loss: 2.5852 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6137/12542 | Batch Loss: 0.7342 | Learning Rate: 0.000837 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6138/12542 | Batch Loss: 0.8500 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6139/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6140/12542 | Batch Loss: 2.6738 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6141/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6142/12542 | Batch Loss: 0.7769 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6143/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000837 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6144/12542 | Batch Loss: 0.7417 | Learning Rate: 0.000837 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6145/12542 | Batch Loss: 1.1671 | Learning Rate: 0.000837 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6146/12542 | Batch Loss: 0.4683 | Learning Rate: 0.000837 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6147/12542 | Batch Loss: 1.8335 | Learning Rate: 0.000837 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6148/12542 | Batch Loss: 0.9231 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6149/12542 | Batch Loss: 2.2204 | Learning Rate: 0.000837 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6150/12542 | Batch Loss: 1.7538 | Learning Rate: 0.000837 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6151/12542 | Batch Loss: 2.2575 | Learning Rate: 0.000837 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6152/12542 | Batch Loss: 0.6941 | Learning Rate: 0.000836 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6153/12542 | Batch Loss: 1.6115 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6154/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6155/12542 | Batch Loss: 2.1395 | Learning Rate: 0.000836 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6156/12542 | Batch Loss: 1.3457 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6157/12542 | Batch Loss: 1.4721 | Learning Rate: 0.000836 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6158/12542 | Batch Loss: 1.4922 | Learning Rate: 0.000836 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6159/12542 | Batch Loss: 2.3153 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6160/12542 | Batch Loss: 1.3690 | Learning Rate: 0.000836 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6161/12542 | Batch Loss: 2.0168 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6162/12542 | Batch Loss: 0.8910 | Learning Rate: 0.000836 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6163/12542 | Batch Loss: 0.7992 | Learning Rate: 0.000836 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6164/12542 | Batch Loss: 1.3077 | Learning Rate: 0.000836 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6165/12542 | Batch Loss: 1.5232 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6166/12542 | Batch Loss: 2.8403 | Learning Rate: 0.000836 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6167/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6168/12542 | Batch Loss: 1.0486 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6169/12542 | Batch Loss: 1.3100 | Learning Rate: 0.000836 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6170/12542 | Batch Loss: 1.7809 | Learning Rate: 0.000836 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6171/12542 | Batch Loss: 1.7717 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6172/12542 | Batch Loss: 0.8511 | Learning Rate: 0.000836 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6173/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6174/12542 | Batch Loss: 1.8163 | Learning Rate: 0.000836 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6175/12542 | Batch Loss: 1.2251 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6176/12542 | Batch Loss: 2.5133 | Learning Rate: 0.000836 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6177/12542 | Batch Loss: 1.5158 | Learning Rate: 0.000836 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6178/12542 | Batch Loss: 0.7475 | Learning Rate: 0.000836 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6179/12542 | Batch Loss: 0.8595 | Learning Rate: 0.000836 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6180/12542 | Batch Loss: 1.2260 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6181/12542 | Batch Loss: 1.1224 | Learning Rate: 0.000836 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6182/12542 | Batch Loss: 1.1372 | Learning Rate: 0.000836 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6183/12542 | Batch Loss: 1.8859 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6184/12542 | Batch Loss: 1.5572 | Learning Rate: 0.000836 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6185/12542 | Batch Loss: 1.6798 | Learning Rate: 0.000836 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6186/12542 | Batch Loss: 0.6728 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6187/12542 | Batch Loss: 0.6304 | Learning Rate: 0.000836 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6188/12542 | Batch Loss: 1.2032 | Learning Rate: 0.000836 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6189/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000836 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6190/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6191/12542 | Batch Loss: 2.4849 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6192/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6193/12542 | Batch Loss: 2.0409 | Learning Rate: 0.000835 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6194/12542 | Batch Loss: 1.0729 | Learning Rate: 0.000835 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6195/12542 | Batch Loss: 0.7431 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6196/12542 | Batch Loss: 1.1620 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6197/12542 | Batch Loss: 1.3881 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6198/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6199/12542 | Batch Loss: 1.2216 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6200/12542 | Batch Loss: 1.5912 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6201/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000835 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6202/12542 | Batch Loss: 1.9371 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6203/12542 | Batch Loss: 1.1661 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6204/12542 | Batch Loss: 1.3586 | Learning Rate: 0.000835 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6205/12542 | Batch Loss: 1.6271 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6206/12542 | Batch Loss: 0.7436 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6207/12542 | Batch Loss: 0.8916 | Learning Rate: 0.000835 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6208/12542 | Batch Loss: 1.5080 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6209/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6210/12542 | Batch Loss: 1.1908 | Learning Rate: 0.000835 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6211/12542 | Batch Loss: 0.8377 | Learning Rate: 0.000835 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6212/12542 | Batch Loss: 0.7043 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6213/12542 | Batch Loss: 2.1860 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6214/12542 | Batch Loss: 1.9946 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6215/12542 | Batch Loss: 2.1787 | Learning Rate: 0.000835 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6216/12542 | Batch Loss: 1.7568 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6217/12542 | Batch Loss: 1.9158 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6218/12542 | Batch Loss: 2.2260 | Learning Rate: 0.000835 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6219/12542 | Batch Loss: 1.1463 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6220/12542 | Batch Loss: 2.1891 | Learning Rate: 0.000835 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6221/12542 | Batch Loss: 1.4579 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6222/12542 | Batch Loss: 3.0824 | Learning Rate: 0.000835 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6223/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000835 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6224/12542 | Batch Loss: 1.2672 | Learning Rate: 0.000835 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6225/12542 | Batch Loss: 2.5528 | Learning Rate: 0.000835 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6226/12542 | Batch Loss: 1.9143 | Learning Rate: 0.000835 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6227/12542 | Batch Loss: 1.1621 | Learning Rate: 0.000835 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6228/12542 | Batch Loss: 0.5201 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6229/12542 | Batch Loss: 0.7844 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6230/12542 | Batch Loss: 1.0449 | Learning Rate: 0.000834 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6231/12542 | Batch Loss: 3.1052 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6232/12542 | Batch Loss: 1.0184 | Learning Rate: 0.000834 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6233/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6234/12542 | Batch Loss: 1.8738 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6235/12542 | Batch Loss: 1.0245 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6236/12542 | Batch Loss: 1.6502 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6237/12542 | Batch Loss: 0.9544 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6238/12542 | Batch Loss: 2.3237 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6239/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6240/12542 | Batch Loss: 1.2534 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6241/12542 | Batch Loss: 1.3182 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6242/12542 | Batch Loss: 1.5775 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6243/12542 | Batch Loss: 1.2614 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6244/12542 | Batch Loss: 1.3615 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6245/12542 | Batch Loss: 2.0302 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6246/12542 | Batch Loss: 1.4192 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6247/12542 | Batch Loss: 1.5813 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6248/12542 | Batch Loss: 2.2272 | Learning Rate: 0.000834 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6249/12542 | Batch Loss: 0.8786 | Learning Rate: 0.000834 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6250/12542 | Batch Loss: 1.7189 | Learning Rate: 0.000834 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6251/12542 | Batch Loss: 1.3769 | Learning Rate: 0.000834 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6252/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000834 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6253/12542 | Batch Loss: 0.4522 | Learning Rate: 0.000834 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6254/12542 | Batch Loss: 1.6790 | Learning Rate: 0.000834 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6255/12542 | Batch Loss: 1.5680 | Learning Rate: 0.000834 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6256/12542 | Batch Loss: 1.3500 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6257/12542 | Batch Loss: 2.4808 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6258/12542 | Batch Loss: 0.7932 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6259/12542 | Batch Loss: 0.4883 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6260/12542 | Batch Loss: 1.2228 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6261/12542 | Batch Loss: 2.0277 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6262/12542 | Batch Loss: 0.9451 | Learning Rate: 0.000834 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6263/12542 | Batch Loss: 1.0623 | Learning Rate: 0.000834 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6264/12542 | Batch Loss: 1.9448 | Learning Rate: 0.000834 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6265/12542 | Batch Loss: 1.0977 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6266/12542 | Batch Loss: 0.9417 | Learning Rate: 0.000833 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6267/12542 | Batch Loss: 2.2002 | Learning Rate: 0.000833 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6268/12542 | Batch Loss: 1.2948 | Learning Rate: 0.000833 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6269/12542 | Batch Loss: 2.4163 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6270/12542 | Batch Loss: 1.5699 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6271/12542 | Batch Loss: 0.8829 | Learning Rate: 0.000833 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6272/12542 | Batch Loss: 1.5879 | Learning Rate: 0.000833 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6273/12542 | Batch Loss: 1.7878 | Learning Rate: 0.000833 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6274/12542 | Batch Loss: 1.1000 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6275/12542 | Batch Loss: 1.4051 | Learning Rate: 0.000833 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6276/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000833 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6277/12542 | Batch Loss: 1.8528 | Learning Rate: 0.000833 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6278/12542 | Batch Loss: 3.3045 | Learning Rate: 0.000833 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6279/12542 | Batch Loss: 1.7410 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6280/12542 | Batch Loss: 1.2768 | Learning Rate: 0.000833 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6281/12542 | Batch Loss: 2.9710 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6282/12542 | Batch Loss: 1.4738 | Learning Rate: 0.000833 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6283/12542 | Batch Loss: 1.6023 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6284/12542 | Batch Loss: 1.3058 | Learning Rate: 0.000833 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6285/12542 | Batch Loss: 2.4792 | Learning Rate: 0.000833 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6286/12542 | Batch Loss: 1.7934 | Learning Rate: 0.000833 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6287/12542 | Batch Loss: 1.1600 | Learning Rate: 0.000833 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6288/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6289/12542 | Batch Loss: 0.5364 | Learning Rate: 0.000833 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6290/12542 | Batch Loss: 2.1028 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6291/12542 | Batch Loss: 1.6346 | Learning Rate: 0.000833 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6292/12542 | Batch Loss: 1.3006 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6293/12542 | Batch Loss: 1.1638 | Learning Rate: 0.000833 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6294/12542 | Batch Loss: 1.3454 | Learning Rate: 0.000833 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6295/12542 | Batch Loss: 1.1825 | Learning Rate: 0.000833 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6296/12542 | Batch Loss: 0.8703 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6297/12542 | Batch Loss: 0.7945 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6298/12542 | Batch Loss: 1.0702 | Learning Rate: 0.000833 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6299/12542 | Batch Loss: 0.5902 | Learning Rate: 0.000833 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6300/12542 | Batch Loss: 0.6092 | Learning Rate: 0.000833 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6301/12542 | Batch Loss: 1.4246 | Learning Rate: 0.000833 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6302/12542 | Batch Loss: 0.5230 | Learning Rate: 0.000833 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6303/12542 | Batch Loss: 0.8241 | Learning Rate: 0.000832 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6304/12542 | Batch Loss: 0.7069 | Learning Rate: 0.000832 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6305/12542 | Batch Loss: 1.3704 | Learning Rate: 0.000832 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6306/12542 | Batch Loss: 1.8286 | Learning Rate: 0.000832 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6307/12542 | Batch Loss: 1.3868 | Learning Rate: 0.000832 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6308/12542 | Batch Loss: 0.6414 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6309/12542 | Batch Loss: 0.7664 | Learning Rate: 0.000832 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6310/12542 | Batch Loss: 1.3212 | Learning Rate: 0.000832 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6311/12542 | Batch Loss: 0.6375 | Learning Rate: 0.000832 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6312/12542 | Batch Loss: 1.6642 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6313/12542 | Batch Loss: 1.3465 | Learning Rate: 0.000832 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6314/12542 | Batch Loss: 0.5631 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6315/12542 | Batch Loss: 1.5647 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6316/12542 | Batch Loss: 1.1111 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6317/12542 | Batch Loss: 1.2935 | Learning Rate: 0.000832 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6318/12542 | Batch Loss: 2.3570 | Learning Rate: 0.000832 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6319/12542 | Batch Loss: 0.9775 | Learning Rate: 0.000832 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6320/12542 | Batch Loss: 0.7802 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6321/12542 | Batch Loss: 1.4786 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6322/12542 | Batch Loss: 1.8210 | Learning Rate: 0.000832 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6323/12542 | Batch Loss: 2.6758 | Learning Rate: 0.000832 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6324/12542 | Batch Loss: 1.0557 | Learning Rate: 0.000832 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6325/12542 | Batch Loss: 1.1215 | Learning Rate: 0.000832 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6326/12542 | Batch Loss: 1.8772 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6327/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000832 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6328/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6329/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000832 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6330/12542 | Batch Loss: 2.5790 | Learning Rate: 0.000832 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6331/12542 | Batch Loss: 1.3947 | Learning Rate: 0.000832 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6332/12542 | Batch Loss: 1.7463 | Learning Rate: 0.000832 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6333/12542 | Batch Loss: 1.2400 | Learning Rate: 0.000832 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6334/12542 | Batch Loss: 1.2472 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6335/12542 | Batch Loss: 0.7972 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6336/12542 | Batch Loss: 0.5962 | Learning Rate: 0.000832 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6337/12542 | Batch Loss: 1.2303 | Learning Rate: 0.000832 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6338/12542 | Batch Loss: 1.2960 | Learning Rate: 0.000832 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6339/12542 | Batch Loss: 1.1770 | Learning Rate: 0.000832 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6340/12542 | Batch Loss: 1.7161 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6341/12542 | Batch Loss: 1.3215 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6342/12542 | Batch Loss: 1.0395 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6343/12542 | Batch Loss: 1.3390 | Learning Rate: 0.000831 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6344/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000831 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6345/12542 | Batch Loss: 1.2528 | Learning Rate: 0.000831 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6346/12542 | Batch Loss: 2.9936 | Learning Rate: 0.000831 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6347/12542 | Batch Loss: 0.9373 | Learning Rate: 0.000831 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6348/12542 | Batch Loss: 1.0287 | Learning Rate: 0.000831 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6349/12542 | Batch Loss: 1.1550 | Learning Rate: 0.000831 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6350/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000831 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6351/12542 | Batch Loss: 1.2287 | Learning Rate: 0.000831 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6352/12542 | Batch Loss: 0.9305 | Learning Rate: 0.000831 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6353/12542 | Batch Loss: 0.6723 | Learning Rate: 0.000831 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6354/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000831 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6355/12542 | Batch Loss: 1.5965 | Learning Rate: 0.000831 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6356/12542 | Batch Loss: 0.8379 | Learning Rate: 0.000831 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6357/12542 | Batch Loss: 0.7578 | Learning Rate: 0.000831 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6358/12542 | Batch Loss: 0.6112 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6359/12542 | Batch Loss: 2.1534 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6360/12542 | Batch Loss: 1.6814 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6361/12542 | Batch Loss: 0.6435 | Learning Rate: 0.000831 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6362/12542 | Batch Loss: 1.8172 | Learning Rate: 0.000831 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6363/12542 | Batch Loss: 0.9584 | Learning Rate: 0.000831 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6364/12542 | Batch Loss: 1.9901 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6365/12542 | Batch Loss: 1.7443 | Learning Rate: 0.000831 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6366/12542 | Batch Loss: 2.0634 | Learning Rate: 0.000831 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6367/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000831 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6368/12542 | Batch Loss: 0.8308 | Learning Rate: 0.000831 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6369/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000831 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6370/12542 | Batch Loss: 0.8047 | Learning Rate: 0.000831 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6371/12542 | Batch Loss: 1.3214 | Learning Rate: 0.000831 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6372/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6373/12542 | Batch Loss: 0.8417 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6374/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6375/12542 | Batch Loss: 1.7291 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6376/12542 | Batch Loss: 0.7790 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6377/12542 | Batch Loss: 1.9515 | Learning Rate: 0.000831 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6378/12542 | Batch Loss: 2.4238 | Learning Rate: 0.000830 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6379/12542 | Batch Loss: 1.1642 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6380/12542 | Batch Loss: 3.9803 | Learning Rate: 0.000830 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6381/12542 | Batch Loss: 3.4334 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6382/12542 | Batch Loss: 1.2054 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6383/12542 | Batch Loss: 0.8695 | Learning Rate: 0.000830 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6384/12542 | Batch Loss: 1.1968 | Learning Rate: 0.000830 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6385/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000830 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6386/12542 | Batch Loss: 1.0377 | Learning Rate: 0.000830 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6387/12542 | Batch Loss: 0.6929 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6388/12542 | Batch Loss: 2.0897 | Learning Rate: 0.000830 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6389/12542 | Batch Loss: 1.7551 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6390/12542 | Batch Loss: 1.3887 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6391/12542 | Batch Loss: 1.8358 | Learning Rate: 0.000830 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6392/12542 | Batch Loss: 2.3207 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6393/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6394/12542 | Batch Loss: 1.8332 | Learning Rate: 0.000830 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6395/12542 | Batch Loss: 0.9885 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6396/12542 | Batch Loss: 1.2991 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6397/12542 | Batch Loss: 1.4932 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6398/12542 | Batch Loss: 0.8096 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6399/12542 | Batch Loss: 0.9888 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6400/12542 | Batch Loss: 0.5609 | Learning Rate: 0.000830 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6401/12542 | Batch Loss: 1.4912 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6402/12542 | Batch Loss: 0.9596 | Learning Rate: 0.000830 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6403/12542 | Batch Loss: 2.1574 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6404/12542 | Batch Loss: 1.0806 | Learning Rate: 0.000830 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6405/12542 | Batch Loss: 1.8435 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6406/12542 | Batch Loss: 1.4619 | Learning Rate: 0.000830 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6407/12542 | Batch Loss: 1.2310 | Learning Rate: 0.000830 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6408/12542 | Batch Loss: 1.0453 | Learning Rate: 0.000830 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6409/12542 | Batch Loss: 2.9376 | Learning Rate: 0.000830 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6410/12542 | Batch Loss: 2.2559 | Learning Rate: 0.000830 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6411/12542 | Batch Loss: 0.9030 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6412/12542 | Batch Loss: 1.1085 | Learning Rate: 0.000830 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6413/12542 | Batch Loss: 0.8169 | Learning Rate: 0.000830 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6414/12542 | Batch Loss: 2.0688 | Learning Rate: 0.000830 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6415/12542 | Batch Loss: 1.7939 | Learning Rate: 0.000830 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6416/12542 | Batch Loss: 0.5604 | Learning Rate: 0.000829 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6417/12542 | Batch Loss: 0.6842 | Learning Rate: 0.000829 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6418/12542 | Batch Loss: 1.4163 | Learning Rate: 0.000829 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6419/12542 | Batch Loss: 1.8643 | Learning Rate: 0.000829 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6420/12542 | Batch Loss: 1.0163 | Learning Rate: 0.000829 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6421/12542 | Batch Loss: 1.9119 | Learning Rate: 0.000829 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6422/12542 | Batch Loss: 2.1151 | Learning Rate: 0.000829 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6423/12542 | Batch Loss: 1.2106 | Learning Rate: 0.000829 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6424/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6425/12542 | Batch Loss: 1.2402 | Learning Rate: 0.000829 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6426/12542 | Batch Loss: 1.3161 | Learning Rate: 0.000829 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 6427/12542 | Batch Loss: 0.6628 | Learning Rate: 0.000829 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6428/12542 | Batch Loss: 1.6202 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6429/12542 | Batch Loss: 0.5741 | Learning Rate: 0.000829 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6430/12542 | Batch Loss: 0.6918 | Learning Rate: 0.000829 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6431/12542 | Batch Loss: 1.2076 | Learning Rate: 0.000829 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6432/12542 | Batch Loss: 0.7507 | Learning Rate: 0.000829 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6433/12542 | Batch Loss: 1.2815 | Learning Rate: 0.000829 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6434/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000829 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6435/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000829 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6436/12542 | Batch Loss: 1.7287 | Learning Rate: 0.000829 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6437/12542 | Batch Loss: 0.8566 | Learning Rate: 0.000829 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6438/12542 | Batch Loss: 1.5199 | Learning Rate: 0.000829 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6439/12542 | Batch Loss: 1.6807 | Learning Rate: 0.000829 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6440/12542 | Batch Loss: 1.5649 | Learning Rate: 0.000829 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6441/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6442/12542 | Batch Loss: 0.6979 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6443/12542 | Batch Loss: 0.4344 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6444/12542 | Batch Loss: 1.3647 | Learning Rate: 0.000829 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6445/12542 | Batch Loss: 1.3414 | Learning Rate: 0.000829 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6446/12542 | Batch Loss: 1.0278 | Learning Rate: 0.000829 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6447/12542 | Batch Loss: 0.6168 | Learning Rate: 0.000829 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6448/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000829 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6449/12542 | Batch Loss: 1.2060 | Learning Rate: 0.000829 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6450/12542 | Batch Loss: 0.8335 | Learning Rate: 0.000829 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6451/12542 | Batch Loss: 1.7388 | Learning Rate: 0.000829 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6452/12542 | Batch Loss: 0.9952 | Learning Rate: 0.000829 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6453/12542 | Batch Loss: 0.7745 | Learning Rate: 0.000828 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6454/12542 | Batch Loss: 1.8661 | Learning Rate: 0.000828 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6455/12542 | Batch Loss: 0.8143 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6456/12542 | Batch Loss: 1.0069 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6457/12542 | Batch Loss: 0.4213 | Learning Rate: 0.000828 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6458/12542 | Batch Loss: 1.7383 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6459/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000828 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6460/12542 | Batch Loss: 1.7238 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6461/12542 | Batch Loss: 0.9483 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6462/12542 | Batch Loss: 0.5480 | Learning Rate: 0.000828 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6463/12542 | Batch Loss: 2.9286 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6464/12542 | Batch Loss: 1.2739 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6465/12542 | Batch Loss: 1.6755 | Learning Rate: 0.000828 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6466/12542 | Batch Loss: 1.4732 | Learning Rate: 0.000828 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6467/12542 | Batch Loss: 2.0422 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6468/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000828 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6469/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000828 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6470/12542 | Batch Loss: 0.5724 | Learning Rate: 0.000828 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6471/12542 | Batch Loss: 1.4336 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6472/12542 | Batch Loss: 4.2908 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6473/12542 | Batch Loss: 1.4134 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6474/12542 | Batch Loss: 1.0372 | Learning Rate: 0.000828 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6475/12542 | Batch Loss: 0.8994 | Learning Rate: 0.000828 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6476/12542 | Batch Loss: 1.2540 | Learning Rate: 0.000828 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6477/12542 | Batch Loss: 0.8570 | Learning Rate: 0.000828 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6478/12542 | Batch Loss: 1.3616 | Learning Rate: 0.000828 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6479/12542 | Batch Loss: 1.3447 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6480/12542 | Batch Loss: 1.2796 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6481/12542 | Batch Loss: 0.9498 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6482/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000828 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6483/12542 | Batch Loss: 1.8601 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6484/12542 | Batch Loss: 1.2937 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6485/12542 | Batch Loss: 1.3353 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6486/12542 | Batch Loss: 1.0151 | Learning Rate: 0.000828 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6487/12542 | Batch Loss: 0.7793 | Learning Rate: 0.000828 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6488/12542 | Batch Loss: 1.5527 | Learning Rate: 0.000828 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6489/12542 | Batch Loss: 0.5779 | Learning Rate: 0.000828 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6490/12542 | Batch Loss: 0.6894 | Learning Rate: 0.000828 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6491/12542 | Batch Loss: 0.7223 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6492/12542 | Batch Loss: 2.4803 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6493/12542 | Batch Loss: 1.8973 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6494/12542 | Batch Loss: 1.0888 | Learning Rate: 0.000827 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6495/12542 | Batch Loss: 1.0667 | Learning Rate: 0.000827 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6496/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000827 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6497/12542 | Batch Loss: 0.9979 | Learning Rate: 0.000827 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6498/12542 | Batch Loss: 1.3685 | Learning Rate: 0.000827 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6499/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6500/12542 | Batch Loss: 1.9467 | Learning Rate: 0.000827 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6501/12542 | Batch Loss: 2.5435 | Learning Rate: 0.000827 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6502/12542 | Batch Loss: 0.9530 | Learning Rate: 0.000827 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6503/12542 | Batch Loss: 1.5432 | Learning Rate: 0.000827 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6504/12542 | Batch Loss: 2.4139 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6505/12542 | Batch Loss: 0.7295 | Learning Rate: 0.000827 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6506/12542 | Batch Loss: 2.7364 | Learning Rate: 0.000827 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6507/12542 | Batch Loss: 1.0120 | Learning Rate: 0.000827 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6508/12542 | Batch Loss: 0.4729 | Learning Rate: 0.000827 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 6509/12542 | Batch Loss: 0.8189 | Learning Rate: 0.000827 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6510/12542 | Batch Loss: 2.0565 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6511/12542 | Batch Loss: 1.8701 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6512/12542 | Batch Loss: 1.0787 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6513/12542 | Batch Loss: 0.8880 | Learning Rate: 0.000827 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6514/12542 | Batch Loss: 0.7255 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6515/12542 | Batch Loss: 1.4616 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6516/12542 | Batch Loss: 1.3160 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6517/12542 | Batch Loss: 0.7533 | Learning Rate: 0.000827 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6518/12542 | Batch Loss: 0.7085 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6519/12542 | Batch Loss: 0.9669 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6520/12542 | Batch Loss: 1.0659 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6521/12542 | Batch Loss: 1.3784 | Learning Rate: 0.000827 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6522/12542 | Batch Loss: 0.6630 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6523/12542 | Batch Loss: 1.3470 | Learning Rate: 0.000827 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6524/12542 | Batch Loss: 0.7391 | Learning Rate: 0.000827 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6525/12542 | Batch Loss: 1.9974 | Learning Rate: 0.000827 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6526/12542 | Batch Loss: 0.6222 | Learning Rate: 0.000827 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6527/12542 | Batch Loss: 1.6311 | Learning Rate: 0.000827 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6528/12542 | Batch Loss: 0.8284 | Learning Rate: 0.000827 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6529/12542 | Batch Loss: 0.6568 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6530/12542 | Batch Loss: 0.7064 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6531/12542 | Batch Loss: 1.1358 | Learning Rate: 0.000826 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6532/12542 | Batch Loss: 1.0771 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6533/12542 | Batch Loss: 1.8647 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6534/12542 | Batch Loss: 0.9541 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6535/12542 | Batch Loss: 0.9566 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6536/12542 | Batch Loss: 0.8606 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6537/12542 | Batch Loss: 1.2766 | Learning Rate: 0.000826 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6538/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000826 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6539/12542 | Batch Loss: 2.8675 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6540/12542 | Batch Loss: 1.6723 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6541/12542 | Batch Loss: 0.8613 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6542/12542 | Batch Loss: 1.3643 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6543/12542 | Batch Loss: 1.0636 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6544/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6545/12542 | Batch Loss: 2.4416 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6546/12542 | Batch Loss: 1.9652 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6547/12542 | Batch Loss: 0.9115 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6548/12542 | Batch Loss: 0.9415 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6549/12542 | Batch Loss: 1.4358 | Learning Rate: 0.000826 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6550/12542 | Batch Loss: 0.8027 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6551/12542 | Batch Loss: 0.9771 | Learning Rate: 0.000826 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6552/12542 | Batch Loss: 0.7481 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6553/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6554/12542 | Batch Loss: 1.4837 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6555/12542 | Batch Loss: 2.9616 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6556/12542 | Batch Loss: 1.2611 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6557/12542 | Batch Loss: 1.2447 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6558/12542 | Batch Loss: 2.5304 | Learning Rate: 0.000826 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6559/12542 | Batch Loss: 0.8666 | Learning Rate: 0.000826 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6560/12542 | Batch Loss: 1.0459 | Learning Rate: 0.000826 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6561/12542 | Batch Loss: 1.4612 | Learning Rate: 0.000826 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6562/12542 | Batch Loss: 1.0001 | Learning Rate: 0.000826 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6563/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6564/12542 | Batch Loss: 1.3581 | Learning Rate: 0.000826 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6565/12542 | Batch Loss: 0.9576 | Learning Rate: 0.000826 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6566/12542 | Batch Loss: 1.0382 | Learning Rate: 0.000825 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6567/12542 | Batch Loss: 1.2498 | Learning Rate: 0.000825 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6568/12542 | Batch Loss: 4.3408 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6569/12542 | Batch Loss: 0.5955 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6570/12542 | Batch Loss: 1.9634 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6571/12542 | Batch Loss: 1.2133 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6572/12542 | Batch Loss: 0.8350 | Learning Rate: 0.000825 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6573/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000825 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6574/12542 | Batch Loss: 3.0052 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6575/12542 | Batch Loss: 1.3714 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6576/12542 | Batch Loss: 1.1503 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6577/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000825 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6578/12542 | Batch Loss: 1.1888 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6579/12542 | Batch Loss: 0.6674 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6580/12542 | Batch Loss: 1.1493 | Learning Rate: 0.000825 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6581/12542 | Batch Loss: 1.4435 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6582/12542 | Batch Loss: 1.9624 | Learning Rate: 0.000825 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6583/12542 | Batch Loss: 0.9506 | Learning Rate: 0.000825 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6584/12542 | Batch Loss: 1.2216 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6585/12542 | Batch Loss: 1.1350 | Learning Rate: 0.000825 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6586/12542 | Batch Loss: 1.2311 | Learning Rate: 0.000825 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6587/12542 | Batch Loss: 0.5851 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6588/12542 | Batch Loss: 1.3843 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6589/12542 | Batch Loss: 0.6261 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6590/12542 | Batch Loss: 2.1501 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6591/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000825 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6592/12542 | Batch Loss: 2.5806 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6593/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000825 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6594/12542 | Batch Loss: 1.3329 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6595/12542 | Batch Loss: 2.0011 | Learning Rate: 0.000825 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6596/12542 | Batch Loss: 0.8096 | Learning Rate: 0.000825 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6597/12542 | Batch Loss: 1.6192 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6598/12542 | Batch Loss: 1.7556 | Learning Rate: 0.000825 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6599/12542 | Batch Loss: 0.7649 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6600/12542 | Batch Loss: 0.7050 | Learning Rate: 0.000825 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6601/12542 | Batch Loss: 1.4179 | Learning Rate: 0.000825 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6602/12542 | Batch Loss: 1.2263 | Learning Rate: 0.000825 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6603/12542 | Batch Loss: 0.8576 | Learning Rate: 0.000825 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6604/12542 | Batch Loss: 1.2843 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6605/12542 | Batch Loss: 0.7812 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6606/12542 | Batch Loss: 1.4391 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6607/12542 | Batch Loss: 0.8012 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6608/12542 | Batch Loss: 1.1302 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6609/12542 | Batch Loss: 0.6635 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6610/12542 | Batch Loss: 1.4977 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6611/12542 | Batch Loss: 0.7726 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6612/12542 | Batch Loss: 2.6482 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6613/12542 | Batch Loss: 1.3785 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6614/12542 | Batch Loss: 3.1792 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6615/12542 | Batch Loss: 1.6708 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6616/12542 | Batch Loss: 1.1773 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6617/12542 | Batch Loss: 1.2689 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6618/12542 | Batch Loss: 2.1415 | Learning Rate: 0.000824 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6619/12542 | Batch Loss: 1.1817 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6620/12542 | Batch Loss: 1.0559 | Learning Rate: 0.000824 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6621/12542 | Batch Loss: 1.4654 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6622/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000824 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6623/12542 | Batch Loss: 1.8184 | Learning Rate: 0.000824 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6624/12542 | Batch Loss: 1.4269 | Learning Rate: 0.000824 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6625/12542 | Batch Loss: 0.8556 | Learning Rate: 0.000824 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6626/12542 | Batch Loss: 0.6249 | Learning Rate: 0.000824 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6627/12542 | Batch Loss: 1.2061 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6628/12542 | Batch Loss: 1.7018 | Learning Rate: 0.000824 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6629/12542 | Batch Loss: 0.8851 | Learning Rate: 0.000824 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 6630/12542 | Batch Loss: 0.7379 | Learning Rate: 0.000824 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6631/12542 | Batch Loss: 0.7763 | Learning Rate: 0.000824 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6632/12542 | Batch Loss: 1.4239 | Learning Rate: 0.000824 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6633/12542 | Batch Loss: 0.9466 | Learning Rate: 0.000824 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6634/12542 | Batch Loss: 1.5302 | Learning Rate: 0.000824 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6635/12542 | Batch Loss: 2.0544 | Learning Rate: 0.000824 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6636/12542 | Batch Loss: 1.7787 | Learning Rate: 0.000824 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6637/12542 | Batch Loss: 1.7080 | Learning Rate: 0.000824 | Batch Time: 0.73s\n",
      "Epoch 1 | Step 6638/12542 | Batch Loss: 0.6419 | Learning Rate: 0.000824 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6639/12542 | Batch Loss: 0.9811 | Learning Rate: 0.000824 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6640/12542 | Batch Loss: 0.8112 | Learning Rate: 0.000824 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6641/12542 | Batch Loss: 1.8647 | Learning Rate: 0.000823 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6642/12542 | Batch Loss: 1.3990 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6643/12542 | Batch Loss: 0.9083 | Learning Rate: 0.000823 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6644/12542 | Batch Loss: 2.4154 | Learning Rate: 0.000823 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6645/12542 | Batch Loss: 0.8576 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6646/12542 | Batch Loss: 0.6630 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6647/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000823 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6648/12542 | Batch Loss: 0.7917 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6649/12542 | Batch Loss: 0.5138 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6650/12542 | Batch Loss: 1.4206 | Learning Rate: 0.000823 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6651/12542 | Batch Loss: 0.8436 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6652/12542 | Batch Loss: 2.6414 | Learning Rate: 0.000823 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6653/12542 | Batch Loss: 1.3302 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6654/12542 | Batch Loss: 0.6445 | Learning Rate: 0.000823 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6655/12542 | Batch Loss: 1.6565 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6656/12542 | Batch Loss: 1.1804 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6657/12542 | Batch Loss: 2.1777 | Learning Rate: 0.000823 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6658/12542 | Batch Loss: 2.1397 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6659/12542 | Batch Loss: 1.0234 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6660/12542 | Batch Loss: 2.3335 | Learning Rate: 0.000823 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6661/12542 | Batch Loss: 1.1887 | Learning Rate: 0.000823 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6662/12542 | Batch Loss: 0.8445 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6663/12542 | Batch Loss: 1.2349 | Learning Rate: 0.000823 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6664/12542 | Batch Loss: 0.8700 | Learning Rate: 0.000823 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6665/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000823 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6666/12542 | Batch Loss: 2.9335 | Learning Rate: 0.000823 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6667/12542 | Batch Loss: 1.2597 | Learning Rate: 0.000823 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6668/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000823 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6669/12542 | Batch Loss: 2.2604 | Learning Rate: 0.000823 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6670/12542 | Batch Loss: 1.4826 | Learning Rate: 0.000823 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6671/12542 | Batch Loss: 1.0671 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6672/12542 | Batch Loss: 1.9914 | Learning Rate: 0.000823 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6673/12542 | Batch Loss: 1.1685 | Learning Rate: 0.000823 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6674/12542 | Batch Loss: 1.3016 | Learning Rate: 0.000823 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6675/12542 | Batch Loss: 1.1336 | Learning Rate: 0.000823 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6676/12542 | Batch Loss: 1.0549 | Learning Rate: 0.000823 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6677/12542 | Batch Loss: 2.3451 | Learning Rate: 0.000823 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6678/12542 | Batch Loss: 1.5775 | Learning Rate: 0.000823 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6679/12542 | Batch Loss: 0.7129 | Learning Rate: 0.000822 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6680/12542 | Batch Loss: 0.7463 | Learning Rate: 0.000822 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6681/12542 | Batch Loss: 1.0798 | Learning Rate: 0.000822 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6682/12542 | Batch Loss: 1.5227 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6683/12542 | Batch Loss: 1.1376 | Learning Rate: 0.000822 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6684/12542 | Batch Loss: 2.1357 | Learning Rate: 0.000822 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6685/12542 | Batch Loss: 1.3043 | Learning Rate: 0.000822 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6686/12542 | Batch Loss: 1.7330 | Learning Rate: 0.000822 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6687/12542 | Batch Loss: 2.4475 | Learning Rate: 0.000822 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6688/12542 | Batch Loss: 1.5197 | Learning Rate: 0.000822 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6689/12542 | Batch Loss: 2.2713 | Learning Rate: 0.000822 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6690/12542 | Batch Loss: 1.0008 | Learning Rate: 0.000822 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6691/12542 | Batch Loss: 1.2331 | Learning Rate: 0.000822 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6692/12542 | Batch Loss: 1.5744 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6693/12542 | Batch Loss: 3.6171 | Learning Rate: 0.000822 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6694/12542 | Batch Loss: 1.3444 | Learning Rate: 0.000822 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6695/12542 | Batch Loss: 1.5650 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6696/12542 | Batch Loss: 2.5057 | Learning Rate: 0.000822 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6697/12542 | Batch Loss: 1.7982 | Learning Rate: 0.000822 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6698/12542 | Batch Loss: 1.7605 | Learning Rate: 0.000822 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6699/12542 | Batch Loss: 1.4430 | Learning Rate: 0.000822 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6700/12542 | Batch Loss: 2.4073 | Learning Rate: 0.000822 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6701/12542 | Batch Loss: 0.7798 | Learning Rate: 0.000822 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6702/12542 | Batch Loss: 0.9363 | Learning Rate: 0.000822 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6703/12542 | Batch Loss: 0.7856 | Learning Rate: 0.000822 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6704/12542 | Batch Loss: 1.8579 | Learning Rate: 0.000822 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6705/12542 | Batch Loss: 1.9616 | Learning Rate: 0.000822 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6706/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000822 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6707/12542 | Batch Loss: 0.5105 | Learning Rate: 0.000822 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6708/12542 | Batch Loss: 0.8022 | Learning Rate: 0.000822 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6709/12542 | Batch Loss: 1.9712 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6710/12542 | Batch Loss: 0.8240 | Learning Rate: 0.000822 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6711/12542 | Batch Loss: 1.8712 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6712/12542 | Batch Loss: 1.6302 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6713/12542 | Batch Loss: 2.2798 | Learning Rate: 0.000822 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6714/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000822 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6715/12542 | Batch Loss: 1.5712 | Learning Rate: 0.000822 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6716/12542 | Batch Loss: 1.5358 | Learning Rate: 0.000822 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6717/12542 | Batch Loss: 2.0212 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6718/12542 | Batch Loss: 2.1663 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6719/12542 | Batch Loss: 1.0206 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6720/12542 | Batch Loss: 1.4581 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6721/12542 | Batch Loss: 2.2537 | Learning Rate: 0.000821 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6722/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000821 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6723/12542 | Batch Loss: 0.8066 | Learning Rate: 0.000821 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6724/12542 | Batch Loss: 0.9180 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6725/12542 | Batch Loss: 1.6124 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6726/12542 | Batch Loss: 2.8224 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6727/12542 | Batch Loss: 2.3043 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6728/12542 | Batch Loss: 2.4838 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6729/12542 | Batch Loss: 1.4223 | Learning Rate: 0.000821 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6730/12542 | Batch Loss: 1.1645 | Learning Rate: 0.000821 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6731/12542 | Batch Loss: 3.4242 | Learning Rate: 0.000821 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6732/12542 | Batch Loss: 1.2327 | Learning Rate: 0.000821 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6733/12542 | Batch Loss: 1.5899 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6734/12542 | Batch Loss: 0.8660 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6735/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6736/12542 | Batch Loss: 2.7026 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6737/12542 | Batch Loss: 0.6470 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6738/12542 | Batch Loss: 1.3807 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6739/12542 | Batch Loss: 1.2096 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6740/12542 | Batch Loss: 2.6208 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6741/12542 | Batch Loss: 0.7386 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6742/12542 | Batch Loss: 0.5421 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6743/12542 | Batch Loss: 1.3864 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6744/12542 | Batch Loss: 1.0551 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6745/12542 | Batch Loss: 1.0278 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6746/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6747/12542 | Batch Loss: 1.9765 | Learning Rate: 0.000821 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6748/12542 | Batch Loss: 1.4898 | Learning Rate: 0.000821 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6749/12542 | Batch Loss: 1.0089 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6750/12542 | Batch Loss: 0.8187 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6751/12542 | Batch Loss: 0.9112 | Learning Rate: 0.000821 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6752/12542 | Batch Loss: 1.4842 | Learning Rate: 0.000821 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6753/12542 | Batch Loss: 0.8280 | Learning Rate: 0.000821 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6754/12542 | Batch Loss: 1.4207 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6755/12542 | Batch Loss: 0.9298 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6756/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6757/12542 | Batch Loss: 1.9467 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6758/12542 | Batch Loss: 0.7168 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6759/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6760/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000820 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6761/12542 | Batch Loss: 1.1077 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6762/12542 | Batch Loss: 1.0956 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6763/12542 | Batch Loss: 0.7395 | Learning Rate: 0.000820 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6764/12542 | Batch Loss: 0.7760 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6765/12542 | Batch Loss: 2.1424 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6766/12542 | Batch Loss: 1.3601 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6767/12542 | Batch Loss: 1.0957 | Learning Rate: 0.000820 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6768/12542 | Batch Loss: 1.8299 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6769/12542 | Batch Loss: 1.7536 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6770/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000820 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6771/12542 | Batch Loss: 1.3229 | Learning Rate: 0.000820 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6772/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000820 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6773/12542 | Batch Loss: 0.6684 | Learning Rate: 0.000820 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6774/12542 | Batch Loss: 1.2220 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6775/12542 | Batch Loss: 0.8621 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6776/12542 | Batch Loss: 0.9816 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6777/12542 | Batch Loss: 0.5500 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6778/12542 | Batch Loss: 1.5582 | Learning Rate: 0.000820 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6779/12542 | Batch Loss: 1.9899 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6780/12542 | Batch Loss: 0.9427 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6781/12542 | Batch Loss: 1.1220 | Learning Rate: 0.000820 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6782/12542 | Batch Loss: 1.4700 | Learning Rate: 0.000820 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6783/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000820 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6784/12542 | Batch Loss: 1.5949 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6785/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000820 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6786/12542 | Batch Loss: 1.4504 | Learning Rate: 0.000820 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6787/12542 | Batch Loss: 1.1554 | Learning Rate: 0.000820 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6788/12542 | Batch Loss: 1.2027 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6789/12542 | Batch Loss: 0.6896 | Learning Rate: 0.000820 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6790/12542 | Batch Loss: 1.8281 | Learning Rate: 0.000820 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6791/12542 | Batch Loss: 0.7033 | Learning Rate: 0.000820 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6792/12542 | Batch Loss: 2.4762 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6793/12542 | Batch Loss: 1.2028 | Learning Rate: 0.000819 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6794/12542 | Batch Loss: 0.6316 | Learning Rate: 0.000819 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6795/12542 | Batch Loss: 1.0281 | Learning Rate: 0.000819 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6796/12542 | Batch Loss: 0.7942 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6797/12542 | Batch Loss: 1.2604 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6798/12542 | Batch Loss: 1.4426 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6799/12542 | Batch Loss: 1.2248 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6800/12542 | Batch Loss: 1.2692 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6801/12542 | Batch Loss: 1.2486 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6802/12542 | Batch Loss: 0.4722 | Learning Rate: 0.000819 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6803/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6804/12542 | Batch Loss: 1.7034 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6805/12542 | Batch Loss: 1.8177 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6806/12542 | Batch Loss: 1.5851 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6807/12542 | Batch Loss: 2.0322 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6808/12542 | Batch Loss: 1.6510 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6809/12542 | Batch Loss: 1.2911 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6810/12542 | Batch Loss: 0.9735 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6811/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6812/12542 | Batch Loss: 1.9812 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6813/12542 | Batch Loss: 1.2221 | Learning Rate: 0.000819 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6814/12542 | Batch Loss: 1.4021 | Learning Rate: 0.000819 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6815/12542 | Batch Loss: 2.7139 | Learning Rate: 0.000819 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6816/12542 | Batch Loss: 1.9191 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6817/12542 | Batch Loss: 3.0454 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6818/12542 | Batch Loss: 1.2224 | Learning Rate: 0.000819 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6819/12542 | Batch Loss: 1.0464 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6820/12542 | Batch Loss: 1.2123 | Learning Rate: 0.000819 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6821/12542 | Batch Loss: 1.1657 | Learning Rate: 0.000819 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6822/12542 | Batch Loss: 0.9435 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6823/12542 | Batch Loss: 2.7189 | Learning Rate: 0.000819 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6824/12542 | Batch Loss: 0.8328 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6825/12542 | Batch Loss: 1.6470 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6826/12542 | Batch Loss: 2.5567 | Learning Rate: 0.000819 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6827/12542 | Batch Loss: 1.0749 | Learning Rate: 0.000819 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6828/12542 | Batch Loss: 1.7357 | Learning Rate: 0.000819 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6829/12542 | Batch Loss: 1.3617 | Learning Rate: 0.000819 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6830/12542 | Batch Loss: 2.1396 | Learning Rate: 0.000818 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6831/12542 | Batch Loss: 1.8790 | Learning Rate: 0.000818 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6832/12542 | Batch Loss: 0.5281 | Learning Rate: 0.000818 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6833/12542 | Batch Loss: 1.3172 | Learning Rate: 0.000818 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 6834/12542 | Batch Loss: 1.4829 | Learning Rate: 0.000818 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6835/12542 | Batch Loss: 1.0130 | Learning Rate: 0.000818 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6836/12542 | Batch Loss: 1.8069 | Learning Rate: 0.000818 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6837/12542 | Batch Loss: 2.0574 | Learning Rate: 0.000818 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6838/12542 | Batch Loss: 2.7343 | Learning Rate: 0.000818 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 6839/12542 | Batch Loss: 1.4026 | Learning Rate: 0.000818 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6840/12542 | Batch Loss: 0.9814 | Learning Rate: 0.000818 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6841/12542 | Batch Loss: 1.4709 | Learning Rate: 0.000818 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6842/12542 | Batch Loss: 2.5753 | Learning Rate: 0.000818 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6843/12542 | Batch Loss: 0.5496 | Learning Rate: 0.000818 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6844/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000818 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6845/12542 | Batch Loss: 1.3198 | Learning Rate: 0.000818 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6846/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000818 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6847/12542 | Batch Loss: 1.2181 | Learning Rate: 0.000818 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6848/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000818 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6849/12542 | Batch Loss: 0.9572 | Learning Rate: 0.000818 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6850/12542 | Batch Loss: 1.1561 | Learning Rate: 0.000818 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6851/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000818 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6852/12542 | Batch Loss: 0.8498 | Learning Rate: 0.000818 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6853/12542 | Batch Loss: 1.3085 | Learning Rate: 0.000818 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6854/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000818 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6855/12542 | Batch Loss: 0.3457 | Learning Rate: 0.000818 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6856/12542 | Batch Loss: 0.9601 | Learning Rate: 0.000818 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6857/12542 | Batch Loss: 1.2736 | Learning Rate: 0.000818 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6858/12542 | Batch Loss: 0.9706 | Learning Rate: 0.000818 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6859/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000818 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6860/12542 | Batch Loss: 1.1421 | Learning Rate: 0.000818 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6861/12542 | Batch Loss: 1.6247 | Learning Rate: 0.000818 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6862/12542 | Batch Loss: 2.0058 | Learning Rate: 0.000818 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6863/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000818 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6864/12542 | Batch Loss: 1.9964 | Learning Rate: 0.000818 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6865/12542 | Batch Loss: 1.2056 | Learning Rate: 0.000818 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 6866/12542 | Batch Loss: 0.7216 | Learning Rate: 0.000818 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6867/12542 | Batch Loss: 1.4222 | Learning Rate: 0.000817 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 6868/12542 | Batch Loss: 1.0765 | Learning Rate: 0.000817 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6869/12542 | Batch Loss: 2.2060 | Learning Rate: 0.000817 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6870/12542 | Batch Loss: 0.9567 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6871/12542 | Batch Loss: 2.7981 | Learning Rate: 0.000817 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6872/12542 | Batch Loss: 1.2287 | Learning Rate: 0.000817 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6873/12542 | Batch Loss: 0.3390 | Learning Rate: 0.000817 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6874/12542 | Batch Loss: 0.7896 | Learning Rate: 0.000817 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6875/12542 | Batch Loss: 1.1045 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6876/12542 | Batch Loss: 1.0410 | Learning Rate: 0.000817 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6877/12542 | Batch Loss: 0.4670 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6878/12542 | Batch Loss: 1.3768 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6879/12542 | Batch Loss: 1.3417 | Learning Rate: 0.000817 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6880/12542 | Batch Loss: 0.6871 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6881/12542 | Batch Loss: 2.1063 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6882/12542 | Batch Loss: 1.2580 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6883/12542 | Batch Loss: 2.6821 | Learning Rate: 0.000817 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6884/12542 | Batch Loss: 1.1822 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6885/12542 | Batch Loss: 0.6833 | Learning Rate: 0.000817 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6886/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6887/12542 | Batch Loss: 1.7834 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6888/12542 | Batch Loss: 1.1475 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6889/12542 | Batch Loss: 0.7307 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6890/12542 | Batch Loss: 0.7723 | Learning Rate: 0.000817 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6891/12542 | Batch Loss: 1.3886 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6892/12542 | Batch Loss: 1.2041 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6893/12542 | Batch Loss: 0.4946 | Learning Rate: 0.000817 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6894/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6895/12542 | Batch Loss: 0.9592 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6896/12542 | Batch Loss: 1.0870 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6897/12542 | Batch Loss: 1.5843 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6898/12542 | Batch Loss: 0.6981 | Learning Rate: 0.000817 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6899/12542 | Batch Loss: 1.0947 | Learning Rate: 0.000817 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 6900/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000817 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6901/12542 | Batch Loss: 1.3373 | Learning Rate: 0.000817 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6902/12542 | Batch Loss: 2.1198 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6903/12542 | Batch Loss: 1.8729 | Learning Rate: 0.000817 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6904/12542 | Batch Loss: 1.3622 | Learning Rate: 0.000817 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6905/12542 | Batch Loss: 1.6699 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6906/12542 | Batch Loss: 0.8075 | Learning Rate: 0.000816 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6907/12542 | Batch Loss: 1.5048 | Learning Rate: 0.000816 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6908/12542 | Batch Loss: 1.3703 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6909/12542 | Batch Loss: 0.7977 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6910/12542 | Batch Loss: 1.4515 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6911/12542 | Batch Loss: 1.1342 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6912/12542 | Batch Loss: 0.7060 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6913/12542 | Batch Loss: 1.5788 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6914/12542 | Batch Loss: 1.9068 | Learning Rate: 0.000816 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6915/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000816 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6916/12542 | Batch Loss: 1.2451 | Learning Rate: 0.000816 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 6917/12542 | Batch Loss: 1.3502 | Learning Rate: 0.000816 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6918/12542 | Batch Loss: 1.3633 | Learning Rate: 0.000816 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 6919/12542 | Batch Loss: 0.7393 | Learning Rate: 0.000816 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 6920/12542 | Batch Loss: 0.6520 | Learning Rate: 0.000816 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6921/12542 | Batch Loss: 1.1247 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6922/12542 | Batch Loss: 1.3814 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6923/12542 | Batch Loss: 1.9821 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6924/12542 | Batch Loss: 0.2309 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6925/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6926/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6927/12542 | Batch Loss: 0.7061 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6928/12542 | Batch Loss: 1.0041 | Learning Rate: 0.000816 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6929/12542 | Batch Loss: 0.4075 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6930/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000816 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6931/12542 | Batch Loss: 1.0771 | Learning Rate: 0.000816 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6932/12542 | Batch Loss: 1.9990 | Learning Rate: 0.000816 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6933/12542 | Batch Loss: 1.4308 | Learning Rate: 0.000816 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6934/12542 | Batch Loss: 1.1306 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6935/12542 | Batch Loss: 1.3421 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6936/12542 | Batch Loss: 0.7474 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6937/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000816 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 6938/12542 | Batch Loss: 2.2862 | Learning Rate: 0.000816 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6939/12542 | Batch Loss: 1.2370 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6940/12542 | Batch Loss: 0.3602 | Learning Rate: 0.000816 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6941/12542 | Batch Loss: 1.7549 | Learning Rate: 0.000816 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6942/12542 | Batch Loss: 1.3884 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6943/12542 | Batch Loss: 1.6615 | Learning Rate: 0.000815 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6944/12542 | Batch Loss: 1.4791 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6945/12542 | Batch Loss: 0.5845 | Learning Rate: 0.000815 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6946/12542 | Batch Loss: 2.3117 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6947/12542 | Batch Loss: 2.3500 | Learning Rate: 0.000815 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6948/12542 | Batch Loss: 2.7396 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6949/12542 | Batch Loss: 1.0200 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6950/12542 | Batch Loss: 0.8535 | Learning Rate: 0.000815 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6951/12542 | Batch Loss: 1.5324 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6952/12542 | Batch Loss: 1.0631 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6953/12542 | Batch Loss: 0.8316 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6954/12542 | Batch Loss: 1.1654 | Learning Rate: 0.000815 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6955/12542 | Batch Loss: 0.8053 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6956/12542 | Batch Loss: 1.6884 | Learning Rate: 0.000815 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6957/12542 | Batch Loss: 1.5972 | Learning Rate: 0.000815 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6958/12542 | Batch Loss: 1.8013 | Learning Rate: 0.000815 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6959/12542 | Batch Loss: 0.5807 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6960/12542 | Batch Loss: 2.0475 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6961/12542 | Batch Loss: 0.6139 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6962/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6963/12542 | Batch Loss: 1.6482 | Learning Rate: 0.000815 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 6964/12542 | Batch Loss: 1.3554 | Learning Rate: 0.000815 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6965/12542 | Batch Loss: 2.5623 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6966/12542 | Batch Loss: 2.3494 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6967/12542 | Batch Loss: 4.4739 | Learning Rate: 0.000815 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6968/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000815 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6969/12542 | Batch Loss: 1.5898 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6970/12542 | Batch Loss: 0.9619 | Learning Rate: 0.000815 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6971/12542 | Batch Loss: 0.9084 | Learning Rate: 0.000815 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6972/12542 | Batch Loss: 1.5264 | Learning Rate: 0.000815 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6973/12542 | Batch Loss: 2.0979 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6974/12542 | Batch Loss: 0.9804 | Learning Rate: 0.000815 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6975/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000815 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6976/12542 | Batch Loss: 1.7484 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6977/12542 | Batch Loss: 0.8908 | Learning Rate: 0.000815 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6978/12542 | Batch Loss: 1.0403 | Learning Rate: 0.000815 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 6979/12542 | Batch Loss: 3.3698 | Learning Rate: 0.000815 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6980/12542 | Batch Loss: 1.0585 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6981/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6982/12542 | Batch Loss: 0.9211 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6983/12542 | Batch Loss: 0.8769 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6984/12542 | Batch Loss: 1.4202 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6985/12542 | Batch Loss: 1.6708 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6986/12542 | Batch Loss: 1.4266 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6987/12542 | Batch Loss: 1.9500 | Learning Rate: 0.000814 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 6988/12542 | Batch Loss: 0.8355 | Learning Rate: 0.000814 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 6989/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 6990/12542 | Batch Loss: 1.8974 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6991/12542 | Batch Loss: 0.9472 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6992/12542 | Batch Loss: 1.8029 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6993/12542 | Batch Loss: 2.4833 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6994/12542 | Batch Loss: 1.2903 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 6995/12542 | Batch Loss: 1.4046 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6996/12542 | Batch Loss: 1.3883 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6997/12542 | Batch Loss: 2.0886 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 6998/12542 | Batch Loss: 1.7390 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 6999/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7000/12542 | Batch Loss: 1.7328 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7001/12542 | Batch Loss: 1.1233 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7002/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7003/12542 | Batch Loss: 1.1852 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7004/12542 | Batch Loss: 1.0412 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7005/12542 | Batch Loss: 1.1865 | Learning Rate: 0.000814 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7006/12542 | Batch Loss: 0.5077 | Learning Rate: 0.000814 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7007/12542 | Batch Loss: 1.8228 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7008/12542 | Batch Loss: 1.9846 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7009/12542 | Batch Loss: 1.0996 | Learning Rate: 0.000814 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7010/12542 | Batch Loss: 1.2410 | Learning Rate: 0.000814 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7011/12542 | Batch Loss: 0.7665 | Learning Rate: 0.000814 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7012/12542 | Batch Loss: 2.0876 | Learning Rate: 0.000814 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7013/12542 | Batch Loss: 3.0768 | Learning Rate: 0.000814 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7014/12542 | Batch Loss: 1.9580 | Learning Rate: 0.000814 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7015/12542 | Batch Loss: 2.2296 | Learning Rate: 0.000814 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7016/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000814 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7017/12542 | Batch Loss: 1.4060 | Learning Rate: 0.000814 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7018/12542 | Batch Loss: 0.6599 | Learning Rate: 0.000813 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7019/12542 | Batch Loss: 1.5844 | Learning Rate: 0.000813 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7020/12542 | Batch Loss: 1.4384 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7021/12542 | Batch Loss: 1.1346 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7022/12542 | Batch Loss: 1.8954 | Learning Rate: 0.000813 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7023/12542 | Batch Loss: 0.7085 | Learning Rate: 0.000813 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7024/12542 | Batch Loss: 0.5838 | Learning Rate: 0.000813 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7025/12542 | Batch Loss: 1.8800 | Learning Rate: 0.000813 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7026/12542 | Batch Loss: 0.4630 | Learning Rate: 0.000813 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7027/12542 | Batch Loss: 2.1359 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7028/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7029/12542 | Batch Loss: 0.6913 | Learning Rate: 0.000813 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7030/12542 | Batch Loss: 0.6855 | Learning Rate: 0.000813 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7031/12542 | Batch Loss: 1.2682 | Learning Rate: 0.000813 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7032/12542 | Batch Loss: 1.9489 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7033/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7034/12542 | Batch Loss: 0.8941 | Learning Rate: 0.000813 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7035/12542 | Batch Loss: 1.3322 | Learning Rate: 0.000813 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7036/12542 | Batch Loss: 1.0321 | Learning Rate: 0.000813 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7037/12542 | Batch Loss: 0.9102 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7038/12542 | Batch Loss: 0.6145 | Learning Rate: 0.000813 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7039/12542 | Batch Loss: 1.9460 | Learning Rate: 0.000813 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7040/12542 | Batch Loss: 1.3471 | Learning Rate: 0.000813 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7041/12542 | Batch Loss: 1.9064 | Learning Rate: 0.000813 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7042/12542 | Batch Loss: 2.3198 | Learning Rate: 0.000813 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7043/12542 | Batch Loss: 1.6408 | Learning Rate: 0.000813 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7044/12542 | Batch Loss: 1.4334 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7045/12542 | Batch Loss: 2.0564 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7046/12542 | Batch Loss: 2.4115 | Learning Rate: 0.000813 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7047/12542 | Batch Loss: 1.0273 | Learning Rate: 0.000813 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7048/12542 | Batch Loss: 2.4499 | Learning Rate: 0.000813 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7049/12542 | Batch Loss: 1.7014 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7050/12542 | Batch Loss: 1.0419 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7051/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7052/12542 | Batch Loss: 0.9006 | Learning Rate: 0.000813 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7053/12542 | Batch Loss: 0.3931 | Learning Rate: 0.000813 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7054/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000813 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7055/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7056/12542 | Batch Loss: 1.9367 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7057/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7058/12542 | Batch Loss: 1.5625 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7059/12542 | Batch Loss: 0.9055 | Learning Rate: 0.000812 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7060/12542 | Batch Loss: 0.4672 | Learning Rate: 0.000812 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7061/12542 | Batch Loss: 1.4200 | Learning Rate: 0.000812 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7062/12542 | Batch Loss: 2.7240 | Learning Rate: 0.000812 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7063/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7064/12542 | Batch Loss: 1.0474 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7065/12542 | Batch Loss: 2.1768 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7066/12542 | Batch Loss: 0.6298 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7067/12542 | Batch Loss: 1.9019 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7068/12542 | Batch Loss: 1.3031 | Learning Rate: 0.000812 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7069/12542 | Batch Loss: 2.2144 | Learning Rate: 0.000812 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7070/12542 | Batch Loss: 1.3728 | Learning Rate: 0.000812 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7071/12542 | Batch Loss: 1.5062 | Learning Rate: 0.000812 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7072/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000812 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7073/12542 | Batch Loss: 1.1614 | Learning Rate: 0.000812 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7074/12542 | Batch Loss: 1.3624 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7075/12542 | Batch Loss: 1.1233 | Learning Rate: 0.000812 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7076/12542 | Batch Loss: 1.4681 | Learning Rate: 0.000812 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7077/12542 | Batch Loss: 1.9838 | Learning Rate: 0.000812 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7078/12542 | Batch Loss: 1.0573 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7079/12542 | Batch Loss: 0.7969 | Learning Rate: 0.000812 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7080/12542 | Batch Loss: 0.8562 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7081/12542 | Batch Loss: 0.7623 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7082/12542 | Batch Loss: 2.2070 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7083/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000812 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7084/12542 | Batch Loss: 1.4868 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7085/12542 | Batch Loss: 1.0937 | Learning Rate: 0.000812 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7086/12542 | Batch Loss: 1.0836 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7087/12542 | Batch Loss: 1.3190 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7088/12542 | Batch Loss: 1.3484 | Learning Rate: 0.000812 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7089/12542 | Batch Loss: 0.7891 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7090/12542 | Batch Loss: 1.2891 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7091/12542 | Batch Loss: 1.3553 | Learning Rate: 0.000812 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7092/12542 | Batch Loss: 1.3511 | Learning Rate: 0.000812 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7093/12542 | Batch Loss: 2.2470 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7094/12542 | Batch Loss: 1.2058 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7095/12542 | Batch Loss: 2.1227 | Learning Rate: 0.000811 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7096/12542 | Batch Loss: 1.6218 | Learning Rate: 0.000811 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7097/12542 | Batch Loss: 2.2086 | Learning Rate: 0.000811 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7098/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7099/12542 | Batch Loss: 0.8052 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7100/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000811 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7101/12542 | Batch Loss: 1.4947 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7102/12542 | Batch Loss: 2.1977 | Learning Rate: 0.000811 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7103/12542 | Batch Loss: 2.0072 | Learning Rate: 0.000811 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7104/12542 | Batch Loss: 0.4506 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7105/12542 | Batch Loss: 1.0135 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7106/12542 | Batch Loss: 1.0977 | Learning Rate: 0.000811 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7107/12542 | Batch Loss: 1.8039 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7108/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7109/12542 | Batch Loss: 1.2101 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7110/12542 | Batch Loss: 1.0339 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7111/12542 | Batch Loss: 0.4084 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7112/12542 | Batch Loss: 1.6239 | Learning Rate: 0.000811 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7113/12542 | Batch Loss: 0.8916 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7114/12542 | Batch Loss: 3.5570 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7115/12542 | Batch Loss: 0.7138 | Learning Rate: 0.000811 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7116/12542 | Batch Loss: 1.2580 | Learning Rate: 0.000811 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7117/12542 | Batch Loss: 2.1737 | Learning Rate: 0.000811 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7118/12542 | Batch Loss: 2.7434 | Learning Rate: 0.000811 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7119/12542 | Batch Loss: 1.1924 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7120/12542 | Batch Loss: 0.9292 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7121/12542 | Batch Loss: 0.4359 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7122/12542 | Batch Loss: 1.3195 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7123/12542 | Batch Loss: 1.2494 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7124/12542 | Batch Loss: 1.1034 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7125/12542 | Batch Loss: 2.0475 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7126/12542 | Batch Loss: 1.6757 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7127/12542 | Batch Loss: 0.5024 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7128/12542 | Batch Loss: 1.8449 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7129/12542 | Batch Loss: 2.1553 | Learning Rate: 0.000811 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7130/12542 | Batch Loss: 1.7400 | Learning Rate: 0.000811 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7131/12542 | Batch Loss: 3.3266 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7132/12542 | Batch Loss: 2.8893 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7133/12542 | Batch Loss: 2.0233 | Learning Rate: 0.000810 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7134/12542 | Batch Loss: 0.8797 | Learning Rate: 0.000810 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7135/12542 | Batch Loss: 1.5720 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7136/12542 | Batch Loss: 1.2588 | Learning Rate: 0.000810 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7137/12542 | Batch Loss: 0.7390 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7138/12542 | Batch Loss: 1.8244 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7139/12542 | Batch Loss: 0.8205 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7140/12542 | Batch Loss: 1.0935 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7141/12542 | Batch Loss: 0.6670 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7142/12542 | Batch Loss: 0.6469 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7143/12542 | Batch Loss: 0.9120 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7144/12542 | Batch Loss: 2.3416 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7145/12542 | Batch Loss: 1.9526 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7146/12542 | Batch Loss: 1.6623 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7147/12542 | Batch Loss: 1.0496 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7148/12542 | Batch Loss: 0.6581 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7149/12542 | Batch Loss: 1.4238 | Learning Rate: 0.000810 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7150/12542 | Batch Loss: 1.7440 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7151/12542 | Batch Loss: 0.6821 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7152/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7153/12542 | Batch Loss: 1.0105 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7154/12542 | Batch Loss: 2.0315 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7155/12542 | Batch Loss: 1.4607 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7156/12542 | Batch Loss: 1.3991 | Learning Rate: 0.000810 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7157/12542 | Batch Loss: 1.0552 | Learning Rate: 0.000810 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7158/12542 | Batch Loss: 1.5359 | Learning Rate: 0.000810 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7159/12542 | Batch Loss: 0.7220 | Learning Rate: 0.000810 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7160/12542 | Batch Loss: 1.0816 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7161/12542 | Batch Loss: 2.1344 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7162/12542 | Batch Loss: 2.4103 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7163/12542 | Batch Loss: 2.6847 | Learning Rate: 0.000810 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7164/12542 | Batch Loss: 0.7983 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7165/12542 | Batch Loss: 2.1853 | Learning Rate: 0.000810 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7166/12542 | Batch Loss: 0.7078 | Learning Rate: 0.000810 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7167/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000810 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7168/12542 | Batch Loss: 0.8202 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7169/12542 | Batch Loss: 1.1733 | Learning Rate: 0.000809 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7170/12542 | Batch Loss: 1.0830 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7171/12542 | Batch Loss: 1.0195 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7172/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7173/12542 | Batch Loss: 1.3568 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7174/12542 | Batch Loss: 0.8373 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7175/12542 | Batch Loss: 1.6603 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7176/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7177/12542 | Batch Loss: 1.5785 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7178/12542 | Batch Loss: 2.2497 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7179/12542 | Batch Loss: 1.5678 | Learning Rate: 0.000809 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7180/12542 | Batch Loss: 0.5628 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7181/12542 | Batch Loss: 0.8298 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7182/12542 | Batch Loss: 1.4379 | Learning Rate: 0.000809 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7183/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000809 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7184/12542 | Batch Loss: 1.1937 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7185/12542 | Batch Loss: 1.3219 | Learning Rate: 0.000809 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7186/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000809 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7187/12542 | Batch Loss: 1.1273 | Learning Rate: 0.000809 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7188/12542 | Batch Loss: 1.3312 | Learning Rate: 0.000809 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7189/12542 | Batch Loss: 1.2362 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7190/12542 | Batch Loss: 0.6514 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7191/12542 | Batch Loss: 0.6007 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7192/12542 | Batch Loss: 1.7316 | Learning Rate: 0.000809 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7193/12542 | Batch Loss: 1.3095 | Learning Rate: 0.000809 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7194/12542 | Batch Loss: 1.4796 | Learning Rate: 0.000809 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7195/12542 | Batch Loss: 0.7695 | Learning Rate: 0.000809 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7196/12542 | Batch Loss: 2.6821 | Learning Rate: 0.000809 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7197/12542 | Batch Loss: 1.3816 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7198/12542 | Batch Loss: 1.7895 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7199/12542 | Batch Loss: 0.9470 | Learning Rate: 0.000809 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7200/12542 | Batch Loss: 0.4819 | Learning Rate: 0.000809 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7201/12542 | Batch Loss: 1.3118 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7202/12542 | Batch Loss: 1.5903 | Learning Rate: 0.000809 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7203/12542 | Batch Loss: 1.1817 | Learning Rate: 0.000809 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7204/12542 | Batch Loss: 1.8801 | Learning Rate: 0.000809 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7205/12542 | Batch Loss: 0.6929 | Learning Rate: 0.000809 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7206/12542 | Batch Loss: 2.1105 | Learning Rate: 0.000808 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7207/12542 | Batch Loss: 1.5052 | Learning Rate: 0.000808 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7208/12542 | Batch Loss: 2.1910 | Learning Rate: 0.000808 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7209/12542 | Batch Loss: 0.9982 | Learning Rate: 0.000808 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7210/12542 | Batch Loss: 0.6612 | Learning Rate: 0.000808 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7211/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000808 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7212/12542 | Batch Loss: 1.1978 | Learning Rate: 0.000808 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7213/12542 | Batch Loss: 3.2282 | Learning Rate: 0.000808 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7214/12542 | Batch Loss: 1.7441 | Learning Rate: 0.000808 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7215/12542 | Batch Loss: 1.0409 | Learning Rate: 0.000808 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7216/12542 | Batch Loss: 1.5536 | Learning Rate: 0.000808 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7217/12542 | Batch Loss: 0.8515 | Learning Rate: 0.000808 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7218/12542 | Batch Loss: 2.4650 | Learning Rate: 0.000808 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7219/12542 | Batch Loss: 1.7916 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7220/12542 | Batch Loss: 1.0733 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7221/12542 | Batch Loss: 1.8001 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7222/12542 | Batch Loss: 1.3631 | Learning Rate: 0.000808 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7223/12542 | Batch Loss: 1.4498 | Learning Rate: 0.000808 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7224/12542 | Batch Loss: 2.1412 | Learning Rate: 0.000808 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7225/12542 | Batch Loss: 1.5499 | Learning Rate: 0.000808 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7226/12542 | Batch Loss: 1.6724 | Learning Rate: 0.000808 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7227/12542 | Batch Loss: 1.9622 | Learning Rate: 0.000808 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7228/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000808 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7229/12542 | Batch Loss: 1.2326 | Learning Rate: 0.000808 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7230/12542 | Batch Loss: 1.9796 | Learning Rate: 0.000808 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7231/12542 | Batch Loss: 1.4416 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7232/12542 | Batch Loss: 0.9439 | Learning Rate: 0.000808 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7233/12542 | Batch Loss: 1.2571 | Learning Rate: 0.000808 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7234/12542 | Batch Loss: 0.7922 | Learning Rate: 0.000808 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7235/12542 | Batch Loss: 2.1958 | Learning Rate: 0.000808 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7236/12542 | Batch Loss: 3.0402 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7237/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000808 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7238/12542 | Batch Loss: 1.1255 | Learning Rate: 0.000808 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7239/12542 | Batch Loss: 1.6810 | Learning Rate: 0.000808 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7240/12542 | Batch Loss: 0.7806 | Learning Rate: 0.000808 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7241/12542 | Batch Loss: 1.1373 | Learning Rate: 0.000808 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7242/12542 | Batch Loss: 2.5192 | Learning Rate: 0.000808 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7243/12542 | Batch Loss: 1.4435 | Learning Rate: 0.000808 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7244/12542 | Batch Loss: 1.2224 | Learning Rate: 0.000807 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7245/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000807 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7246/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000807 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7247/12542 | Batch Loss: 1.5450 | Learning Rate: 0.000807 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 7248/12542 | Batch Loss: 1.0743 | Learning Rate: 0.000807 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7249/12542 | Batch Loss: 1.1110 | Learning Rate: 0.000807 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7250/12542 | Batch Loss: 1.1362 | Learning Rate: 0.000807 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7251/12542 | Batch Loss: 0.9177 | Learning Rate: 0.000807 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7252/12542 | Batch Loss: 1.6836 | Learning Rate: 0.000807 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7253/12542 | Batch Loss: 1.6994 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7254/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7255/12542 | Batch Loss: 0.8783 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7256/12542 | Batch Loss: 1.1546 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7257/12542 | Batch Loss: 0.4985 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7258/12542 | Batch Loss: 0.9439 | Learning Rate: 0.000807 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7259/12542 | Batch Loss: 0.8674 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7260/12542 | Batch Loss: 0.9073 | Learning Rate: 0.000807 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7261/12542 | Batch Loss: 2.0305 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7262/12542 | Batch Loss: 0.7594 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7263/12542 | Batch Loss: 1.3850 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7264/12542 | Batch Loss: 0.9123 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7265/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7266/12542 | Batch Loss: 1.4859 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7267/12542 | Batch Loss: 0.5860 | Learning Rate: 0.000807 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7268/12542 | Batch Loss: 3.2978 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7269/12542 | Batch Loss: 1.0657 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7270/12542 | Batch Loss: 0.4090 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7271/12542 | Batch Loss: 0.8234 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7272/12542 | Batch Loss: 1.3802 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7273/12542 | Batch Loss: 1.5776 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7274/12542 | Batch Loss: 1.0930 | Learning Rate: 0.000807 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7275/12542 | Batch Loss: 1.3075 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7276/12542 | Batch Loss: 1.2916 | Learning Rate: 0.000807 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7277/12542 | Batch Loss: 0.9939 | Learning Rate: 0.000807 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7278/12542 | Batch Loss: 0.6003 | Learning Rate: 0.000807 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7279/12542 | Batch Loss: 0.8297 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7280/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000807 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7281/12542 | Batch Loss: 3.2779 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7282/12542 | Batch Loss: 0.8781 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7283/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7284/12542 | Batch Loss: 0.8282 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7285/12542 | Batch Loss: 1.9683 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7286/12542 | Batch Loss: 1.6000 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7287/12542 | Batch Loss: 1.3680 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7288/12542 | Batch Loss: 1.3211 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7289/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000806 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7290/12542 | Batch Loss: 1.1520 | Learning Rate: 0.000806 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7291/12542 | Batch Loss: 0.5052 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7292/12542 | Batch Loss: 1.7148 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7293/12542 | Batch Loss: 0.8175 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7294/12542 | Batch Loss: 1.1119 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7295/12542 | Batch Loss: 0.7060 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7296/12542 | Batch Loss: 1.2264 | Learning Rate: 0.000806 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7297/12542 | Batch Loss: 2.0184 | Learning Rate: 0.000806 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7298/12542 | Batch Loss: 4.1783 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7299/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000806 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7300/12542 | Batch Loss: 1.7393 | Learning Rate: 0.000806 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7301/12542 | Batch Loss: 1.1000 | Learning Rate: 0.000806 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7302/12542 | Batch Loss: 0.6133 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7303/12542 | Batch Loss: 1.1908 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7304/12542 | Batch Loss: 1.4423 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7305/12542 | Batch Loss: 2.2129 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7306/12542 | Batch Loss: 0.8922 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7307/12542 | Batch Loss: 1.1220 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7308/12542 | Batch Loss: 1.1706 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7309/12542 | Batch Loss: 0.7838 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7310/12542 | Batch Loss: 1.1306 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7311/12542 | Batch Loss: 1.8129 | Learning Rate: 0.000806 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7312/12542 | Batch Loss: 0.8335 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7313/12542 | Batch Loss: 1.4262 | Learning Rate: 0.000806 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7314/12542 | Batch Loss: 0.9414 | Learning Rate: 0.000806 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7315/12542 | Batch Loss: 1.1867 | Learning Rate: 0.000806 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7316/12542 | Batch Loss: 1.7751 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7317/12542 | Batch Loss: 0.7452 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7318/12542 | Batch Loss: 1.9888 | Learning Rate: 0.000806 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7319/12542 | Batch Loss: 0.9587 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7320/12542 | Batch Loss: 0.6242 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7321/12542 | Batch Loss: 1.4569 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7322/12542 | Batch Loss: 1.3931 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7323/12542 | Batch Loss: 0.6276 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7324/12542 | Batch Loss: 0.7654 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7325/12542 | Batch Loss: 3.1310 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7326/12542 | Batch Loss: 2.2673 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7327/12542 | Batch Loss: 1.9098 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7328/12542 | Batch Loss: 2.2995 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7329/12542 | Batch Loss: 1.5888 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7330/12542 | Batch Loss: 1.1004 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7331/12542 | Batch Loss: 1.0551 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7332/12542 | Batch Loss: 1.3087 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7333/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7334/12542 | Batch Loss: 2.3101 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7335/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7336/12542 | Batch Loss: 1.7606 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7337/12542 | Batch Loss: 2.0386 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7338/12542 | Batch Loss: 1.2170 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7339/12542 | Batch Loss: 0.6546 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7340/12542 | Batch Loss: 0.9701 | Learning Rate: 0.000805 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7341/12542 | Batch Loss: 1.2378 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7342/12542 | Batch Loss: 1.0870 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7343/12542 | Batch Loss: 2.6310 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7344/12542 | Batch Loss: 1.6021 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7345/12542 | Batch Loss: 0.9217 | Learning Rate: 0.000805 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7346/12542 | Batch Loss: 1.0932 | Learning Rate: 0.000805 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 7347/12542 | Batch Loss: 0.4640 | Learning Rate: 0.000805 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7348/12542 | Batch Loss: 1.7563 | Learning Rate: 0.000805 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7349/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7350/12542 | Batch Loss: 0.5205 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7351/12542 | Batch Loss: 0.8205 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7352/12542 | Batch Loss: 1.9747 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7353/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000805 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7354/12542 | Batch Loss: 1.4304 | Learning Rate: 0.000805 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7355/12542 | Batch Loss: 1.4000 | Learning Rate: 0.000805 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7356/12542 | Batch Loss: 2.1347 | Learning Rate: 0.000804 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7357/12542 | Batch Loss: 1.2686 | Learning Rate: 0.000804 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7358/12542 | Batch Loss: 1.7347 | Learning Rate: 0.000804 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7359/12542 | Batch Loss: 1.4422 | Learning Rate: 0.000804 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7360/12542 | Batch Loss: 3.1607 | Learning Rate: 0.000804 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7361/12542 | Batch Loss: 2.4973 | Learning Rate: 0.000804 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7362/12542 | Batch Loss: 1.0513 | Learning Rate: 0.000804 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7363/12542 | Batch Loss: 1.9655 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7364/12542 | Batch Loss: 1.3939 | Learning Rate: 0.000804 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7365/12542 | Batch Loss: 2.3015 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7366/12542 | Batch Loss: 1.2019 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7367/12542 | Batch Loss: 1.1724 | Learning Rate: 0.000804 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7368/12542 | Batch Loss: 1.2180 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7369/12542 | Batch Loss: 1.5771 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7370/12542 | Batch Loss: 1.4115 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7371/12542 | Batch Loss: 1.6924 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7372/12542 | Batch Loss: 1.3630 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7373/12542 | Batch Loss: 1.0273 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7374/12542 | Batch Loss: 3.6079 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7375/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7376/12542 | Batch Loss: 1.1800 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7377/12542 | Batch Loss: 1.1042 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7378/12542 | Batch Loss: 1.5072 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7379/12542 | Batch Loss: 1.9841 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7380/12542 | Batch Loss: 1.6971 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7381/12542 | Batch Loss: 0.7079 | Learning Rate: 0.000804 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7382/12542 | Batch Loss: 2.1423 | Learning Rate: 0.000804 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7383/12542 | Batch Loss: 2.1226 | Learning Rate: 0.000804 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7384/12542 | Batch Loss: 1.1599 | Learning Rate: 0.000804 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7385/12542 | Batch Loss: 1.9841 | Learning Rate: 0.000804 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7386/12542 | Batch Loss: 2.4977 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7387/12542 | Batch Loss: 1.5725 | Learning Rate: 0.000804 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7388/12542 | Batch Loss: 1.3964 | Learning Rate: 0.000804 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7389/12542 | Batch Loss: 1.2367 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7390/12542 | Batch Loss: 0.6888 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7391/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7392/12542 | Batch Loss: 0.8365 | Learning Rate: 0.000804 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7393/12542 | Batch Loss: 0.8849 | Learning Rate: 0.000804 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7394/12542 | Batch Loss: 1.4611 | Learning Rate: 0.000803 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7395/12542 | Batch Loss: 1.8974 | Learning Rate: 0.000803 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7396/12542 | Batch Loss: 0.8711 | Learning Rate: 0.000803 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7397/12542 | Batch Loss: 1.2053 | Learning Rate: 0.000803 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7398/12542 | Batch Loss: 1.3721 | Learning Rate: 0.000803 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7399/12542 | Batch Loss: 0.6585 | Learning Rate: 0.000803 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7400/12542 | Batch Loss: 2.3156 | Learning Rate: 0.000803 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7401/12542 | Batch Loss: 1.1416 | Learning Rate: 0.000803 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7402/12542 | Batch Loss: 0.8325 | Learning Rate: 0.000803 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7403/12542 | Batch Loss: 0.2639 | Learning Rate: 0.000803 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7404/12542 | Batch Loss: 1.2663 | Learning Rate: 0.000803 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7405/12542 | Batch Loss: 1.5336 | Learning Rate: 0.000803 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7406/12542 | Batch Loss: 1.2399 | Learning Rate: 0.000803 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7407/12542 | Batch Loss: 1.6409 | Learning Rate: 0.000803 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7408/12542 | Batch Loss: 0.9015 | Learning Rate: 0.000803 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7409/12542 | Batch Loss: 1.6538 | Learning Rate: 0.000803 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 7410/12542 | Batch Loss: 2.4410 | Learning Rate: 0.000803 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7411/12542 | Batch Loss: 0.6926 | Learning Rate: 0.000803 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7412/12542 | Batch Loss: 1.0878 | Learning Rate: 0.000803 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7413/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000803 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7414/12542 | Batch Loss: 1.2793 | Learning Rate: 0.000803 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7415/12542 | Batch Loss: 1.2005 | Learning Rate: 0.000803 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7416/12542 | Batch Loss: 1.4434 | Learning Rate: 0.000803 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7417/12542 | Batch Loss: 2.6068 | Learning Rate: 0.000803 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7418/12542 | Batch Loss: 1.2273 | Learning Rate: 0.000803 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7419/12542 | Batch Loss: 1.2971 | Learning Rate: 0.000803 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7420/12542 | Batch Loss: 0.9128 | Learning Rate: 0.000803 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7421/12542 | Batch Loss: 1.7863 | Learning Rate: 0.000803 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7422/12542 | Batch Loss: 1.2857 | Learning Rate: 0.000803 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7423/12542 | Batch Loss: 1.2218 | Learning Rate: 0.000803 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7424/12542 | Batch Loss: 1.4504 | Learning Rate: 0.000803 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7425/12542 | Batch Loss: 1.1559 | Learning Rate: 0.000803 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7426/12542 | Batch Loss: 1.4320 | Learning Rate: 0.000803 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7427/12542 | Batch Loss: 1.0859 | Learning Rate: 0.000803 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 7428/12542 | Batch Loss: 0.7253 | Learning Rate: 0.000803 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7429/12542 | Batch Loss: 1.1308 | Learning Rate: 0.000803 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7430/12542 | Batch Loss: 1.9836 | Learning Rate: 0.000803 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7431/12542 | Batch Loss: 2.4168 | Learning Rate: 0.000803 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7432/12542 | Batch Loss: 1.3859 | Learning Rate: 0.000802 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7433/12542 | Batch Loss: 1.0046 | Learning Rate: 0.000802 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7434/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000802 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7435/12542 | Batch Loss: 1.2154 | Learning Rate: 0.000802 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7436/12542 | Batch Loss: 2.3208 | Learning Rate: 0.000802 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7437/12542 | Batch Loss: 1.0433 | Learning Rate: 0.000802 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7438/12542 | Batch Loss: 1.1377 | Learning Rate: 0.000802 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7439/12542 | Batch Loss: 1.4160 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7440/12542 | Batch Loss: 1.0243 | Learning Rate: 0.000802 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7441/12542 | Batch Loss: 1.9967 | Learning Rate: 0.000802 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7442/12542 | Batch Loss: 1.7764 | Learning Rate: 0.000802 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7443/12542 | Batch Loss: 0.7137 | Learning Rate: 0.000802 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7444/12542 | Batch Loss: 0.4291 | Learning Rate: 0.000802 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7445/12542 | Batch Loss: 0.4378 | Learning Rate: 0.000802 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7446/12542 | Batch Loss: 1.0267 | Learning Rate: 0.000802 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7447/12542 | Batch Loss: 1.4484 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7448/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000802 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7449/12542 | Batch Loss: 0.6605 | Learning Rate: 0.000802 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7450/12542 | Batch Loss: 1.2922 | Learning Rate: 0.000802 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7451/12542 | Batch Loss: 2.1058 | Learning Rate: 0.000802 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7452/12542 | Batch Loss: 1.9541 | Learning Rate: 0.000802 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7453/12542 | Batch Loss: 1.4425 | Learning Rate: 0.000802 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7454/12542 | Batch Loss: 1.5102 | Learning Rate: 0.000802 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7455/12542 | Batch Loss: 1.5481 | Learning Rate: 0.000802 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7456/12542 | Batch Loss: 1.7539 | Learning Rate: 0.000802 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7457/12542 | Batch Loss: 1.6651 | Learning Rate: 0.000802 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7458/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000802 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7459/12542 | Batch Loss: 1.3776 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7460/12542 | Batch Loss: 1.6575 | Learning Rate: 0.000802 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7461/12542 | Batch Loss: 1.4790 | Learning Rate: 0.000802 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7462/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7463/12542 | Batch Loss: 1.4516 | Learning Rate: 0.000802 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7464/12542 | Batch Loss: 2.4990 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7465/12542 | Batch Loss: 0.7270 | Learning Rate: 0.000802 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7466/12542 | Batch Loss: 1.1409 | Learning Rate: 0.000802 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7467/12542 | Batch Loss: 2.0140 | Learning Rate: 0.000802 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7468/12542 | Batch Loss: 0.8072 | Learning Rate: 0.000802 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7469/12542 | Batch Loss: 0.8429 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7470/12542 | Batch Loss: 0.7370 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7471/12542 | Batch Loss: 0.7669 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7472/12542 | Batch Loss: 1.2900 | Learning Rate: 0.000801 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7473/12542 | Batch Loss: 0.7379 | Learning Rate: 0.000801 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7474/12542 | Batch Loss: 1.1400 | Learning Rate: 0.000801 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7475/12542 | Batch Loss: 1.0692 | Learning Rate: 0.000801 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7476/12542 | Batch Loss: 0.8693 | Learning Rate: 0.000801 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7477/12542 | Batch Loss: 1.1020 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7478/12542 | Batch Loss: 1.3134 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7479/12542 | Batch Loss: 0.8909 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7480/12542 | Batch Loss: 1.4189 | Learning Rate: 0.000801 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7481/12542 | Batch Loss: 2.7362 | Learning Rate: 0.000801 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7482/12542 | Batch Loss: 1.1156 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7483/12542 | Batch Loss: 3.3111 | Learning Rate: 0.000801 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7484/12542 | Batch Loss: 1.4370 | Learning Rate: 0.000801 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7485/12542 | Batch Loss: 1.4269 | Learning Rate: 0.000801 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7486/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000801 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7487/12542 | Batch Loss: 1.3583 | Learning Rate: 0.000801 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7488/12542 | Batch Loss: 0.9464 | Learning Rate: 0.000801 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7489/12542 | Batch Loss: 1.0642 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7490/12542 | Batch Loss: 1.5000 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7491/12542 | Batch Loss: 1.0062 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7492/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7493/12542 | Batch Loss: 0.2778 | Learning Rate: 0.000801 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7494/12542 | Batch Loss: 1.1652 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7495/12542 | Batch Loss: 1.6103 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7496/12542 | Batch Loss: 0.8823 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7497/12542 | Batch Loss: 0.6976 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7498/12542 | Batch Loss: 0.8025 | Learning Rate: 0.000801 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7499/12542 | Batch Loss: 1.9293 | Learning Rate: 0.000801 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7500/12542 | Batch Loss: 1.2797 | Learning Rate: 0.000801 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7501/12542 | Batch Loss: 2.3065 | Learning Rate: 0.000801 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7502/12542 | Batch Loss: 0.9044 | Learning Rate: 0.000801 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7503/12542 | Batch Loss: 1.2431 | Learning Rate: 0.000801 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7504/12542 | Batch Loss: 0.5332 | Learning Rate: 0.000801 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7505/12542 | Batch Loss: 1.0202 | Learning Rate: 0.000801 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7506/12542 | Batch Loss: 0.9186 | Learning Rate: 0.000801 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7507/12542 | Batch Loss: 1.6110 | Learning Rate: 0.000800 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7508/12542 | Batch Loss: 1.2192 | Learning Rate: 0.000800 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7509/12542 | Batch Loss: 3.2630 | Learning Rate: 0.000800 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7510/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000800 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7511/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000800 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7512/12542 | Batch Loss: 1.1712 | Learning Rate: 0.000800 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7513/12542 | Batch Loss: 1.4284 | Learning Rate: 0.000800 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7514/12542 | Batch Loss: 1.4499 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7515/12542 | Batch Loss: 0.7435 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7516/12542 | Batch Loss: 0.9445 | Learning Rate: 0.000800 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7517/12542 | Batch Loss: 0.9244 | Learning Rate: 0.000800 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7518/12542 | Batch Loss: 2.8591 | Learning Rate: 0.000800 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7519/12542 | Batch Loss: 0.9044 | Learning Rate: 0.000800 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7520/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7521/12542 | Batch Loss: 1.0100 | Learning Rate: 0.000800 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7522/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7523/12542 | Batch Loss: 0.8933 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7524/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7525/12542 | Batch Loss: 2.5196 | Learning Rate: 0.000800 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7526/12542 | Batch Loss: 0.8908 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7527/12542 | Batch Loss: 1.2454 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7528/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000800 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7529/12542 | Batch Loss: 0.9317 | Learning Rate: 0.000800 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7530/12542 | Batch Loss: 1.2370 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7531/12542 | Batch Loss: 1.5865 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7532/12542 | Batch Loss: 1.1245 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7533/12542 | Batch Loss: 0.9744 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7534/12542 | Batch Loss: 1.6036 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7535/12542 | Batch Loss: 1.3843 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7536/12542 | Batch Loss: 1.3931 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7537/12542 | Batch Loss: 0.7766 | Learning Rate: 0.000800 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7538/12542 | Batch Loss: 1.7144 | Learning Rate: 0.000800 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7539/12542 | Batch Loss: 1.7452 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7540/12542 | Batch Loss: 1.1345 | Learning Rate: 0.000800 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7541/12542 | Batch Loss: 1.1678 | Learning Rate: 0.000800 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7542/12542 | Batch Loss: 0.6525 | Learning Rate: 0.000800 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7543/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000800 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7544/12542 | Batch Loss: 2.4013 | Learning Rate: 0.000800 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7545/12542 | Batch Loss: 2.1585 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7546/12542 | Batch Loss: 1.6858 | Learning Rate: 0.000799 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7547/12542 | Batch Loss: 1.5565 | Learning Rate: 0.000799 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7548/12542 | Batch Loss: 0.8398 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7549/12542 | Batch Loss: 1.1580 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7550/12542 | Batch Loss: 1.1391 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7551/12542 | Batch Loss: 1.3075 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7552/12542 | Batch Loss: 1.4784 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7553/12542 | Batch Loss: 1.3899 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7554/12542 | Batch Loss: 1.2481 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7555/12542 | Batch Loss: 2.9378 | Learning Rate: 0.000799 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7556/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7557/12542 | Batch Loss: 0.9711 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7558/12542 | Batch Loss: 0.6594 | Learning Rate: 0.000799 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7559/12542 | Batch Loss: 0.7473 | Learning Rate: 0.000799 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7560/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7561/12542 | Batch Loss: 1.8973 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7562/12542 | Batch Loss: 1.6128 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7563/12542 | Batch Loss: 0.6346 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7564/12542 | Batch Loss: 2.9560 | Learning Rate: 0.000799 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7565/12542 | Batch Loss: 1.1795 | Learning Rate: 0.000799 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7566/12542 | Batch Loss: 1.1534 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7567/12542 | Batch Loss: 1.5167 | Learning Rate: 0.000799 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7568/12542 | Batch Loss: 0.6247 | Learning Rate: 0.000799 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7569/12542 | Batch Loss: 0.9057 | Learning Rate: 0.000799 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 7570/12542 | Batch Loss: 1.7018 | Learning Rate: 0.000799 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7571/12542 | Batch Loss: 1.2380 | Learning Rate: 0.000799 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7572/12542 | Batch Loss: 1.6130 | Learning Rate: 0.000799 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7573/12542 | Batch Loss: 1.1542 | Learning Rate: 0.000799 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7574/12542 | Batch Loss: 1.2444 | Learning Rate: 0.000799 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7575/12542 | Batch Loss: 1.6153 | Learning Rate: 0.000799 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7576/12542 | Batch Loss: 1.2716 | Learning Rate: 0.000799 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7577/12542 | Batch Loss: 0.8871 | Learning Rate: 0.000799 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7578/12542 | Batch Loss: 1.8615 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7579/12542 | Batch Loss: 2.9070 | Learning Rate: 0.000799 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7580/12542 | Batch Loss: 1.3728 | Learning Rate: 0.000799 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7581/12542 | Batch Loss: 1.8810 | Learning Rate: 0.000799 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7582/12542 | Batch Loss: 0.9663 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7583/12542 | Batch Loss: 1.2134 | Learning Rate: 0.000798 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7584/12542 | Batch Loss: 0.8806 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7585/12542 | Batch Loss: 1.1989 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7586/12542 | Batch Loss: 2.5804 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7587/12542 | Batch Loss: 0.7904 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7588/12542 | Batch Loss: 0.7073 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7589/12542 | Batch Loss: 0.4805 | Learning Rate: 0.000798 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7590/12542 | Batch Loss: 0.6772 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7591/12542 | Batch Loss: 1.2801 | Learning Rate: 0.000798 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7592/12542 | Batch Loss: 1.2229 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7593/12542 | Batch Loss: 1.9826 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7594/12542 | Batch Loss: 1.5722 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7595/12542 | Batch Loss: 1.2719 | Learning Rate: 0.000798 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7596/12542 | Batch Loss: 1.0430 | Learning Rate: 0.000798 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7597/12542 | Batch Loss: 1.0812 | Learning Rate: 0.000798 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7598/12542 | Batch Loss: 0.4673 | Learning Rate: 0.000798 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7599/12542 | Batch Loss: 1.0268 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7600/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7601/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7602/12542 | Batch Loss: 0.6773 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7603/12542 | Batch Loss: 3.2738 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7604/12542 | Batch Loss: 1.7039 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7605/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000798 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7606/12542 | Batch Loss: 1.9086 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7607/12542 | Batch Loss: 1.9425 | Learning Rate: 0.000798 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7608/12542 | Batch Loss: 1.2647 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7609/12542 | Batch Loss: 1.7459 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7610/12542 | Batch Loss: 1.6331 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7611/12542 | Batch Loss: 1.0154 | Learning Rate: 0.000798 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7612/12542 | Batch Loss: 1.4760 | Learning Rate: 0.000798 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7613/12542 | Batch Loss: 1.7031 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7614/12542 | Batch Loss: 1.2616 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7615/12542 | Batch Loss: 1.2135 | Learning Rate: 0.000798 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7616/12542 | Batch Loss: 1.8873 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7617/12542 | Batch Loss: 0.5907 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7618/12542 | Batch Loss: 0.7611 | Learning Rate: 0.000798 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7619/12542 | Batch Loss: 2.2483 | Learning Rate: 0.000798 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7620/12542 | Batch Loss: 0.9028 | Learning Rate: 0.000797 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7621/12542 | Batch Loss: 0.5811 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7622/12542 | Batch Loss: 1.6199 | Learning Rate: 0.000797 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7623/12542 | Batch Loss: 2.0730 | Learning Rate: 0.000797 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 7624/12542 | Batch Loss: 1.8616 | Learning Rate: 0.000797 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7625/12542 | Batch Loss: 0.6014 | Learning Rate: 0.000797 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7626/12542 | Batch Loss: 0.9036 | Learning Rate: 0.000797 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7627/12542 | Batch Loss: 2.7448 | Learning Rate: 0.000797 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7628/12542 | Batch Loss: 1.1087 | Learning Rate: 0.000797 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7629/12542 | Batch Loss: 0.4793 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7630/12542 | Batch Loss: 1.4578 | Learning Rate: 0.000797 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7631/12542 | Batch Loss: 2.1905 | Learning Rate: 0.000797 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7632/12542 | Batch Loss: 1.1894 | Learning Rate: 0.000797 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7633/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000797 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7634/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7635/12542 | Batch Loss: 1.5075 | Learning Rate: 0.000797 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7636/12542 | Batch Loss: 2.0785 | Learning Rate: 0.000797 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7637/12542 | Batch Loss: 1.0373 | Learning Rate: 0.000797 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7638/12542 | Batch Loss: 1.8852 | Learning Rate: 0.000797 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7639/12542 | Batch Loss: 1.5020 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7640/12542 | Batch Loss: 1.3244 | Learning Rate: 0.000797 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7641/12542 | Batch Loss: 1.5337 | Learning Rate: 0.000797 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7642/12542 | Batch Loss: 1.3756 | Learning Rate: 0.000797 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7643/12542 | Batch Loss: 1.1939 | Learning Rate: 0.000797 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7644/12542 | Batch Loss: 1.6358 | Learning Rate: 0.000797 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7645/12542 | Batch Loss: 1.1843 | Learning Rate: 0.000797 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7646/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000797 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7647/12542 | Batch Loss: 2.0307 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7648/12542 | Batch Loss: 2.0572 | Learning Rate: 0.000797 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7649/12542 | Batch Loss: 0.6667 | Learning Rate: 0.000797 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7650/12542 | Batch Loss: 1.2317 | Learning Rate: 0.000797 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7651/12542 | Batch Loss: 1.5815 | Learning Rate: 0.000797 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7652/12542 | Batch Loss: 0.7381 | Learning Rate: 0.000797 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7653/12542 | Batch Loss: 0.6970 | Learning Rate: 0.000797 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7654/12542 | Batch Loss: 2.2010 | Learning Rate: 0.000797 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7655/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000797 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7656/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000797 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7657/12542 | Batch Loss: 0.4726 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7658/12542 | Batch Loss: 0.6566 | Learning Rate: 0.000796 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7659/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7660/12542 | Batch Loss: 1.2017 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7661/12542 | Batch Loss: 1.1303 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7662/12542 | Batch Loss: 1.2275 | Learning Rate: 0.000796 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7663/12542 | Batch Loss: 0.8730 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7664/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7665/12542 | Batch Loss: 2.4368 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7666/12542 | Batch Loss: 1.2546 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7667/12542 | Batch Loss: 1.1090 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7668/12542 | Batch Loss: 0.6115 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7669/12542 | Batch Loss: 2.2372 | Learning Rate: 0.000796 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7670/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000796 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7671/12542 | Batch Loss: 2.3518 | Learning Rate: 0.000796 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7672/12542 | Batch Loss: 1.7775 | Learning Rate: 0.000796 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7673/12542 | Batch Loss: 0.8377 | Learning Rate: 0.000796 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7674/12542 | Batch Loss: 1.5112 | Learning Rate: 0.000796 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7675/12542 | Batch Loss: 1.2210 | Learning Rate: 0.000796 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 7676/12542 | Batch Loss: 1.2383 | Learning Rate: 0.000796 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7677/12542 | Batch Loss: 1.0869 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7678/12542 | Batch Loss: 1.0812 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7679/12542 | Batch Loss: 0.7353 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7680/12542 | Batch Loss: 0.8961 | Learning Rate: 0.000796 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7681/12542 | Batch Loss: 0.6705 | Learning Rate: 0.000796 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7682/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7683/12542 | Batch Loss: 3.1411 | Learning Rate: 0.000796 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7684/12542 | Batch Loss: 0.9770 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7685/12542 | Batch Loss: 0.7418 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7686/12542 | Batch Loss: 1.0026 | Learning Rate: 0.000796 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7687/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7688/12542 | Batch Loss: 1.2693 | Learning Rate: 0.000796 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7689/12542 | Batch Loss: 1.6788 | Learning Rate: 0.000796 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7690/12542 | Batch Loss: 1.0725 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7691/12542 | Batch Loss: 2.6835 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7692/12542 | Batch Loss: 0.9550 | Learning Rate: 0.000796 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7693/12542 | Batch Loss: 2.8254 | Learning Rate: 0.000796 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7694/12542 | Batch Loss: 1.2614 | Learning Rate: 0.000796 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7695/12542 | Batch Loss: 0.6242 | Learning Rate: 0.000795 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7696/12542 | Batch Loss: 1.9696 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7697/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7698/12542 | Batch Loss: 0.7658 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7699/12542 | Batch Loss: 1.0830 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7700/12542 | Batch Loss: 1.4197 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7701/12542 | Batch Loss: 1.0854 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7702/12542 | Batch Loss: 0.5417 | Learning Rate: 0.000795 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7703/12542 | Batch Loss: 0.6131 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7704/12542 | Batch Loss: 1.4197 | Learning Rate: 0.000795 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7705/12542 | Batch Loss: 1.9999 | Learning Rate: 0.000795 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7706/12542 | Batch Loss: 0.5892 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7707/12542 | Batch Loss: 1.4647 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7708/12542 | Batch Loss: 1.5737 | Learning Rate: 0.000795 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7709/12542 | Batch Loss: 0.9273 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7710/12542 | Batch Loss: 1.1280 | Learning Rate: 0.000795 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7711/12542 | Batch Loss: 2.9486 | Learning Rate: 0.000795 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7712/12542 | Batch Loss: 0.7368 | Learning Rate: 0.000795 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7713/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000795 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7714/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000795 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7715/12542 | Batch Loss: 0.5848 | Learning Rate: 0.000795 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7716/12542 | Batch Loss: 1.2317 | Learning Rate: 0.000795 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7717/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7718/12542 | Batch Loss: 0.8719 | Learning Rate: 0.000795 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7719/12542 | Batch Loss: 1.2968 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7720/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7721/12542 | Batch Loss: 1.5296 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7722/12542 | Batch Loss: 0.5012 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7723/12542 | Batch Loss: 2.5613 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7724/12542 | Batch Loss: 1.7037 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7725/12542 | Batch Loss: 2.6550 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7726/12542 | Batch Loss: 2.6608 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7727/12542 | Batch Loss: 1.6295 | Learning Rate: 0.000795 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7728/12542 | Batch Loss: 1.0136 | Learning Rate: 0.000795 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7729/12542 | Batch Loss: 0.7575 | Learning Rate: 0.000795 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7730/12542 | Batch Loss: 1.1927 | Learning Rate: 0.000795 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7731/12542 | Batch Loss: 1.7517 | Learning Rate: 0.000795 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7732/12542 | Batch Loss: 1.0301 | Learning Rate: 0.000795 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7733/12542 | Batch Loss: 1.8415 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7734/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000794 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7735/12542 | Batch Loss: 0.9202 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7736/12542 | Batch Loss: 1.1719 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7737/12542 | Batch Loss: 2.6678 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7738/12542 | Batch Loss: 0.5089 | Learning Rate: 0.000794 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7739/12542 | Batch Loss: 1.8836 | Learning Rate: 0.000794 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7740/12542 | Batch Loss: 0.7913 | Learning Rate: 0.000794 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7741/12542 | Batch Loss: 0.8574 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7742/12542 | Batch Loss: 1.6799 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7743/12542 | Batch Loss: 0.6411 | Learning Rate: 0.000794 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7744/12542 | Batch Loss: 0.9829 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7745/12542 | Batch Loss: 3.5015 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7746/12542 | Batch Loss: 1.4119 | Learning Rate: 0.000794 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7747/12542 | Batch Loss: 0.5305 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7748/12542 | Batch Loss: 1.8259 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7749/12542 | Batch Loss: 1.9345 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7750/12542 | Batch Loss: 1.3572 | Learning Rate: 0.000794 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7751/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000794 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7752/12542 | Batch Loss: 1.0102 | Learning Rate: 0.000794 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7753/12542 | Batch Loss: 1.0650 | Learning Rate: 0.000794 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7754/12542 | Batch Loss: 1.0115 | Learning Rate: 0.000794 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7755/12542 | Batch Loss: 3.0662 | Learning Rate: 0.000794 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7756/12542 | Batch Loss: 3.1347 | Learning Rate: 0.000794 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7757/12542 | Batch Loss: 2.0747 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7758/12542 | Batch Loss: 1.1564 | Learning Rate: 0.000794 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7759/12542 | Batch Loss: 1.6987 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7760/12542 | Batch Loss: 2.2477 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7761/12542 | Batch Loss: 1.5908 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7762/12542 | Batch Loss: 0.9212 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7763/12542 | Batch Loss: 0.8381 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7764/12542 | Batch Loss: 0.6437 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7765/12542 | Batch Loss: 1.4639 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7766/12542 | Batch Loss: 1.0827 | Learning Rate: 0.000794 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7767/12542 | Batch Loss: 1.0886 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7768/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000794 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 7769/12542 | Batch Loss: 0.7719 | Learning Rate: 0.000794 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7770/12542 | Batch Loss: 1.2755 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7771/12542 | Batch Loss: 1.1195 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7772/12542 | Batch Loss: 1.2482 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7773/12542 | Batch Loss: 1.2669 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7774/12542 | Batch Loss: 1.3037 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7775/12542 | Batch Loss: 2.7347 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7776/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000793 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7777/12542 | Batch Loss: 1.4539 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7778/12542 | Batch Loss: 0.6427 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7779/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7780/12542 | Batch Loss: 0.9761 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7781/12542 | Batch Loss: 1.5563 | Learning Rate: 0.000793 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7782/12542 | Batch Loss: 0.9853 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7783/12542 | Batch Loss: 1.2845 | Learning Rate: 0.000793 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7784/12542 | Batch Loss: 0.9427 | Learning Rate: 0.000793 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7785/12542 | Batch Loss: 1.2323 | Learning Rate: 0.000793 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7786/12542 | Batch Loss: 1.5962 | Learning Rate: 0.000793 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7787/12542 | Batch Loss: 2.2685 | Learning Rate: 0.000793 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7788/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000793 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7789/12542 | Batch Loss: 1.9944 | Learning Rate: 0.000793 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7790/12542 | Batch Loss: 0.6320 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7791/12542 | Batch Loss: 1.1606 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7792/12542 | Batch Loss: 0.7614 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7793/12542 | Batch Loss: 1.7050 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7794/12542 | Batch Loss: 1.5235 | Learning Rate: 0.000793 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7795/12542 | Batch Loss: 0.8217 | Learning Rate: 0.000793 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7796/12542 | Batch Loss: 0.7996 | Learning Rate: 0.000793 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7797/12542 | Batch Loss: 0.8766 | Learning Rate: 0.000793 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7798/12542 | Batch Loss: 1.4641 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7799/12542 | Batch Loss: 1.5473 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7800/12542 | Batch Loss: 1.3726 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7801/12542 | Batch Loss: 0.7086 | Learning Rate: 0.000793 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7802/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000793 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7803/12542 | Batch Loss: 2.6023 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7804/12542 | Batch Loss: 1.2013 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7805/12542 | Batch Loss: 1.6603 | Learning Rate: 0.000793 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7806/12542 | Batch Loss: 1.6397 | Learning Rate: 0.000793 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7807/12542 | Batch Loss: 0.9804 | Learning Rate: 0.000793 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7808/12542 | Batch Loss: 0.9827 | Learning Rate: 0.000792 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7809/12542 | Batch Loss: 1.6088 | Learning Rate: 0.000792 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 7810/12542 | Batch Loss: 1.2556 | Learning Rate: 0.000792 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7811/12542 | Batch Loss: 0.8077 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7812/12542 | Batch Loss: 2.0550 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7813/12542 | Batch Loss: 1.2732 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7814/12542 | Batch Loss: 1.4855 | Learning Rate: 0.000792 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7815/12542 | Batch Loss: 1.5110 | Learning Rate: 0.000792 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 7816/12542 | Batch Loss: 0.8698 | Learning Rate: 0.000792 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7817/12542 | Batch Loss: 0.6710 | Learning Rate: 0.000792 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7818/12542 | Batch Loss: 2.1026 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7819/12542 | Batch Loss: 1.1857 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7820/12542 | Batch Loss: 2.2478 | Learning Rate: 0.000792 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 7821/12542 | Batch Loss: 1.5967 | Learning Rate: 0.000792 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 7822/12542 | Batch Loss: 1.1466 | Learning Rate: 0.000792 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 7823/12542 | Batch Loss: 1.4966 | Learning Rate: 0.000792 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7824/12542 | Batch Loss: 0.7422 | Learning Rate: 0.000792 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 7825/12542 | Batch Loss: 1.1604 | Learning Rate: 0.000792 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7826/12542 | Batch Loss: 1.0958 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7827/12542 | Batch Loss: 1.9217 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7828/12542 | Batch Loss: 0.8429 | Learning Rate: 0.000792 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 7829/12542 | Batch Loss: 2.2099 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7830/12542 | Batch Loss: 0.8219 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7831/12542 | Batch Loss: 1.2144 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7832/12542 | Batch Loss: 0.8799 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7833/12542 | Batch Loss: 0.7240 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7834/12542 | Batch Loss: 0.6279 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7835/12542 | Batch Loss: 0.7954 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7836/12542 | Batch Loss: 0.8459 | Learning Rate: 0.000792 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7837/12542 | Batch Loss: 1.0453 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7838/12542 | Batch Loss: 0.9369 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7839/12542 | Batch Loss: 2.4389 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7840/12542 | Batch Loss: 0.9231 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7841/12542 | Batch Loss: 0.5237 | Learning Rate: 0.000792 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7842/12542 | Batch Loss: 1.0723 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7843/12542 | Batch Loss: 1.2799 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7844/12542 | Batch Loss: 1.3008 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7845/12542 | Batch Loss: 0.9882 | Learning Rate: 0.000792 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7846/12542 | Batch Loss: 1.9578 | Learning Rate: 0.000791 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7847/12542 | Batch Loss: 1.7780 | Learning Rate: 0.000791 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7848/12542 | Batch Loss: 0.7812 | Learning Rate: 0.000791 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7849/12542 | Batch Loss: 0.4934 | Learning Rate: 0.000791 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 7850/12542 | Batch Loss: 1.0469 | Learning Rate: 0.000791 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 7851/12542 | Batch Loss: 1.7617 | Learning Rate: 0.000791 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7852/12542 | Batch Loss: 0.7058 | Learning Rate: 0.000791 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 7853/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000791 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 7854/12542 | Batch Loss: 1.2602 | Learning Rate: 0.000791 | Batch Time: 0.77s\n",
      "Epoch 1 | Step 7855/12542 | Batch Loss: 1.2862 | Learning Rate: 0.000791 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 7856/12542 | Batch Loss: 2.5543 | Learning Rate: 0.000791 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7857/12542 | Batch Loss: 0.7057 | Learning Rate: 0.000791 | Batch Time: 2.65s\n",
      "Epoch 1 | Step 7858/12542 | Batch Loss: 1.4189 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7859/12542 | Batch Loss: 3.4611 | Learning Rate: 0.000791 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7860/12542 | Batch Loss: 1.8792 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7861/12542 | Batch Loss: 0.9471 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7862/12542 | Batch Loss: 2.6926 | Learning Rate: 0.000791 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 7863/12542 | Batch Loss: 0.9904 | Learning Rate: 0.000791 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 7864/12542 | Batch Loss: 2.0425 | Learning Rate: 0.000791 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 7865/12542 | Batch Loss: 1.3782 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7866/12542 | Batch Loss: 1.0519 | Learning Rate: 0.000791 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7867/12542 | Batch Loss: 1.7697 | Learning Rate: 0.000791 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7868/12542 | Batch Loss: 1.9207 | Learning Rate: 0.000791 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 7869/12542 | Batch Loss: 0.8633 | Learning Rate: 0.000791 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 7870/12542 | Batch Loss: 0.9126 | Learning Rate: 0.000791 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 7871/12542 | Batch Loss: 1.2244 | Learning Rate: 0.000791 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7872/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000791 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7873/12542 | Batch Loss: 1.9428 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7874/12542 | Batch Loss: 0.7952 | Learning Rate: 0.000791 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7875/12542 | Batch Loss: 1.7886 | Learning Rate: 0.000791 | Batch Time: 2.56s\n",
      "Epoch 1 | Step 7876/12542 | Batch Loss: 1.3742 | Learning Rate: 0.000791 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7877/12542 | Batch Loss: 0.8910 | Learning Rate: 0.000791 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 7878/12542 | Batch Loss: 0.8705 | Learning Rate: 0.000791 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 7879/12542 | Batch Loss: 1.6721 | Learning Rate: 0.000791 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7880/12542 | Batch Loss: 1.1582 | Learning Rate: 0.000791 | Batch Time: 2.48s\n",
      "Epoch 1 | Step 7881/12542 | Batch Loss: 1.8449 | Learning Rate: 0.000791 | Batch Time: 2.56s\n",
      "Epoch 1 | Step 7882/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000791 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 7883/12542 | Batch Loss: 1.5234 | Learning Rate: 0.000790 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7884/12542 | Batch Loss: 1.2530 | Learning Rate: 0.000790 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7885/12542 | Batch Loss: 0.7335 | Learning Rate: 0.000790 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7886/12542 | Batch Loss: 1.7683 | Learning Rate: 0.000790 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7887/12542 | Batch Loss: 0.8397 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7888/12542 | Batch Loss: 0.6586 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7889/12542 | Batch Loss: 0.6147 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7890/12542 | Batch Loss: 0.9025 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7891/12542 | Batch Loss: 1.3706 | Learning Rate: 0.000790 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7892/12542 | Batch Loss: 1.9877 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7893/12542 | Batch Loss: 0.6029 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7894/12542 | Batch Loss: 1.9147 | Learning Rate: 0.000790 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 7895/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000790 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 7896/12542 | Batch Loss: 0.5478 | Learning Rate: 0.000790 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 7897/12542 | Batch Loss: 2.1080 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7898/12542 | Batch Loss: 0.6226 | Learning Rate: 0.000790 | Batch Time: 2.26s\n",
      "Epoch 1 | Step 7899/12542 | Batch Loss: 0.6548 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7900/12542 | Batch Loss: 0.9265 | Learning Rate: 0.000790 | Batch Time: 2.40s\n",
      "Epoch 1 | Step 7901/12542 | Batch Loss: 0.5695 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7902/12542 | Batch Loss: 0.8147 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7903/12542 | Batch Loss: 0.6702 | Learning Rate: 0.000790 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 7904/12542 | Batch Loss: 1.5219 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7905/12542 | Batch Loss: 1.5467 | Learning Rate: 0.000790 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7906/12542 | Batch Loss: 1.0194 | Learning Rate: 0.000790 | Batch Time: 2.33s\n",
      "Epoch 1 | Step 7907/12542 | Batch Loss: 1.2725 | Learning Rate: 0.000790 | Batch Time: 2.32s\n",
      "Epoch 1 | Step 7908/12542 | Batch Loss: 3.0856 | Learning Rate: 0.000790 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 7909/12542 | Batch Loss: 0.8631 | Learning Rate: 0.000790 | Batch Time: 2.36s\n",
      "Epoch 1 | Step 7910/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000790 | Batch Time: 2.45s\n",
      "Epoch 1 | Step 7911/12542 | Batch Loss: 3.6065 | Learning Rate: 0.000790 | Batch Time: 2.35s\n",
      "Epoch 1 | Step 7912/12542 | Batch Loss: 2.3124 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7913/12542 | Batch Loss: 0.7459 | Learning Rate: 0.000790 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 7914/12542 | Batch Loss: 1.6233 | Learning Rate: 0.000790 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7915/12542 | Batch Loss: 1.3246 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7916/12542 | Batch Loss: 0.6858 | Learning Rate: 0.000790 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7917/12542 | Batch Loss: 0.8290 | Learning Rate: 0.000790 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7918/12542 | Batch Loss: 1.9609 | Learning Rate: 0.000790 | Batch Time: 2.33s\n",
      "Epoch 1 | Step 7919/12542 | Batch Loss: 1.0530 | Learning Rate: 0.000790 | Batch Time: 2.18s\n",
      "Epoch 1 | Step 7920/12542 | Batch Loss: 1.1131 | Learning Rate: 0.000790 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7921/12542 | Batch Loss: 1.1171 | Learning Rate: 0.000789 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 7922/12542 | Batch Loss: 1.3243 | Learning Rate: 0.000789 | Batch Time: 2.33s\n",
      "Epoch 1 | Step 7923/12542 | Batch Loss: 2.9630 | Learning Rate: 0.000789 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 7924/12542 | Batch Loss: 1.2169 | Learning Rate: 0.000789 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7925/12542 | Batch Loss: 1.0622 | Learning Rate: 0.000789 | Batch Time: 2.35s\n",
      "Epoch 1 | Step 7926/12542 | Batch Loss: 3.1275 | Learning Rate: 0.000789 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 7927/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000789 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 7928/12542 | Batch Loss: 1.6238 | Learning Rate: 0.000789 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 7929/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000789 | Batch Time: 2.19s\n",
      "Epoch 1 | Step 7930/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000789 | Batch Time: 2.18s\n",
      "Epoch 1 | Step 7931/12542 | Batch Loss: 1.6150 | Learning Rate: 0.000789 | Batch Time: 2.20s\n",
      "Epoch 1 | Step 7932/12542 | Batch Loss: 2.1458 | Learning Rate: 0.000789 | Batch Time: 2.24s\n",
      "Epoch 1 | Step 7933/12542 | Batch Loss: 1.6138 | Learning Rate: 0.000789 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7934/12542 | Batch Loss: 1.4751 | Learning Rate: 0.000789 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7935/12542 | Batch Loss: 0.6715 | Learning Rate: 0.000789 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7936/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000789 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7937/12542 | Batch Loss: 1.7920 | Learning Rate: 0.000789 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7938/12542 | Batch Loss: 0.8220 | Learning Rate: 0.000789 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 7939/12542 | Batch Loss: 0.9195 | Learning Rate: 0.000789 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7940/12542 | Batch Loss: 2.7873 | Learning Rate: 0.000789 | Batch Time: 1.97s\n",
      "Epoch 1 | Step 7941/12542 | Batch Loss: 1.1756 | Learning Rate: 0.000789 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 7942/12542 | Batch Loss: 2.6445 | Learning Rate: 0.000789 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 7943/12542 | Batch Loss: 0.7177 | Learning Rate: 0.000789 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7944/12542 | Batch Loss: 1.4451 | Learning Rate: 0.000789 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7945/12542 | Batch Loss: 0.8442 | Learning Rate: 0.000789 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 7946/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000789 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 7947/12542 | Batch Loss: 1.4394 | Learning Rate: 0.000789 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 7948/12542 | Batch Loss: 1.0686 | Learning Rate: 0.000789 | Batch Time: 2.22s\n",
      "Epoch 1 | Step 7949/12542 | Batch Loss: 0.7500 | Learning Rate: 0.000789 | Batch Time: 2.28s\n",
      "Epoch 1 | Step 7950/12542 | Batch Loss: 1.3442 | Learning Rate: 0.000789 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7951/12542 | Batch Loss: 1.0446 | Learning Rate: 0.000789 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7952/12542 | Batch Loss: 1.7838 | Learning Rate: 0.000789 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7953/12542 | Batch Loss: 2.0344 | Learning Rate: 0.000789 | Batch Time: 2.34s\n",
      "Epoch 1 | Step 7954/12542 | Batch Loss: 2.4159 | Learning Rate: 0.000789 | Batch Time: 2.28s\n",
      "Epoch 1 | Step 7955/12542 | Batch Loss: 0.8014 | Learning Rate: 0.000789 | Batch Time: 2.42s\n",
      "Epoch 1 | Step 7956/12542 | Batch Loss: 1.5580 | Learning Rate: 0.000789 | Batch Time: 2.30s\n",
      "Epoch 1 | Step 7957/12542 | Batch Loss: 1.2761 | Learning Rate: 0.000789 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7958/12542 | Batch Loss: 2.4418 | Learning Rate: 0.000788 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 7959/12542 | Batch Loss: 0.7543 | Learning Rate: 0.000788 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7960/12542 | Batch Loss: 0.8613 | Learning Rate: 0.000788 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7961/12542 | Batch Loss: 0.9473 | Learning Rate: 0.000788 | Batch Time: 2.46s\n",
      "Epoch 1 | Step 7962/12542 | Batch Loss: 1.2566 | Learning Rate: 0.000788 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 7963/12542 | Batch Loss: 0.7351 | Learning Rate: 0.000788 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 7964/12542 | Batch Loss: 1.0309 | Learning Rate: 0.000788 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 7965/12542 | Batch Loss: 1.4107 | Learning Rate: 0.000788 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 7966/12542 | Batch Loss: 1.3830 | Learning Rate: 0.000788 | Batch Time: 2.36s\n",
      "Epoch 1 | Step 7967/12542 | Batch Loss: 3.1650 | Learning Rate: 0.000788 | Batch Time: 2.41s\n",
      "Epoch 1 | Step 7968/12542 | Batch Loss: 2.8138 | Learning Rate: 0.000788 | Batch Time: 2.24s\n",
      "Epoch 1 | Step 7969/12542 | Batch Loss: 1.0646 | Learning Rate: 0.000788 | Batch Time: 2.16s\n",
      "Epoch 1 | Step 7970/12542 | Batch Loss: 0.8344 | Learning Rate: 0.000788 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 7971/12542 | Batch Loss: 2.3888 | Learning Rate: 0.000788 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 7972/12542 | Batch Loss: 2.0711 | Learning Rate: 0.000788 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 7973/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000788 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7974/12542 | Batch Loss: 1.2842 | Learning Rate: 0.000788 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7975/12542 | Batch Loss: 1.0491 | Learning Rate: 0.000788 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 7976/12542 | Batch Loss: 1.6586 | Learning Rate: 0.000788 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7977/12542 | Batch Loss: 1.2497 | Learning Rate: 0.000788 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 7978/12542 | Batch Loss: 1.8523 | Learning Rate: 0.000788 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7979/12542 | Batch Loss: 1.1233 | Learning Rate: 0.000788 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7980/12542 | Batch Loss: 1.1611 | Learning Rate: 0.000788 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7981/12542 | Batch Loss: 1.9826 | Learning Rate: 0.000788 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 7982/12542 | Batch Loss: 1.0564 | Learning Rate: 0.000788 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 7983/12542 | Batch Loss: 1.2609 | Learning Rate: 0.000788 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 7984/12542 | Batch Loss: 1.6289 | Learning Rate: 0.000788 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 7985/12542 | Batch Loss: 0.7966 | Learning Rate: 0.000788 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 7986/12542 | Batch Loss: 1.6752 | Learning Rate: 0.000788 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 7987/12542 | Batch Loss: 1.4592 | Learning Rate: 0.000788 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 7988/12542 | Batch Loss: 0.6230 | Learning Rate: 0.000788 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 7989/12542 | Batch Loss: 0.7735 | Learning Rate: 0.000788 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 7990/12542 | Batch Loss: 1.2252 | Learning Rate: 0.000788 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 7991/12542 | Batch Loss: 1.6022 | Learning Rate: 0.000788 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 7992/12542 | Batch Loss: 0.8322 | Learning Rate: 0.000788 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 7993/12542 | Batch Loss: 1.2633 | Learning Rate: 0.000788 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 7994/12542 | Batch Loss: 0.9456 | Learning Rate: 0.000788 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 7995/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000788 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 7996/12542 | Batch Loss: 0.5723 | Learning Rate: 0.000787 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 7997/12542 | Batch Loss: 2.2664 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 7998/12542 | Batch Loss: 0.5640 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 7999/12542 | Batch Loss: 1.6757 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8000/12542 | Batch Loss: 0.9216 | Learning Rate: 0.000787 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8001/12542 | Batch Loss: 1.6063 | Learning Rate: 0.000787 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8002/12542 | Batch Loss: 2.4286 | Learning Rate: 0.000787 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8003/12542 | Batch Loss: 1.4258 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8004/12542 | Batch Loss: 1.9520 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8005/12542 | Batch Loss: 1.4535 | Learning Rate: 0.000787 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8006/12542 | Batch Loss: 2.0675 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8007/12542 | Batch Loss: 2.6639 | Learning Rate: 0.000787 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8008/12542 | Batch Loss: 1.0634 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8009/12542 | Batch Loss: 2.8766 | Learning Rate: 0.000787 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8010/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000787 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8011/12542 | Batch Loss: 0.6410 | Learning Rate: 0.000787 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8012/12542 | Batch Loss: 2.3529 | Learning Rate: 0.000787 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8013/12542 | Batch Loss: 2.0322 | Learning Rate: 0.000787 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8014/12542 | Batch Loss: 1.2339 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8015/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8016/12542 | Batch Loss: 2.1233 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8017/12542 | Batch Loss: 2.2196 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8018/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8019/12542 | Batch Loss: 0.7979 | Learning Rate: 0.000787 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8020/12542 | Batch Loss: 1.6963 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8021/12542 | Batch Loss: 1.4770 | Learning Rate: 0.000787 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 8022/12542 | Batch Loss: 1.2696 | Learning Rate: 0.000787 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8023/12542 | Batch Loss: 0.8866 | Learning Rate: 0.000787 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8024/12542 | Batch Loss: 0.6698 | Learning Rate: 0.000787 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8025/12542 | Batch Loss: 0.6193 | Learning Rate: 0.000787 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8026/12542 | Batch Loss: 0.5781 | Learning Rate: 0.000787 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8027/12542 | Batch Loss: 1.6118 | Learning Rate: 0.000787 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8028/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000787 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8029/12542 | Batch Loss: 0.8544 | Learning Rate: 0.000787 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8030/12542 | Batch Loss: 0.9937 | Learning Rate: 0.000787 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8031/12542 | Batch Loss: 1.9749 | Learning Rate: 0.000787 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8032/12542 | Batch Loss: 1.5576 | Learning Rate: 0.000787 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8033/12542 | Batch Loss: 0.8279 | Learning Rate: 0.000787 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8034/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000786 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8035/12542 | Batch Loss: 1.7586 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8036/12542 | Batch Loss: 1.0122 | Learning Rate: 0.000786 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8037/12542 | Batch Loss: 1.5951 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8038/12542 | Batch Loss: 1.6488 | Learning Rate: 0.000786 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8039/12542 | Batch Loss: 1.0225 | Learning Rate: 0.000786 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8040/12542 | Batch Loss: 0.7135 | Learning Rate: 0.000786 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8041/12542 | Batch Loss: 1.5432 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8042/12542 | Batch Loss: 1.9089 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8043/12542 | Batch Loss: 1.2346 | Learning Rate: 0.000786 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8044/12542 | Batch Loss: 1.0683 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8045/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8046/12542 | Batch Loss: 1.9093 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8047/12542 | Batch Loss: 1.7721 | Learning Rate: 0.000786 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8048/12542 | Batch Loss: 1.4003 | Learning Rate: 0.000786 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8049/12542 | Batch Loss: 1.7978 | Learning Rate: 0.000786 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8050/12542 | Batch Loss: 3.6838 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8051/12542 | Batch Loss: 1.0263 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8052/12542 | Batch Loss: 0.4911 | Learning Rate: 0.000786 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8053/12542 | Batch Loss: 1.0001 | Learning Rate: 0.000786 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8054/12542 | Batch Loss: 0.8136 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8055/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000786 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8056/12542 | Batch Loss: 1.7977 | Learning Rate: 0.000786 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8057/12542 | Batch Loss: 1.0293 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8058/12542 | Batch Loss: 1.5173 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8059/12542 | Batch Loss: 0.7547 | Learning Rate: 0.000786 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8060/12542 | Batch Loss: 1.1003 | Learning Rate: 0.000786 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8061/12542 | Batch Loss: 2.4126 | Learning Rate: 0.000786 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8062/12542 | Batch Loss: 0.6398 | Learning Rate: 0.000786 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8063/12542 | Batch Loss: 0.5023 | Learning Rate: 0.000786 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8064/12542 | Batch Loss: 1.1516 | Learning Rate: 0.000786 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8065/12542 | Batch Loss: 1.7518 | Learning Rate: 0.000786 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8066/12542 | Batch Loss: 1.4882 | Learning Rate: 0.000786 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8067/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8068/12542 | Batch Loss: 4.2307 | Learning Rate: 0.000786 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8069/12542 | Batch Loss: 0.5428 | Learning Rate: 0.000786 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8070/12542 | Batch Loss: 1.8100 | Learning Rate: 0.000786 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8071/12542 | Batch Loss: 0.9349 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8072/12542 | Batch Loss: 0.6810 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8073/12542 | Batch Loss: 1.6627 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8074/12542 | Batch Loss: 1.3093 | Learning Rate: 0.000785 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8075/12542 | Batch Loss: 3.5503 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8076/12542 | Batch Loss: 1.5017 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8077/12542 | Batch Loss: 2.7984 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8078/12542 | Batch Loss: 1.6548 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8079/12542 | Batch Loss: 2.2335 | Learning Rate: 0.000785 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8080/12542 | Batch Loss: 1.4456 | Learning Rate: 0.000785 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8081/12542 | Batch Loss: 1.6404 | Learning Rate: 0.000785 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8082/12542 | Batch Loss: 1.9225 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8083/12542 | Batch Loss: 1.2110 | Learning Rate: 0.000785 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8084/12542 | Batch Loss: 1.6849 | Learning Rate: 0.000785 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8085/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8086/12542 | Batch Loss: 0.9018 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8087/12542 | Batch Loss: 1.0153 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8088/12542 | Batch Loss: 1.3349 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8089/12542 | Batch Loss: 1.2456 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8090/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000785 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8091/12542 | Batch Loss: 2.0590 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8092/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8093/12542 | Batch Loss: 1.9506 | Learning Rate: 0.000785 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8094/12542 | Batch Loss: 1.0574 | Learning Rate: 0.000785 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8095/12542 | Batch Loss: 0.8625 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8096/12542 | Batch Loss: 1.4429 | Learning Rate: 0.000785 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8097/12542 | Batch Loss: 1.2903 | Learning Rate: 0.000785 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8098/12542 | Batch Loss: 1.1930 | Learning Rate: 0.000785 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8099/12542 | Batch Loss: 1.5956 | Learning Rate: 0.000785 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8100/12542 | Batch Loss: 0.7610 | Learning Rate: 0.000785 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8101/12542 | Batch Loss: 0.8981 | Learning Rate: 0.000785 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8102/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000785 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8103/12542 | Batch Loss: 0.4366 | Learning Rate: 0.000785 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8104/12542 | Batch Loss: 1.1789 | Learning Rate: 0.000785 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8105/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000785 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8106/12542 | Batch Loss: 0.9755 | Learning Rate: 0.000785 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8107/12542 | Batch Loss: 1.2713 | Learning Rate: 0.000785 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8108/12542 | Batch Loss: 1.0465 | Learning Rate: 0.000785 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8109/12542 | Batch Loss: 1.0767 | Learning Rate: 0.000784 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8110/12542 | Batch Loss: 1.3052 | Learning Rate: 0.000784 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8111/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8112/12542 | Batch Loss: 0.7407 | Learning Rate: 0.000784 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8113/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8114/12542 | Batch Loss: 2.4358 | Learning Rate: 0.000784 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8115/12542 | Batch Loss: 1.1779 | Learning Rate: 0.000784 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8116/12542 | Batch Loss: 1.2668 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8117/12542 | Batch Loss: 1.4700 | Learning Rate: 0.000784 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8118/12542 | Batch Loss: 3.0162 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8119/12542 | Batch Loss: 0.5811 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8120/12542 | Batch Loss: 2.3337 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8121/12542 | Batch Loss: 1.3965 | Learning Rate: 0.000784 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8122/12542 | Batch Loss: 1.1301 | Learning Rate: 0.000784 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8123/12542 | Batch Loss: 0.9569 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8124/12542 | Batch Loss: 0.5116 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8125/12542 | Batch Loss: 0.5495 | Learning Rate: 0.000784 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8126/12542 | Batch Loss: 1.2562 | Learning Rate: 0.000784 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8127/12542 | Batch Loss: 1.5532 | Learning Rate: 0.000784 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8128/12542 | Batch Loss: 1.8581 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8129/12542 | Batch Loss: 0.7851 | Learning Rate: 0.000784 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8130/12542 | Batch Loss: 1.5649 | Learning Rate: 0.000784 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8131/12542 | Batch Loss: 1.6415 | Learning Rate: 0.000784 | Batch Time: 2.13s\n",
      "Epoch 1 | Step 8132/12542 | Batch Loss: 1.3674 | Learning Rate: 0.000784 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8133/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8134/12542 | Batch Loss: 0.8663 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8135/12542 | Batch Loss: 0.7921 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8136/12542 | Batch Loss: 1.3114 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8137/12542 | Batch Loss: 1.5489 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8138/12542 | Batch Loss: 1.2872 | Learning Rate: 0.000784 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8139/12542 | Batch Loss: 1.2348 | Learning Rate: 0.000784 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8140/12542 | Batch Loss: 2.1367 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8141/12542 | Batch Loss: 1.3823 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8142/12542 | Batch Loss: 3.0272 | Learning Rate: 0.000784 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8143/12542 | Batch Loss: 2.4108 | Learning Rate: 0.000784 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8144/12542 | Batch Loss: 0.4267 | Learning Rate: 0.000784 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8145/12542 | Batch Loss: 1.2966 | Learning Rate: 0.000784 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8146/12542 | Batch Loss: 1.5894 | Learning Rate: 0.000784 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8147/12542 | Batch Loss: 1.2035 | Learning Rate: 0.000783 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8148/12542 | Batch Loss: 2.5034 | Learning Rate: 0.000783 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8149/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000783 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8150/12542 | Batch Loss: 1.3286 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8151/12542 | Batch Loss: 1.8325 | Learning Rate: 0.000783 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8152/12542 | Batch Loss: 1.0713 | Learning Rate: 0.000783 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8153/12542 | Batch Loss: 2.2810 | Learning Rate: 0.000783 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8154/12542 | Batch Loss: 1.7189 | Learning Rate: 0.000783 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8155/12542 | Batch Loss: 1.1293 | Learning Rate: 0.000783 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8156/12542 | Batch Loss: 1.5100 | Learning Rate: 0.000783 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8157/12542 | Batch Loss: 1.2223 | Learning Rate: 0.000783 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8158/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000783 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8159/12542 | Batch Loss: 2.2516 | Learning Rate: 0.000783 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8160/12542 | Batch Loss: 2.2721 | Learning Rate: 0.000783 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8161/12542 | Batch Loss: 2.7887 | Learning Rate: 0.000783 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8162/12542 | Batch Loss: 1.6016 | Learning Rate: 0.000783 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8163/12542 | Batch Loss: 0.6156 | Learning Rate: 0.000783 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8164/12542 | Batch Loss: 1.1496 | Learning Rate: 0.000783 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8165/12542 | Batch Loss: 1.6340 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8166/12542 | Batch Loss: 1.0203 | Learning Rate: 0.000783 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8167/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000783 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8168/12542 | Batch Loss: 1.1691 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8169/12542 | Batch Loss: 1.9234 | Learning Rate: 0.000783 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8170/12542 | Batch Loss: 1.2752 | Learning Rate: 0.000783 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8171/12542 | Batch Loss: 0.8940 | Learning Rate: 0.000783 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8172/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000783 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 8173/12542 | Batch Loss: 1.0862 | Learning Rate: 0.000783 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8174/12542 | Batch Loss: 0.2574 | Learning Rate: 0.000783 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8175/12542 | Batch Loss: 0.5158 | Learning Rate: 0.000783 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8176/12542 | Batch Loss: 3.2546 | Learning Rate: 0.000783 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8177/12542 | Batch Loss: 1.4705 | Learning Rate: 0.000783 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8178/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000783 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8179/12542 | Batch Loss: 0.5145 | Learning Rate: 0.000783 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8180/12542 | Batch Loss: 2.5345 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8181/12542 | Batch Loss: 1.0384 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8182/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000783 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8183/12542 | Batch Loss: 0.6681 | Learning Rate: 0.000783 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8184/12542 | Batch Loss: 0.6271 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8185/12542 | Batch Loss: 2.1413 | Learning Rate: 0.000782 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8186/12542 | Batch Loss: 1.8685 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8187/12542 | Batch Loss: 0.7630 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8188/12542 | Batch Loss: 1.0400 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8189/12542 | Batch Loss: 0.5642 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8190/12542 | Batch Loss: 0.5907 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8191/12542 | Batch Loss: 0.6690 | Learning Rate: 0.000782 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8192/12542 | Batch Loss: 0.6965 | Learning Rate: 0.000782 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8193/12542 | Batch Loss: 0.6760 | Learning Rate: 0.000782 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8194/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8195/12542 | Batch Loss: 3.5288 | Learning Rate: 0.000782 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8196/12542 | Batch Loss: 2.1999 | Learning Rate: 0.000782 | Batch Time: 1.97s\n",
      "Epoch 1 | Step 8197/12542 | Batch Loss: 0.4406 | Learning Rate: 0.000782 | Batch Time: 1.96s\n",
      "Epoch 1 | Step 8198/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000782 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8199/12542 | Batch Loss: 2.6966 | Learning Rate: 0.000782 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 8200/12542 | Batch Loss: 1.5584 | Learning Rate: 0.000782 | Batch Time: 1.98s\n",
      "Epoch 1 | Step 8201/12542 | Batch Loss: 1.5020 | Learning Rate: 0.000782 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8202/12542 | Batch Loss: 1.1019 | Learning Rate: 0.000782 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8203/12542 | Batch Loss: 0.7761 | Learning Rate: 0.000782 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8204/12542 | Batch Loss: 1.0136 | Learning Rate: 0.000782 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8205/12542 | Batch Loss: 1.6457 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8206/12542 | Batch Loss: 0.9333 | Learning Rate: 0.000782 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8207/12542 | Batch Loss: 0.6659 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8208/12542 | Batch Loss: 1.1983 | Learning Rate: 0.000782 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8209/12542 | Batch Loss: 1.9284 | Learning Rate: 0.000782 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8210/12542 | Batch Loss: 2.0246 | Learning Rate: 0.000782 | Batch Time: 2.24s\n",
      "Epoch 1 | Step 8211/12542 | Batch Loss: 0.8622 | Learning Rate: 0.000782 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8212/12542 | Batch Loss: 1.3587 | Learning Rate: 0.000782 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8213/12542 | Batch Loss: 0.8976 | Learning Rate: 0.000782 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8214/12542 | Batch Loss: 2.2742 | Learning Rate: 0.000782 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8215/12542 | Batch Loss: 0.8602 | Learning Rate: 0.000782 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8216/12542 | Batch Loss: 0.7077 | Learning Rate: 0.000782 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8217/12542 | Batch Loss: 0.7758 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8218/12542 | Batch Loss: 0.6281 | Learning Rate: 0.000782 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8219/12542 | Batch Loss: 2.4796 | Learning Rate: 0.000782 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8220/12542 | Batch Loss: 0.5142 | Learning Rate: 0.000782 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8221/12542 | Batch Loss: 1.7092 | Learning Rate: 0.000782 | Batch Time: 2.30s\n",
      "Epoch 1 | Step 8222/12542 | Batch Loss: 1.1513 | Learning Rate: 0.000781 | Batch Time: 2.48s\n",
      "Epoch 1 | Step 8223/12542 | Batch Loss: 2.0392 | Learning Rate: 0.000781 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8224/12542 | Batch Loss: 1.9555 | Learning Rate: 0.000781 | Batch Time: 2.27s\n",
      "Epoch 1 | Step 8225/12542 | Batch Loss: 1.1143 | Learning Rate: 0.000781 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8226/12542 | Batch Loss: 1.1052 | Learning Rate: 0.000781 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8227/12542 | Batch Loss: 1.1817 | Learning Rate: 0.000781 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8228/12542 | Batch Loss: 1.1321 | Learning Rate: 0.000781 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8229/12542 | Batch Loss: 2.9311 | Learning Rate: 0.000781 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8230/12542 | Batch Loss: 1.1905 | Learning Rate: 0.000781 | Batch Time: 2.32s\n",
      "Epoch 1 | Step 8231/12542 | Batch Loss: 2.1557 | Learning Rate: 0.000781 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8232/12542 | Batch Loss: 0.9133 | Learning Rate: 0.000781 | Batch Time: 2.30s\n",
      "Epoch 1 | Step 8233/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000781 | Batch Time: 2.39s\n",
      "Epoch 1 | Step 8234/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000781 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8235/12542 | Batch Loss: 0.6957 | Learning Rate: 0.000781 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 8236/12542 | Batch Loss: 1.5701 | Learning Rate: 0.000781 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8237/12542 | Batch Loss: 2.0918 | Learning Rate: 0.000781 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8238/12542 | Batch Loss: 0.5491 | Learning Rate: 0.000781 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 8239/12542 | Batch Loss: 1.9660 | Learning Rate: 0.000781 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8240/12542 | Batch Loss: 1.2275 | Learning Rate: 0.000781 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8241/12542 | Batch Loss: 0.8958 | Learning Rate: 0.000781 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8242/12542 | Batch Loss: 0.8219 | Learning Rate: 0.000781 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8243/12542 | Batch Loss: 2.1351 | Learning Rate: 0.000781 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8244/12542 | Batch Loss: 1.1026 | Learning Rate: 0.000781 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8245/12542 | Batch Loss: 0.6391 | Learning Rate: 0.000781 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 8246/12542 | Batch Loss: 0.9772 | Learning Rate: 0.000781 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8247/12542 | Batch Loss: 1.4856 | Learning Rate: 0.000781 | Batch Time: 1.99s\n",
      "Epoch 1 | Step 8248/12542 | Batch Loss: 0.6912 | Learning Rate: 0.000781 | Batch Time: 1.98s\n",
      "Epoch 1 | Step 8249/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000781 | Batch Time: 2.00s\n",
      "Epoch 1 | Step 8250/12542 | Batch Loss: 1.3009 | Learning Rate: 0.000781 | Batch Time: 1.97s\n",
      "Epoch 1 | Step 8251/12542 | Batch Loss: 1.0130 | Learning Rate: 0.000781 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8252/12542 | Batch Loss: 1.4424 | Learning Rate: 0.000781 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8253/12542 | Batch Loss: 1.4123 | Learning Rate: 0.000781 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8254/12542 | Batch Loss: 0.9963 | Learning Rate: 0.000781 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8255/12542 | Batch Loss: 2.4127 | Learning Rate: 0.000781 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8256/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000781 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8257/12542 | Batch Loss: 1.4804 | Learning Rate: 0.000781 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8258/12542 | Batch Loss: 2.0104 | Learning Rate: 0.000781 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8259/12542 | Batch Loss: 1.3694 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8260/12542 | Batch Loss: 1.4863 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8261/12542 | Batch Loss: 1.8906 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8262/12542 | Batch Loss: 1.4543 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8263/12542 | Batch Loss: 3.1089 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8264/12542 | Batch Loss: 0.6773 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8265/12542 | Batch Loss: 1.6101 | Learning Rate: 0.000780 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8266/12542 | Batch Loss: 0.8788 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8267/12542 | Batch Loss: 0.7865 | Learning Rate: 0.000780 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8268/12542 | Batch Loss: 0.7812 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8269/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8270/12542 | Batch Loss: 0.6383 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8271/12542 | Batch Loss: 0.6231 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8272/12542 | Batch Loss: 2.2244 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8273/12542 | Batch Loss: 1.3475 | Learning Rate: 0.000780 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8274/12542 | Batch Loss: 2.6455 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8275/12542 | Batch Loss: 2.1420 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8276/12542 | Batch Loss: 1.8014 | Learning Rate: 0.000780 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8277/12542 | Batch Loss: 0.9683 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8278/12542 | Batch Loss: 2.0794 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8279/12542 | Batch Loss: 1.1931 | Learning Rate: 0.000780 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8280/12542 | Batch Loss: 1.2111 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8281/12542 | Batch Loss: 2.5202 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8282/12542 | Batch Loss: 1.5170 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8283/12542 | Batch Loss: 0.7813 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8284/12542 | Batch Loss: 1.6155 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8285/12542 | Batch Loss: 0.8050 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8286/12542 | Batch Loss: 1.5147 | Learning Rate: 0.000780 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8287/12542 | Batch Loss: 1.5731 | Learning Rate: 0.000780 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8288/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8289/12542 | Batch Loss: 1.2826 | Learning Rate: 0.000780 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8290/12542 | Batch Loss: 2.4509 | Learning Rate: 0.000780 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8291/12542 | Batch Loss: 0.6519 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8292/12542 | Batch Loss: 0.7648 | Learning Rate: 0.000780 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8293/12542 | Batch Loss: 0.6547 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8294/12542 | Batch Loss: 1.4627 | Learning Rate: 0.000780 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8295/12542 | Batch Loss: 2.3685 | Learning Rate: 0.000780 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8296/12542 | Batch Loss: 1.4482 | Learning Rate: 0.000780 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8297/12542 | Batch Loss: 1.0787 | Learning Rate: 0.000779 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8298/12542 | Batch Loss: 1.7906 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8299/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000779 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8300/12542 | Batch Loss: 1.9896 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8301/12542 | Batch Loss: 2.1409 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8302/12542 | Batch Loss: 1.4813 | Learning Rate: 0.000779 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8303/12542 | Batch Loss: 3.1427 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8304/12542 | Batch Loss: 2.2792 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8305/12542 | Batch Loss: 1.7952 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8306/12542 | Batch Loss: 1.6357 | Learning Rate: 0.000779 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8307/12542 | Batch Loss: 0.7664 | Learning Rate: 0.000779 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8308/12542 | Batch Loss: 1.0377 | Learning Rate: 0.000779 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8309/12542 | Batch Loss: 0.8704 | Learning Rate: 0.000779 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8310/12542 | Batch Loss: 2.0341 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8311/12542 | Batch Loss: 1.2591 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8312/12542 | Batch Loss: 2.3291 | Learning Rate: 0.000779 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8313/12542 | Batch Loss: 0.7988 | Learning Rate: 0.000779 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8314/12542 | Batch Loss: 1.4048 | Learning Rate: 0.000779 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8315/12542 | Batch Loss: 1.0899 | Learning Rate: 0.000779 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8316/12542 | Batch Loss: 1.7740 | Learning Rate: 0.000779 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8317/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8318/12542 | Batch Loss: 1.5268 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8319/12542 | Batch Loss: 1.2135 | Learning Rate: 0.000779 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8320/12542 | Batch Loss: 3.3241 | Learning Rate: 0.000779 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8321/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8322/12542 | Batch Loss: 0.7831 | Learning Rate: 0.000779 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8323/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8324/12542 | Batch Loss: 0.6864 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8325/12542 | Batch Loss: 0.7857 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8326/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8327/12542 | Batch Loss: 1.2794 | Learning Rate: 0.000779 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8328/12542 | Batch Loss: 1.0265 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8329/12542 | Batch Loss: 0.8792 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8330/12542 | Batch Loss: 1.3948 | Learning Rate: 0.000779 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8331/12542 | Batch Loss: 0.7937 | Learning Rate: 0.000779 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8332/12542 | Batch Loss: 1.8057 | Learning Rate: 0.000779 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8333/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000779 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8334/12542 | Batch Loss: 0.8980 | Learning Rate: 0.000779 | Batch Time: 2.13s\n",
      "Epoch 1 | Step 8335/12542 | Batch Loss: 2.9726 | Learning Rate: 0.000778 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8336/12542 | Batch Loss: 0.6977 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8337/12542 | Batch Loss: 0.6886 | Learning Rate: 0.000778 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8338/12542 | Batch Loss: 1.4977 | Learning Rate: 0.000778 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8339/12542 | Batch Loss: 1.4387 | Learning Rate: 0.000778 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8340/12542 | Batch Loss: 1.8683 | Learning Rate: 0.000778 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8341/12542 | Batch Loss: 2.1365 | Learning Rate: 0.000778 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8342/12542 | Batch Loss: 0.6238 | Learning Rate: 0.000778 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8343/12542 | Batch Loss: 1.8069 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8344/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000778 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8345/12542 | Batch Loss: 2.0371 | Learning Rate: 0.000778 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8346/12542 | Batch Loss: 0.9200 | Learning Rate: 0.000778 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8347/12542 | Batch Loss: 0.5201 | Learning Rate: 0.000778 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8348/12542 | Batch Loss: 1.6292 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8349/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8350/12542 | Batch Loss: 0.7981 | Learning Rate: 0.000778 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8351/12542 | Batch Loss: 1.9574 | Learning Rate: 0.000778 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8352/12542 | Batch Loss: 0.9183 | Learning Rate: 0.000778 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8353/12542 | Batch Loss: 0.7631 | Learning Rate: 0.000778 | Batch Time: 2.12s\n",
      "Epoch 1 | Step 8354/12542 | Batch Loss: 2.7902 | Learning Rate: 0.000778 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8355/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000778 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8356/12542 | Batch Loss: 0.6697 | Learning Rate: 0.000778 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8357/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000778 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8358/12542 | Batch Loss: 1.7227 | Learning Rate: 0.000778 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8359/12542 | Batch Loss: 2.1813 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8360/12542 | Batch Loss: 2.0120 | Learning Rate: 0.000778 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8361/12542 | Batch Loss: 2.5099 | Learning Rate: 0.000778 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8362/12542 | Batch Loss: 1.8479 | Learning Rate: 0.000778 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8363/12542 | Batch Loss: 1.7491 | Learning Rate: 0.000778 | Batch Time: 2.18s\n",
      "Epoch 1 | Step 8364/12542 | Batch Loss: 0.8080 | Learning Rate: 0.000778 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8365/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000778 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8366/12542 | Batch Loss: 1.6088 | Learning Rate: 0.000778 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8367/12542 | Batch Loss: 1.7595 | Learning Rate: 0.000778 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8368/12542 | Batch Loss: 2.3203 | Learning Rate: 0.000778 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8369/12542 | Batch Loss: 2.1196 | Learning Rate: 0.000778 | Batch Time: 1.95s\n",
      "Epoch 1 | Step 8370/12542 | Batch Loss: 1.1135 | Learning Rate: 0.000778 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8371/12542 | Batch Loss: 1.4164 | Learning Rate: 0.000778 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8372/12542 | Batch Loss: 3.2615 | Learning Rate: 0.000777 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8373/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000777 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8374/12542 | Batch Loss: 1.6738 | Learning Rate: 0.000777 | Batch Time: 2.02s\n",
      "Epoch 1 | Step 8375/12542 | Batch Loss: 1.8085 | Learning Rate: 0.000777 | Batch Time: 2.04s\n",
      "Epoch 1 | Step 8376/12542 | Batch Loss: 1.2154 | Learning Rate: 0.000777 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8377/12542 | Batch Loss: 1.2830 | Learning Rate: 0.000777 | Batch Time: 2.11s\n",
      "Epoch 1 | Step 8378/12542 | Batch Loss: 0.6569 | Learning Rate: 0.000777 | Batch Time: 2.03s\n",
      "Epoch 1 | Step 8379/12542 | Batch Loss: 1.0174 | Learning Rate: 0.000777 | Batch Time: 2.01s\n",
      "Epoch 1 | Step 8380/12542 | Batch Loss: 1.9549 | Learning Rate: 0.000777 | Batch Time: 2.09s\n",
      "Epoch 1 | Step 8381/12542 | Batch Loss: 2.5845 | Learning Rate: 0.000777 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8382/12542 | Batch Loss: 1.6852 | Learning Rate: 0.000777 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8383/12542 | Batch Loss: 2.2883 | Learning Rate: 0.000777 | Batch Time: 2.07s\n",
      "Epoch 1 | Step 8384/12542 | Batch Loss: 1.7429 | Learning Rate: 0.000777 | Batch Time: 2.08s\n",
      "Epoch 1 | Step 8385/12542 | Batch Loss: 0.9809 | Learning Rate: 0.000777 | Batch Time: 2.06s\n",
      "Epoch 1 | Step 8386/12542 | Batch Loss: 0.7605 | Learning Rate: 0.000777 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8387/12542 | Batch Loss: 0.5686 | Learning Rate: 0.000777 | Batch Time: 2.05s\n",
      "Epoch 1 | Step 8388/12542 | Batch Loss: 1.2572 | Learning Rate: 0.000777 | Batch Time: 2.10s\n",
      "Epoch 1 | Step 8389/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000777 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8390/12542 | Batch Loss: 1.8741 | Learning Rate: 0.000777 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8391/12542 | Batch Loss: 1.3387 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8392/12542 | Batch Loss: 1.4238 | Learning Rate: 0.000777 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8393/12542 | Batch Loss: 0.3705 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8394/12542 | Batch Loss: 1.4872 | Learning Rate: 0.000777 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8395/12542 | Batch Loss: 0.9624 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8396/12542 | Batch Loss: 1.2333 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8397/12542 | Batch Loss: 2.0159 | Learning Rate: 0.000777 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8398/12542 | Batch Loss: 1.5350 | Learning Rate: 0.000777 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8399/12542 | Batch Loss: 0.6282 | Learning Rate: 0.000777 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8400/12542 | Batch Loss: 2.9392 | Learning Rate: 0.000777 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8401/12542 | Batch Loss: 1.4627 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8402/12542 | Batch Loss: 1.2308 | Learning Rate: 0.000777 | Batch Time: 2.56s\n",
      "Epoch 1 | Step 8403/12542 | Batch Loss: 2.4835 | Learning Rate: 0.000777 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8404/12542 | Batch Loss: 1.0684 | Learning Rate: 0.000777 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8405/12542 | Batch Loss: 1.0539 | Learning Rate: 0.000777 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8406/12542 | Batch Loss: 2.0533 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8407/12542 | Batch Loss: 0.9934 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8408/12542 | Batch Loss: 2.2829 | Learning Rate: 0.000777 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8409/12542 | Batch Loss: 1.3300 | Learning Rate: 0.000777 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8410/12542 | Batch Loss: 3.8808 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8411/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8412/12542 | Batch Loss: 1.1408 | Learning Rate: 0.000776 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8413/12542 | Batch Loss: 1.1849 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8414/12542 | Batch Loss: 1.4786 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8415/12542 | Batch Loss: 1.3565 | Learning Rate: 0.000776 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8416/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8417/12542 | Batch Loss: 1.0131 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8418/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8419/12542 | Batch Loss: 4.3460 | Learning Rate: 0.000776 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8420/12542 | Batch Loss: 1.0879 | Learning Rate: 0.000776 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8421/12542 | Batch Loss: 2.8901 | Learning Rate: 0.000776 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 8422/12542 | Batch Loss: 1.1094 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8423/12542 | Batch Loss: 1.2506 | Learning Rate: 0.000776 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8424/12542 | Batch Loss: 1.4118 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8425/12542 | Batch Loss: 3.1628 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8426/12542 | Batch Loss: 0.6740 | Learning Rate: 0.000776 | Batch Time: 2.56s\n",
      "Epoch 1 | Step 8427/12542 | Batch Loss: 0.5956 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8428/12542 | Batch Loss: 0.9586 | Learning Rate: 0.000776 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8429/12542 | Batch Loss: 0.7511 | Learning Rate: 0.000776 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8430/12542 | Batch Loss: 1.6930 | Learning Rate: 0.000776 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8431/12542 | Batch Loss: 0.6973 | Learning Rate: 0.000776 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8432/12542 | Batch Loss: 1.0040 | Learning Rate: 0.000776 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8433/12542 | Batch Loss: 0.8192 | Learning Rate: 0.000776 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8434/12542 | Batch Loss: 2.0534 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8435/12542 | Batch Loss: 0.5593 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8436/12542 | Batch Loss: 1.3442 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8437/12542 | Batch Loss: 1.1152 | Learning Rate: 0.000776 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8438/12542 | Batch Loss: 1.0101 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8439/12542 | Batch Loss: 0.7792 | Learning Rate: 0.000776 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8440/12542 | Batch Loss: 1.3091 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8441/12542 | Batch Loss: 1.8253 | Learning Rate: 0.000776 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8442/12542 | Batch Loss: 1.1170 | Learning Rate: 0.000776 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8443/12542 | Batch Loss: 0.8698 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8444/12542 | Batch Loss: 1.7409 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8445/12542 | Batch Loss: 1.0702 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8446/12542 | Batch Loss: 2.0365 | Learning Rate: 0.000776 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8447/12542 | Batch Loss: 1.6652 | Learning Rate: 0.000776 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8448/12542 | Batch Loss: 1.3219 | Learning Rate: 0.000775 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8449/12542 | Batch Loss: 0.7910 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8450/12542 | Batch Loss: 0.7555 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8451/12542 | Batch Loss: 0.6001 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8452/12542 | Batch Loss: 0.6701 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8453/12542 | Batch Loss: 1.4084 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8454/12542 | Batch Loss: 1.0178 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8455/12542 | Batch Loss: 0.6404 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8456/12542 | Batch Loss: 0.9521 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8457/12542 | Batch Loss: 0.9322 | Learning Rate: 0.000775 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8458/12542 | Batch Loss: 2.0272 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8459/12542 | Batch Loss: 1.0153 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8460/12542 | Batch Loss: 0.8335 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8461/12542 | Batch Loss: 0.7655 | Learning Rate: 0.000775 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8462/12542 | Batch Loss: 0.8943 | Learning Rate: 0.000775 | Batch Time: 2.48s\n",
      "Epoch 1 | Step 8463/12542 | Batch Loss: 1.7373 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8464/12542 | Batch Loss: 1.6459 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8465/12542 | Batch Loss: 1.0581 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8466/12542 | Batch Loss: 1.1276 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8467/12542 | Batch Loss: 1.4019 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8468/12542 | Batch Loss: 0.9395 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8469/12542 | Batch Loss: 0.9545 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8470/12542 | Batch Loss: 0.4922 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8471/12542 | Batch Loss: 2.8035 | Learning Rate: 0.000775 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8472/12542 | Batch Loss: 2.0287 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8473/12542 | Batch Loss: 1.1679 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8474/12542 | Batch Loss: 0.8403 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8475/12542 | Batch Loss: 0.7698 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8476/12542 | Batch Loss: 2.6607 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8477/12542 | Batch Loss: 0.4816 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8478/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000775 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8479/12542 | Batch Loss: 0.9817 | Learning Rate: 0.000775 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8480/12542 | Batch Loss: 2.2174 | Learning Rate: 0.000775 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8481/12542 | Batch Loss: 4.2940 | Learning Rate: 0.000775 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8482/12542 | Batch Loss: 2.1639 | Learning Rate: 0.000775 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8483/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000775 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8484/12542 | Batch Loss: 1.6285 | Learning Rate: 0.000775 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8485/12542 | Batch Loss: 0.9273 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8486/12542 | Batch Loss: 1.6606 | Learning Rate: 0.000774 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8487/12542 | Batch Loss: 1.5795 | Learning Rate: 0.000774 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8488/12542 | Batch Loss: 1.4099 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8489/12542 | Batch Loss: 1.4163 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8490/12542 | Batch Loss: 2.1815 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8491/12542 | Batch Loss: 1.0823 | Learning Rate: 0.000774 | Batch Time: 2.47s\n",
      "Epoch 1 | Step 8492/12542 | Batch Loss: 1.3431 | Learning Rate: 0.000774 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8493/12542 | Batch Loss: 0.8927 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8494/12542 | Batch Loss: 2.9873 | Learning Rate: 0.000774 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8495/12542 | Batch Loss: 0.7132 | Learning Rate: 0.000774 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8496/12542 | Batch Loss: 1.7327 | Learning Rate: 0.000774 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8497/12542 | Batch Loss: 1.5214 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8498/12542 | Batch Loss: 2.1783 | Learning Rate: 0.000774 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8499/12542 | Batch Loss: 1.5886 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8500/12542 | Batch Loss: 0.9799 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8501/12542 | Batch Loss: 1.7335 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8502/12542 | Batch Loss: 1.1740 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8503/12542 | Batch Loss: 0.7064 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8504/12542 | Batch Loss: 0.8281 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8505/12542 | Batch Loss: 2.4439 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8506/12542 | Batch Loss: 1.7645 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8507/12542 | Batch Loss: 0.7183 | Learning Rate: 0.000774 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8508/12542 | Batch Loss: 0.5715 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8509/12542 | Batch Loss: 1.3246 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8510/12542 | Batch Loss: 1.1910 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8511/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8512/12542 | Batch Loss: 0.8469 | Learning Rate: 0.000774 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8513/12542 | Batch Loss: 1.0923 | Learning Rate: 0.000774 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8514/12542 | Batch Loss: 0.7919 | Learning Rate: 0.000774 | Batch Time: 2.45s\n",
      "Epoch 1 | Step 8515/12542 | Batch Loss: 2.2468 | Learning Rate: 0.000774 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8516/12542 | Batch Loss: 1.9015 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8517/12542 | Batch Loss: 0.4030 | Learning Rate: 0.000774 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8518/12542 | Batch Loss: 1.0340 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8519/12542 | Batch Loss: 0.8584 | Learning Rate: 0.000774 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8520/12542 | Batch Loss: 1.1928 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8521/12542 | Batch Loss: 0.8516 | Learning Rate: 0.000774 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8522/12542 | Batch Loss: 1.5497 | Learning Rate: 0.000774 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8523/12542 | Batch Loss: 1.4719 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8524/12542 | Batch Loss: 2.2231 | Learning Rate: 0.000773 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8525/12542 | Batch Loss: 1.4899 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8526/12542 | Batch Loss: 2.1273 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8527/12542 | Batch Loss: 1.3307 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8528/12542 | Batch Loss: 0.9763 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8529/12542 | Batch Loss: 1.6647 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8530/12542 | Batch Loss: 1.6294 | Learning Rate: 0.000773 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8531/12542 | Batch Loss: 1.8435 | Learning Rate: 0.000773 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8532/12542 | Batch Loss: 1.0421 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8533/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000773 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8534/12542 | Batch Loss: 1.7936 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8535/12542 | Batch Loss: 2.4538 | Learning Rate: 0.000773 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8536/12542 | Batch Loss: 1.9559 | Learning Rate: 0.000773 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8537/12542 | Batch Loss: 0.9023 | Learning Rate: 0.000773 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8538/12542 | Batch Loss: 0.7728 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8539/12542 | Batch Loss: 1.9532 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8540/12542 | Batch Loss: 2.6140 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8541/12542 | Batch Loss: 0.7305 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8542/12542 | Batch Loss: 0.8893 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8543/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8544/12542 | Batch Loss: 0.9092 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8545/12542 | Batch Loss: 1.2200 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8546/12542 | Batch Loss: 0.7634 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8547/12542 | Batch Loss: 0.6171 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8548/12542 | Batch Loss: 2.1255 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8549/12542 | Batch Loss: 2.5317 | Learning Rate: 0.000773 | Batch Time: 2.55s\n",
      "Epoch 1 | Step 8550/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8551/12542 | Batch Loss: 0.8838 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8552/12542 | Batch Loss: 0.6180 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8553/12542 | Batch Loss: 1.6406 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8554/12542 | Batch Loss: 2.1961 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8555/12542 | Batch Loss: 0.5848 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8556/12542 | Batch Loss: 0.3144 | Learning Rate: 0.000773 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8557/12542 | Batch Loss: 0.9308 | Learning Rate: 0.000773 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8558/12542 | Batch Loss: 1.1202 | Learning Rate: 0.000773 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8559/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000773 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8560/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8561/12542 | Batch Loss: 0.9203 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8562/12542 | Batch Loss: 1.6499 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8563/12542 | Batch Loss: 0.6795 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8564/12542 | Batch Loss: 1.3472 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8565/12542 | Batch Loss: 0.8858 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8566/12542 | Batch Loss: 1.0828 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8567/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8568/12542 | Batch Loss: 1.8913 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8569/12542 | Batch Loss: 0.6963 | Learning Rate: 0.000772 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8570/12542 | Batch Loss: 0.9671 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8571/12542 | Batch Loss: 1.3844 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8572/12542 | Batch Loss: 0.7319 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8573/12542 | Batch Loss: 1.9122 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8574/12542 | Batch Loss: 0.9846 | Learning Rate: 0.000772 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8575/12542 | Batch Loss: 1.3165 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8576/12542 | Batch Loss: 1.8475 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8577/12542 | Batch Loss: 0.7037 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8578/12542 | Batch Loss: 1.3404 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8579/12542 | Batch Loss: 2.3702 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8580/12542 | Batch Loss: 0.8803 | Learning Rate: 0.000772 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8581/12542 | Batch Loss: 1.5844 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8582/12542 | Batch Loss: 1.4293 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8583/12542 | Batch Loss: 1.2196 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8584/12542 | Batch Loss: 1.9620 | Learning Rate: 0.000772 | Batch Time: 2.48s\n",
      "Epoch 1 | Step 8585/12542 | Batch Loss: 1.9576 | Learning Rate: 0.000772 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8586/12542 | Batch Loss: 1.1845 | Learning Rate: 0.000772 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8587/12542 | Batch Loss: 1.1456 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8588/12542 | Batch Loss: 1.4687 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8589/12542 | Batch Loss: 1.6761 | Learning Rate: 0.000772 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8590/12542 | Batch Loss: 1.7431 | Learning Rate: 0.000772 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8591/12542 | Batch Loss: 1.8133 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8592/12542 | Batch Loss: 1.0825 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8593/12542 | Batch Loss: 0.8538 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8594/12542 | Batch Loss: 1.0768 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8595/12542 | Batch Loss: 1.9222 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8596/12542 | Batch Loss: 2.6783 | Learning Rate: 0.000772 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8597/12542 | Batch Loss: 1.7118 | Learning Rate: 0.000772 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8598/12542 | Batch Loss: 0.7954 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8599/12542 | Batch Loss: 1.4361 | Learning Rate: 0.000771 | Batch Time: 2.48s\n",
      "Epoch 1 | Step 8600/12542 | Batch Loss: 1.5562 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8601/12542 | Batch Loss: 0.8592 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8602/12542 | Batch Loss: 1.5144 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8603/12542 | Batch Loss: 1.4923 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8604/12542 | Batch Loss: 0.3431 | Learning Rate: 0.000771 | Batch Time: 2.49s\n",
      "Epoch 1 | Step 8605/12542 | Batch Loss: 1.8178 | Learning Rate: 0.000771 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8606/12542 | Batch Loss: 1.6181 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8607/12542 | Batch Loss: 0.8502 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8608/12542 | Batch Loss: 1.4618 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8609/12542 | Batch Loss: 0.9168 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8610/12542 | Batch Loss: 1.1550 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8611/12542 | Batch Loss: 1.4407 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8612/12542 | Batch Loss: 0.5193 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8613/12542 | Batch Loss: 0.5302 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8614/12542 | Batch Loss: 1.8603 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8615/12542 | Batch Loss: 1.1713 | Learning Rate: 0.000771 | Batch Time: 2.50s\n",
      "Epoch 1 | Step 8616/12542 | Batch Loss: 0.5081 | Learning Rate: 0.000771 | Batch Time: 2.51s\n",
      "Epoch 1 | Step 8617/12542 | Batch Loss: 0.6410 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8618/12542 | Batch Loss: 1.6635 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8619/12542 | Batch Loss: 3.0515 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8620/12542 | Batch Loss: 1.3131 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8621/12542 | Batch Loss: 2.1760 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8622/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8623/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8624/12542 | Batch Loss: 1.5756 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8625/12542 | Batch Loss: 0.6259 | Learning Rate: 0.000771 | Batch Time: 2.52s\n",
      "Epoch 1 | Step 8626/12542 | Batch Loss: 0.9399 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8627/12542 | Batch Loss: 1.5514 | Learning Rate: 0.000771 | Batch Time: 2.54s\n",
      "Epoch 1 | Step 8628/12542 | Batch Loss: 1.0792 | Learning Rate: 0.000771 | Batch Time: 2.63s\n",
      "Epoch 1 | Step 8629/12542 | Batch Loss: 1.0092 | Learning Rate: 0.000771 | Batch Time: 2.53s\n",
      "Epoch 1 | Step 8630/12542 | Batch Loss: 2.1722 | Learning Rate: 0.000771 | Batch Time: 504.83s\n",
      "Epoch 1 | Step 8631/12542 | Batch Loss: 1.7405 | Learning Rate: 0.000771 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8632/12542 | Batch Loss: 1.2925 | Learning Rate: 0.000771 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8633/12542 | Batch Loss: 1.0785 | Learning Rate: 0.000771 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8634/12542 | Batch Loss: 2.1950 | Learning Rate: 0.000771 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8635/12542 | Batch Loss: 2.5855 | Learning Rate: 0.000771 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8636/12542 | Batch Loss: 1.0522 | Learning Rate: 0.000770 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8637/12542 | Batch Loss: 1.1612 | Learning Rate: 0.000770 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8638/12542 | Batch Loss: 0.5778 | Learning Rate: 0.000770 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8639/12542 | Batch Loss: 0.5241 | Learning Rate: 0.000770 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8640/12542 | Batch Loss: 0.7806 | Learning Rate: 0.000770 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8641/12542 | Batch Loss: 2.0056 | Learning Rate: 0.000770 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8642/12542 | Batch Loss: 1.3888 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8643/12542 | Batch Loss: 1.4304 | Learning Rate: 0.000770 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8644/12542 | Batch Loss: 1.6709 | Learning Rate: 0.000770 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8645/12542 | Batch Loss: 1.3058 | Learning Rate: 0.000770 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8646/12542 | Batch Loss: 0.5347 | Learning Rate: 0.000770 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8647/12542 | Batch Loss: 0.8416 | Learning Rate: 0.000770 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 8648/12542 | Batch Loss: 0.9574 | Learning Rate: 0.000770 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8649/12542 | Batch Loss: 0.7404 | Learning Rate: 0.000770 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8650/12542 | Batch Loss: 0.5821 | Learning Rate: 0.000770 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8651/12542 | Batch Loss: 1.3407 | Learning Rate: 0.000770 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8652/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000770 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8653/12542 | Batch Loss: 0.9188 | Learning Rate: 0.000770 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8654/12542 | Batch Loss: 1.3130 | Learning Rate: 0.000770 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8655/12542 | Batch Loss: 1.6856 | Learning Rate: 0.000770 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8656/12542 | Batch Loss: 2.1285 | Learning Rate: 0.000770 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8657/12542 | Batch Loss: 0.6774 | Learning Rate: 0.000770 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8658/12542 | Batch Loss: 1.6877 | Learning Rate: 0.000770 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8659/12542 | Batch Loss: 0.7607 | Learning Rate: 0.000770 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8660/12542 | Batch Loss: 2.1831 | Learning Rate: 0.000770 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8661/12542 | Batch Loss: 1.3027 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8662/12542 | Batch Loss: 0.6754 | Learning Rate: 0.000770 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8663/12542 | Batch Loss: 1.0491 | Learning Rate: 0.000770 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8664/12542 | Batch Loss: 1.8199 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8665/12542 | Batch Loss: 2.2162 | Learning Rate: 0.000770 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8666/12542 | Batch Loss: 2.3229 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8667/12542 | Batch Loss: 1.6414 | Learning Rate: 0.000770 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8668/12542 | Batch Loss: 1.2165 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8669/12542 | Batch Loss: 0.8151 | Learning Rate: 0.000770 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8670/12542 | Batch Loss: 0.4865 | Learning Rate: 0.000770 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8671/12542 | Batch Loss: 1.0227 | Learning Rate: 0.000770 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8672/12542 | Batch Loss: 1.2828 | Learning Rate: 0.000770 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8673/12542 | Batch Loss: 0.7658 | Learning Rate: 0.000769 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8674/12542 | Batch Loss: 1.7151 | Learning Rate: 0.000769 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8675/12542 | Batch Loss: 2.6122 | Learning Rate: 0.000769 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8676/12542 | Batch Loss: 2.3524 | Learning Rate: 0.000769 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8677/12542 | Batch Loss: 1.4560 | Learning Rate: 0.000769 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8678/12542 | Batch Loss: 2.0301 | Learning Rate: 0.000769 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8679/12542 | Batch Loss: 0.6532 | Learning Rate: 0.000769 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8680/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000769 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8681/12542 | Batch Loss: 0.4225 | Learning Rate: 0.000769 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8682/12542 | Batch Loss: 1.7845 | Learning Rate: 0.000769 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8683/12542 | Batch Loss: 1.1875 | Learning Rate: 0.000769 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8684/12542 | Batch Loss: 1.8320 | Learning Rate: 0.000769 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8685/12542 | Batch Loss: 1.2875 | Learning Rate: 0.000769 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8686/12542 | Batch Loss: 0.4673 | Learning Rate: 0.000769 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8687/12542 | Batch Loss: 0.8063 | Learning Rate: 0.000769 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8688/12542 | Batch Loss: 1.0624 | Learning Rate: 0.000769 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8689/12542 | Batch Loss: 0.9956 | Learning Rate: 0.000769 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8690/12542 | Batch Loss: 1.8283 | Learning Rate: 0.000769 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8691/12542 | Batch Loss: 2.1315 | Learning Rate: 0.000769 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8692/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000769 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8693/12542 | Batch Loss: 0.5744 | Learning Rate: 0.000769 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8694/12542 | Batch Loss: 0.5746 | Learning Rate: 0.000769 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8695/12542 | Batch Loss: 1.1465 | Learning Rate: 0.000769 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8696/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000769 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8697/12542 | Batch Loss: 2.5543 | Learning Rate: 0.000769 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8698/12542 | Batch Loss: 1.7322 | Learning Rate: 0.000769 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8699/12542 | Batch Loss: 1.6651 | Learning Rate: 0.000769 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8700/12542 | Batch Loss: 0.7733 | Learning Rate: 0.000769 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8701/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000769 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8702/12542 | Batch Loss: 2.7398 | Learning Rate: 0.000769 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8703/12542 | Batch Loss: 1.8940 | Learning Rate: 0.000769 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8704/12542 | Batch Loss: 1.3286 | Learning Rate: 0.000769 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8705/12542 | Batch Loss: 1.8361 | Learning Rate: 0.000769 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8706/12542 | Batch Loss: 1.2083 | Learning Rate: 0.000769 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8707/12542 | Batch Loss: 1.0906 | Learning Rate: 0.000769 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8708/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000769 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8709/12542 | Batch Loss: 1.6436 | Learning Rate: 0.000769 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8710/12542 | Batch Loss: 1.2507 | Learning Rate: 0.000769 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8711/12542 | Batch Loss: 0.3488 | Learning Rate: 0.000768 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8712/12542 | Batch Loss: 1.2852 | Learning Rate: 0.000768 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8713/12542 | Batch Loss: 1.4658 | Learning Rate: 0.000768 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8714/12542 | Batch Loss: 1.4267 | Learning Rate: 0.000768 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8715/12542 | Batch Loss: 1.6639 | Learning Rate: 0.000768 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8716/12542 | Batch Loss: 1.5563 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8717/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000768 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8718/12542 | Batch Loss: 0.6796 | Learning Rate: 0.000768 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8719/12542 | Batch Loss: 1.7327 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8720/12542 | Batch Loss: 1.0725 | Learning Rate: 0.000768 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8721/12542 | Batch Loss: 0.8144 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8722/12542 | Batch Loss: 1.5708 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8723/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000768 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8724/12542 | Batch Loss: 0.9544 | Learning Rate: 0.000768 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8725/12542 | Batch Loss: 0.5153 | Learning Rate: 0.000768 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8726/12542 | Batch Loss: 0.8424 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8727/12542 | Batch Loss: 1.0789 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8728/12542 | Batch Loss: 1.9734 | Learning Rate: 0.000768 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8729/12542 | Batch Loss: 1.0912 | Learning Rate: 0.000768 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8730/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8731/12542 | Batch Loss: 2.4752 | Learning Rate: 0.000768 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 8732/12542 | Batch Loss: 1.7245 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8733/12542 | Batch Loss: 1.1990 | Learning Rate: 0.000768 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8734/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000768 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8735/12542 | Batch Loss: 1.4917 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8736/12542 | Batch Loss: 0.7763 | Learning Rate: 0.000768 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8737/12542 | Batch Loss: 0.3951 | Learning Rate: 0.000768 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8738/12542 | Batch Loss: 0.9710 | Learning Rate: 0.000768 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8739/12542 | Batch Loss: 1.1291 | Learning Rate: 0.000768 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8740/12542 | Batch Loss: 0.5124 | Learning Rate: 0.000768 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8741/12542 | Batch Loss: 2.1585 | Learning Rate: 0.000768 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8742/12542 | Batch Loss: 1.9702 | Learning Rate: 0.000768 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8743/12542 | Batch Loss: 0.9039 | Learning Rate: 0.000768 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8744/12542 | Batch Loss: 1.6059 | Learning Rate: 0.000768 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8745/12542 | Batch Loss: 2.2574 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8746/12542 | Batch Loss: 0.6053 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8747/12542 | Batch Loss: 1.3999 | Learning Rate: 0.000768 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8748/12542 | Batch Loss: 1.5014 | Learning Rate: 0.000768 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8749/12542 | Batch Loss: 3.1743 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8750/12542 | Batch Loss: 1.1131 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8751/12542 | Batch Loss: 1.7053 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8752/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8753/12542 | Batch Loss: 1.9366 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8754/12542 | Batch Loss: 1.7931 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8755/12542 | Batch Loss: 0.5968 | Learning Rate: 0.000767 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8756/12542 | Batch Loss: 1.3169 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8757/12542 | Batch Loss: 2.1769 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8758/12542 | Batch Loss: 1.3786 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8759/12542 | Batch Loss: 1.4506 | Learning Rate: 0.000767 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8760/12542 | Batch Loss: 1.0562 | Learning Rate: 0.000767 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8761/12542 | Batch Loss: 0.8843 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8762/12542 | Batch Loss: 1.9687 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8763/12542 | Batch Loss: 1.7456 | Learning Rate: 0.000767 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8764/12542 | Batch Loss: 2.2278 | Learning Rate: 0.000767 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8765/12542 | Batch Loss: 0.9429 | Learning Rate: 0.000767 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8766/12542 | Batch Loss: 1.5370 | Learning Rate: 0.000767 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8767/12542 | Batch Loss: 1.5065 | Learning Rate: 0.000767 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8768/12542 | Batch Loss: 0.7691 | Learning Rate: 0.000767 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8769/12542 | Batch Loss: 0.7129 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8770/12542 | Batch Loss: 0.9953 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8771/12542 | Batch Loss: 1.6894 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8772/12542 | Batch Loss: 0.7392 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8773/12542 | Batch Loss: 1.7660 | Learning Rate: 0.000767 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8774/12542 | Batch Loss: 1.6952 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8775/12542 | Batch Loss: 0.5303 | Learning Rate: 0.000767 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8776/12542 | Batch Loss: 0.9949 | Learning Rate: 0.000767 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8777/12542 | Batch Loss: 1.7320 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8778/12542 | Batch Loss: 1.2735 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8779/12542 | Batch Loss: 0.9173 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8780/12542 | Batch Loss: 1.4970 | Learning Rate: 0.000767 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8781/12542 | Batch Loss: 1.0836 | Learning Rate: 0.000767 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8782/12542 | Batch Loss: 1.2605 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8783/12542 | Batch Loss: 1.1537 | Learning Rate: 0.000767 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8784/12542 | Batch Loss: 0.8059 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8785/12542 | Batch Loss: 2.0174 | Learning Rate: 0.000767 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8786/12542 | Batch Loss: 1.1592 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8787/12542 | Batch Loss: 1.4417 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8788/12542 | Batch Loss: 1.2330 | Learning Rate: 0.000766 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8789/12542 | Batch Loss: 0.9180 | Learning Rate: 0.000766 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8790/12542 | Batch Loss: 0.7381 | Learning Rate: 0.000766 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8791/12542 | Batch Loss: 1.0593 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8792/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8793/12542 | Batch Loss: 2.7772 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8794/12542 | Batch Loss: 1.4525 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8795/12542 | Batch Loss: 2.0331 | Learning Rate: 0.000766 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8796/12542 | Batch Loss: 1.7610 | Learning Rate: 0.000766 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8797/12542 | Batch Loss: 1.5003 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8798/12542 | Batch Loss: 0.8311 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8799/12542 | Batch Loss: 1.6856 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8800/12542 | Batch Loss: 0.8121 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8801/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8802/12542 | Batch Loss: 0.7725 | Learning Rate: 0.000766 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8803/12542 | Batch Loss: 1.3907 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8804/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8805/12542 | Batch Loss: 0.6896 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8806/12542 | Batch Loss: 1.0195 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8807/12542 | Batch Loss: 0.8308 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8808/12542 | Batch Loss: 0.8939 | Learning Rate: 0.000766 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8809/12542 | Batch Loss: 0.7070 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8810/12542 | Batch Loss: 2.3976 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8811/12542 | Batch Loss: 1.5964 | Learning Rate: 0.000766 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8812/12542 | Batch Loss: 0.5856 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8813/12542 | Batch Loss: 3.2195 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8814/12542 | Batch Loss: 1.3887 | Learning Rate: 0.000766 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8815/12542 | Batch Loss: 1.3131 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8816/12542 | Batch Loss: 1.0437 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8817/12542 | Batch Loss: 1.7023 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8818/12542 | Batch Loss: 1.1971 | Learning Rate: 0.000766 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8819/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000766 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8820/12542 | Batch Loss: 1.5776 | Learning Rate: 0.000766 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8821/12542 | Batch Loss: 1.8512 | Learning Rate: 0.000766 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8822/12542 | Batch Loss: 0.6589 | Learning Rate: 0.000766 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8823/12542 | Batch Loss: 0.7165 | Learning Rate: 0.000766 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8824/12542 | Batch Loss: 0.6849 | Learning Rate: 0.000765 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8825/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000765 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8826/12542 | Batch Loss: 0.6254 | Learning Rate: 0.000765 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8827/12542 | Batch Loss: 1.6031 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8828/12542 | Batch Loss: 1.6238 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8829/12542 | Batch Loss: 1.5020 | Learning Rate: 0.000765 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8830/12542 | Batch Loss: 0.9699 | Learning Rate: 0.000765 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8831/12542 | Batch Loss: 2.0266 | Learning Rate: 0.000765 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8832/12542 | Batch Loss: 1.9312 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8833/12542 | Batch Loss: 2.0467 | Learning Rate: 0.000765 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8834/12542 | Batch Loss: 1.5797 | Learning Rate: 0.000765 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8835/12542 | Batch Loss: 2.2713 | Learning Rate: 0.000765 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8836/12542 | Batch Loss: 0.7569 | Learning Rate: 0.000765 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8837/12542 | Batch Loss: 1.3158 | Learning Rate: 0.000765 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8838/12542 | Batch Loss: 1.4143 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8839/12542 | Batch Loss: 1.4230 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8840/12542 | Batch Loss: 1.7126 | Learning Rate: 0.000765 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8841/12542 | Batch Loss: 1.4268 | Learning Rate: 0.000765 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8842/12542 | Batch Loss: 1.5676 | Learning Rate: 0.000765 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8843/12542 | Batch Loss: 1.9286 | Learning Rate: 0.000765 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8844/12542 | Batch Loss: 2.3880 | Learning Rate: 0.000765 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8845/12542 | Batch Loss: 1.4908 | Learning Rate: 0.000765 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8846/12542 | Batch Loss: 0.5329 | Learning Rate: 0.000765 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8847/12542 | Batch Loss: 2.0436 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8848/12542 | Batch Loss: 0.7226 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8849/12542 | Batch Loss: 0.9735 | Learning Rate: 0.000765 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8850/12542 | Batch Loss: 0.6787 | Learning Rate: 0.000765 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8851/12542 | Batch Loss: 2.9132 | Learning Rate: 0.000765 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8852/12542 | Batch Loss: 1.5928 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8853/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000765 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8854/12542 | Batch Loss: 0.7219 | Learning Rate: 0.000765 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8855/12542 | Batch Loss: 0.7012 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8856/12542 | Batch Loss: 2.9872 | Learning Rate: 0.000765 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8857/12542 | Batch Loss: 1.0442 | Learning Rate: 0.000765 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8858/12542 | Batch Loss: 1.1155 | Learning Rate: 0.000765 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8859/12542 | Batch Loss: 1.3763 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8860/12542 | Batch Loss: 1.5828 | Learning Rate: 0.000765 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8861/12542 | Batch Loss: 2.2367 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8862/12542 | Batch Loss: 1.3325 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8863/12542 | Batch Loss: 1.4377 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8864/12542 | Batch Loss: 2.3442 | Learning Rate: 0.000764 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8865/12542 | Batch Loss: 2.4685 | Learning Rate: 0.000764 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8866/12542 | Batch Loss: 1.2229 | Learning Rate: 0.000764 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8867/12542 | Batch Loss: 1.7545 | Learning Rate: 0.000764 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8868/12542 | Batch Loss: 1.1320 | Learning Rate: 0.000764 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8869/12542 | Batch Loss: 1.3628 | Learning Rate: 0.000764 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8870/12542 | Batch Loss: 1.0568 | Learning Rate: 0.000764 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8871/12542 | Batch Loss: 1.7306 | Learning Rate: 0.000764 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8872/12542 | Batch Loss: 1.3820 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8873/12542 | Batch Loss: 1.2456 | Learning Rate: 0.000764 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8874/12542 | Batch Loss: 0.7613 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8875/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8876/12542 | Batch Loss: 1.3203 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8877/12542 | Batch Loss: 1.2058 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8878/12542 | Batch Loss: 2.0729 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8879/12542 | Batch Loss: 1.5674 | Learning Rate: 0.000764 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8880/12542 | Batch Loss: 1.0175 | Learning Rate: 0.000764 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8881/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000764 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8882/12542 | Batch Loss: 0.8350 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8883/12542 | Batch Loss: 1.7866 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8884/12542 | Batch Loss: 1.3639 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8885/12542 | Batch Loss: 1.4020 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8886/12542 | Batch Loss: 1.0001 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8887/12542 | Batch Loss: 2.2061 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8888/12542 | Batch Loss: 1.0386 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8889/12542 | Batch Loss: 0.7491 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8890/12542 | Batch Loss: 1.5401 | Learning Rate: 0.000764 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8891/12542 | Batch Loss: 1.4558 | Learning Rate: 0.000764 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8892/12542 | Batch Loss: 1.7024 | Learning Rate: 0.000764 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8893/12542 | Batch Loss: 0.3803 | Learning Rate: 0.000764 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8894/12542 | Batch Loss: 2.2796 | Learning Rate: 0.000764 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8895/12542 | Batch Loss: 2.5792 | Learning Rate: 0.000764 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8896/12542 | Batch Loss: 1.5552 | Learning Rate: 0.000764 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8897/12542 | Batch Loss: 3.0734 | Learning Rate: 0.000764 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8898/12542 | Batch Loss: 2.0459 | Learning Rate: 0.000764 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8899/12542 | Batch Loss: 1.9509 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8900/12542 | Batch Loss: 1.3973 | Learning Rate: 0.000763 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8901/12542 | Batch Loss: 1.1168 | Learning Rate: 0.000763 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 8902/12542 | Batch Loss: 1.3647 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8903/12542 | Batch Loss: 1.5341 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8904/12542 | Batch Loss: 0.9518 | Learning Rate: 0.000763 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8905/12542 | Batch Loss: 1.0452 | Learning Rate: 0.000763 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8906/12542 | Batch Loss: 1.4742 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8907/12542 | Batch Loss: 2.3029 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8908/12542 | Batch Loss: 1.7872 | Learning Rate: 0.000763 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8909/12542 | Batch Loss: 1.2762 | Learning Rate: 0.000763 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8910/12542 | Batch Loss: 2.7267 | Learning Rate: 0.000763 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8911/12542 | Batch Loss: 0.3047 | Learning Rate: 0.000763 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8912/12542 | Batch Loss: 0.6415 | Learning Rate: 0.000763 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8913/12542 | Batch Loss: 0.7899 | Learning Rate: 0.000763 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8914/12542 | Batch Loss: 1.2329 | Learning Rate: 0.000763 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8915/12542 | Batch Loss: 2.3764 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8916/12542 | Batch Loss: 3.0855 | Learning Rate: 0.000763 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8917/12542 | Batch Loss: 2.1723 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8918/12542 | Batch Loss: 1.6361 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8919/12542 | Batch Loss: 1.0986 | Learning Rate: 0.000763 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8920/12542 | Batch Loss: 1.6940 | Learning Rate: 0.000763 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8921/12542 | Batch Loss: 0.7546 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8922/12542 | Batch Loss: 0.4793 | Learning Rate: 0.000763 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8923/12542 | Batch Loss: 2.0679 | Learning Rate: 0.000763 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8924/12542 | Batch Loss: 1.6644 | Learning Rate: 0.000763 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 8925/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8926/12542 | Batch Loss: 1.3455 | Learning Rate: 0.000763 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8927/12542 | Batch Loss: 0.8297 | Learning Rate: 0.000763 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8928/12542 | Batch Loss: 1.1749 | Learning Rate: 0.000763 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8929/12542 | Batch Loss: 0.7650 | Learning Rate: 0.000763 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8930/12542 | Batch Loss: 1.1406 | Learning Rate: 0.000763 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 8931/12542 | Batch Loss: 0.9421 | Learning Rate: 0.000763 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8932/12542 | Batch Loss: 1.5310 | Learning Rate: 0.000763 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8933/12542 | Batch Loss: 1.7808 | Learning Rate: 0.000763 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8934/12542 | Batch Loss: 0.5860 | Learning Rate: 0.000763 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8935/12542 | Batch Loss: 1.2657 | Learning Rate: 0.000763 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8936/12542 | Batch Loss: 2.7523 | Learning Rate: 0.000763 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8937/12542 | Batch Loss: 2.3720 | Learning Rate: 0.000762 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 8938/12542 | Batch Loss: 0.8617 | Learning Rate: 0.000762 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8939/12542 | Batch Loss: 1.1425 | Learning Rate: 0.000762 | Batch Time: 0.74s\n",
      "Epoch 1 | Step 8940/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000762 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8941/12542 | Batch Loss: 1.2651 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8942/12542 | Batch Loss: 0.6999 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8943/12542 | Batch Loss: 1.3681 | Learning Rate: 0.000762 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8944/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8945/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000762 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8946/12542 | Batch Loss: 2.2734 | Learning Rate: 0.000762 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8947/12542 | Batch Loss: 1.6708 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8948/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8949/12542 | Batch Loss: 0.8663 | Learning Rate: 0.000762 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8950/12542 | Batch Loss: 2.5085 | Learning Rate: 0.000762 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8951/12542 | Batch Loss: 1.1199 | Learning Rate: 0.000762 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8952/12542 | Batch Loss: 1.7636 | Learning Rate: 0.000762 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8953/12542 | Batch Loss: 1.0442 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8954/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000762 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8955/12542 | Batch Loss: 1.1151 | Learning Rate: 0.000762 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8956/12542 | Batch Loss: 1.4386 | Learning Rate: 0.000762 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8957/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000762 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 8958/12542 | Batch Loss: 2.4450 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8959/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000762 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8960/12542 | Batch Loss: 1.0666 | Learning Rate: 0.000762 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8961/12542 | Batch Loss: 1.6697 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8962/12542 | Batch Loss: 1.5251 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8963/12542 | Batch Loss: 1.7466 | Learning Rate: 0.000762 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8964/12542 | Batch Loss: 1.0528 | Learning Rate: 0.000762 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8965/12542 | Batch Loss: 1.0619 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8966/12542 | Batch Loss: 2.1541 | Learning Rate: 0.000762 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 8967/12542 | Batch Loss: 1.5715 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8968/12542 | Batch Loss: 0.7918 | Learning Rate: 0.000762 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8969/12542 | Batch Loss: 2.1405 | Learning Rate: 0.000762 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8970/12542 | Batch Loss: 1.2208 | Learning Rate: 0.000762 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 8971/12542 | Batch Loss: 0.9989 | Learning Rate: 0.000762 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 8972/12542 | Batch Loss: 2.1215 | Learning Rate: 0.000762 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 8973/12542 | Batch Loss: 1.4126 | Learning Rate: 0.000762 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8974/12542 | Batch Loss: 0.5843 | Learning Rate: 0.000761 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8975/12542 | Batch Loss: 0.7615 | Learning Rate: 0.000761 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 8976/12542 | Batch Loss: 1.1907 | Learning Rate: 0.000761 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8977/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8978/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000761 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 8979/12542 | Batch Loss: 0.4639 | Learning Rate: 0.000761 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8980/12542 | Batch Loss: 0.5068 | Learning Rate: 0.000761 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 8981/12542 | Batch Loss: 2.0304 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8982/12542 | Batch Loss: 1.0343 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8983/12542 | Batch Loss: 0.6754 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8984/12542 | Batch Loss: 1.3810 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8985/12542 | Batch Loss: 0.6272 | Learning Rate: 0.000761 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8986/12542 | Batch Loss: 1.5321 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8987/12542 | Batch Loss: 0.9307 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8988/12542 | Batch Loss: 1.7246 | Learning Rate: 0.000761 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 8989/12542 | Batch Loss: 3.2175 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8990/12542 | Batch Loss: 1.6800 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8991/12542 | Batch Loss: 1.8205 | Learning Rate: 0.000761 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 8992/12542 | Batch Loss: 0.7419 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8993/12542 | Batch Loss: 1.4281 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 8994/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000761 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 8995/12542 | Batch Loss: 1.4608 | Learning Rate: 0.000761 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8996/12542 | Batch Loss: 2.3399 | Learning Rate: 0.000761 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 8997/12542 | Batch Loss: 1.9256 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 8998/12542 | Batch Loss: 1.1230 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 8999/12542 | Batch Loss: 1.1097 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9000/12542 | Batch Loss: 2.3173 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9001/12542 | Batch Loss: 2.6532 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9002/12542 | Batch Loss: 1.6639 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9003/12542 | Batch Loss: 0.6021 | Learning Rate: 0.000761 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9004/12542 | Batch Loss: 1.2827 | Learning Rate: 0.000761 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9005/12542 | Batch Loss: 1.4117 | Learning Rate: 0.000761 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9006/12542 | Batch Loss: 1.1723 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9007/12542 | Batch Loss: 1.1627 | Learning Rate: 0.000761 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9008/12542 | Batch Loss: 0.8619 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9009/12542 | Batch Loss: 0.7725 | Learning Rate: 0.000761 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9010/12542 | Batch Loss: 2.6291 | Learning Rate: 0.000761 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9011/12542 | Batch Loss: 0.9379 | Learning Rate: 0.000761 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9012/12542 | Batch Loss: 1.7112 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9013/12542 | Batch Loss: 0.8382 | Learning Rate: 0.000760 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9014/12542 | Batch Loss: 0.8082 | Learning Rate: 0.000760 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9015/12542 | Batch Loss: 2.3349 | Learning Rate: 0.000760 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9016/12542 | Batch Loss: 1.7503 | Learning Rate: 0.000760 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9017/12542 | Batch Loss: 1.6772 | Learning Rate: 0.000760 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9018/12542 | Batch Loss: 2.5243 | Learning Rate: 0.000760 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9019/12542 | Batch Loss: 2.1320 | Learning Rate: 0.000760 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9020/12542 | Batch Loss: 1.9355 | Learning Rate: 0.000760 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9021/12542 | Batch Loss: 1.5899 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9022/12542 | Batch Loss: 1.5564 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9023/12542 | Batch Loss: 0.8140 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9024/12542 | Batch Loss: 1.4669 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9025/12542 | Batch Loss: 1.3660 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9026/12542 | Batch Loss: 1.2622 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9027/12542 | Batch Loss: 0.6024 | Learning Rate: 0.000760 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9028/12542 | Batch Loss: 0.6570 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9029/12542 | Batch Loss: 0.9641 | Learning Rate: 0.000760 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9030/12542 | Batch Loss: 2.8412 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9031/12542 | Batch Loss: 0.5488 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9032/12542 | Batch Loss: 0.8122 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9033/12542 | Batch Loss: 1.5846 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9034/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9035/12542 | Batch Loss: 0.4309 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9036/12542 | Batch Loss: 1.4960 | Learning Rate: 0.000760 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9037/12542 | Batch Loss: 0.6071 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9038/12542 | Batch Loss: 1.7134 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9039/12542 | Batch Loss: 1.0410 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9040/12542 | Batch Loss: 1.1131 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9041/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9042/12542 | Batch Loss: 1.5509 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9043/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9044/12542 | Batch Loss: 0.9962 | Learning Rate: 0.000760 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9045/12542 | Batch Loss: 0.4627 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9046/12542 | Batch Loss: 1.0547 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9047/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000760 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9048/12542 | Batch Loss: 2.7314 | Learning Rate: 0.000760 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9049/12542 | Batch Loss: 0.8551 | Learning Rate: 0.000760 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9050/12542 | Batch Loss: 1.3458 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9051/12542 | Batch Loss: 1.6351 | Learning Rate: 0.000759 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9052/12542 | Batch Loss: 1.2889 | Learning Rate: 0.000759 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9053/12542 | Batch Loss: 1.3234 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9054/12542 | Batch Loss: 2.0482 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9055/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9056/12542 | Batch Loss: 0.9916 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9057/12542 | Batch Loss: 0.8468 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9058/12542 | Batch Loss: 0.9789 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9059/12542 | Batch Loss: 0.8418 | Learning Rate: 0.000759 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9060/12542 | Batch Loss: 0.8874 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9061/12542 | Batch Loss: 1.4168 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9062/12542 | Batch Loss: 2.7489 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9063/12542 | Batch Loss: 1.1667 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9064/12542 | Batch Loss: 1.0477 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9065/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9066/12542 | Batch Loss: 0.8470 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9067/12542 | Batch Loss: 1.6077 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9068/12542 | Batch Loss: 1.6219 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9069/12542 | Batch Loss: 1.8248 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9070/12542 | Batch Loss: 0.7403 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9071/12542 | Batch Loss: 1.8109 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9072/12542 | Batch Loss: 1.4266 | Learning Rate: 0.000759 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9073/12542 | Batch Loss: 0.7994 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9074/12542 | Batch Loss: 0.7888 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9075/12542 | Batch Loss: 1.9451 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9076/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9077/12542 | Batch Loss: 1.4148 | Learning Rate: 0.000759 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9078/12542 | Batch Loss: 1.6308 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9079/12542 | Batch Loss: 1.1714 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9080/12542 | Batch Loss: 0.6018 | Learning Rate: 0.000759 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9081/12542 | Batch Loss: 1.1275 | Learning Rate: 0.000759 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9082/12542 | Batch Loss: 0.5501 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9083/12542 | Batch Loss: 1.6568 | Learning Rate: 0.000759 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9084/12542 | Batch Loss: 0.6970 | Learning Rate: 0.000759 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9085/12542 | Batch Loss: 0.9268 | Learning Rate: 0.000759 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9086/12542 | Batch Loss: 0.8442 | Learning Rate: 0.000759 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9087/12542 | Batch Loss: 0.9771 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9088/12542 | Batch Loss: 0.9450 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9089/12542 | Batch Loss: 1.7566 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9090/12542 | Batch Loss: 2.0039 | Learning Rate: 0.000758 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9091/12542 | Batch Loss: 2.3022 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9092/12542 | Batch Loss: 1.0773 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9093/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000758 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9094/12542 | Batch Loss: 1.8579 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9095/12542 | Batch Loss: 0.6145 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9096/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9097/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000758 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9098/12542 | Batch Loss: 0.7229 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9099/12542 | Batch Loss: 0.8983 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9100/12542 | Batch Loss: 1.3283 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9101/12542 | Batch Loss: 0.5515 | Learning Rate: 0.000758 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9102/12542 | Batch Loss: 2.6355 | Learning Rate: 0.000758 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9103/12542 | Batch Loss: 0.5316 | Learning Rate: 0.000758 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9104/12542 | Batch Loss: 1.0269 | Learning Rate: 0.000758 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9105/12542 | Batch Loss: 2.4949 | Learning Rate: 0.000758 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9106/12542 | Batch Loss: 1.5787 | Learning Rate: 0.000758 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9107/12542 | Batch Loss: 0.5546 | Learning Rate: 0.000758 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9108/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9109/12542 | Batch Loss: 0.8774 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9110/12542 | Batch Loss: 1.1334 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9111/12542 | Batch Loss: 1.0829 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9112/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9113/12542 | Batch Loss: 1.3554 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9114/12542 | Batch Loss: 1.1648 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9115/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000758 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9116/12542 | Batch Loss: 1.8068 | Learning Rate: 0.000758 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9117/12542 | Batch Loss: 1.4336 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9118/12542 | Batch Loss: 0.4081 | Learning Rate: 0.000758 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9119/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000758 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9120/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000758 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9121/12542 | Batch Loss: 1.7659 | Learning Rate: 0.000758 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9122/12542 | Batch Loss: 2.2122 | Learning Rate: 0.000758 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9123/12542 | Batch Loss: 0.9917 | Learning Rate: 0.000758 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9124/12542 | Batch Loss: 1.5385 | Learning Rate: 0.000758 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9125/12542 | Batch Loss: 1.8179 | Learning Rate: 0.000757 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9126/12542 | Batch Loss: 0.9745 | Learning Rate: 0.000757 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9127/12542 | Batch Loss: 2.2813 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9128/12542 | Batch Loss: 1.4793 | Learning Rate: 0.000757 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9129/12542 | Batch Loss: 0.9825 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9130/12542 | Batch Loss: 1.4659 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9131/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000757 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9132/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9133/12542 | Batch Loss: 1.7944 | Learning Rate: 0.000757 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9134/12542 | Batch Loss: 1.4037 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9135/12542 | Batch Loss: 1.8023 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9136/12542 | Batch Loss: 1.1446 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9137/12542 | Batch Loss: 0.8325 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9138/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000757 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9139/12542 | Batch Loss: 2.4257 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9140/12542 | Batch Loss: 1.4057 | Learning Rate: 0.000757 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9141/12542 | Batch Loss: 0.7619 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9142/12542 | Batch Loss: 0.9180 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9143/12542 | Batch Loss: 4.0166 | Learning Rate: 0.000757 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9144/12542 | Batch Loss: 1.4913 | Learning Rate: 0.000757 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9145/12542 | Batch Loss: 1.8243 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9146/12542 | Batch Loss: 1.2397 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9147/12542 | Batch Loss: 1.0257 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9148/12542 | Batch Loss: 0.5581 | Learning Rate: 0.000757 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9149/12542 | Batch Loss: 0.8931 | Learning Rate: 0.000757 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9150/12542 | Batch Loss: 2.0668 | Learning Rate: 0.000757 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9151/12542 | Batch Loss: 1.3799 | Learning Rate: 0.000757 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9152/12542 | Batch Loss: 1.0711 | Learning Rate: 0.000757 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9153/12542 | Batch Loss: 1.1061 | Learning Rate: 0.000757 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9154/12542 | Batch Loss: 1.0818 | Learning Rate: 0.000757 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9155/12542 | Batch Loss: 0.8391 | Learning Rate: 0.000757 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9156/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000757 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9157/12542 | Batch Loss: 0.6049 | Learning Rate: 0.000757 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9158/12542 | Batch Loss: 0.7501 | Learning Rate: 0.000757 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9159/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000757 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9160/12542 | Batch Loss: 1.3221 | Learning Rate: 0.000757 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9161/12542 | Batch Loss: 1.4123 | Learning Rate: 0.000757 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9162/12542 | Batch Loss: 1.3492 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9163/12542 | Batch Loss: 0.5665 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9164/12542 | Batch Loss: 0.8817 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9165/12542 | Batch Loss: 1.0460 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9166/12542 | Batch Loss: 1.0025 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9167/12542 | Batch Loss: 1.3872 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9168/12542 | Batch Loss: 2.3398 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9169/12542 | Batch Loss: 1.3182 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9170/12542 | Batch Loss: 0.8678 | Learning Rate: 0.000756 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9171/12542 | Batch Loss: 3.1770 | Learning Rate: 0.000756 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 9172/12542 | Batch Loss: 1.1757 | Learning Rate: 0.000756 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9173/12542 | Batch Loss: 2.0952 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9174/12542 | Batch Loss: 1.7156 | Learning Rate: 0.000756 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9175/12542 | Batch Loss: 1.1265 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9176/12542 | Batch Loss: 0.8176 | Learning Rate: 0.000756 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9177/12542 | Batch Loss: 1.5805 | Learning Rate: 0.000756 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9178/12542 | Batch Loss: 1.5184 | Learning Rate: 0.000756 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9179/12542 | Batch Loss: 0.5168 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9180/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9181/12542 | Batch Loss: 1.9153 | Learning Rate: 0.000756 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9182/12542 | Batch Loss: 1.0127 | Learning Rate: 0.000756 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9183/12542 | Batch Loss: 1.2375 | Learning Rate: 0.000756 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9184/12542 | Batch Loss: 0.9568 | Learning Rate: 0.000756 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9185/12542 | Batch Loss: 1.2045 | Learning Rate: 0.000756 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9186/12542 | Batch Loss: 0.7553 | Learning Rate: 0.000756 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9187/12542 | Batch Loss: 1.4462 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9188/12542 | Batch Loss: 1.5878 | Learning Rate: 0.000756 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9189/12542 | Batch Loss: 1.9562 | Learning Rate: 0.000756 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9190/12542 | Batch Loss: 3.0324 | Learning Rate: 0.000756 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9191/12542 | Batch Loss: 2.8512 | Learning Rate: 0.000756 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9192/12542 | Batch Loss: 1.6536 | Learning Rate: 0.000756 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9193/12542 | Batch Loss: 0.8229 | Learning Rate: 0.000756 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9194/12542 | Batch Loss: 1.3739 | Learning Rate: 0.000756 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9195/12542 | Batch Loss: 2.2517 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9196/12542 | Batch Loss: 1.7888 | Learning Rate: 0.000756 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9197/12542 | Batch Loss: 1.2138 | Learning Rate: 0.000756 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9198/12542 | Batch Loss: 0.5027 | Learning Rate: 0.000756 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9199/12542 | Batch Loss: 2.7965 | Learning Rate: 0.000756 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9200/12542 | Batch Loss: 1.9459 | Learning Rate: 0.000755 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9201/12542 | Batch Loss: 1.6169 | Learning Rate: 0.000755 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9202/12542 | Batch Loss: 1.0658 | Learning Rate: 0.000755 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9203/12542 | Batch Loss: 1.3868 | Learning Rate: 0.000755 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9204/12542 | Batch Loss: 1.4554 | Learning Rate: 0.000755 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9205/12542 | Batch Loss: 1.4124 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9206/12542 | Batch Loss: 1.6970 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9207/12542 | Batch Loss: 2.6586 | Learning Rate: 0.000755 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9208/12542 | Batch Loss: 1.7542 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9209/12542 | Batch Loss: 1.6660 | Learning Rate: 0.000755 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9210/12542 | Batch Loss: 1.8752 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9211/12542 | Batch Loss: 1.3843 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9212/12542 | Batch Loss: 1.3763 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9213/12542 | Batch Loss: 0.6868 | Learning Rate: 0.000755 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9214/12542 | Batch Loss: 0.5795 | Learning Rate: 0.000755 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9215/12542 | Batch Loss: 1.1761 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9216/12542 | Batch Loss: 0.8287 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9217/12542 | Batch Loss: 1.1114 | Learning Rate: 0.000755 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9218/12542 | Batch Loss: 0.6600 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9219/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000755 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9220/12542 | Batch Loss: 0.9679 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9221/12542 | Batch Loss: 1.5794 | Learning Rate: 0.000755 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9222/12542 | Batch Loss: 2.5021 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9223/12542 | Batch Loss: 1.0627 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9224/12542 | Batch Loss: 1.1532 | Learning Rate: 0.000755 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9225/12542 | Batch Loss: 1.4683 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9226/12542 | Batch Loss: 2.3939 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9227/12542 | Batch Loss: 0.6366 | Learning Rate: 0.000755 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9228/12542 | Batch Loss: 1.0356 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9229/12542 | Batch Loss: 1.5303 | Learning Rate: 0.000755 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9230/12542 | Batch Loss: 1.4490 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9231/12542 | Batch Loss: 1.6249 | Learning Rate: 0.000755 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9232/12542 | Batch Loss: 0.9285 | Learning Rate: 0.000755 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9233/12542 | Batch Loss: 0.6447 | Learning Rate: 0.000755 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9234/12542 | Batch Loss: 0.7914 | Learning Rate: 0.000755 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9235/12542 | Batch Loss: 1.5828 | Learning Rate: 0.000755 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9236/12542 | Batch Loss: 1.7103 | Learning Rate: 0.000755 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9237/12542 | Batch Loss: 0.9800 | Learning Rate: 0.000755 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9238/12542 | Batch Loss: 0.7174 | Learning Rate: 0.000754 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9239/12542 | Batch Loss: 0.8912 | Learning Rate: 0.000754 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9240/12542 | Batch Loss: 0.8611 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9241/12542 | Batch Loss: 1.4108 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9242/12542 | Batch Loss: 2.6372 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9243/12542 | Batch Loss: 0.8023 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9244/12542 | Batch Loss: 0.9612 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9245/12542 | Batch Loss: 2.5440 | Learning Rate: 0.000754 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9246/12542 | Batch Loss: 1.5806 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9247/12542 | Batch Loss: 1.2583 | Learning Rate: 0.000754 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9248/12542 | Batch Loss: 1.1397 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9249/12542 | Batch Loss: 0.8910 | Learning Rate: 0.000754 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9250/12542 | Batch Loss: 1.0051 | Learning Rate: 0.000754 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9251/12542 | Batch Loss: 1.0090 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9252/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000754 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9253/12542 | Batch Loss: 1.2175 | Learning Rate: 0.000754 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9254/12542 | Batch Loss: 0.7810 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9255/12542 | Batch Loss: 1.3624 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9256/12542 | Batch Loss: 0.7376 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9257/12542 | Batch Loss: 2.4457 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9258/12542 | Batch Loss: 1.4898 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9259/12542 | Batch Loss: 1.4303 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9260/12542 | Batch Loss: 1.9144 | Learning Rate: 0.000754 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9261/12542 | Batch Loss: 1.6233 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9262/12542 | Batch Loss: 0.8056 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9263/12542 | Batch Loss: 1.3214 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9264/12542 | Batch Loss: 1.7437 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9265/12542 | Batch Loss: 1.4821 | Learning Rate: 0.000754 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9266/12542 | Batch Loss: 1.2604 | Learning Rate: 0.000754 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9267/12542 | Batch Loss: 0.8563 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9268/12542 | Batch Loss: 1.7874 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9269/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9270/12542 | Batch Loss: 1.7191 | Learning Rate: 0.000754 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9271/12542 | Batch Loss: 1.2784 | Learning Rate: 0.000754 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9272/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000754 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9273/12542 | Batch Loss: 0.7572 | Learning Rate: 0.000754 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9274/12542 | Batch Loss: 0.6607 | Learning Rate: 0.000754 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9275/12542 | Batch Loss: 1.5591 | Learning Rate: 0.000753 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9276/12542 | Batch Loss: 0.9939 | Learning Rate: 0.000753 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9277/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9278/12542 | Batch Loss: 1.6971 | Learning Rate: 0.000753 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9279/12542 | Batch Loss: 1.4525 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9280/12542 | Batch Loss: 1.4002 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9281/12542 | Batch Loss: 1.0018 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9282/12542 | Batch Loss: 1.1868 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9283/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9284/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000753 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9285/12542 | Batch Loss: 1.5179 | Learning Rate: 0.000753 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9286/12542 | Batch Loss: 1.1370 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9287/12542 | Batch Loss: 1.8280 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9288/12542 | Batch Loss: 1.2058 | Learning Rate: 0.000753 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9289/12542 | Batch Loss: 1.8721 | Learning Rate: 0.000753 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9290/12542 | Batch Loss: 1.3502 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9291/12542 | Batch Loss: 1.3013 | Learning Rate: 0.000753 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9292/12542 | Batch Loss: 1.4306 | Learning Rate: 0.000753 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9293/12542 | Batch Loss: 0.6975 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9294/12542 | Batch Loss: 0.9736 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9295/12542 | Batch Loss: 0.9195 | Learning Rate: 0.000753 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9296/12542 | Batch Loss: 1.7291 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9297/12542 | Batch Loss: 1.2024 | Learning Rate: 0.000753 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9298/12542 | Batch Loss: 0.8337 | Learning Rate: 0.000753 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9299/12542 | Batch Loss: 1.6161 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9300/12542 | Batch Loss: 1.1243 | Learning Rate: 0.000753 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9301/12542 | Batch Loss: 0.7929 | Learning Rate: 0.000753 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9302/12542 | Batch Loss: 1.5250 | Learning Rate: 0.000753 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9303/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000753 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9304/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000753 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9305/12542 | Batch Loss: 0.9380 | Learning Rate: 0.000753 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9306/12542 | Batch Loss: 1.0448 | Learning Rate: 0.000753 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9307/12542 | Batch Loss: 0.3765 | Learning Rate: 0.000753 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9308/12542 | Batch Loss: 0.6514 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9309/12542 | Batch Loss: 1.0587 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9310/12542 | Batch Loss: 0.7085 | Learning Rate: 0.000753 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9311/12542 | Batch Loss: 2.3436 | Learning Rate: 0.000753 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9312/12542 | Batch Loss: 1.4637 | Learning Rate: 0.000753 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9313/12542 | Batch Loss: 1.4067 | Learning Rate: 0.000752 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9314/12542 | Batch Loss: 0.7927 | Learning Rate: 0.000752 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9315/12542 | Batch Loss: 1.4291 | Learning Rate: 0.000752 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9316/12542 | Batch Loss: 1.4313 | Learning Rate: 0.000752 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9317/12542 | Batch Loss: 1.2363 | Learning Rate: 0.000752 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9318/12542 | Batch Loss: 2.6825 | Learning Rate: 0.000752 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9319/12542 | Batch Loss: 1.4635 | Learning Rate: 0.000752 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9320/12542 | Batch Loss: 1.1045 | Learning Rate: 0.000752 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9321/12542 | Batch Loss: 1.6637 | Learning Rate: 0.000752 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9322/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000752 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9323/12542 | Batch Loss: 1.6881 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9324/12542 | Batch Loss: 1.6086 | Learning Rate: 0.000752 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9325/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000752 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9326/12542 | Batch Loss: 1.0149 | Learning Rate: 0.000752 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9327/12542 | Batch Loss: 2.2028 | Learning Rate: 0.000752 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9328/12542 | Batch Loss: 0.6628 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9329/12542 | Batch Loss: 1.4386 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9330/12542 | Batch Loss: 1.2274 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9331/12542 | Batch Loss: 1.7591 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9332/12542 | Batch Loss: 1.5591 | Learning Rate: 0.000752 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9333/12542 | Batch Loss: 1.4281 | Learning Rate: 0.000752 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9334/12542 | Batch Loss: 1.3788 | Learning Rate: 0.000752 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9335/12542 | Batch Loss: 0.9005 | Learning Rate: 0.000752 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9336/12542 | Batch Loss: 1.2017 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9337/12542 | Batch Loss: 1.1246 | Learning Rate: 0.000752 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9338/12542 | Batch Loss: 0.8122 | Learning Rate: 0.000752 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9339/12542 | Batch Loss: 1.4423 | Learning Rate: 0.000752 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9340/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000752 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9341/12542 | Batch Loss: 0.9597 | Learning Rate: 0.000752 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9342/12542 | Batch Loss: 0.6535 | Learning Rate: 0.000752 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9343/12542 | Batch Loss: 0.6803 | Learning Rate: 0.000752 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9344/12542 | Batch Loss: 1.1441 | Learning Rate: 0.000752 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9345/12542 | Batch Loss: 0.7577 | Learning Rate: 0.000752 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9346/12542 | Batch Loss: 1.3371 | Learning Rate: 0.000752 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9347/12542 | Batch Loss: 0.9404 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9348/12542 | Batch Loss: 1.2208 | Learning Rate: 0.000752 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9349/12542 | Batch Loss: 0.7092 | Learning Rate: 0.000752 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9350/12542 | Batch Loss: 2.1356 | Learning Rate: 0.000752 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9351/12542 | Batch Loss: 1.4762 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9352/12542 | Batch Loss: 1.2430 | Learning Rate: 0.000751 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9353/12542 | Batch Loss: 0.7215 | Learning Rate: 0.000751 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9354/12542 | Batch Loss: 1.6633 | Learning Rate: 0.000751 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9355/12542 | Batch Loss: 0.6090 | Learning Rate: 0.000751 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9356/12542 | Batch Loss: 1.3634 | Learning Rate: 0.000751 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9357/12542 | Batch Loss: 0.9168 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9358/12542 | Batch Loss: 1.4590 | Learning Rate: 0.000751 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9359/12542 | Batch Loss: 2.1008 | Learning Rate: 0.000751 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9360/12542 | Batch Loss: 1.1773 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9361/12542 | Batch Loss: 0.8263 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9362/12542 | Batch Loss: 1.9602 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9363/12542 | Batch Loss: 3.2198 | Learning Rate: 0.000751 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9364/12542 | Batch Loss: 1.4208 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9365/12542 | Batch Loss: 0.5400 | Learning Rate: 0.000751 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9366/12542 | Batch Loss: 1.1359 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9367/12542 | Batch Loss: 1.0427 | Learning Rate: 0.000751 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9368/12542 | Batch Loss: 2.0539 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9369/12542 | Batch Loss: 1.5539 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9370/12542 | Batch Loss: 1.6062 | Learning Rate: 0.000751 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9371/12542 | Batch Loss: 0.6892 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9372/12542 | Batch Loss: 1.8863 | Learning Rate: 0.000751 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9373/12542 | Batch Loss: 3.6014 | Learning Rate: 0.000751 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9374/12542 | Batch Loss: 0.8328 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9375/12542 | Batch Loss: 0.5883 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9376/12542 | Batch Loss: 0.7850 | Learning Rate: 0.000751 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9377/12542 | Batch Loss: 0.9084 | Learning Rate: 0.000751 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9378/12542 | Batch Loss: 0.8847 | Learning Rate: 0.000751 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9379/12542 | Batch Loss: 0.8444 | Learning Rate: 0.000751 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9380/12542 | Batch Loss: 1.5322 | Learning Rate: 0.000751 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9381/12542 | Batch Loss: 1.4553 | Learning Rate: 0.000751 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9382/12542 | Batch Loss: 0.8991 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9383/12542 | Batch Loss: 1.8649 | Learning Rate: 0.000751 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9384/12542 | Batch Loss: 1.0743 | Learning Rate: 0.000751 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9385/12542 | Batch Loss: 3.3975 | Learning Rate: 0.000751 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9386/12542 | Batch Loss: 1.1572 | Learning Rate: 0.000751 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9387/12542 | Batch Loss: 1.8332 | Learning Rate: 0.000751 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9388/12542 | Batch Loss: 0.7464 | Learning Rate: 0.000750 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9389/12542 | Batch Loss: 1.6577 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9390/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9391/12542 | Batch Loss: 1.7225 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9392/12542 | Batch Loss: 1.5559 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9393/12542 | Batch Loss: 0.7297 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9394/12542 | Batch Loss: 0.8351 | Learning Rate: 0.000750 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9395/12542 | Batch Loss: 0.7297 | Learning Rate: 0.000750 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9396/12542 | Batch Loss: 0.9226 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9397/12542 | Batch Loss: 2.1614 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9398/12542 | Batch Loss: 1.3303 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9399/12542 | Batch Loss: 1.6013 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9400/12542 | Batch Loss: 0.8999 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9401/12542 | Batch Loss: 0.8834 | Learning Rate: 0.000750 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9402/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9403/12542 | Batch Loss: 0.6089 | Learning Rate: 0.000750 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9404/12542 | Batch Loss: 1.1149 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9405/12542 | Batch Loss: 1.2239 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9406/12542 | Batch Loss: 1.3639 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9407/12542 | Batch Loss: 0.8477 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9408/12542 | Batch Loss: 1.1674 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9409/12542 | Batch Loss: 2.4463 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9410/12542 | Batch Loss: 0.8024 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9411/12542 | Batch Loss: 1.9194 | Learning Rate: 0.000750 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9412/12542 | Batch Loss: 1.9288 | Learning Rate: 0.000750 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9413/12542 | Batch Loss: 0.5472 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9414/12542 | Batch Loss: 2.0230 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9415/12542 | Batch Loss: 0.5925 | Learning Rate: 0.000750 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9416/12542 | Batch Loss: 2.4207 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9417/12542 | Batch Loss: 1.3668 | Learning Rate: 0.000750 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9418/12542 | Batch Loss: 1.1634 | Learning Rate: 0.000750 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9419/12542 | Batch Loss: 0.6928 | Learning Rate: 0.000750 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9420/12542 | Batch Loss: 0.5640 | Learning Rate: 0.000750 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9421/12542 | Batch Loss: 0.7608 | Learning Rate: 0.000750 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9422/12542 | Batch Loss: 0.6220 | Learning Rate: 0.000750 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9423/12542 | Batch Loss: 1.2338 | Learning Rate: 0.000750 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9424/12542 | Batch Loss: 2.0042 | Learning Rate: 0.000750 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9425/12542 | Batch Loss: 2.0996 | Learning Rate: 0.000750 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9426/12542 | Batch Loss: 1.6699 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9427/12542 | Batch Loss: 2.4294 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9428/12542 | Batch Loss: 1.4904 | Learning Rate: 0.000749 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9429/12542 | Batch Loss: 2.1569 | Learning Rate: 0.000749 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9430/12542 | Batch Loss: 0.8595 | Learning Rate: 0.000749 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9431/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9432/12542 | Batch Loss: 1.4089 | Learning Rate: 0.000749 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9433/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000749 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9434/12542 | Batch Loss: 0.6761 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9435/12542 | Batch Loss: 2.4805 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9436/12542 | Batch Loss: 1.0209 | Learning Rate: 0.000749 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9437/12542 | Batch Loss: 2.8661 | Learning Rate: 0.000749 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9438/12542 | Batch Loss: 1.4029 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9439/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000749 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9440/12542 | Batch Loss: 0.8967 | Learning Rate: 0.000749 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9441/12542 | Batch Loss: 0.8818 | Learning Rate: 0.000749 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9442/12542 | Batch Loss: 0.7324 | Learning Rate: 0.000749 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9443/12542 | Batch Loss: 1.5284 | Learning Rate: 0.000749 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9444/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9445/12542 | Batch Loss: 1.4629 | Learning Rate: 0.000749 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9446/12542 | Batch Loss: 2.4628 | Learning Rate: 0.000749 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9447/12542 | Batch Loss: 0.8575 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9448/12542 | Batch Loss: 0.9152 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9449/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9450/12542 | Batch Loss: 1.5466 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9451/12542 | Batch Loss: 1.5142 | Learning Rate: 0.000749 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9452/12542 | Batch Loss: 2.1195 | Learning Rate: 0.000749 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9453/12542 | Batch Loss: 1.2396 | Learning Rate: 0.000749 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9454/12542 | Batch Loss: 2.3501 | Learning Rate: 0.000749 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9455/12542 | Batch Loss: 4.2327 | Learning Rate: 0.000749 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9456/12542 | Batch Loss: 0.6246 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9457/12542 | Batch Loss: 1.9281 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9458/12542 | Batch Loss: 0.8051 | Learning Rate: 0.000749 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9459/12542 | Batch Loss: 2.6896 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9460/12542 | Batch Loss: 0.7411 | Learning Rate: 0.000749 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9461/12542 | Batch Loss: 2.4635 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9462/12542 | Batch Loss: 1.3928 | Learning Rate: 0.000749 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9463/12542 | Batch Loss: 1.8114 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9464/12542 | Batch Loss: 0.5238 | Learning Rate: 0.000748 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9465/12542 | Batch Loss: 1.1565 | Learning Rate: 0.000748 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9466/12542 | Batch Loss: 1.6222 | Learning Rate: 0.000748 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9467/12542 | Batch Loss: 0.7530 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9468/12542 | Batch Loss: 0.6735 | Learning Rate: 0.000748 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9469/12542 | Batch Loss: 1.2407 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9470/12542 | Batch Loss: 1.6276 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9471/12542 | Batch Loss: 1.0060 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9472/12542 | Batch Loss: 0.9285 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9473/12542 | Batch Loss: 1.4510 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9474/12542 | Batch Loss: 1.3332 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9475/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000748 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9476/12542 | Batch Loss: 1.9350 | Learning Rate: 0.000748 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9477/12542 | Batch Loss: 1.4174 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9478/12542 | Batch Loss: 1.4709 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9479/12542 | Batch Loss: 0.9352 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9480/12542 | Batch Loss: 1.2729 | Learning Rate: 0.000748 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9481/12542 | Batch Loss: 2.0149 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9482/12542 | Batch Loss: 1.7997 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9483/12542 | Batch Loss: 2.3646 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9484/12542 | Batch Loss: 2.5983 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9485/12542 | Batch Loss: 1.8198 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9486/12542 | Batch Loss: 0.7833 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9487/12542 | Batch Loss: 1.3320 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9488/12542 | Batch Loss: 1.6797 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9489/12542 | Batch Loss: 0.7110 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9490/12542 | Batch Loss: 2.2224 | Learning Rate: 0.000748 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9491/12542 | Batch Loss: 1.8225 | Learning Rate: 0.000748 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9492/12542 | Batch Loss: 1.6515 | Learning Rate: 0.000748 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9493/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000748 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9494/12542 | Batch Loss: 1.2788 | Learning Rate: 0.000748 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9495/12542 | Batch Loss: 2.1308 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9496/12542 | Batch Loss: 1.2007 | Learning Rate: 0.000748 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9497/12542 | Batch Loss: 1.1695 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9498/12542 | Batch Loss: 0.6549 | Learning Rate: 0.000748 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9499/12542 | Batch Loss: 1.8546 | Learning Rate: 0.000748 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9500/12542 | Batch Loss: 0.7518 | Learning Rate: 0.000748 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9501/12542 | Batch Loss: 1.3046 | Learning Rate: 0.000747 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9502/12542 | Batch Loss: 2.1206 | Learning Rate: 0.000747 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9503/12542 | Batch Loss: 2.8032 | Learning Rate: 0.000747 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9504/12542 | Batch Loss: 1.4647 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9505/12542 | Batch Loss: 1.9984 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9506/12542 | Batch Loss: 1.6955 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9507/12542 | Batch Loss: 2.1298 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9508/12542 | Batch Loss: 1.7870 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9509/12542 | Batch Loss: 1.5641 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9510/12542 | Batch Loss: 1.4457 | Learning Rate: 0.000747 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9511/12542 | Batch Loss: 2.4821 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9512/12542 | Batch Loss: 0.7286 | Learning Rate: 0.000747 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9513/12542 | Batch Loss: 0.8640 | Learning Rate: 0.000747 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9514/12542 | Batch Loss: 0.8806 | Learning Rate: 0.000747 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9515/12542 | Batch Loss: 1.3729 | Learning Rate: 0.000747 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9516/12542 | Batch Loss: 0.5242 | Learning Rate: 0.000747 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9517/12542 | Batch Loss: 0.8558 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9518/12542 | Batch Loss: 1.0884 | Learning Rate: 0.000747 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9519/12542 | Batch Loss: 1.2046 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9520/12542 | Batch Loss: 1.2590 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9521/12542 | Batch Loss: 0.8149 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9522/12542 | Batch Loss: 1.6505 | Learning Rate: 0.000747 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9523/12542 | Batch Loss: 1.4757 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9524/12542 | Batch Loss: 0.8045 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9525/12542 | Batch Loss: 1.6480 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9526/12542 | Batch Loss: 1.3730 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9527/12542 | Batch Loss: 3.2607 | Learning Rate: 0.000747 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9528/12542 | Batch Loss: 2.0529 | Learning Rate: 0.000747 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9529/12542 | Batch Loss: 0.7623 | Learning Rate: 0.000747 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9530/12542 | Batch Loss: 2.1525 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9531/12542 | Batch Loss: 1.1545 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9532/12542 | Batch Loss: 1.5247 | Learning Rate: 0.000747 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9533/12542 | Batch Loss: 1.7132 | Learning Rate: 0.000747 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9534/12542 | Batch Loss: 1.5458 | Learning Rate: 0.000747 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9535/12542 | Batch Loss: 1.6763 | Learning Rate: 0.000747 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9536/12542 | Batch Loss: 2.0640 | Learning Rate: 0.000747 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9537/12542 | Batch Loss: 0.9078 | Learning Rate: 0.000747 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9538/12542 | Batch Loss: 1.3383 | Learning Rate: 0.000747 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9539/12542 | Batch Loss: 2.4437 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9540/12542 | Batch Loss: 2.6216 | Learning Rate: 0.000746 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9541/12542 | Batch Loss: 1.5887 | Learning Rate: 0.000746 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9542/12542 | Batch Loss: 0.8424 | Learning Rate: 0.000746 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9543/12542 | Batch Loss: 0.8942 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9544/12542 | Batch Loss: 0.7498 | Learning Rate: 0.000746 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9545/12542 | Batch Loss: 1.3822 | Learning Rate: 0.000746 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9546/12542 | Batch Loss: 1.8917 | Learning Rate: 0.000746 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9547/12542 | Batch Loss: 1.3717 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9548/12542 | Batch Loss: 2.0499 | Learning Rate: 0.000746 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9549/12542 | Batch Loss: 1.4596 | Learning Rate: 0.000746 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9550/12542 | Batch Loss: 2.0159 | Learning Rate: 0.000746 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9551/12542 | Batch Loss: 1.2444 | Learning Rate: 0.000746 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9552/12542 | Batch Loss: 0.7588 | Learning Rate: 0.000746 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9553/12542 | Batch Loss: 2.5845 | Learning Rate: 0.000746 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9554/12542 | Batch Loss: 0.7459 | Learning Rate: 0.000746 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9555/12542 | Batch Loss: 0.7428 | Learning Rate: 0.000746 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9556/12542 | Batch Loss: 0.8514 | Learning Rate: 0.000746 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9557/12542 | Batch Loss: 1.3320 | Learning Rate: 0.000746 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9558/12542 | Batch Loss: 2.3634 | Learning Rate: 0.000746 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9559/12542 | Batch Loss: 1.0957 | Learning Rate: 0.000746 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9560/12542 | Batch Loss: 1.8844 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9561/12542 | Batch Loss: 1.2076 | Learning Rate: 0.000746 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9562/12542 | Batch Loss: 1.7326 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9563/12542 | Batch Loss: 0.9178 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9564/12542 | Batch Loss: 2.0762 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9565/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9566/12542 | Batch Loss: 1.9383 | Learning Rate: 0.000746 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9567/12542 | Batch Loss: 1.0609 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9568/12542 | Batch Loss: 0.9348 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9569/12542 | Batch Loss: 0.8825 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9570/12542 | Batch Loss: 1.5567 | Learning Rate: 0.000746 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9571/12542 | Batch Loss: 0.6314 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9572/12542 | Batch Loss: 1.1313 | Learning Rate: 0.000746 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9573/12542 | Batch Loss: 0.8067 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9574/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000746 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9575/12542 | Batch Loss: 2.0586 | Learning Rate: 0.000746 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9576/12542 | Batch Loss: 0.6690 | Learning Rate: 0.000745 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 9577/12542 | Batch Loss: 0.5610 | Learning Rate: 0.000745 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9578/12542 | Batch Loss: 0.4962 | Learning Rate: 0.000745 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9579/12542 | Batch Loss: 0.4731 | Learning Rate: 0.000745 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9580/12542 | Batch Loss: 0.8480 | Learning Rate: 0.000745 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9581/12542 | Batch Loss: 1.1440 | Learning Rate: 0.000745 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9582/12542 | Batch Loss: 0.5455 | Learning Rate: 0.000745 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9583/12542 | Batch Loss: 2.2497 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9584/12542 | Batch Loss: 2.4430 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9585/12542 | Batch Loss: 0.4954 | Learning Rate: 0.000745 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9586/12542 | Batch Loss: 1.3380 | Learning Rate: 0.000745 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9587/12542 | Batch Loss: 0.8214 | Learning Rate: 0.000745 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9588/12542 | Batch Loss: 0.6672 | Learning Rate: 0.000745 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9589/12542 | Batch Loss: 0.9965 | Learning Rate: 0.000745 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9590/12542 | Batch Loss: 2.1080 | Learning Rate: 0.000745 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9591/12542 | Batch Loss: 1.0808 | Learning Rate: 0.000745 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9592/12542 | Batch Loss: 0.8262 | Learning Rate: 0.000745 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9593/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000745 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9594/12542 | Batch Loss: 0.9673 | Learning Rate: 0.000745 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9595/12542 | Batch Loss: 1.1922 | Learning Rate: 0.000745 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9596/12542 | Batch Loss: 0.5336 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9597/12542 | Batch Loss: 0.7929 | Learning Rate: 0.000745 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9598/12542 | Batch Loss: 1.8552 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9599/12542 | Batch Loss: 1.3478 | Learning Rate: 0.000745 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9600/12542 | Batch Loss: 1.4369 | Learning Rate: 0.000745 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9601/12542 | Batch Loss: 1.7188 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9602/12542 | Batch Loss: 0.6997 | Learning Rate: 0.000745 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9603/12542 | Batch Loss: 1.0425 | Learning Rate: 0.000745 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9604/12542 | Batch Loss: 1.2280 | Learning Rate: 0.000745 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9605/12542 | Batch Loss: 1.1420 | Learning Rate: 0.000745 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9606/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000745 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9607/12542 | Batch Loss: 1.7428 | Learning Rate: 0.000745 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9608/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000745 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9609/12542 | Batch Loss: 1.9315 | Learning Rate: 0.000745 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9610/12542 | Batch Loss: 1.8366 | Learning Rate: 0.000745 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9611/12542 | Batch Loss: 1.4678 | Learning Rate: 0.000745 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9612/12542 | Batch Loss: 0.9574 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9613/12542 | Batch Loss: 2.6077 | Learning Rate: 0.000745 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9614/12542 | Batch Loss: 1.1427 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9615/12542 | Batch Loss: 0.6737 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9616/12542 | Batch Loss: 1.0323 | Learning Rate: 0.000744 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9617/12542 | Batch Loss: 1.4820 | Learning Rate: 0.000744 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9618/12542 | Batch Loss: 1.1442 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9619/12542 | Batch Loss: 2.3476 | Learning Rate: 0.000744 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9620/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000744 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9621/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000744 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 9622/12542 | Batch Loss: 0.7926 | Learning Rate: 0.000744 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 9623/12542 | Batch Loss: 0.9455 | Learning Rate: 0.000744 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9624/12542 | Batch Loss: 1.1964 | Learning Rate: 0.000744 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9625/12542 | Batch Loss: 1.1130 | Learning Rate: 0.000744 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9626/12542 | Batch Loss: 2.1970 | Learning Rate: 0.000744 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9627/12542 | Batch Loss: 1.2145 | Learning Rate: 0.000744 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9628/12542 | Batch Loss: 2.2453 | Learning Rate: 0.000744 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9629/12542 | Batch Loss: 1.2293 | Learning Rate: 0.000744 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 9630/12542 | Batch Loss: 1.1905 | Learning Rate: 0.000744 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9631/12542 | Batch Loss: 0.7418 | Learning Rate: 0.000744 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9632/12542 | Batch Loss: 0.8394 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9633/12542 | Batch Loss: 1.7860 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9634/12542 | Batch Loss: 1.4124 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9635/12542 | Batch Loss: 2.1467 | Learning Rate: 0.000744 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9636/12542 | Batch Loss: 1.3076 | Learning Rate: 0.000744 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9637/12542 | Batch Loss: 1.5964 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9638/12542 | Batch Loss: 2.0250 | Learning Rate: 0.000744 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9639/12542 | Batch Loss: 0.8727 | Learning Rate: 0.000744 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9640/12542 | Batch Loss: 1.9844 | Learning Rate: 0.000744 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9641/12542 | Batch Loss: 1.0684 | Learning Rate: 0.000744 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 9642/12542 | Batch Loss: 0.8967 | Learning Rate: 0.000744 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9643/12542 | Batch Loss: 1.3421 | Learning Rate: 0.000744 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9644/12542 | Batch Loss: 0.9734 | Learning Rate: 0.000744 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9645/12542 | Batch Loss: 1.0696 | Learning Rate: 0.000744 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9646/12542 | Batch Loss: 1.0299 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9647/12542 | Batch Loss: 0.7814 | Learning Rate: 0.000744 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9648/12542 | Batch Loss: 0.7948 | Learning Rate: 0.000744 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9649/12542 | Batch Loss: 1.4501 | Learning Rate: 0.000744 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9650/12542 | Batch Loss: 2.4293 | Learning Rate: 0.000744 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9651/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000744 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9652/12542 | Batch Loss: 1.1325 | Learning Rate: 0.000743 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9653/12542 | Batch Loss: 1.7278 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9654/12542 | Batch Loss: 1.5127 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9655/12542 | Batch Loss: 1.9662 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9656/12542 | Batch Loss: 1.3204 | Learning Rate: 0.000743 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 9657/12542 | Batch Loss: 1.7009 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9658/12542 | Batch Loss: 1.9960 | Learning Rate: 0.000743 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9659/12542 | Batch Loss: 1.4572 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9660/12542 | Batch Loss: 1.2031 | Learning Rate: 0.000743 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9661/12542 | Batch Loss: 0.8481 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9662/12542 | Batch Loss: 1.4048 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9663/12542 | Batch Loss: 1.1900 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9664/12542 | Batch Loss: 0.7553 | Learning Rate: 0.000743 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9665/12542 | Batch Loss: 0.8251 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9666/12542 | Batch Loss: 0.7169 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9667/12542 | Batch Loss: 3.5504 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9668/12542 | Batch Loss: 1.6402 | Learning Rate: 0.000743 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9669/12542 | Batch Loss: 1.5758 | Learning Rate: 0.000743 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9670/12542 | Batch Loss: 1.6153 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9671/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000743 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9672/12542 | Batch Loss: 1.4251 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9673/12542 | Batch Loss: 0.7735 | Learning Rate: 0.000743 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9674/12542 | Batch Loss: 1.4100 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9675/12542 | Batch Loss: 1.1624 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9676/12542 | Batch Loss: 1.0765 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9677/12542 | Batch Loss: 1.5081 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9678/12542 | Batch Loss: 1.1040 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9679/12542 | Batch Loss: 1.1761 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9680/12542 | Batch Loss: 3.0322 | Learning Rate: 0.000743 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9681/12542 | Batch Loss: 1.7835 | Learning Rate: 0.000743 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9682/12542 | Batch Loss: 1.9246 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9683/12542 | Batch Loss: 1.2727 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9684/12542 | Batch Loss: 1.9497 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9685/12542 | Batch Loss: 1.4012 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9686/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000743 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9687/12542 | Batch Loss: 0.6477 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9688/12542 | Batch Loss: 2.5021 | Learning Rate: 0.000743 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9689/12542 | Batch Loss: 1.9586 | Learning Rate: 0.000742 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9690/12542 | Batch Loss: 1.3281 | Learning Rate: 0.000742 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9691/12542 | Batch Loss: 0.8013 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9692/12542 | Batch Loss: 1.2450 | Learning Rate: 0.000742 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9693/12542 | Batch Loss: 1.0664 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9694/12542 | Batch Loss: 2.1601 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9695/12542 | Batch Loss: 0.9614 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9696/12542 | Batch Loss: 0.6433 | Learning Rate: 0.000742 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9697/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000742 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9698/12542 | Batch Loss: 1.0066 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9699/12542 | Batch Loss: 1.2382 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9700/12542 | Batch Loss: 4.3164 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9701/12542 | Batch Loss: 0.8737 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9702/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9703/12542 | Batch Loss: 1.5751 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9704/12542 | Batch Loss: 1.0554 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9705/12542 | Batch Loss: 0.7306 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9706/12542 | Batch Loss: 1.2957 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9707/12542 | Batch Loss: 2.9720 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9708/12542 | Batch Loss: 1.8329 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9709/12542 | Batch Loss: 0.5123 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9710/12542 | Batch Loss: 0.9821 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9711/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9712/12542 | Batch Loss: 0.9267 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9713/12542 | Batch Loss: 0.5588 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9714/12542 | Batch Loss: 1.3579 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9715/12542 | Batch Loss: 2.3183 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9716/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9717/12542 | Batch Loss: 0.7366 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9718/12542 | Batch Loss: 0.7042 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9719/12542 | Batch Loss: 0.9464 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9720/12542 | Batch Loss: 1.1525 | Learning Rate: 0.000742 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9721/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9722/12542 | Batch Loss: 1.3405 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9723/12542 | Batch Loss: 1.6734 | Learning Rate: 0.000742 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9724/12542 | Batch Loss: 2.1402 | Learning Rate: 0.000742 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9725/12542 | Batch Loss: 0.8850 | Learning Rate: 0.000742 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9726/12542 | Batch Loss: 0.9716 | Learning Rate: 0.000742 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9727/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9728/12542 | Batch Loss: 2.6488 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9729/12542 | Batch Loss: 2.3894 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9730/12542 | Batch Loss: 3.5459 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9731/12542 | Batch Loss: 1.4113 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9732/12542 | Batch Loss: 1.5711 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9733/12542 | Batch Loss: 1.5584 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9734/12542 | Batch Loss: 1.3738 | Learning Rate: 0.000741 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9735/12542 | Batch Loss: 1.8425 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9736/12542 | Batch Loss: 2.9140 | Learning Rate: 0.000741 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9737/12542 | Batch Loss: 1.0428 | Learning Rate: 0.000741 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9738/12542 | Batch Loss: 1.7977 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9739/12542 | Batch Loss: 1.1367 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9740/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9741/12542 | Batch Loss: 0.4608 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9742/12542 | Batch Loss: 2.4290 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9743/12542 | Batch Loss: 0.8731 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9744/12542 | Batch Loss: 1.8147 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9745/12542 | Batch Loss: 1.5603 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9746/12542 | Batch Loss: 1.8163 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9747/12542 | Batch Loss: 1.6860 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9748/12542 | Batch Loss: 2.5010 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9749/12542 | Batch Loss: 1.7711 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9750/12542 | Batch Loss: 1.9848 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9751/12542 | Batch Loss: 1.5000 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9752/12542 | Batch Loss: 1.1159 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9753/12542 | Batch Loss: 1.1943 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9754/12542 | Batch Loss: 2.8797 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9755/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9756/12542 | Batch Loss: 1.6344 | Learning Rate: 0.000741 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9757/12542 | Batch Loss: 1.0966 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9758/12542 | Batch Loss: 1.3309 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9759/12542 | Batch Loss: 0.8026 | Learning Rate: 0.000741 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9760/12542 | Batch Loss: 2.6644 | Learning Rate: 0.000741 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9761/12542 | Batch Loss: 1.6501 | Learning Rate: 0.000741 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9762/12542 | Batch Loss: 2.5683 | Learning Rate: 0.000741 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9763/12542 | Batch Loss: 1.1299 | Learning Rate: 0.000741 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9764/12542 | Batch Loss: 2.0114 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9765/12542 | Batch Loss: 1.9247 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9766/12542 | Batch Loss: 0.8288 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9767/12542 | Batch Loss: 2.3575 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9768/12542 | Batch Loss: 1.4955 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9769/12542 | Batch Loss: 0.9607 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9770/12542 | Batch Loss: 1.4282 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9771/12542 | Batch Loss: 1.1334 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9772/12542 | Batch Loss: 2.3928 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9773/12542 | Batch Loss: 1.5118 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9774/12542 | Batch Loss: 4.5021 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9775/12542 | Batch Loss: 1.0182 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9776/12542 | Batch Loss: 1.5388 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9777/12542 | Batch Loss: 1.7459 | Learning Rate: 0.000740 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9778/12542 | Batch Loss: 1.1590 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9779/12542 | Batch Loss: 1.1627 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9780/12542 | Batch Loss: 0.9247 | Learning Rate: 0.000740 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9781/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9782/12542 | Batch Loss: 1.1792 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9783/12542 | Batch Loss: 0.7798 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9784/12542 | Batch Loss: 1.6669 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9785/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9786/12542 | Batch Loss: 1.7785 | Learning Rate: 0.000740 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9787/12542 | Batch Loss: 0.4239 | Learning Rate: 0.000740 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9788/12542 | Batch Loss: 1.9531 | Learning Rate: 0.000740 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9789/12542 | Batch Loss: 1.6096 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9790/12542 | Batch Loss: 1.3507 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9791/12542 | Batch Loss: 1.1086 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9792/12542 | Batch Loss: 1.0889 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9793/12542 | Batch Loss: 1.7264 | Learning Rate: 0.000740 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9794/12542 | Batch Loss: 1.7239 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9795/12542 | Batch Loss: 1.8281 | Learning Rate: 0.000740 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9796/12542 | Batch Loss: 2.3713 | Learning Rate: 0.000740 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9797/12542 | Batch Loss: 2.4027 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9798/12542 | Batch Loss: 1.6657 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9799/12542 | Batch Loss: 1.3695 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9800/12542 | Batch Loss: 1.2958 | Learning Rate: 0.000740 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9801/12542 | Batch Loss: 0.9558 | Learning Rate: 0.000740 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9802/12542 | Batch Loss: 0.4593 | Learning Rate: 0.000739 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9803/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000739 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9804/12542 | Batch Loss: 1.2803 | Learning Rate: 0.000739 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9805/12542 | Batch Loss: 1.0463 | Learning Rate: 0.000739 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9806/12542 | Batch Loss: 4.1197 | Learning Rate: 0.000739 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9807/12542 | Batch Loss: 0.8304 | Learning Rate: 0.000739 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9808/12542 | Batch Loss: 1.0892 | Learning Rate: 0.000739 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9809/12542 | Batch Loss: 0.7972 | Learning Rate: 0.000739 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9810/12542 | Batch Loss: 0.6600 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9811/12542 | Batch Loss: 1.1837 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9812/12542 | Batch Loss: 2.0617 | Learning Rate: 0.000739 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9813/12542 | Batch Loss: 1.2550 | Learning Rate: 0.000739 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9814/12542 | Batch Loss: 0.9133 | Learning Rate: 0.000739 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9815/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000739 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 9816/12542 | Batch Loss: 1.4344 | Learning Rate: 0.000739 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9817/12542 | Batch Loss: 1.8861 | Learning Rate: 0.000739 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9818/12542 | Batch Loss: 0.6569 | Learning Rate: 0.000739 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9819/12542 | Batch Loss: 2.4845 | Learning Rate: 0.000739 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9820/12542 | Batch Loss: 0.9975 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9821/12542 | Batch Loss: 1.4694 | Learning Rate: 0.000739 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9822/12542 | Batch Loss: 2.0153 | Learning Rate: 0.000739 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9823/12542 | Batch Loss: 1.8948 | Learning Rate: 0.000739 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9824/12542 | Batch Loss: 1.3085 | Learning Rate: 0.000739 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9825/12542 | Batch Loss: 0.8834 | Learning Rate: 0.000739 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9826/12542 | Batch Loss: 0.9523 | Learning Rate: 0.000739 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9827/12542 | Batch Loss: 1.6025 | Learning Rate: 0.000739 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9828/12542 | Batch Loss: 1.7341 | Learning Rate: 0.000739 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9829/12542 | Batch Loss: 1.7304 | Learning Rate: 0.000739 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9830/12542 | Batch Loss: 1.7614 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9831/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000739 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9832/12542 | Batch Loss: 1.9950 | Learning Rate: 0.000739 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9833/12542 | Batch Loss: 0.9462 | Learning Rate: 0.000739 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9834/12542 | Batch Loss: 1.3111 | Learning Rate: 0.000739 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9835/12542 | Batch Loss: 0.9366 | Learning Rate: 0.000739 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9836/12542 | Batch Loss: 2.1014 | Learning Rate: 0.000739 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9837/12542 | Batch Loss: 1.5533 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9838/12542 | Batch Loss: 1.9843 | Learning Rate: 0.000739 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9839/12542 | Batch Loss: 2.5334 | Learning Rate: 0.000739 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9840/12542 | Batch Loss: 0.9894 | Learning Rate: 0.000738 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9841/12542 | Batch Loss: 2.3973 | Learning Rate: 0.000738 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9842/12542 | Batch Loss: 1.9734 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9843/12542 | Batch Loss: 0.7251 | Learning Rate: 0.000738 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 9844/12542 | Batch Loss: 1.5741 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9845/12542 | Batch Loss: 0.8458 | Learning Rate: 0.000738 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9846/12542 | Batch Loss: 0.9612 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9847/12542 | Batch Loss: 1.7572 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9848/12542 | Batch Loss: 1.6429 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9849/12542 | Batch Loss: 1.3143 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9850/12542 | Batch Loss: 0.7228 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9851/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9852/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9853/12542 | Batch Loss: 1.4379 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9854/12542 | Batch Loss: 0.6855 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9855/12542 | Batch Loss: 1.8240 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9856/12542 | Batch Loss: 0.7442 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9857/12542 | Batch Loss: 0.8573 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9858/12542 | Batch Loss: 1.8775 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9859/12542 | Batch Loss: 1.4248 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9860/12542 | Batch Loss: 2.4311 | Learning Rate: 0.000738 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9861/12542 | Batch Loss: 2.0537 | Learning Rate: 0.000738 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 9862/12542 | Batch Loss: 1.7525 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9863/12542 | Batch Loss: 1.3537 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9864/12542 | Batch Loss: 0.9716 | Learning Rate: 0.000738 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9865/12542 | Batch Loss: 1.0428 | Learning Rate: 0.000738 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9866/12542 | Batch Loss: 1.0135 | Learning Rate: 0.000738 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9867/12542 | Batch Loss: 0.8783 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9868/12542 | Batch Loss: 0.6755 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9869/12542 | Batch Loss: 0.8428 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9870/12542 | Batch Loss: 1.3957 | Learning Rate: 0.000738 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9871/12542 | Batch Loss: 0.4862 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9872/12542 | Batch Loss: 1.8089 | Learning Rate: 0.000738 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9873/12542 | Batch Loss: 1.5357 | Learning Rate: 0.000738 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9874/12542 | Batch Loss: 1.6146 | Learning Rate: 0.000738 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9875/12542 | Batch Loss: 1.8915 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9876/12542 | Batch Loss: 1.1671 | Learning Rate: 0.000738 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9877/12542 | Batch Loss: 1.1340 | Learning Rate: 0.000737 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9878/12542 | Batch Loss: 1.2326 | Learning Rate: 0.000737 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9879/12542 | Batch Loss: 1.7175 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9880/12542 | Batch Loss: 1.2763 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9881/12542 | Batch Loss: 2.1415 | Learning Rate: 0.000737 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9882/12542 | Batch Loss: 0.8888 | Learning Rate: 0.000737 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 9883/12542 | Batch Loss: 1.0989 | Learning Rate: 0.000737 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9884/12542 | Batch Loss: 2.2107 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9885/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9886/12542 | Batch Loss: 1.2240 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9887/12542 | Batch Loss: 1.0185 | Learning Rate: 0.000737 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 9888/12542 | Batch Loss: 2.0221 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9889/12542 | Batch Loss: 1.7073 | Learning Rate: 0.000737 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9890/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000737 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9891/12542 | Batch Loss: 0.6673 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9892/12542 | Batch Loss: 1.1687 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9893/12542 | Batch Loss: 1.8291 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9894/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000737 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 9895/12542 | Batch Loss: 1.1264 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9896/12542 | Batch Loss: 1.5190 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9897/12542 | Batch Loss: 1.4526 | Learning Rate: 0.000737 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9898/12542 | Batch Loss: 0.9382 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9899/12542 | Batch Loss: 1.5676 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9900/12542 | Batch Loss: 0.9260 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9901/12542 | Batch Loss: 1.6037 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9902/12542 | Batch Loss: 0.6523 | Learning Rate: 0.000737 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9903/12542 | Batch Loss: 1.5619 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9904/12542 | Batch Loss: 0.7475 | Learning Rate: 0.000737 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9905/12542 | Batch Loss: 1.2966 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9906/12542 | Batch Loss: 0.7054 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9907/12542 | Batch Loss: 2.2221 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9908/12542 | Batch Loss: 2.0350 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9909/12542 | Batch Loss: 1.7030 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9910/12542 | Batch Loss: 1.4800 | Learning Rate: 0.000737 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9911/12542 | Batch Loss: 1.2322 | Learning Rate: 0.000737 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9912/12542 | Batch Loss: 2.9853 | Learning Rate: 0.000737 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9913/12542 | Batch Loss: 1.4339 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9914/12542 | Batch Loss: 2.2092 | Learning Rate: 0.000737 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9915/12542 | Batch Loss: 0.9559 | Learning Rate: 0.000736 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9916/12542 | Batch Loss: 1.0907 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9917/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9918/12542 | Batch Loss: 1.1186 | Learning Rate: 0.000736 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9919/12542 | Batch Loss: 1.0167 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9920/12542 | Batch Loss: 2.3053 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9921/12542 | Batch Loss: 1.4286 | Learning Rate: 0.000736 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9922/12542 | Batch Loss: 1.3810 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9923/12542 | Batch Loss: 0.9924 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9924/12542 | Batch Loss: 1.1184 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9925/12542 | Batch Loss: 1.2209 | Learning Rate: 0.000736 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9926/12542 | Batch Loss: 0.6515 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9927/12542 | Batch Loss: 1.2419 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9928/12542 | Batch Loss: 0.6635 | Learning Rate: 0.000736 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9929/12542 | Batch Loss: 1.9482 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9930/12542 | Batch Loss: 1.2146 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9931/12542 | Batch Loss: 1.2841 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9932/12542 | Batch Loss: 0.6562 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9933/12542 | Batch Loss: 1.8201 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9934/12542 | Batch Loss: 0.6272 | Learning Rate: 0.000736 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9935/12542 | Batch Loss: 3.2180 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9936/12542 | Batch Loss: 1.1802 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9937/12542 | Batch Loss: 0.9238 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9938/12542 | Batch Loss: 1.3176 | Learning Rate: 0.000736 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 9939/12542 | Batch Loss: 0.6260 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9940/12542 | Batch Loss: 1.1865 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9941/12542 | Batch Loss: 1.3418 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9942/12542 | Batch Loss: 1.8350 | Learning Rate: 0.000736 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9943/12542 | Batch Loss: 0.8306 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9944/12542 | Batch Loss: 1.0999 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9945/12542 | Batch Loss: 0.8856 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9946/12542 | Batch Loss: 2.3949 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9947/12542 | Batch Loss: 1.8514 | Learning Rate: 0.000736 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9948/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9949/12542 | Batch Loss: 2.8086 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9950/12542 | Batch Loss: 2.9018 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9951/12542 | Batch Loss: 1.1834 | Learning Rate: 0.000736 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9952/12542 | Batch Loss: 0.6269 | Learning Rate: 0.000736 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9953/12542 | Batch Loss: 1.1337 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9954/12542 | Batch Loss: 1.2215 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9955/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9956/12542 | Batch Loss: 2.9319 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9957/12542 | Batch Loss: 1.6471 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9958/12542 | Batch Loss: 2.0230 | Learning Rate: 0.000735 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9959/12542 | Batch Loss: 1.3023 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9960/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9961/12542 | Batch Loss: 0.6323 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9962/12542 | Batch Loss: 0.9187 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9963/12542 | Batch Loss: 1.3211 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9964/12542 | Batch Loss: 0.8268 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9965/12542 | Batch Loss: 1.1884 | Learning Rate: 0.000735 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9966/12542 | Batch Loss: 1.0395 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9967/12542 | Batch Loss: 0.8345 | Learning Rate: 0.000735 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9968/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9969/12542 | Batch Loss: 2.0702 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9970/12542 | Batch Loss: 1.2642 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9971/12542 | Batch Loss: 1.0172 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9972/12542 | Batch Loss: 1.7012 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9973/12542 | Batch Loss: 0.9474 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9974/12542 | Batch Loss: 0.8806 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9975/12542 | Batch Loss: 0.9824 | Learning Rate: 0.000735 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9976/12542 | Batch Loss: 0.9506 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9977/12542 | Batch Loss: 1.4223 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9978/12542 | Batch Loss: 1.5131 | Learning Rate: 0.000735 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9979/12542 | Batch Loss: 2.1688 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9980/12542 | Batch Loss: 0.9343 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9981/12542 | Batch Loss: 1.6874 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9982/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9983/12542 | Batch Loss: 1.2409 | Learning Rate: 0.000735 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9984/12542 | Batch Loss: 1.1450 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9985/12542 | Batch Loss: 1.1080 | Learning Rate: 0.000735 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9986/12542 | Batch Loss: 1.9413 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9987/12542 | Batch Loss: 0.9451 | Learning Rate: 0.000735 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 9988/12542 | Batch Loss: 2.4804 | Learning Rate: 0.000735 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9989/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000735 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9990/12542 | Batch Loss: 0.9151 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 9991/12542 | Batch Loss: 2.1934 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9992/12542 | Batch Loss: 0.7890 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9993/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000734 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9994/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9995/12542 | Batch Loss: 1.7430 | Learning Rate: 0.000734 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 9996/12542 | Batch Loss: 0.8450 | Learning Rate: 0.000734 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9997/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 9998/12542 | Batch Loss: 1.2777 | Learning Rate: 0.000734 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 9999/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10000/12542 | Batch Loss: 0.8152 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10001/12542 | Batch Loss: 1.0566 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10002/12542 | Batch Loss: 1.7162 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10003/12542 | Batch Loss: 1.6784 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10004/12542 | Batch Loss: 0.9339 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10005/12542 | Batch Loss: 1.1144 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10006/12542 | Batch Loss: 0.7594 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10007/12542 | Batch Loss: 1.2960 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10008/12542 | Batch Loss: 2.1268 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10009/12542 | Batch Loss: 1.4124 | Learning Rate: 0.000734 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10010/12542 | Batch Loss: 1.2671 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10011/12542 | Batch Loss: 1.1739 | Learning Rate: 0.000734 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10012/12542 | Batch Loss: 1.9627 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10013/12542 | Batch Loss: 1.6232 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10014/12542 | Batch Loss: 1.8733 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10015/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10016/12542 | Batch Loss: 2.8238 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10017/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10018/12542 | Batch Loss: 1.8438 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10019/12542 | Batch Loss: 0.8763 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10020/12542 | Batch Loss: 1.0440 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10021/12542 | Batch Loss: 1.1012 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10022/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10023/12542 | Batch Loss: 1.9318 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10024/12542 | Batch Loss: 1.2464 | Learning Rate: 0.000734 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10025/12542 | Batch Loss: 1.5411 | Learning Rate: 0.000734 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10026/12542 | Batch Loss: 1.3929 | Learning Rate: 0.000734 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10027/12542 | Batch Loss: 0.8529 | Learning Rate: 0.000734 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10028/12542 | Batch Loss: 1.4111 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10029/12542 | Batch Loss: 0.6764 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10030/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10031/12542 | Batch Loss: 2.1112 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10032/12542 | Batch Loss: 1.6991 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10033/12542 | Batch Loss: 2.8903 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10034/12542 | Batch Loss: 2.4593 | Learning Rate: 0.000733 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10035/12542 | Batch Loss: 1.2029 | Learning Rate: 0.000733 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10036/12542 | Batch Loss: 1.7837 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10037/12542 | Batch Loss: 2.7924 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10038/12542 | Batch Loss: 1.5341 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10039/12542 | Batch Loss: 0.7544 | Learning Rate: 0.000733 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10040/12542 | Batch Loss: 1.3897 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10041/12542 | Batch Loss: 1.1057 | Learning Rate: 0.000733 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10042/12542 | Batch Loss: 1.2804 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10043/12542 | Batch Loss: 0.7663 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10044/12542 | Batch Loss: 2.2224 | Learning Rate: 0.000733 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10045/12542 | Batch Loss: 0.7208 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10046/12542 | Batch Loss: 1.5800 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10047/12542 | Batch Loss: 1.1990 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10048/12542 | Batch Loss: 1.7809 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10049/12542 | Batch Loss: 1.3187 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10050/12542 | Batch Loss: 1.6925 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10051/12542 | Batch Loss: 0.7714 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10052/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10053/12542 | Batch Loss: 1.1366 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10054/12542 | Batch Loss: 1.2006 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10055/12542 | Batch Loss: 1.5804 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10056/12542 | Batch Loss: 1.3414 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10057/12542 | Batch Loss: 2.9103 | Learning Rate: 0.000733 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10058/12542 | Batch Loss: 1.5714 | Learning Rate: 0.000733 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10059/12542 | Batch Loss: 1.4984 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10060/12542 | Batch Loss: 1.6108 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10061/12542 | Batch Loss: 0.9794 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10062/12542 | Batch Loss: 1.6305 | Learning Rate: 0.000733 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10063/12542 | Batch Loss: 1.4522 | Learning Rate: 0.000733 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10064/12542 | Batch Loss: 0.5767 | Learning Rate: 0.000733 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10065/12542 | Batch Loss: 0.9651 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10066/12542 | Batch Loss: 1.2110 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10067/12542 | Batch Loss: 0.8745 | Learning Rate: 0.000732 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10068/12542 | Batch Loss: 2.3331 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10069/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000732 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10070/12542 | Batch Loss: 1.0349 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10071/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000732 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10072/12542 | Batch Loss: 1.1313 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10073/12542 | Batch Loss: 0.5637 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10074/12542 | Batch Loss: 1.3867 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10075/12542 | Batch Loss: 1.0201 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10076/12542 | Batch Loss: 0.9405 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10077/12542 | Batch Loss: 0.4361 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10078/12542 | Batch Loss: 1.4754 | Learning Rate: 0.000732 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10079/12542 | Batch Loss: 0.6750 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10080/12542 | Batch Loss: 0.6952 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10081/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10082/12542 | Batch Loss: 1.1232 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10083/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10084/12542 | Batch Loss: 1.1922 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10085/12542 | Batch Loss: 0.8985 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10086/12542 | Batch Loss: 1.6155 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10087/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10088/12542 | Batch Loss: 0.6048 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10089/12542 | Batch Loss: 1.2070 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10090/12542 | Batch Loss: 3.1045 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10091/12542 | Batch Loss: 0.6106 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10092/12542 | Batch Loss: 1.3528 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10093/12542 | Batch Loss: 2.6366 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10094/12542 | Batch Loss: 1.1159 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10095/12542 | Batch Loss: 1.7785 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10096/12542 | Batch Loss: 1.6067 | Learning Rate: 0.000732 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10097/12542 | Batch Loss: 1.1733 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10098/12542 | Batch Loss: 1.3578 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10099/12542 | Batch Loss: 0.5427 | Learning Rate: 0.000732 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10100/12542 | Batch Loss: 1.5284 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10101/12542 | Batch Loss: 1.6250 | Learning Rate: 0.000732 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10102/12542 | Batch Loss: 0.5584 | Learning Rate: 0.000732 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10103/12542 | Batch Loss: 1.5701 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10104/12542 | Batch Loss: 1.0620 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10105/12542 | Batch Loss: 0.6585 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10106/12542 | Batch Loss: 1.3849 | Learning Rate: 0.000731 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10107/12542 | Batch Loss: 1.6853 | Learning Rate: 0.000731 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10108/12542 | Batch Loss: 1.0055 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10109/12542 | Batch Loss: 1.6030 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10110/12542 | Batch Loss: 1.4894 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10111/12542 | Batch Loss: 1.1100 | Learning Rate: 0.000731 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10112/12542 | Batch Loss: 2.0011 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10113/12542 | Batch Loss: 2.6635 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10114/12542 | Batch Loss: 1.0317 | Learning Rate: 0.000731 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10115/12542 | Batch Loss: 1.0319 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10116/12542 | Batch Loss: 1.1040 | Learning Rate: 0.000731 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10117/12542 | Batch Loss: 0.5656 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10118/12542 | Batch Loss: 1.0635 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10119/12542 | Batch Loss: 0.8565 | Learning Rate: 0.000731 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10120/12542 | Batch Loss: 1.1442 | Learning Rate: 0.000731 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10121/12542 | Batch Loss: 1.7959 | Learning Rate: 0.000731 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10122/12542 | Batch Loss: 0.7588 | Learning Rate: 0.000731 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10123/12542 | Batch Loss: 2.0356 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10124/12542 | Batch Loss: 1.1536 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10125/12542 | Batch Loss: 1.5159 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10126/12542 | Batch Loss: 1.5393 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10127/12542 | Batch Loss: 0.5453 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10128/12542 | Batch Loss: 1.4300 | Learning Rate: 0.000731 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10129/12542 | Batch Loss: 1.1295 | Learning Rate: 0.000731 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10130/12542 | Batch Loss: 1.0223 | Learning Rate: 0.000731 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10131/12542 | Batch Loss: 1.4526 | Learning Rate: 0.000731 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10132/12542 | Batch Loss: 1.8815 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10133/12542 | Batch Loss: 1.2742 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10134/12542 | Batch Loss: 0.7245 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10135/12542 | Batch Loss: 1.3581 | Learning Rate: 0.000731 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10136/12542 | Batch Loss: 1.4968 | Learning Rate: 0.000731 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10137/12542 | Batch Loss: 0.5532 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10138/12542 | Batch Loss: 0.8927 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10139/12542 | Batch Loss: 0.4431 | Learning Rate: 0.000731 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10140/12542 | Batch Loss: 0.6459 | Learning Rate: 0.000731 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10141/12542 | Batch Loss: 1.2969 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10142/12542 | Batch Loss: 2.1708 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10143/12542 | Batch Loss: 0.9827 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10144/12542 | Batch Loss: 1.3956 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10145/12542 | Batch Loss: 1.2757 | Learning Rate: 0.000730 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10146/12542 | Batch Loss: 1.9118 | Learning Rate: 0.000730 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10147/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10148/12542 | Batch Loss: 1.2072 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10149/12542 | Batch Loss: 1.3792 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10150/12542 | Batch Loss: 3.2191 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10151/12542 | Batch Loss: 2.8459 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10152/12542 | Batch Loss: 0.6368 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10153/12542 | Batch Loss: 1.7219 | Learning Rate: 0.000730 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10154/12542 | Batch Loss: 1.7892 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10155/12542 | Batch Loss: 1.3452 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10156/12542 | Batch Loss: 1.0967 | Learning Rate: 0.000730 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10157/12542 | Batch Loss: 1.3513 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10158/12542 | Batch Loss: 1.7105 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10159/12542 | Batch Loss: 0.7816 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10160/12542 | Batch Loss: 1.1207 | Learning Rate: 0.000730 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10161/12542 | Batch Loss: 1.0365 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10162/12542 | Batch Loss: 1.5540 | Learning Rate: 0.000730 | Batch Time: 0.54s\n",
      "Epoch 1 | Step 10163/12542 | Batch Loss: 1.8633 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10164/12542 | Batch Loss: 0.8267 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10165/12542 | Batch Loss: 0.9303 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10166/12542 | Batch Loss: 1.4762 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10167/12542 | Batch Loss: 0.9372 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10168/12542 | Batch Loss: 1.6487 | Learning Rate: 0.000730 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 10169/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10170/12542 | Batch Loss: 0.5813 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10171/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000730 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10172/12542 | Batch Loss: 3.8736 | Learning Rate: 0.000730 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10173/12542 | Batch Loss: 1.4000 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10174/12542 | Batch Loss: 0.8129 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10175/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10176/12542 | Batch Loss: 0.8694 | Learning Rate: 0.000730 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10177/12542 | Batch Loss: 1.7430 | Learning Rate: 0.000730 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10178/12542 | Batch Loss: 1.2163 | Learning Rate: 0.000729 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10179/12542 | Batch Loss: 1.0718 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10180/12542 | Batch Loss: 2.4225 | Learning Rate: 0.000729 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10181/12542 | Batch Loss: 1.6687 | Learning Rate: 0.000729 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10182/12542 | Batch Loss: 1.1204 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10183/12542 | Batch Loss: 2.0558 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10184/12542 | Batch Loss: 1.3328 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10185/12542 | Batch Loss: 1.3554 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10186/12542 | Batch Loss: 1.0200 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10187/12542 | Batch Loss: 0.8838 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10188/12542 | Batch Loss: 0.8160 | Learning Rate: 0.000729 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10189/12542 | Batch Loss: 0.9446 | Learning Rate: 0.000729 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10190/12542 | Batch Loss: 0.8778 | Learning Rate: 0.000729 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10191/12542 | Batch Loss: 1.1997 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10192/12542 | Batch Loss: 0.8768 | Learning Rate: 0.000729 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10193/12542 | Batch Loss: 1.2487 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10194/12542 | Batch Loss: 1.3203 | Learning Rate: 0.000729 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10195/12542 | Batch Loss: 3.9650 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10196/12542 | Batch Loss: 0.6452 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10197/12542 | Batch Loss: 0.6608 | Learning Rate: 0.000729 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10198/12542 | Batch Loss: 0.6933 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10199/12542 | Batch Loss: 1.3075 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10200/12542 | Batch Loss: 0.9269 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10201/12542 | Batch Loss: 1.2105 | Learning Rate: 0.000729 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10202/12542 | Batch Loss: 1.3470 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10203/12542 | Batch Loss: 1.1155 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10204/12542 | Batch Loss: 1.6485 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10205/12542 | Batch Loss: 0.6490 | Learning Rate: 0.000729 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10206/12542 | Batch Loss: 1.6390 | Learning Rate: 0.000729 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10207/12542 | Batch Loss: 1.6083 | Learning Rate: 0.000729 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10208/12542 | Batch Loss: 0.8211 | Learning Rate: 0.000729 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10209/12542 | Batch Loss: 1.1647 | Learning Rate: 0.000729 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10210/12542 | Batch Loss: 1.3990 | Learning Rate: 0.000729 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10211/12542 | Batch Loss: 0.5503 | Learning Rate: 0.000729 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10212/12542 | Batch Loss: 1.1134 | Learning Rate: 0.000729 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10213/12542 | Batch Loss: 1.4932 | Learning Rate: 0.000729 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10214/12542 | Batch Loss: 1.7841 | Learning Rate: 0.000729 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10215/12542 | Batch Loss: 2.8837 | Learning Rate: 0.000729 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10216/12542 | Batch Loss: 0.8580 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10217/12542 | Batch Loss: 1.8518 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10218/12542 | Batch Loss: 1.3888 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10219/12542 | Batch Loss: 2.0839 | Learning Rate: 0.000728 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10220/12542 | Batch Loss: 2.7625 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10221/12542 | Batch Loss: 1.6636 | Learning Rate: 0.000728 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10222/12542 | Batch Loss: 1.7732 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10223/12542 | Batch Loss: 2.3637 | Learning Rate: 0.000728 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10224/12542 | Batch Loss: 0.9816 | Learning Rate: 0.000728 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10225/12542 | Batch Loss: 1.6503 | Learning Rate: 0.000728 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10226/12542 | Batch Loss: 1.5792 | Learning Rate: 0.000728 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10227/12542 | Batch Loss: 0.7407 | Learning Rate: 0.000728 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10228/12542 | Batch Loss: 1.6398 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10229/12542 | Batch Loss: 2.5324 | Learning Rate: 0.000728 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10230/12542 | Batch Loss: 0.9876 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10231/12542 | Batch Loss: 1.6529 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10232/12542 | Batch Loss: 0.9983 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10233/12542 | Batch Loss: 1.3704 | Learning Rate: 0.000728 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10234/12542 | Batch Loss: 1.0236 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10235/12542 | Batch Loss: 1.3444 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10236/12542 | Batch Loss: 0.7917 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10237/12542 | Batch Loss: 1.3523 | Learning Rate: 0.000728 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10238/12542 | Batch Loss: 0.7455 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10239/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000728 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10240/12542 | Batch Loss: 3.1119 | Learning Rate: 0.000728 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10241/12542 | Batch Loss: 1.4189 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10242/12542 | Batch Loss: 1.1615 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10243/12542 | Batch Loss: 0.9767 | Learning Rate: 0.000728 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10244/12542 | Batch Loss: 1.5708 | Learning Rate: 0.000728 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10245/12542 | Batch Loss: 1.3424 | Learning Rate: 0.000728 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10246/12542 | Batch Loss: 2.4877 | Learning Rate: 0.000728 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10247/12542 | Batch Loss: 0.9363 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10248/12542 | Batch Loss: 1.2730 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10249/12542 | Batch Loss: 2.0732 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10250/12542 | Batch Loss: 1.7210 | Learning Rate: 0.000728 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10251/12542 | Batch Loss: 1.9738 | Learning Rate: 0.000728 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10252/12542 | Batch Loss: 1.4544 | Learning Rate: 0.000728 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10253/12542 | Batch Loss: 1.3980 | Learning Rate: 0.000728 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10254/12542 | Batch Loss: 1.3430 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10255/12542 | Batch Loss: 0.9254 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10256/12542 | Batch Loss: 0.7834 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10257/12542 | Batch Loss: 1.2813 | Learning Rate: 0.000727 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10258/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10259/12542 | Batch Loss: 0.8709 | Learning Rate: 0.000727 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10260/12542 | Batch Loss: 2.0741 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10261/12542 | Batch Loss: 1.7258 | Learning Rate: 0.000727 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10262/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10263/12542 | Batch Loss: 2.6538 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10264/12542 | Batch Loss: 1.2569 | Learning Rate: 0.000727 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10265/12542 | Batch Loss: 0.8842 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10266/12542 | Batch Loss: 2.4509 | Learning Rate: 0.000727 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10267/12542 | Batch Loss: 0.9057 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10268/12542 | Batch Loss: 1.0377 | Learning Rate: 0.000727 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10269/12542 | Batch Loss: 2.8546 | Learning Rate: 0.000727 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10270/12542 | Batch Loss: 1.5954 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10271/12542 | Batch Loss: 2.1771 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10272/12542 | Batch Loss: 0.6697 | Learning Rate: 0.000727 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10273/12542 | Batch Loss: 0.6620 | Learning Rate: 0.000727 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10274/12542 | Batch Loss: 1.0423 | Learning Rate: 0.000727 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10275/12542 | Batch Loss: 0.9814 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10276/12542 | Batch Loss: 1.4424 | Learning Rate: 0.000727 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10277/12542 | Batch Loss: 1.0849 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10278/12542 | Batch Loss: 0.9876 | Learning Rate: 0.000727 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10279/12542 | Batch Loss: 1.9424 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10280/12542 | Batch Loss: 2.3420 | Learning Rate: 0.000727 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10281/12542 | Batch Loss: 0.7500 | Learning Rate: 0.000727 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10282/12542 | Batch Loss: 0.3607 | Learning Rate: 0.000727 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10283/12542 | Batch Loss: 1.3019 | Learning Rate: 0.000727 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10284/12542 | Batch Loss: 1.1341 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10285/12542 | Batch Loss: 1.1030 | Learning Rate: 0.000727 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10286/12542 | Batch Loss: 1.4048 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10287/12542 | Batch Loss: 1.6959 | Learning Rate: 0.000727 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10288/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000727 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10289/12542 | Batch Loss: 2.9081 | Learning Rate: 0.000727 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10290/12542 | Batch Loss: 1.4299 | Learning Rate: 0.000727 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10291/12542 | Batch Loss: 1.0147 | Learning Rate: 0.000726 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10292/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10293/12542 | Batch Loss: 1.6229 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10294/12542 | Batch Loss: 1.0819 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10295/12542 | Batch Loss: 0.9997 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10296/12542 | Batch Loss: 1.7012 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10297/12542 | Batch Loss: 1.5525 | Learning Rate: 0.000726 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10298/12542 | Batch Loss: 2.4752 | Learning Rate: 0.000726 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10299/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10300/12542 | Batch Loss: 2.2368 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10301/12542 | Batch Loss: 0.8279 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10302/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000726 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10303/12542 | Batch Loss: 0.7128 | Learning Rate: 0.000726 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10304/12542 | Batch Loss: 0.8166 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10305/12542 | Batch Loss: 0.6895 | Learning Rate: 0.000726 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10306/12542 | Batch Loss: 1.6328 | Learning Rate: 0.000726 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10307/12542 | Batch Loss: 2.3222 | Learning Rate: 0.000726 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10308/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10309/12542 | Batch Loss: 0.7228 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10310/12542 | Batch Loss: 2.0009 | Learning Rate: 0.000726 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10311/12542 | Batch Loss: 0.5301 | Learning Rate: 0.000726 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10312/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000726 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10313/12542 | Batch Loss: 1.6444 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10314/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000726 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10315/12542 | Batch Loss: 2.5923 | Learning Rate: 0.000726 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10316/12542 | Batch Loss: 1.3807 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10317/12542 | Batch Loss: 1.5472 | Learning Rate: 0.000726 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10318/12542 | Batch Loss: 1.3035 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10319/12542 | Batch Loss: 1.2343 | Learning Rate: 0.000726 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10320/12542 | Batch Loss: 0.9811 | Learning Rate: 0.000726 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10321/12542 | Batch Loss: 1.6618 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10322/12542 | Batch Loss: 1.5577 | Learning Rate: 0.000726 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10323/12542 | Batch Loss: 1.7536 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10324/12542 | Batch Loss: 1.0584 | Learning Rate: 0.000726 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10325/12542 | Batch Loss: 1.1825 | Learning Rate: 0.000726 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10326/12542 | Batch Loss: 0.6544 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10327/12542 | Batch Loss: 1.7113 | Learning Rate: 0.000726 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10328/12542 | Batch Loss: 1.1986 | Learning Rate: 0.000726 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10329/12542 | Batch Loss: 2.1765 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10330/12542 | Batch Loss: 1.6668 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10331/12542 | Batch Loss: 1.2058 | Learning Rate: 0.000725 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 10332/12542 | Batch Loss: 2.0014 | Learning Rate: 0.000725 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10333/12542 | Batch Loss: 2.3744 | Learning Rate: 0.000725 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10334/12542 | Batch Loss: 1.5220 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10335/12542 | Batch Loss: 1.0245 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10336/12542 | Batch Loss: 2.1077 | Learning Rate: 0.000725 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10337/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10338/12542 | Batch Loss: 1.1803 | Learning Rate: 0.000725 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 10339/12542 | Batch Loss: 2.5587 | Learning Rate: 0.000725 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 10340/12542 | Batch Loss: 0.9986 | Learning Rate: 0.000725 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10341/12542 | Batch Loss: 1.7961 | Learning Rate: 0.000725 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10342/12542 | Batch Loss: 1.7669 | Learning Rate: 0.000725 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10343/12542 | Batch Loss: 2.1446 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10344/12542 | Batch Loss: 1.5712 | Learning Rate: 0.000725 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10345/12542 | Batch Loss: 1.2313 | Learning Rate: 0.000725 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10346/12542 | Batch Loss: 1.6054 | Learning Rate: 0.000725 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10347/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000725 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10348/12542 | Batch Loss: 1.7144 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10349/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000725 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10350/12542 | Batch Loss: 1.5397 | Learning Rate: 0.000725 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10351/12542 | Batch Loss: 1.8787 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10352/12542 | Batch Loss: 1.4439 | Learning Rate: 0.000725 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10353/12542 | Batch Loss: 2.1232 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10354/12542 | Batch Loss: 0.9750 | Learning Rate: 0.000725 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10355/12542 | Batch Loss: 1.7914 | Learning Rate: 0.000725 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 10356/12542 | Batch Loss: 1.9331 | Learning Rate: 0.000725 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 10357/12542 | Batch Loss: 1.0148 | Learning Rate: 0.000725 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10358/12542 | Batch Loss: 0.6554 | Learning Rate: 0.000725 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10359/12542 | Batch Loss: 1.8549 | Learning Rate: 0.000725 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10360/12542 | Batch Loss: 1.2647 | Learning Rate: 0.000725 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10361/12542 | Batch Loss: 0.8112 | Learning Rate: 0.000725 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10362/12542 | Batch Loss: 1.8229 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10363/12542 | Batch Loss: 1.5079 | Learning Rate: 0.000725 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10364/12542 | Batch Loss: 0.8692 | Learning Rate: 0.000725 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10365/12542 | Batch Loss: 0.9972 | Learning Rate: 0.000725 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10366/12542 | Batch Loss: 1.6669 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10367/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10368/12542 | Batch Loss: 1.3014 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10369/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000724 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10370/12542 | Batch Loss: 0.7096 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10371/12542 | Batch Loss: 1.8210 | Learning Rate: 0.000724 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10372/12542 | Batch Loss: 1.5924 | Learning Rate: 0.000724 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10373/12542 | Batch Loss: 1.3374 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10374/12542 | Batch Loss: 3.1993 | Learning Rate: 0.000724 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10375/12542 | Batch Loss: 0.7271 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10376/12542 | Batch Loss: 1.7073 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10377/12542 | Batch Loss: 3.1925 | Learning Rate: 0.000724 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10378/12542 | Batch Loss: 1.0619 | Learning Rate: 0.000724 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10379/12542 | Batch Loss: 1.8967 | Learning Rate: 0.000724 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10380/12542 | Batch Loss: 1.0285 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10381/12542 | Batch Loss: 1.4725 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10382/12542 | Batch Loss: 2.2143 | Learning Rate: 0.000724 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10383/12542 | Batch Loss: 1.7144 | Learning Rate: 0.000724 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10384/12542 | Batch Loss: 0.9947 | Learning Rate: 0.000724 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10385/12542 | Batch Loss: 2.5023 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10386/12542 | Batch Loss: 1.2570 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10387/12542 | Batch Loss: 1.4031 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10388/12542 | Batch Loss: 0.6792 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10389/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000724 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10390/12542 | Batch Loss: 1.8091 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10391/12542 | Batch Loss: 0.8667 | Learning Rate: 0.000724 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10392/12542 | Batch Loss: 0.9859 | Learning Rate: 0.000724 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10393/12542 | Batch Loss: 0.8677 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10394/12542 | Batch Loss: 1.5456 | Learning Rate: 0.000724 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10395/12542 | Batch Loss: 1.4411 | Learning Rate: 0.000724 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10396/12542 | Batch Loss: 0.9633 | Learning Rate: 0.000724 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10397/12542 | Batch Loss: 1.2403 | Learning Rate: 0.000724 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10398/12542 | Batch Loss: 1.2583 | Learning Rate: 0.000724 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10399/12542 | Batch Loss: 1.6311 | Learning Rate: 0.000724 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10400/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000724 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10401/12542 | Batch Loss: 0.5850 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10402/12542 | Batch Loss: 0.3471 | Learning Rate: 0.000724 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10403/12542 | Batch Loss: 0.5542 | Learning Rate: 0.000724 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10404/12542 | Batch Loss: 0.7196 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10405/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10406/12542 | Batch Loss: 0.5763 | Learning Rate: 0.000723 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10407/12542 | Batch Loss: 1.4107 | Learning Rate: 0.000723 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10408/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000723 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10409/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10410/12542 | Batch Loss: 2.9100 | Learning Rate: 0.000723 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10411/12542 | Batch Loss: 0.6906 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10412/12542 | Batch Loss: 2.7977 | Learning Rate: 0.000723 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10413/12542 | Batch Loss: 1.5923 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10414/12542 | Batch Loss: 0.9855 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10415/12542 | Batch Loss: 1.7064 | Learning Rate: 0.000723 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10416/12542 | Batch Loss: 1.2685 | Learning Rate: 0.000723 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10417/12542 | Batch Loss: 1.0873 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10418/12542 | Batch Loss: 0.8904 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10419/12542 | Batch Loss: 0.8393 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10420/12542 | Batch Loss: 1.6552 | Learning Rate: 0.000723 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10421/12542 | Batch Loss: 1.6014 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10422/12542 | Batch Loss: 1.2241 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10423/12542 | Batch Loss: 1.4265 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10424/12542 | Batch Loss: 0.9474 | Learning Rate: 0.000723 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10425/12542 | Batch Loss: 1.0865 | Learning Rate: 0.000723 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10426/12542 | Batch Loss: 0.6974 | Learning Rate: 0.000723 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10427/12542 | Batch Loss: 2.2023 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10428/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10429/12542 | Batch Loss: 1.1245 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10430/12542 | Batch Loss: 1.3429 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10431/12542 | Batch Loss: 2.7221 | Learning Rate: 0.000723 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10432/12542 | Batch Loss: 1.5276 | Learning Rate: 0.000723 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10433/12542 | Batch Loss: 0.9639 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10434/12542 | Batch Loss: 2.7072 | Learning Rate: 0.000723 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10435/12542 | Batch Loss: 1.4040 | Learning Rate: 0.000723 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10436/12542 | Batch Loss: 0.7977 | Learning Rate: 0.000723 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10437/12542 | Batch Loss: 1.0950 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10438/12542 | Batch Loss: 0.8657 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10439/12542 | Batch Loss: 1.3289 | Learning Rate: 0.000723 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10440/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10441/12542 | Batch Loss: 0.7637 | Learning Rate: 0.000723 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10442/12542 | Batch Loss: 1.9598 | Learning Rate: 0.000722 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10443/12542 | Batch Loss: 2.9156 | Learning Rate: 0.000722 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10444/12542 | Batch Loss: 0.6727 | Learning Rate: 0.000722 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10445/12542 | Batch Loss: 1.5687 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10446/12542 | Batch Loss: 0.5892 | Learning Rate: 0.000722 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10447/12542 | Batch Loss: 1.3734 | Learning Rate: 0.000722 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10448/12542 | Batch Loss: 0.9253 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10449/12542 | Batch Loss: 1.9760 | Learning Rate: 0.000722 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10450/12542 | Batch Loss: 1.3316 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10451/12542 | Batch Loss: 1.5091 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10452/12542 | Batch Loss: 0.6794 | Learning Rate: 0.000722 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10453/12542 | Batch Loss: 0.9477 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10454/12542 | Batch Loss: 1.1890 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10455/12542 | Batch Loss: 1.9752 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10456/12542 | Batch Loss: 3.7604 | Learning Rate: 0.000722 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10457/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000722 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10458/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000722 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10459/12542 | Batch Loss: 2.1985 | Learning Rate: 0.000722 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10460/12542 | Batch Loss: 1.1880 | Learning Rate: 0.000722 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10461/12542 | Batch Loss: 2.1882 | Learning Rate: 0.000722 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10462/12542 | Batch Loss: 1.8135 | Learning Rate: 0.000722 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10463/12542 | Batch Loss: 1.8939 | Learning Rate: 0.000722 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10464/12542 | Batch Loss: 0.8360 | Learning Rate: 0.000722 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10465/12542 | Batch Loss: 1.3404 | Learning Rate: 0.000722 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10466/12542 | Batch Loss: 3.2007 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10467/12542 | Batch Loss: 1.7725 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10468/12542 | Batch Loss: 2.2999 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10469/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10470/12542 | Batch Loss: 1.6319 | Learning Rate: 0.000722 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10471/12542 | Batch Loss: 2.0302 | Learning Rate: 0.000722 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10472/12542 | Batch Loss: 1.4510 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10473/12542 | Batch Loss: 0.8675 | Learning Rate: 0.000722 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10474/12542 | Batch Loss: 0.9293 | Learning Rate: 0.000722 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10475/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000722 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10476/12542 | Batch Loss: 2.9695 | Learning Rate: 0.000722 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10477/12542 | Batch Loss: 1.5254 | Learning Rate: 0.000722 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10478/12542 | Batch Loss: 0.7538 | Learning Rate: 0.000722 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10479/12542 | Batch Loss: 2.0192 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10480/12542 | Batch Loss: 1.2395 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10481/12542 | Batch Loss: 1.6896 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10482/12542 | Batch Loss: 0.5759 | Learning Rate: 0.000721 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10483/12542 | Batch Loss: 1.6471 | Learning Rate: 0.000721 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 10484/12542 | Batch Loss: 1.6168 | Learning Rate: 0.000721 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10485/12542 | Batch Loss: 1.3532 | Learning Rate: 0.000721 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10486/12542 | Batch Loss: 1.4142 | Learning Rate: 0.000721 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10487/12542 | Batch Loss: 1.8689 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10488/12542 | Batch Loss: 1.7869 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10489/12542 | Batch Loss: 1.1955 | Learning Rate: 0.000721 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10490/12542 | Batch Loss: 2.2252 | Learning Rate: 0.000721 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10491/12542 | Batch Loss: 1.6794 | Learning Rate: 0.000721 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10492/12542 | Batch Loss: 0.9914 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10493/12542 | Batch Loss: 1.5958 | Learning Rate: 0.000721 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10494/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000721 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10495/12542 | Batch Loss: 1.2361 | Learning Rate: 0.000721 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10496/12542 | Batch Loss: 1.1405 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10497/12542 | Batch Loss: 1.1509 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10498/12542 | Batch Loss: 1.8180 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10499/12542 | Batch Loss: 1.4244 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10500/12542 | Batch Loss: 1.1882 | Learning Rate: 0.000721 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10501/12542 | Batch Loss: 2.1774 | Learning Rate: 0.000721 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10502/12542 | Batch Loss: 4.8054 | Learning Rate: 0.000721 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10503/12542 | Batch Loss: 1.9522 | Learning Rate: 0.000721 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10504/12542 | Batch Loss: 1.4619 | Learning Rate: 0.000721 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10505/12542 | Batch Loss: 1.1532 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10506/12542 | Batch Loss: 1.5507 | Learning Rate: 0.000721 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10507/12542 | Batch Loss: 1.7572 | Learning Rate: 0.000721 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10508/12542 | Batch Loss: 2.5838 | Learning Rate: 0.000721 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 10509/12542 | Batch Loss: 1.9534 | Learning Rate: 0.000721 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10510/12542 | Batch Loss: 1.0364 | Learning Rate: 0.000721 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10511/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000721 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10512/12542 | Batch Loss: 2.7559 | Learning Rate: 0.000721 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10513/12542 | Batch Loss: 1.6135 | Learning Rate: 0.000721 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10514/12542 | Batch Loss: 0.4815 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10515/12542 | Batch Loss: 0.6377 | Learning Rate: 0.000721 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10516/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000721 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10517/12542 | Batch Loss: 1.0467 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10518/12542 | Batch Loss: 0.7685 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10519/12542 | Batch Loss: 2.1991 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10520/12542 | Batch Loss: 1.1087 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10521/12542 | Batch Loss: 0.4444 | Learning Rate: 0.000720 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10522/12542 | Batch Loss: 0.5583 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10523/12542 | Batch Loss: 0.7856 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10524/12542 | Batch Loss: 1.9571 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10525/12542 | Batch Loss: 0.9119 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10526/12542 | Batch Loss: 0.6616 | Learning Rate: 0.000720 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10527/12542 | Batch Loss: 0.9985 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10528/12542 | Batch Loss: 1.1369 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10529/12542 | Batch Loss: 1.1337 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10530/12542 | Batch Loss: 2.0581 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10531/12542 | Batch Loss: 1.3626 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10532/12542 | Batch Loss: 2.0023 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10533/12542 | Batch Loss: 1.5422 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10534/12542 | Batch Loss: 1.1091 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10535/12542 | Batch Loss: 1.4107 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10536/12542 | Batch Loss: 1.2621 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10537/12542 | Batch Loss: 1.6419 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10538/12542 | Batch Loss: 1.3619 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10539/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000720 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10540/12542 | Batch Loss: 3.0333 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10541/12542 | Batch Loss: 2.3549 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10542/12542 | Batch Loss: 0.9354 | Learning Rate: 0.000720 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10543/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10544/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10545/12542 | Batch Loss: 1.9923 | Learning Rate: 0.000720 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10546/12542 | Batch Loss: 0.8164 | Learning Rate: 0.000720 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10547/12542 | Batch Loss: 0.8505 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10548/12542 | Batch Loss: 2.1134 | Learning Rate: 0.000720 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10549/12542 | Batch Loss: 1.3942 | Learning Rate: 0.000720 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10550/12542 | Batch Loss: 1.5750 | Learning Rate: 0.000720 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10551/12542 | Batch Loss: 1.2218 | Learning Rate: 0.000720 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10552/12542 | Batch Loss: 1.1091 | Learning Rate: 0.000720 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10553/12542 | Batch Loss: 1.6281 | Learning Rate: 0.000720 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10554/12542 | Batch Loss: 0.9448 | Learning Rate: 0.000720 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10555/12542 | Batch Loss: 0.8555 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10556/12542 | Batch Loss: 0.8446 | Learning Rate: 0.000719 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10557/12542 | Batch Loss: 0.9335 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10558/12542 | Batch Loss: 1.1516 | Learning Rate: 0.000719 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10559/12542 | Batch Loss: 1.0965 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10560/12542 | Batch Loss: 1.3486 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10561/12542 | Batch Loss: 0.9128 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10562/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10563/12542 | Batch Loss: 1.7803 | Learning Rate: 0.000719 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10564/12542 | Batch Loss: 2.2295 | Learning Rate: 0.000719 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10565/12542 | Batch Loss: 0.8890 | Learning Rate: 0.000719 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10566/12542 | Batch Loss: 0.7972 | Learning Rate: 0.000719 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10567/12542 | Batch Loss: 2.1428 | Learning Rate: 0.000719 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10568/12542 | Batch Loss: 1.0928 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10569/12542 | Batch Loss: 0.6879 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10570/12542 | Batch Loss: 2.0378 | Learning Rate: 0.000719 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10571/12542 | Batch Loss: 1.7605 | Learning Rate: 0.000719 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10572/12542 | Batch Loss: 1.2932 | Learning Rate: 0.000719 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10573/12542 | Batch Loss: 1.3071 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10574/12542 | Batch Loss: 1.8298 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10575/12542 | Batch Loss: 1.3224 | Learning Rate: 0.000719 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10576/12542 | Batch Loss: 2.2588 | Learning Rate: 0.000719 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10577/12542 | Batch Loss: 1.4478 | Learning Rate: 0.000719 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10578/12542 | Batch Loss: 0.7432 | Learning Rate: 0.000719 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10579/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000719 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10580/12542 | Batch Loss: 3.6203 | Learning Rate: 0.000719 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10581/12542 | Batch Loss: 2.3237 | Learning Rate: 0.000719 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10582/12542 | Batch Loss: 1.4756 | Learning Rate: 0.000719 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10583/12542 | Batch Loss: 2.1866 | Learning Rate: 0.000719 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10584/12542 | Batch Loss: 1.0032 | Learning Rate: 0.000719 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10585/12542 | Batch Loss: 2.0272 | Learning Rate: 0.000719 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10586/12542 | Batch Loss: 0.9233 | Learning Rate: 0.000719 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10587/12542 | Batch Loss: 1.1280 | Learning Rate: 0.000719 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10588/12542 | Batch Loss: 1.8023 | Learning Rate: 0.000719 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10589/12542 | Batch Loss: 1.1926 | Learning Rate: 0.000719 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10590/12542 | Batch Loss: 1.9734 | Learning Rate: 0.000719 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 10591/12542 | Batch Loss: 1.0385 | Learning Rate: 0.000719 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 10592/12542 | Batch Loss: 0.9300 | Learning Rate: 0.000718 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10593/12542 | Batch Loss: 0.8345 | Learning Rate: 0.000718 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10594/12542 | Batch Loss: 1.3618 | Learning Rate: 0.000718 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10595/12542 | Batch Loss: 1.2532 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10596/12542 | Batch Loss: 1.6311 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10597/12542 | Batch Loss: 1.5006 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10598/12542 | Batch Loss: 2.3137 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10599/12542 | Batch Loss: 1.5474 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10600/12542 | Batch Loss: 1.7184 | Learning Rate: 0.000718 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10601/12542 | Batch Loss: 1.2471 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10602/12542 | Batch Loss: 1.1929 | Learning Rate: 0.000718 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10603/12542 | Batch Loss: 1.0425 | Learning Rate: 0.000718 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10604/12542 | Batch Loss: 1.3655 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10605/12542 | Batch Loss: 3.0362 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10606/12542 | Batch Loss: 0.8947 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10607/12542 | Batch Loss: 1.8603 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10608/12542 | Batch Loss: 1.5198 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10609/12542 | Batch Loss: 1.3115 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10610/12542 | Batch Loss: 1.4622 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10611/12542 | Batch Loss: 1.2311 | Learning Rate: 0.000718 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10612/12542 | Batch Loss: 1.0015 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10613/12542 | Batch Loss: 1.4223 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10614/12542 | Batch Loss: 0.6877 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10615/12542 | Batch Loss: 1.2799 | Learning Rate: 0.000718 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10616/12542 | Batch Loss: 0.4298 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10617/12542 | Batch Loss: 2.4652 | Learning Rate: 0.000718 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10618/12542 | Batch Loss: 1.1767 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10619/12542 | Batch Loss: 1.5920 | Learning Rate: 0.000718 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10620/12542 | Batch Loss: 1.4689 | Learning Rate: 0.000718 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 10621/12542 | Batch Loss: 0.5104 | Learning Rate: 0.000718 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10622/12542 | Batch Loss: 1.2380 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10623/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000718 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10624/12542 | Batch Loss: 1.5369 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10625/12542 | Batch Loss: 1.3173 | Learning Rate: 0.000718 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10626/12542 | Batch Loss: 1.1375 | Learning Rate: 0.000718 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10627/12542 | Batch Loss: 1.4492 | Learning Rate: 0.000718 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10628/12542 | Batch Loss: 1.2662 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10629/12542 | Batch Loss: 1.6991 | Learning Rate: 0.000718 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10630/12542 | Batch Loss: 3.2218 | Learning Rate: 0.000717 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10631/12542 | Batch Loss: 1.5043 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10632/12542 | Batch Loss: 1.1499 | Learning Rate: 0.000717 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10633/12542 | Batch Loss: 0.8996 | Learning Rate: 0.000717 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10634/12542 | Batch Loss: 1.0834 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10635/12542 | Batch Loss: 1.3492 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10636/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10637/12542 | Batch Loss: 2.1594 | Learning Rate: 0.000717 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10638/12542 | Batch Loss: 1.1844 | Learning Rate: 0.000717 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10639/12542 | Batch Loss: 1.3877 | Learning Rate: 0.000717 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10640/12542 | Batch Loss: 0.9420 | Learning Rate: 0.000717 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10641/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000717 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10642/12542 | Batch Loss: 2.5594 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10643/12542 | Batch Loss: 1.2720 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10644/12542 | Batch Loss: 2.3143 | Learning Rate: 0.000717 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10645/12542 | Batch Loss: 1.6198 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10646/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10647/12542 | Batch Loss: 1.3090 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10648/12542 | Batch Loss: 0.8047 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10649/12542 | Batch Loss: 0.9817 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10650/12542 | Batch Loss: 1.7542 | Learning Rate: 0.000717 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10651/12542 | Batch Loss: 1.1655 | Learning Rate: 0.000717 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10652/12542 | Batch Loss: 1.7849 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10653/12542 | Batch Loss: 1.1637 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10654/12542 | Batch Loss: 0.8476 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10655/12542 | Batch Loss: 2.1987 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10656/12542 | Batch Loss: 0.5877 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10657/12542 | Batch Loss: 0.6107 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10658/12542 | Batch Loss: 0.4080 | Learning Rate: 0.000717 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10659/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000717 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10660/12542 | Batch Loss: 0.7070 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10661/12542 | Batch Loss: 2.4108 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10662/12542 | Batch Loss: 1.3440 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10663/12542 | Batch Loss: 0.7502 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10664/12542 | Batch Loss: 1.0927 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10665/12542 | Batch Loss: 1.3414 | Learning Rate: 0.000717 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10666/12542 | Batch Loss: 4.1282 | Learning Rate: 0.000717 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10667/12542 | Batch Loss: 0.3114 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10668/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10669/12542 | Batch Loss: 2.7768 | Learning Rate: 0.000716 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10670/12542 | Batch Loss: 0.6031 | Learning Rate: 0.000716 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10671/12542 | Batch Loss: 1.5462 | Learning Rate: 0.000716 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10672/12542 | Batch Loss: 1.3939 | Learning Rate: 0.000716 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10673/12542 | Batch Loss: 1.3430 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10674/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000716 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10675/12542 | Batch Loss: 1.7396 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10676/12542 | Batch Loss: 0.5126 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10677/12542 | Batch Loss: 1.6840 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10678/12542 | Batch Loss: 0.5177 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10679/12542 | Batch Loss: 2.7801 | Learning Rate: 0.000716 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10680/12542 | Batch Loss: 2.1915 | Learning Rate: 0.000716 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10681/12542 | Batch Loss: 2.3725 | Learning Rate: 0.000716 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10682/12542 | Batch Loss: 1.3768 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10683/12542 | Batch Loss: 1.8901 | Learning Rate: 0.000716 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10684/12542 | Batch Loss: 1.5656 | Learning Rate: 0.000716 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10685/12542 | Batch Loss: 1.4453 | Learning Rate: 0.000716 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10686/12542 | Batch Loss: 0.8479 | Learning Rate: 0.000716 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10687/12542 | Batch Loss: 1.2545 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10688/12542 | Batch Loss: 0.4769 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10689/12542 | Batch Loss: 1.0226 | Learning Rate: 0.000716 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10690/12542 | Batch Loss: 1.7717 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10691/12542 | Batch Loss: 1.2861 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10692/12542 | Batch Loss: 0.9190 | Learning Rate: 0.000716 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10693/12542 | Batch Loss: 1.5489 | Learning Rate: 0.000716 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10694/12542 | Batch Loss: 1.6299 | Learning Rate: 0.000716 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10695/12542 | Batch Loss: 1.2271 | Learning Rate: 0.000716 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10696/12542 | Batch Loss: 0.7640 | Learning Rate: 0.000716 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10697/12542 | Batch Loss: 0.7960 | Learning Rate: 0.000716 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10698/12542 | Batch Loss: 0.7882 | Learning Rate: 0.000716 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10699/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000716 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10700/12542 | Batch Loss: 1.6777 | Learning Rate: 0.000716 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10701/12542 | Batch Loss: 2.0793 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10702/12542 | Batch Loss: 0.6444 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10703/12542 | Batch Loss: 0.9818 | Learning Rate: 0.000716 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10704/12542 | Batch Loss: 1.0241 | Learning Rate: 0.000716 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10705/12542 | Batch Loss: 1.0564 | Learning Rate: 0.000715 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10706/12542 | Batch Loss: 1.1950 | Learning Rate: 0.000715 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10707/12542 | Batch Loss: 0.5361 | Learning Rate: 0.000715 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10708/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000715 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10709/12542 | Batch Loss: 1.1129 | Learning Rate: 0.000715 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10710/12542 | Batch Loss: 0.6509 | Learning Rate: 0.000715 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10711/12542 | Batch Loss: 1.9680 | Learning Rate: 0.000715 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 10712/12542 | Batch Loss: 1.2705 | Learning Rate: 0.000715 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10713/12542 | Batch Loss: 1.1819 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10714/12542 | Batch Loss: 0.6632 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10715/12542 | Batch Loss: 1.0552 | Learning Rate: 0.000715 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10716/12542 | Batch Loss: 1.5807 | Learning Rate: 0.000715 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10717/12542 | Batch Loss: 1.2827 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10718/12542 | Batch Loss: 2.4982 | Learning Rate: 0.000715 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10719/12542 | Batch Loss: 1.1013 | Learning Rate: 0.000715 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10720/12542 | Batch Loss: 1.3038 | Learning Rate: 0.000715 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10721/12542 | Batch Loss: 1.8583 | Learning Rate: 0.000715 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10722/12542 | Batch Loss: 1.8996 | Learning Rate: 0.000715 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10723/12542 | Batch Loss: 0.9092 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10724/12542 | Batch Loss: 1.6622 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10725/12542 | Batch Loss: 2.9782 | Learning Rate: 0.000715 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10726/12542 | Batch Loss: 1.9194 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10727/12542 | Batch Loss: 2.5476 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10728/12542 | Batch Loss: 1.4363 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10729/12542 | Batch Loss: 3.6619 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10730/12542 | Batch Loss: 2.0720 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10731/12542 | Batch Loss: 1.3656 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10732/12542 | Batch Loss: 1.9049 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10733/12542 | Batch Loss: 1.5526 | Learning Rate: 0.000715 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10734/12542 | Batch Loss: 1.8711 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10735/12542 | Batch Loss: 1.0503 | Learning Rate: 0.000715 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10736/12542 | Batch Loss: 2.8387 | Learning Rate: 0.000715 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10737/12542 | Batch Loss: 1.4618 | Learning Rate: 0.000715 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10738/12542 | Batch Loss: 0.7418 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10739/12542 | Batch Loss: 1.0235 | Learning Rate: 0.000715 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10740/12542 | Batch Loss: 0.4064 | Learning Rate: 0.000715 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10741/12542 | Batch Loss: 0.7678 | Learning Rate: 0.000715 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10742/12542 | Batch Loss: 0.9742 | Learning Rate: 0.000715 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10743/12542 | Batch Loss: 0.6453 | Learning Rate: 0.000714 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10744/12542 | Batch Loss: 0.7970 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10745/12542 | Batch Loss: 1.5153 | Learning Rate: 0.000714 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10746/12542 | Batch Loss: 1.3868 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10747/12542 | Batch Loss: 1.5068 | Learning Rate: 0.000714 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10748/12542 | Batch Loss: 1.6945 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10749/12542 | Batch Loss: 1.6712 | Learning Rate: 0.000714 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10750/12542 | Batch Loss: 1.4929 | Learning Rate: 0.000714 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10751/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10752/12542 | Batch Loss: 1.3559 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10753/12542 | Batch Loss: 1.8994 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10754/12542 | Batch Loss: 1.1557 | Learning Rate: 0.000714 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10755/12542 | Batch Loss: 1.5989 | Learning Rate: 0.000714 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10756/12542 | Batch Loss: 1.3228 | Learning Rate: 0.000714 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 10757/12542 | Batch Loss: 1.9730 | Learning Rate: 0.000714 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 10758/12542 | Batch Loss: 0.9683 | Learning Rate: 0.000714 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 10759/12542 | Batch Loss: 0.8134 | Learning Rate: 0.000714 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10760/12542 | Batch Loss: 0.7846 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10761/12542 | Batch Loss: 1.6653 | Learning Rate: 0.000714 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10762/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10763/12542 | Batch Loss: 1.1610 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10764/12542 | Batch Loss: 1.5434 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10765/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10766/12542 | Batch Loss: 1.5660 | Learning Rate: 0.000714 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10767/12542 | Batch Loss: 1.1599 | Learning Rate: 0.000714 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10768/12542 | Batch Loss: 0.9115 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10769/12542 | Batch Loss: 1.7878 | Learning Rate: 0.000714 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10770/12542 | Batch Loss: 1.2946 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10771/12542 | Batch Loss: 0.8532 | Learning Rate: 0.000714 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10772/12542 | Batch Loss: 0.8940 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10773/12542 | Batch Loss: 1.3700 | Learning Rate: 0.000714 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10774/12542 | Batch Loss: 1.5230 | Learning Rate: 0.000714 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10775/12542 | Batch Loss: 0.8318 | Learning Rate: 0.000714 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10776/12542 | Batch Loss: 1.1572 | Learning Rate: 0.000714 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 10777/12542 | Batch Loss: 0.4957 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10778/12542 | Batch Loss: 1.8802 | Learning Rate: 0.000714 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10779/12542 | Batch Loss: 0.6519 | Learning Rate: 0.000714 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10780/12542 | Batch Loss: 1.0510 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10781/12542 | Batch Loss: 1.4238 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10782/12542 | Batch Loss: 0.8149 | Learning Rate: 0.000713 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10783/12542 | Batch Loss: 0.7600 | Learning Rate: 0.000713 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 10784/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000713 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10785/12542 | Batch Loss: 0.8823 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10786/12542 | Batch Loss: 0.6192 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10787/12542 | Batch Loss: 0.6861 | Learning Rate: 0.000713 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10788/12542 | Batch Loss: 1.4660 | Learning Rate: 0.000713 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10789/12542 | Batch Loss: 1.8286 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10790/12542 | Batch Loss: 0.5312 | Learning Rate: 0.000713 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10791/12542 | Batch Loss: 1.4462 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10792/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10793/12542 | Batch Loss: 1.2694 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10794/12542 | Batch Loss: 1.2694 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10795/12542 | Batch Loss: 1.0045 | Learning Rate: 0.000713 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10796/12542 | Batch Loss: 1.4697 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10797/12542 | Batch Loss: 2.4172 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10798/12542 | Batch Loss: 0.9707 | Learning Rate: 0.000713 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10799/12542 | Batch Loss: 0.6241 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10800/12542 | Batch Loss: 1.7391 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10801/12542 | Batch Loss: 0.8572 | Learning Rate: 0.000713 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10802/12542 | Batch Loss: 2.3612 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10803/12542 | Batch Loss: 0.8073 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10804/12542 | Batch Loss: 1.2485 | Learning Rate: 0.000713 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10805/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000713 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10806/12542 | Batch Loss: 1.6687 | Learning Rate: 0.000713 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10807/12542 | Batch Loss: 1.1071 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10808/12542 | Batch Loss: 0.6417 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10809/12542 | Batch Loss: 2.5599 | Learning Rate: 0.000713 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10810/12542 | Batch Loss: 1.0156 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10811/12542 | Batch Loss: 2.2384 | Learning Rate: 0.000713 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10812/12542 | Batch Loss: 0.9265 | Learning Rate: 0.000713 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10813/12542 | Batch Loss: 1.7096 | Learning Rate: 0.000713 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10814/12542 | Batch Loss: 2.2671 | Learning Rate: 0.000713 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10815/12542 | Batch Loss: 3.0329 | Learning Rate: 0.000713 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10816/12542 | Batch Loss: 0.5048 | Learning Rate: 0.000713 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10817/12542 | Batch Loss: 0.6577 | Learning Rate: 0.000713 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10818/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000712 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10819/12542 | Batch Loss: 1.0842 | Learning Rate: 0.000712 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10820/12542 | Batch Loss: 2.3624 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10821/12542 | Batch Loss: 1.3763 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10822/12542 | Batch Loss: 1.5947 | Learning Rate: 0.000712 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10823/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10824/12542 | Batch Loss: 0.9874 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10825/12542 | Batch Loss: 1.5394 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10826/12542 | Batch Loss: 0.7170 | Learning Rate: 0.000712 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10827/12542 | Batch Loss: 1.1068 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10828/12542 | Batch Loss: 1.4011 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10829/12542 | Batch Loss: 1.7801 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10830/12542 | Batch Loss: 0.7743 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10831/12542 | Batch Loss: 0.8975 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10832/12542 | Batch Loss: 1.7337 | Learning Rate: 0.000712 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10833/12542 | Batch Loss: 1.5971 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10834/12542 | Batch Loss: 0.5095 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10835/12542 | Batch Loss: 0.5731 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10836/12542 | Batch Loss: 0.8391 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10837/12542 | Batch Loss: 1.3409 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10838/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10839/12542 | Batch Loss: 0.9267 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10840/12542 | Batch Loss: 0.6231 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10841/12542 | Batch Loss: 0.9719 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10842/12542 | Batch Loss: 1.4741 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10843/12542 | Batch Loss: 1.6038 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10844/12542 | Batch Loss: 2.6736 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10845/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10846/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10847/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000712 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10848/12542 | Batch Loss: 1.8782 | Learning Rate: 0.000712 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10849/12542 | Batch Loss: 1.3697 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10850/12542 | Batch Loss: 0.7122 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10851/12542 | Batch Loss: 2.8971 | Learning Rate: 0.000712 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10852/12542 | Batch Loss: 0.6998 | Learning Rate: 0.000712 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 10853/12542 | Batch Loss: 2.2922 | Learning Rate: 0.000712 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10854/12542 | Batch Loss: 1.6995 | Learning Rate: 0.000712 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10855/12542 | Batch Loss: 0.8463 | Learning Rate: 0.000712 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10856/12542 | Batch Loss: 1.0072 | Learning Rate: 0.000711 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10857/12542 | Batch Loss: 1.1571 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10858/12542 | Batch Loss: 2.8976 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10859/12542 | Batch Loss: 2.3138 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10860/12542 | Batch Loss: 1.5327 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10861/12542 | Batch Loss: 0.8411 | Learning Rate: 0.000711 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10862/12542 | Batch Loss: 1.3597 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10863/12542 | Batch Loss: 1.5031 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10864/12542 | Batch Loss: 1.3288 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10865/12542 | Batch Loss: 0.8113 | Learning Rate: 0.000711 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10866/12542 | Batch Loss: 1.5124 | Learning Rate: 0.000711 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10867/12542 | Batch Loss: 1.5112 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10868/12542 | Batch Loss: 1.9557 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10869/12542 | Batch Loss: 0.6896 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10870/12542 | Batch Loss: 1.5075 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10871/12542 | Batch Loss: 1.0116 | Learning Rate: 0.000711 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10872/12542 | Batch Loss: 1.0356 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10873/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000711 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10874/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10875/12542 | Batch Loss: 0.5831 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10876/12542 | Batch Loss: 1.6511 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10877/12542 | Batch Loss: 1.5374 | Learning Rate: 0.000711 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10878/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10879/12542 | Batch Loss: 1.7324 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10880/12542 | Batch Loss: 2.1531 | Learning Rate: 0.000711 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10881/12542 | Batch Loss: 1.5515 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10882/12542 | Batch Loss: 0.5689 | Learning Rate: 0.000711 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10883/12542 | Batch Loss: 1.5690 | Learning Rate: 0.000711 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10884/12542 | Batch Loss: 1.2364 | Learning Rate: 0.000711 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10885/12542 | Batch Loss: 0.8955 | Learning Rate: 0.000711 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10886/12542 | Batch Loss: 2.4881 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10887/12542 | Batch Loss: 1.6692 | Learning Rate: 0.000711 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10888/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000711 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10889/12542 | Batch Loss: 0.9332 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10890/12542 | Batch Loss: 0.6303 | Learning Rate: 0.000711 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10891/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000711 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10892/12542 | Batch Loss: 0.5375 | Learning Rate: 0.000711 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10893/12542 | Batch Loss: 1.4009 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10894/12542 | Batch Loss: 0.8518 | Learning Rate: 0.000710 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10895/12542 | Batch Loss: 1.4000 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10896/12542 | Batch Loss: 1.5813 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10897/12542 | Batch Loss: 1.2660 | Learning Rate: 0.000710 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10898/12542 | Batch Loss: 1.7126 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10899/12542 | Batch Loss: 0.9645 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10900/12542 | Batch Loss: 0.7772 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10901/12542 | Batch Loss: 1.8838 | Learning Rate: 0.000710 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10902/12542 | Batch Loss: 1.1839 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10903/12542 | Batch Loss: 1.6324 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10904/12542 | Batch Loss: 3.1744 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10905/12542 | Batch Loss: 1.1739 | Learning Rate: 0.000710 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10906/12542 | Batch Loss: 1.4790 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10907/12542 | Batch Loss: 1.2508 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10908/12542 | Batch Loss: 0.8503 | Learning Rate: 0.000710 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 10909/12542 | Batch Loss: 0.9343 | Learning Rate: 0.000710 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10910/12542 | Batch Loss: 1.6947 | Learning Rate: 0.000710 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10911/12542 | Batch Loss: 0.8972 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10912/12542 | Batch Loss: 2.1647 | Learning Rate: 0.000710 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 10913/12542 | Batch Loss: 2.8304 | Learning Rate: 0.000710 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10914/12542 | Batch Loss: 1.9924 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10915/12542 | Batch Loss: 1.2368 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10916/12542 | Batch Loss: 0.8210 | Learning Rate: 0.000710 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10917/12542 | Batch Loss: 0.9537 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10918/12542 | Batch Loss: 0.7828 | Learning Rate: 0.000710 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10919/12542 | Batch Loss: 0.9189 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10920/12542 | Batch Loss: 1.7695 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10921/12542 | Batch Loss: 0.8168 | Learning Rate: 0.000710 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 10922/12542 | Batch Loss: 0.5587 | Learning Rate: 0.000710 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10923/12542 | Batch Loss: 1.4752 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10924/12542 | Batch Loss: 1.0873 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10925/12542 | Batch Loss: 0.5398 | Learning Rate: 0.000710 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10926/12542 | Batch Loss: 1.6361 | Learning Rate: 0.000710 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10927/12542 | Batch Loss: 1.0538 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10928/12542 | Batch Loss: 1.3029 | Learning Rate: 0.000710 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10929/12542 | Batch Loss: 2.1386 | Learning Rate: 0.000710 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10930/12542 | Batch Loss: 1.6734 | Learning Rate: 0.000710 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10931/12542 | Batch Loss: 1.4199 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10932/12542 | Batch Loss: 1.3636 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10933/12542 | Batch Loss: 2.4231 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10934/12542 | Batch Loss: 2.6266 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10935/12542 | Batch Loss: 1.3721 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10936/12542 | Batch Loss: 0.7271 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10937/12542 | Batch Loss: 1.8837 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10938/12542 | Batch Loss: 1.0899 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10939/12542 | Batch Loss: 0.6369 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10940/12542 | Batch Loss: 1.0833 | Learning Rate: 0.000709 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 10941/12542 | Batch Loss: 1.3699 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10942/12542 | Batch Loss: 0.9176 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10943/12542 | Batch Loss: 1.6788 | Learning Rate: 0.000709 | Batch Time: 0.55s\n",
      "Epoch 1 | Step 10944/12542 | Batch Loss: 0.5317 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10945/12542 | Batch Loss: 0.8969 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10946/12542 | Batch Loss: 1.3217 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10947/12542 | Batch Loss: 3.5792 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10948/12542 | Batch Loss: 1.3179 | Learning Rate: 0.000709 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10949/12542 | Batch Loss: 0.9429 | Learning Rate: 0.000709 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10950/12542 | Batch Loss: 2.0177 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10951/12542 | Batch Loss: 1.4514 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10952/12542 | Batch Loss: 0.8235 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10953/12542 | Batch Loss: 0.8061 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10954/12542 | Batch Loss: 2.3077 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10955/12542 | Batch Loss: 1.3035 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10956/12542 | Batch Loss: 1.3416 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10957/12542 | Batch Loss: 1.7266 | Learning Rate: 0.000709 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10958/12542 | Batch Loss: 1.1591 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10959/12542 | Batch Loss: 0.8785 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10960/12542 | Batch Loss: 2.1807 | Learning Rate: 0.000709 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10961/12542 | Batch Loss: 1.5267 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10962/12542 | Batch Loss: 1.3746 | Learning Rate: 0.000709 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 10963/12542 | Batch Loss: 1.2965 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10964/12542 | Batch Loss: 1.6186 | Learning Rate: 0.000709 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10965/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000709 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10966/12542 | Batch Loss: 1.3922 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10967/12542 | Batch Loss: 1.0873 | Learning Rate: 0.000709 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10968/12542 | Batch Loss: 0.9436 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10969/12542 | Batch Loss: 0.8727 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10970/12542 | Batch Loss: 1.4404 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10971/12542 | Batch Loss: 0.8696 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10972/12542 | Batch Loss: 1.0297 | Learning Rate: 0.000708 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10973/12542 | Batch Loss: 1.2835 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10974/12542 | Batch Loss: 1.9144 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10975/12542 | Batch Loss: 0.9771 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10976/12542 | Batch Loss: 0.7575 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10977/12542 | Batch Loss: 0.3836 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10978/12542 | Batch Loss: 1.4908 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10979/12542 | Batch Loss: 1.1958 | Learning Rate: 0.000708 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10980/12542 | Batch Loss: 1.5516 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10981/12542 | Batch Loss: 0.7359 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10982/12542 | Batch Loss: 1.2286 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10983/12542 | Batch Loss: 1.5915 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10984/12542 | Batch Loss: 2.3697 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10985/12542 | Batch Loss: 0.7321 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10986/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10987/12542 | Batch Loss: 2.6803 | Learning Rate: 0.000708 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 10988/12542 | Batch Loss: 0.7978 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10989/12542 | Batch Loss: 2.1353 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10990/12542 | Batch Loss: 1.7912 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10991/12542 | Batch Loss: 1.3361 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10992/12542 | Batch Loss: 0.8632 | Learning Rate: 0.000708 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 10993/12542 | Batch Loss: 2.0125 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10994/12542 | Batch Loss: 0.9140 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10995/12542 | Batch Loss: 0.8246 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10996/12542 | Batch Loss: 2.1790 | Learning Rate: 0.000708 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 10997/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 10998/12542 | Batch Loss: 1.2316 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 10999/12542 | Batch Loss: 1.4786 | Learning Rate: 0.000708 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11000/12542 | Batch Loss: 1.0608 | Learning Rate: 0.000708 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 11001/12542 | Batch Loss: 0.8822 | Learning Rate: 0.000708 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11002/12542 | Batch Loss: 2.6949 | Learning Rate: 0.000708 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11003/12542 | Batch Loss: 1.1320 | Learning Rate: 0.000708 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11004/12542 | Batch Loss: 0.7500 | Learning Rate: 0.000708 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11005/12542 | Batch Loss: 2.0187 | Learning Rate: 0.000708 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11006/12542 | Batch Loss: 0.5898 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11007/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11008/12542 | Batch Loss: 2.6741 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11009/12542 | Batch Loss: 1.5563 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11010/12542 | Batch Loss: 1.3058 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11011/12542 | Batch Loss: 1.7190 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11012/12542 | Batch Loss: 0.9682 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11013/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000707 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11014/12542 | Batch Loss: 0.6698 | Learning Rate: 0.000707 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11015/12542 | Batch Loss: 2.0062 | Learning Rate: 0.000707 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11016/12542 | Batch Loss: 1.7146 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11017/12542 | Batch Loss: 1.4933 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11018/12542 | Batch Loss: 1.7519 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11019/12542 | Batch Loss: 1.9557 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11020/12542 | Batch Loss: 3.0165 | Learning Rate: 0.000707 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11021/12542 | Batch Loss: 2.3025 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11022/12542 | Batch Loss: 1.8006 | Learning Rate: 0.000707 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11023/12542 | Batch Loss: 1.1480 | Learning Rate: 0.000707 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11024/12542 | Batch Loss: 1.3149 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11025/12542 | Batch Loss: 2.2427 | Learning Rate: 0.000707 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11026/12542 | Batch Loss: 0.9843 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11027/12542 | Batch Loss: 2.2199 | Learning Rate: 0.000707 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11028/12542 | Batch Loss: 1.1124 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11029/12542 | Batch Loss: 1.1291 | Learning Rate: 0.000707 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 11030/12542 | Batch Loss: 2.7328 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11031/12542 | Batch Loss: 3.2459 | Learning Rate: 0.000707 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 11032/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000707 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11033/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000707 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11034/12542 | Batch Loss: 1.5580 | Learning Rate: 0.000707 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11035/12542 | Batch Loss: 3.2860 | Learning Rate: 0.000707 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11036/12542 | Batch Loss: 1.2167 | Learning Rate: 0.000707 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11037/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000707 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11038/12542 | Batch Loss: 0.8202 | Learning Rate: 0.000707 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11039/12542 | Batch Loss: 1.2904 | Learning Rate: 0.000707 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11040/12542 | Batch Loss: 1.6286 | Learning Rate: 0.000707 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11041/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000707 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11042/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000707 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11043/12542 | Batch Loss: 0.9553 | Learning Rate: 0.000707 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11044/12542 | Batch Loss: 1.5121 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11045/12542 | Batch Loss: 1.2501 | Learning Rate: 0.000706 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11046/12542 | Batch Loss: 0.8043 | Learning Rate: 0.000706 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11047/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000706 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11048/12542 | Batch Loss: 3.3317 | Learning Rate: 0.000706 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11049/12542 | Batch Loss: 1.1584 | Learning Rate: 0.000706 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11050/12542 | Batch Loss: 1.8249 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11051/12542 | Batch Loss: 0.8939 | Learning Rate: 0.000706 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11052/12542 | Batch Loss: 1.1459 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11053/12542 | Batch Loss: 0.7354 | Learning Rate: 0.000706 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11054/12542 | Batch Loss: 2.4375 | Learning Rate: 0.000706 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11055/12542 | Batch Loss: 1.2060 | Learning Rate: 0.000706 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11056/12542 | Batch Loss: 0.6908 | Learning Rate: 0.000706 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11057/12542 | Batch Loss: 2.0878 | Learning Rate: 0.000706 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11058/12542 | Batch Loss: 1.0267 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11059/12542 | Batch Loss: 1.1803 | Learning Rate: 0.000706 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11060/12542 | Batch Loss: 1.3290 | Learning Rate: 0.000706 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11061/12542 | Batch Loss: 1.0661 | Learning Rate: 0.000706 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11062/12542 | Batch Loss: 0.5266 | Learning Rate: 0.000706 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11063/12542 | Batch Loss: 1.7665 | Learning Rate: 0.000706 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11064/12542 | Batch Loss: 0.9043 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11065/12542 | Batch Loss: 1.6368 | Learning Rate: 0.000706 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11066/12542 | Batch Loss: 1.6747 | Learning Rate: 0.000706 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11067/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000706 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11068/12542 | Batch Loss: 1.3477 | Learning Rate: 0.000706 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11069/12542 | Batch Loss: 1.4803 | Learning Rate: 0.000706 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11070/12542 | Batch Loss: 1.7381 | Learning Rate: 0.000706 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11071/12542 | Batch Loss: 1.3906 | Learning Rate: 0.000706 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11072/12542 | Batch Loss: 0.4970 | Learning Rate: 0.000706 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11073/12542 | Batch Loss: 1.7707 | Learning Rate: 0.000706 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11074/12542 | Batch Loss: 0.7313 | Learning Rate: 0.000706 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11075/12542 | Batch Loss: 2.1283 | Learning Rate: 0.000706 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11076/12542 | Batch Loss: 2.0622 | Learning Rate: 0.000706 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11077/12542 | Batch Loss: 1.2946 | Learning Rate: 0.000706 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11078/12542 | Batch Loss: 1.3600 | Learning Rate: 0.000706 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11079/12542 | Batch Loss: 1.5236 | Learning Rate: 0.000706 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11080/12542 | Batch Loss: 1.4071 | Learning Rate: 0.000706 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11081/12542 | Batch Loss: 1.4142 | Learning Rate: 0.000705 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11082/12542 | Batch Loss: 0.8640 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11083/12542 | Batch Loss: 1.4124 | Learning Rate: 0.000705 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11084/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11085/12542 | Batch Loss: 1.7501 | Learning Rate: 0.000705 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11086/12542 | Batch Loss: 0.8757 | Learning Rate: 0.000705 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11087/12542 | Batch Loss: 1.5271 | Learning Rate: 0.000705 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11088/12542 | Batch Loss: 2.8396 | Learning Rate: 0.000705 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11089/12542 | Batch Loss: 0.9207 | Learning Rate: 0.000705 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11090/12542 | Batch Loss: 0.9761 | Learning Rate: 0.000705 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11091/12542 | Batch Loss: 1.3912 | Learning Rate: 0.000705 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11092/12542 | Batch Loss: 1.4003 | Learning Rate: 0.000705 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11093/12542 | Batch Loss: 1.1262 | Learning Rate: 0.000705 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11094/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000705 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11095/12542 | Batch Loss: 2.2689 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11096/12542 | Batch Loss: 1.3170 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11097/12542 | Batch Loss: 1.8008 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11098/12542 | Batch Loss: 1.1368 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11099/12542 | Batch Loss: 0.8772 | Learning Rate: 0.000705 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11100/12542 | Batch Loss: 1.2881 | Learning Rate: 0.000705 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11101/12542 | Batch Loss: 1.1628 | Learning Rate: 0.000705 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11102/12542 | Batch Loss: 1.6429 | Learning Rate: 0.000705 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11103/12542 | Batch Loss: 0.3551 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11104/12542 | Batch Loss: 1.1489 | Learning Rate: 0.000705 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11105/12542 | Batch Loss: 3.3417 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11106/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000705 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11107/12542 | Batch Loss: 0.7617 | Learning Rate: 0.000705 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11108/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000705 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11109/12542 | Batch Loss: 1.9518 | Learning Rate: 0.000705 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11110/12542 | Batch Loss: 0.7870 | Learning Rate: 0.000705 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11111/12542 | Batch Loss: 1.0198 | Learning Rate: 0.000705 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11112/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000705 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11113/12542 | Batch Loss: 1.7027 | Learning Rate: 0.000705 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11114/12542 | Batch Loss: 1.3953 | Learning Rate: 0.000705 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11115/12542 | Batch Loss: 1.1307 | Learning Rate: 0.000705 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11116/12542 | Batch Loss: 1.4930 | Learning Rate: 0.000705 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11117/12542 | Batch Loss: 1.3233 | Learning Rate: 0.000705 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11118/12542 | Batch Loss: 2.1762 | Learning Rate: 0.000705 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11119/12542 | Batch Loss: 2.3745 | Learning Rate: 0.000704 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11120/12542 | Batch Loss: 0.9059 | Learning Rate: 0.000704 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11121/12542 | Batch Loss: 1.5355 | Learning Rate: 0.000704 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11122/12542 | Batch Loss: 1.1759 | Learning Rate: 0.000704 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11123/12542 | Batch Loss: 0.7104 | Learning Rate: 0.000704 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11124/12542 | Batch Loss: 0.3005 | Learning Rate: 0.000704 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11125/12542 | Batch Loss: 0.8576 | Learning Rate: 0.000704 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11126/12542 | Batch Loss: 1.6907 | Learning Rate: 0.000704 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11127/12542 | Batch Loss: 1.5765 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11128/12542 | Batch Loss: 0.8728 | Learning Rate: 0.000704 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11129/12542 | Batch Loss: 1.0481 | Learning Rate: 0.000704 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11130/12542 | Batch Loss: 1.5042 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11131/12542 | Batch Loss: 2.0456 | Learning Rate: 0.000704 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11132/12542 | Batch Loss: 1.0948 | Learning Rate: 0.000704 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11133/12542 | Batch Loss: 1.5566 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11134/12542 | Batch Loss: 1.7382 | Learning Rate: 0.000704 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11135/12542 | Batch Loss: 2.8961 | Learning Rate: 0.000704 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11136/12542 | Batch Loss: 3.9939 | Learning Rate: 0.000704 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11137/12542 | Batch Loss: 1.0163 | Learning Rate: 0.000704 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11138/12542 | Batch Loss: 1.6144 | Learning Rate: 0.000704 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11139/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000704 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11140/12542 | Batch Loss: 3.6255 | Learning Rate: 0.000704 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11141/12542 | Batch Loss: 1.1885 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11142/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000704 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11143/12542 | Batch Loss: 1.3630 | Learning Rate: 0.000704 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11144/12542 | Batch Loss: 1.4243 | Learning Rate: 0.000704 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11145/12542 | Batch Loss: 1.9681 | Learning Rate: 0.000704 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11146/12542 | Batch Loss: 2.1681 | Learning Rate: 0.000704 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11147/12542 | Batch Loss: 1.1684 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11148/12542 | Batch Loss: 0.8646 | Learning Rate: 0.000704 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11149/12542 | Batch Loss: 0.7634 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11150/12542 | Batch Loss: 1.0626 | Learning Rate: 0.000704 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11151/12542 | Batch Loss: 1.1586 | Learning Rate: 0.000704 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11152/12542 | Batch Loss: 0.6033 | Learning Rate: 0.000704 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11153/12542 | Batch Loss: 1.7196 | Learning Rate: 0.000704 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11154/12542 | Batch Loss: 3.4275 | Learning Rate: 0.000704 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11155/12542 | Batch Loss: 0.8602 | Learning Rate: 0.000704 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11156/12542 | Batch Loss: 1.3159 | Learning Rate: 0.000704 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11157/12542 | Batch Loss: 2.6369 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11158/12542 | Batch Loss: 0.8705 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11159/12542 | Batch Loss: 0.6624 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11160/12542 | Batch Loss: 1.6029 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11161/12542 | Batch Loss: 0.7153 | Learning Rate: 0.000703 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11162/12542 | Batch Loss: 2.0633 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11163/12542 | Batch Loss: 0.8648 | Learning Rate: 0.000703 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11164/12542 | Batch Loss: 0.7745 | Learning Rate: 0.000703 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11165/12542 | Batch Loss: 1.3537 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11166/12542 | Batch Loss: 1.5373 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11167/12542 | Batch Loss: 1.6121 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11168/12542 | Batch Loss: 2.0376 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11169/12542 | Batch Loss: 1.3671 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11170/12542 | Batch Loss: 2.2168 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11171/12542 | Batch Loss: 1.8528 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11172/12542 | Batch Loss: 1.5133 | Learning Rate: 0.000703 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11173/12542 | Batch Loss: 3.1029 | Learning Rate: 0.000703 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11174/12542 | Batch Loss: 0.6225 | Learning Rate: 0.000703 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11175/12542 | Batch Loss: 0.8159 | Learning Rate: 0.000703 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11176/12542 | Batch Loss: 0.8483 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11177/12542 | Batch Loss: 0.3999 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11178/12542 | Batch Loss: 1.5518 | Learning Rate: 0.000703 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11179/12542 | Batch Loss: 1.0559 | Learning Rate: 0.000703 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11180/12542 | Batch Loss: 1.2264 | Learning Rate: 0.000703 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11181/12542 | Batch Loss: 1.4889 | Learning Rate: 0.000703 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11182/12542 | Batch Loss: 0.9293 | Learning Rate: 0.000703 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11183/12542 | Batch Loss: 1.2250 | Learning Rate: 0.000703 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11184/12542 | Batch Loss: 0.6811 | Learning Rate: 0.000703 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11185/12542 | Batch Loss: 1.2461 | Learning Rate: 0.000703 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11186/12542 | Batch Loss: 0.7999 | Learning Rate: 0.000703 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11187/12542 | Batch Loss: 1.1690 | Learning Rate: 0.000703 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11188/12542 | Batch Loss: 2.4202 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11189/12542 | Batch Loss: 0.9937 | Learning Rate: 0.000703 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11190/12542 | Batch Loss: 1.4408 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11191/12542 | Batch Loss: 0.8594 | Learning Rate: 0.000703 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11192/12542 | Batch Loss: 1.3255 | Learning Rate: 0.000703 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11193/12542 | Batch Loss: 1.9513 | Learning Rate: 0.000703 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11194/12542 | Batch Loss: 0.6944 | Learning Rate: 0.000702 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11195/12542 | Batch Loss: 1.5563 | Learning Rate: 0.000702 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11196/12542 | Batch Loss: 2.6096 | Learning Rate: 0.000702 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11197/12542 | Batch Loss: 1.9428 | Learning Rate: 0.000702 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11198/12542 | Batch Loss: 1.3200 | Learning Rate: 0.000702 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11199/12542 | Batch Loss: 1.6307 | Learning Rate: 0.000702 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11200/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000702 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11201/12542 | Batch Loss: 1.6327 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11202/12542 | Batch Loss: 0.9496 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11203/12542 | Batch Loss: 0.5112 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11204/12542 | Batch Loss: 0.7757 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11205/12542 | Batch Loss: 1.3642 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11206/12542 | Batch Loss: 1.4262 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11207/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000702 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11208/12542 | Batch Loss: 3.8051 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11209/12542 | Batch Loss: 2.7240 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11210/12542 | Batch Loss: 1.2129 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11211/12542 | Batch Loss: 0.7011 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11212/12542 | Batch Loss: 1.2312 | Learning Rate: 0.000702 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11213/12542 | Batch Loss: 0.8455 | Learning Rate: 0.000702 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11214/12542 | Batch Loss: 0.4689 | Learning Rate: 0.000702 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11215/12542 | Batch Loss: 0.7762 | Learning Rate: 0.000702 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11216/12542 | Batch Loss: 0.9273 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11217/12542 | Batch Loss: 1.9384 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11218/12542 | Batch Loss: 0.6634 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11219/12542 | Batch Loss: 4.1233 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11220/12542 | Batch Loss: 0.9257 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11221/12542 | Batch Loss: 1.5108 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11222/12542 | Batch Loss: 1.6717 | Learning Rate: 0.000702 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11223/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11224/12542 | Batch Loss: 1.7000 | Learning Rate: 0.000702 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11225/12542 | Batch Loss: 1.3318 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11226/12542 | Batch Loss: 0.8708 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11227/12542 | Batch Loss: 0.7946 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11228/12542 | Batch Loss: 0.9558 | Learning Rate: 0.000702 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11229/12542 | Batch Loss: 1.7727 | Learning Rate: 0.000702 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11230/12542 | Batch Loss: 0.5774 | Learning Rate: 0.000702 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11231/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000702 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11232/12542 | Batch Loss: 1.3855 | Learning Rate: 0.000701 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11233/12542 | Batch Loss: 0.6997 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11234/12542 | Batch Loss: 1.8311 | Learning Rate: 0.000701 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11235/12542 | Batch Loss: 1.6467 | Learning Rate: 0.000701 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11236/12542 | Batch Loss: 1.0383 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11237/12542 | Batch Loss: 1.3978 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11238/12542 | Batch Loss: 0.9035 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11239/12542 | Batch Loss: 0.9680 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11240/12542 | Batch Loss: 1.2043 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11241/12542 | Batch Loss: 1.5707 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11242/12542 | Batch Loss: 0.5165 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11243/12542 | Batch Loss: 2.6716 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11244/12542 | Batch Loss: 0.6860 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11245/12542 | Batch Loss: 1.6893 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11246/12542 | Batch Loss: 1.0511 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11247/12542 | Batch Loss: 1.0330 | Learning Rate: 0.000701 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11248/12542 | Batch Loss: 0.9624 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11249/12542 | Batch Loss: 0.7860 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11250/12542 | Batch Loss: 1.1057 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11251/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000701 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11252/12542 | Batch Loss: 1.1200 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11253/12542 | Batch Loss: 1.5213 | Learning Rate: 0.000701 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11254/12542 | Batch Loss: 1.5827 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11255/12542 | Batch Loss: 1.3162 | Learning Rate: 0.000701 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11256/12542 | Batch Loss: 0.9042 | Learning Rate: 0.000701 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11257/12542 | Batch Loss: 2.2494 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11258/12542 | Batch Loss: 0.5780 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11259/12542 | Batch Loss: 0.5884 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11260/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11261/12542 | Batch Loss: 2.0179 | Learning Rate: 0.000701 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11262/12542 | Batch Loss: 0.5484 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11263/12542 | Batch Loss: 0.6853 | Learning Rate: 0.000701 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11264/12542 | Batch Loss: 1.8347 | Learning Rate: 0.000701 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11265/12542 | Batch Loss: 2.9975 | Learning Rate: 0.000701 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11266/12542 | Batch Loss: 1.4472 | Learning Rate: 0.000701 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11267/12542 | Batch Loss: 1.2762 | Learning Rate: 0.000701 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11268/12542 | Batch Loss: 1.4197 | Learning Rate: 0.000701 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11269/12542 | Batch Loss: 1.0701 | Learning Rate: 0.000700 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11270/12542 | Batch Loss: 1.7844 | Learning Rate: 0.000700 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11271/12542 | Batch Loss: 0.6974 | Learning Rate: 0.000700 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11272/12542 | Batch Loss: 0.9406 | Learning Rate: 0.000700 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11273/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000700 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11274/12542 | Batch Loss: 2.4176 | Learning Rate: 0.000700 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11275/12542 | Batch Loss: 2.2728 | Learning Rate: 0.000700 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11276/12542 | Batch Loss: 1.3917 | Learning Rate: 0.000700 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11277/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000700 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11278/12542 | Batch Loss: 1.2572 | Learning Rate: 0.000700 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11279/12542 | Batch Loss: 1.1486 | Learning Rate: 0.000700 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11280/12542 | Batch Loss: 1.2511 | Learning Rate: 0.000700 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11281/12542 | Batch Loss: 0.7898 | Learning Rate: 0.000700 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11282/12542 | Batch Loss: 0.5883 | Learning Rate: 0.000700 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11283/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000700 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 11284/12542 | Batch Loss: 1.0812 | Learning Rate: 0.000700 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11285/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000700 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11286/12542 | Batch Loss: 2.5651 | Learning Rate: 0.000700 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11287/12542 | Batch Loss: 1.3902 | Learning Rate: 0.000700 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11288/12542 | Batch Loss: 1.3906 | Learning Rate: 0.000700 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11289/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000700 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11290/12542 | Batch Loss: 1.0188 | Learning Rate: 0.000700 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11291/12542 | Batch Loss: 0.9442 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11292/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000700 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11293/12542 | Batch Loss: 1.2744 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11294/12542 | Batch Loss: 0.6701 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11295/12542 | Batch Loss: 2.3171 | Learning Rate: 0.000700 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11296/12542 | Batch Loss: 1.8769 | Learning Rate: 0.000700 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11297/12542 | Batch Loss: 0.9493 | Learning Rate: 0.000700 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11298/12542 | Batch Loss: 1.4120 | Learning Rate: 0.000700 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11299/12542 | Batch Loss: 1.3866 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11300/12542 | Batch Loss: 2.2190 | Learning Rate: 0.000700 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11301/12542 | Batch Loss: 0.5440 | Learning Rate: 0.000700 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11302/12542 | Batch Loss: 1.7721 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11303/12542 | Batch Loss: 1.7724 | Learning Rate: 0.000700 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11304/12542 | Batch Loss: 1.4434 | Learning Rate: 0.000700 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11305/12542 | Batch Loss: 2.3069 | Learning Rate: 0.000700 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11306/12542 | Batch Loss: 1.5473 | Learning Rate: 0.000700 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11307/12542 | Batch Loss: 2.0301 | Learning Rate: 0.000699 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11308/12542 | Batch Loss: 1.1330 | Learning Rate: 0.000699 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11309/12542 | Batch Loss: 1.1723 | Learning Rate: 0.000699 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11310/12542 | Batch Loss: 1.7963 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11311/12542 | Batch Loss: 1.5293 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11312/12542 | Batch Loss: 1.2433 | Learning Rate: 0.000699 | Batch Time: 0.72s\n",
      "Epoch 1 | Step 11313/12542 | Batch Loss: 1.2445 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11314/12542 | Batch Loss: 1.8460 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11315/12542 | Batch Loss: 1.3481 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11316/12542 | Batch Loss: 1.4469 | Learning Rate: 0.000699 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11317/12542 | Batch Loss: 0.8206 | Learning Rate: 0.000699 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11318/12542 | Batch Loss: 1.6837 | Learning Rate: 0.000699 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11319/12542 | Batch Loss: 1.4950 | Learning Rate: 0.000699 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11320/12542 | Batch Loss: 1.7859 | Learning Rate: 0.000699 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11321/12542 | Batch Loss: 0.4832 | Learning Rate: 0.000699 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11322/12542 | Batch Loss: 1.4451 | Learning Rate: 0.000699 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11323/12542 | Batch Loss: 1.1084 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11324/12542 | Batch Loss: 1.4016 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11325/12542 | Batch Loss: 1.4532 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11326/12542 | Batch Loss: 0.1977 | Learning Rate: 0.000699 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11327/12542 | Batch Loss: 1.4054 | Learning Rate: 0.000699 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11328/12542 | Batch Loss: 1.2529 | Learning Rate: 0.000699 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11329/12542 | Batch Loss: 0.9834 | Learning Rate: 0.000699 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11330/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11331/12542 | Batch Loss: 2.6169 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11332/12542 | Batch Loss: 0.7298 | Learning Rate: 0.000699 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11333/12542 | Batch Loss: 1.0921 | Learning Rate: 0.000699 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11334/12542 | Batch Loss: 1.3400 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11335/12542 | Batch Loss: 2.0098 | Learning Rate: 0.000699 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11336/12542 | Batch Loss: 1.1183 | Learning Rate: 0.000699 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11337/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11338/12542 | Batch Loss: 1.6166 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11339/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000699 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11340/12542 | Batch Loss: 1.2757 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11341/12542 | Batch Loss: 0.8261 | Learning Rate: 0.000699 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11342/12542 | Batch Loss: 0.8942 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11343/12542 | Batch Loss: 1.5433 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11344/12542 | Batch Loss: 0.7104 | Learning Rate: 0.000699 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11345/12542 | Batch Loss: 0.7312 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11346/12542 | Batch Loss: 1.2452 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11347/12542 | Batch Loss: 1.7033 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11348/12542 | Batch Loss: 0.7355 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11349/12542 | Batch Loss: 1.6345 | Learning Rate: 0.000698 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11350/12542 | Batch Loss: 1.8385 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11351/12542 | Batch Loss: 0.6692 | Learning Rate: 0.000698 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11352/12542 | Batch Loss: 1.5332 | Learning Rate: 0.000698 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11353/12542 | Batch Loss: 0.7971 | Learning Rate: 0.000698 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11354/12542 | Batch Loss: 2.5205 | Learning Rate: 0.000698 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11355/12542 | Batch Loss: 3.3823 | Learning Rate: 0.000698 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11356/12542 | Batch Loss: 0.6361 | Learning Rate: 0.000698 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11357/12542 | Batch Loss: 2.8589 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11358/12542 | Batch Loss: 0.9758 | Learning Rate: 0.000698 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11359/12542 | Batch Loss: 3.2042 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11360/12542 | Batch Loss: 1.4476 | Learning Rate: 0.000698 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11361/12542 | Batch Loss: 1.4073 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11362/12542 | Batch Loss: 2.3677 | Learning Rate: 0.000698 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 11363/12542 | Batch Loss: 1.4980 | Learning Rate: 0.000698 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11364/12542 | Batch Loss: 2.2942 | Learning Rate: 0.000698 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11365/12542 | Batch Loss: 1.2382 | Learning Rate: 0.000698 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11366/12542 | Batch Loss: 2.9833 | Learning Rate: 0.000698 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11367/12542 | Batch Loss: 2.4269 | Learning Rate: 0.000698 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11368/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000698 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11369/12542 | Batch Loss: 3.9697 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11370/12542 | Batch Loss: 1.1657 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11371/12542 | Batch Loss: 1.3198 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11372/12542 | Batch Loss: 0.7368 | Learning Rate: 0.000698 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11373/12542 | Batch Loss: 1.1908 | Learning Rate: 0.000698 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11374/12542 | Batch Loss: 2.2474 | Learning Rate: 0.000698 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11375/12542 | Batch Loss: 1.8300 | Learning Rate: 0.000698 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11376/12542 | Batch Loss: 1.6630 | Learning Rate: 0.000698 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11377/12542 | Batch Loss: 2.3910 | Learning Rate: 0.000698 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11378/12542 | Batch Loss: 1.2923 | Learning Rate: 0.000698 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11379/12542 | Batch Loss: 1.6824 | Learning Rate: 0.000698 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11380/12542 | Batch Loss: 1.2798 | Learning Rate: 0.000698 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11381/12542 | Batch Loss: 1.7911 | Learning Rate: 0.000698 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11382/12542 | Batch Loss: 1.7857 | Learning Rate: 0.000697 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11383/12542 | Batch Loss: 1.6820 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11384/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11385/12542 | Batch Loss: 2.1726 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11386/12542 | Batch Loss: 0.9307 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11387/12542 | Batch Loss: 0.9556 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11388/12542 | Batch Loss: 1.2309 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11389/12542 | Batch Loss: 0.8357 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11390/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11391/12542 | Batch Loss: 1.2092 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11392/12542 | Batch Loss: 2.3244 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11393/12542 | Batch Loss: 1.0168 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11394/12542 | Batch Loss: 0.4032 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11395/12542 | Batch Loss: 2.0935 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11396/12542 | Batch Loss: 0.9728 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11397/12542 | Batch Loss: 1.9900 | Learning Rate: 0.000697 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11398/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11399/12542 | Batch Loss: 2.4028 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11400/12542 | Batch Loss: 0.6010 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11401/12542 | Batch Loss: 0.7093 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11402/12542 | Batch Loss: 1.3074 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11403/12542 | Batch Loss: 0.5055 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11404/12542 | Batch Loss: 2.0739 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11405/12542 | Batch Loss: 2.9553 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11406/12542 | Batch Loss: 0.8836 | Learning Rate: 0.000697 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11407/12542 | Batch Loss: 0.8005 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11408/12542 | Batch Loss: 1.0901 | Learning Rate: 0.000697 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11409/12542 | Batch Loss: 1.8573 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11410/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000697 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11411/12542 | Batch Loss: 0.7209 | Learning Rate: 0.000697 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11412/12542 | Batch Loss: 1.4316 | Learning Rate: 0.000697 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11413/12542 | Batch Loss: 1.3281 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11414/12542 | Batch Loss: 2.0500 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11415/12542 | Batch Loss: 1.1395 | Learning Rate: 0.000697 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11416/12542 | Batch Loss: 1.0296 | Learning Rate: 0.000697 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11417/12542 | Batch Loss: 0.5269 | Learning Rate: 0.000697 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11418/12542 | Batch Loss: 1.2471 | Learning Rate: 0.000697 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11419/12542 | Batch Loss: 0.5078 | Learning Rate: 0.000697 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11420/12542 | Batch Loss: 1.9968 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11421/12542 | Batch Loss: 1.4909 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11422/12542 | Batch Loss: 1.0634 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11423/12542 | Batch Loss: 1.4694 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11424/12542 | Batch Loss: 1.7770 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11425/12542 | Batch Loss: 1.5929 | Learning Rate: 0.000696 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11426/12542 | Batch Loss: 1.5872 | Learning Rate: 0.000696 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11427/12542 | Batch Loss: 1.5692 | Learning Rate: 0.000696 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11428/12542 | Batch Loss: 0.6923 | Learning Rate: 0.000696 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11429/12542 | Batch Loss: 2.3201 | Learning Rate: 0.000696 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11430/12542 | Batch Loss: 1.3857 | Learning Rate: 0.000696 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11431/12542 | Batch Loss: 1.1312 | Learning Rate: 0.000696 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11432/12542 | Batch Loss: 1.4914 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11433/12542 | Batch Loss: 1.1205 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11434/12542 | Batch Loss: 0.7448 | Learning Rate: 0.000696 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11435/12542 | Batch Loss: 1.5629 | Learning Rate: 0.000696 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11436/12542 | Batch Loss: 1.1188 | Learning Rate: 0.000696 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11437/12542 | Batch Loss: 2.6323 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11438/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11439/12542 | Batch Loss: 1.5128 | Learning Rate: 0.000696 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11440/12542 | Batch Loss: 3.3290 | Learning Rate: 0.000696 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11441/12542 | Batch Loss: 0.7175 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11442/12542 | Batch Loss: 0.9968 | Learning Rate: 0.000696 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11443/12542 | Batch Loss: 1.0123 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11444/12542 | Batch Loss: 0.5851 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11445/12542 | Batch Loss: 1.0240 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11446/12542 | Batch Loss: 1.5225 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11447/12542 | Batch Loss: 1.2977 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11448/12542 | Batch Loss: 0.5693 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11449/12542 | Batch Loss: 1.1482 | Learning Rate: 0.000696 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11450/12542 | Batch Loss: 1.1324 | Learning Rate: 0.000696 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11451/12542 | Batch Loss: 0.7338 | Learning Rate: 0.000696 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11452/12542 | Batch Loss: 0.7787 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11453/12542 | Batch Loss: 0.6901 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11454/12542 | Batch Loss: 0.7547 | Learning Rate: 0.000696 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11455/12542 | Batch Loss: 1.9276 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11456/12542 | Batch Loss: 2.2725 | Learning Rate: 0.000696 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11457/12542 | Batch Loss: 2.6083 | Learning Rate: 0.000696 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11458/12542 | Batch Loss: 2.2360 | Learning Rate: 0.000695 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11459/12542 | Batch Loss: 0.5185 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11460/12542 | Batch Loss: 1.6436 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11461/12542 | Batch Loss: 0.9514 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11462/12542 | Batch Loss: 1.5115 | Learning Rate: 0.000695 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11463/12542 | Batch Loss: 0.9134 | Learning Rate: 0.000695 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11464/12542 | Batch Loss: 1.4129 | Learning Rate: 0.000695 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11465/12542 | Batch Loss: 1.2809 | Learning Rate: 0.000695 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11466/12542 | Batch Loss: 0.8687 | Learning Rate: 0.000695 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11467/12542 | Batch Loss: 0.4846 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11468/12542 | Batch Loss: 0.6277 | Learning Rate: 0.000695 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11469/12542 | Batch Loss: 2.3173 | Learning Rate: 0.000695 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11470/12542 | Batch Loss: 2.3773 | Learning Rate: 0.000695 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11471/12542 | Batch Loss: 1.7068 | Learning Rate: 0.000695 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11472/12542 | Batch Loss: 1.8441 | Learning Rate: 0.000695 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11473/12542 | Batch Loss: 1.3031 | Learning Rate: 0.000695 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11474/12542 | Batch Loss: 1.2695 | Learning Rate: 0.000695 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11475/12542 | Batch Loss: 1.7658 | Learning Rate: 0.000695 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11476/12542 | Batch Loss: 1.4566 | Learning Rate: 0.000695 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11477/12542 | Batch Loss: 0.9161 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11478/12542 | Batch Loss: 1.3867 | Learning Rate: 0.000695 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11479/12542 | Batch Loss: 1.1789 | Learning Rate: 0.000695 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11480/12542 | Batch Loss: 1.8203 | Learning Rate: 0.000695 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11481/12542 | Batch Loss: 1.5495 | Learning Rate: 0.000695 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11482/12542 | Batch Loss: 0.3720 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11483/12542 | Batch Loss: 0.8440 | Learning Rate: 0.000695 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11484/12542 | Batch Loss: 1.6354 | Learning Rate: 0.000695 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11485/12542 | Batch Loss: 1.8787 | Learning Rate: 0.000695 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11486/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000695 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11487/12542 | Batch Loss: 2.1609 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11488/12542 | Batch Loss: 1.8016 | Learning Rate: 0.000695 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11489/12542 | Batch Loss: 2.0093 | Learning Rate: 0.000695 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11490/12542 | Batch Loss: 0.6476 | Learning Rate: 0.000695 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11491/12542 | Batch Loss: 1.2245 | Learning Rate: 0.000695 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11492/12542 | Batch Loss: 1.5595 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11493/12542 | Batch Loss: 1.6304 | Learning Rate: 0.000695 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11494/12542 | Batch Loss: 1.7286 | Learning Rate: 0.000695 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11495/12542 | Batch Loss: 1.2374 | Learning Rate: 0.000694 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11496/12542 | Batch Loss: 0.3973 | Learning Rate: 0.000694 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11497/12542 | Batch Loss: 2.7120 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11498/12542 | Batch Loss: 2.7471 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11499/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000694 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11500/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11501/12542 | Batch Loss: 0.6780 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11502/12542 | Batch Loss: 1.7569 | Learning Rate: 0.000694 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11503/12542 | Batch Loss: 1.2821 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11504/12542 | Batch Loss: 2.5539 | Learning Rate: 0.000694 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11505/12542 | Batch Loss: 1.7717 | Learning Rate: 0.000694 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11506/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000694 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11507/12542 | Batch Loss: 0.9609 | Learning Rate: 0.000694 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11508/12542 | Batch Loss: 1.9805 | Learning Rate: 0.000694 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11509/12542 | Batch Loss: 0.5797 | Learning Rate: 0.000694 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11510/12542 | Batch Loss: 2.3444 | Learning Rate: 0.000694 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11511/12542 | Batch Loss: 1.8918 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11512/12542 | Batch Loss: 0.9537 | Learning Rate: 0.000694 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11513/12542 | Batch Loss: 0.8321 | Learning Rate: 0.000694 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11514/12542 | Batch Loss: 0.5174 | Learning Rate: 0.000694 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11515/12542 | Batch Loss: 0.7260 | Learning Rate: 0.000694 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11516/12542 | Batch Loss: 1.2431 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11517/12542 | Batch Loss: 1.7285 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11518/12542 | Batch Loss: 1.4224 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11519/12542 | Batch Loss: 1.1491 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11520/12542 | Batch Loss: 1.4235 | Learning Rate: 0.000694 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11521/12542 | Batch Loss: 0.6706 | Learning Rate: 0.000694 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11522/12542 | Batch Loss: 1.8925 | Learning Rate: 0.000694 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11523/12542 | Batch Loss: 0.7083 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11524/12542 | Batch Loss: 1.4822 | Learning Rate: 0.000694 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11525/12542 | Batch Loss: 0.4363 | Learning Rate: 0.000694 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11526/12542 | Batch Loss: 0.9419 | Learning Rate: 0.000694 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11527/12542 | Batch Loss: 1.3729 | Learning Rate: 0.000694 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11528/12542 | Batch Loss: 0.8074 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11529/12542 | Batch Loss: 0.6197 | Learning Rate: 0.000694 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11530/12542 | Batch Loss: 0.9168 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11531/12542 | Batch Loss: 1.3444 | Learning Rate: 0.000694 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11532/12542 | Batch Loss: 0.8953 | Learning Rate: 0.000694 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11533/12542 | Batch Loss: 1.5381 | Learning Rate: 0.000693 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11534/12542 | Batch Loss: 1.4036 | Learning Rate: 0.000693 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11535/12542 | Batch Loss: 2.4236 | Learning Rate: 0.000693 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11536/12542 | Batch Loss: 1.2032 | Learning Rate: 0.000693 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11537/12542 | Batch Loss: 1.6647 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11538/12542 | Batch Loss: 1.0219 | Learning Rate: 0.000693 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11539/12542 | Batch Loss: 0.6799 | Learning Rate: 0.000693 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11540/12542 | Batch Loss: 2.3832 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11541/12542 | Batch Loss: 0.6658 | Learning Rate: 0.000693 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11542/12542 | Batch Loss: 1.5809 | Learning Rate: 0.000693 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11543/12542 | Batch Loss: 1.3092 | Learning Rate: 0.000693 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11544/12542 | Batch Loss: 0.8255 | Learning Rate: 0.000693 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11545/12542 | Batch Loss: 1.0018 | Learning Rate: 0.000693 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11546/12542 | Batch Loss: 2.0451 | Learning Rate: 0.000693 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11547/12542 | Batch Loss: 1.1972 | Learning Rate: 0.000693 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11548/12542 | Batch Loss: 0.8083 | Learning Rate: 0.000693 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11549/12542 | Batch Loss: 1.2852 | Learning Rate: 0.000693 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11550/12542 | Batch Loss: 0.8665 | Learning Rate: 0.000693 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11551/12542 | Batch Loss: 2.3703 | Learning Rate: 0.000693 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11552/12542 | Batch Loss: 1.5673 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11553/12542 | Batch Loss: 0.6861 | Learning Rate: 0.000693 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11554/12542 | Batch Loss: 1.5188 | Learning Rate: 0.000693 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11555/12542 | Batch Loss: 1.0233 | Learning Rate: 0.000693 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11556/12542 | Batch Loss: 1.0325 | Learning Rate: 0.000693 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11557/12542 | Batch Loss: 1.6681 | Learning Rate: 0.000693 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11558/12542 | Batch Loss: 1.5903 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11559/12542 | Batch Loss: 0.9375 | Learning Rate: 0.000693 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11560/12542 | Batch Loss: 0.6863 | Learning Rate: 0.000693 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11561/12542 | Batch Loss: 1.6814 | Learning Rate: 0.000693 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11562/12542 | Batch Loss: 0.7539 | Learning Rate: 0.000693 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11563/12542 | Batch Loss: 1.2768 | Learning Rate: 0.000693 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11564/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11565/12542 | Batch Loss: 1.0247 | Learning Rate: 0.000693 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11566/12542 | Batch Loss: 2.9842 | Learning Rate: 0.000693 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11567/12542 | Batch Loss: 2.2446 | Learning Rate: 0.000693 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11568/12542 | Batch Loss: 1.7960 | Learning Rate: 0.000693 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11569/12542 | Batch Loss: 1.4035 | Learning Rate: 0.000693 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11570/12542 | Batch Loss: 0.5054 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11571/12542 | Batch Loss: 0.6007 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11572/12542 | Batch Loss: 3.1191 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11573/12542 | Batch Loss: 0.8619 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11574/12542 | Batch Loss: 1.9707 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11575/12542 | Batch Loss: 1.0938 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11576/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000692 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11577/12542 | Batch Loss: 0.5964 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11578/12542 | Batch Loss: 0.9815 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11579/12542 | Batch Loss: 0.6256 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11580/12542 | Batch Loss: 1.1008 | Learning Rate: 0.000692 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11581/12542 | Batch Loss: 1.2214 | Learning Rate: 0.000692 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11582/12542 | Batch Loss: 1.1380 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11583/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000692 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11584/12542 | Batch Loss: 0.5578 | Learning Rate: 0.000692 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11585/12542 | Batch Loss: 1.0694 | Learning Rate: 0.000692 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11586/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11587/12542 | Batch Loss: 1.6347 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11588/12542 | Batch Loss: 0.8533 | Learning Rate: 0.000692 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11589/12542 | Batch Loss: 1.4571 | Learning Rate: 0.000692 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11590/12542 | Batch Loss: 0.7575 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11591/12542 | Batch Loss: 0.7502 | Learning Rate: 0.000692 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11592/12542 | Batch Loss: 1.5778 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11593/12542 | Batch Loss: 0.6084 | Learning Rate: 0.000692 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11594/12542 | Batch Loss: 1.5105 | Learning Rate: 0.000692 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11595/12542 | Batch Loss: 1.7097 | Learning Rate: 0.000692 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11596/12542 | Batch Loss: 1.8402 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11597/12542 | Batch Loss: 1.0520 | Learning Rate: 0.000692 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11598/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000692 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11599/12542 | Batch Loss: 1.1985 | Learning Rate: 0.000692 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11600/12542 | Batch Loss: 1.9246 | Learning Rate: 0.000692 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11601/12542 | Batch Loss: 0.7122 | Learning Rate: 0.000692 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11602/12542 | Batch Loss: 0.8349 | Learning Rate: 0.000692 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11603/12542 | Batch Loss: 1.1196 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11604/12542 | Batch Loss: 1.8818 | Learning Rate: 0.000692 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11605/12542 | Batch Loss: 2.3348 | Learning Rate: 0.000692 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11606/12542 | Batch Loss: 2.5434 | Learning Rate: 0.000692 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11607/12542 | Batch Loss: 0.5589 | Learning Rate: 0.000692 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11608/12542 | Batch Loss: 1.8463 | Learning Rate: 0.000691 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11609/12542 | Batch Loss: 1.4164 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11610/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11611/12542 | Batch Loss: 1.4559 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11612/12542 | Batch Loss: 1.0285 | Learning Rate: 0.000691 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11613/12542 | Batch Loss: 3.2958 | Learning Rate: 0.000691 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11614/12542 | Batch Loss: 1.1371 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11615/12542 | Batch Loss: 1.4328 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11616/12542 | Batch Loss: 1.0527 | Learning Rate: 0.000691 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11617/12542 | Batch Loss: 1.1774 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11618/12542 | Batch Loss: 1.5428 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11619/12542 | Batch Loss: 1.3448 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11620/12542 | Batch Loss: 1.8874 | Learning Rate: 0.000691 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11621/12542 | Batch Loss: 0.4809 | Learning Rate: 0.000691 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11622/12542 | Batch Loss: 0.9363 | Learning Rate: 0.000691 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11623/12542 | Batch Loss: 0.6435 | Learning Rate: 0.000691 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 11624/12542 | Batch Loss: 1.6887 | Learning Rate: 0.000691 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11625/12542 | Batch Loss: 0.7110 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11626/12542 | Batch Loss: 1.8458 | Learning Rate: 0.000691 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11627/12542 | Batch Loss: 1.0851 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11628/12542 | Batch Loss: 2.7342 | Learning Rate: 0.000691 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11629/12542 | Batch Loss: 1.0218 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11630/12542 | Batch Loss: 0.7146 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11631/12542 | Batch Loss: 1.6989 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11632/12542 | Batch Loss: 1.4732 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11633/12542 | Batch Loss: 1.9713 | Learning Rate: 0.000691 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11634/12542 | Batch Loss: 1.5914 | Learning Rate: 0.000691 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11635/12542 | Batch Loss: 1.1622 | Learning Rate: 0.000691 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11636/12542 | Batch Loss: 1.4329 | Learning Rate: 0.000691 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11637/12542 | Batch Loss: 1.7043 | Learning Rate: 0.000691 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11638/12542 | Batch Loss: 1.7886 | Learning Rate: 0.000691 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11639/12542 | Batch Loss: 0.8442 | Learning Rate: 0.000691 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11640/12542 | Batch Loss: 1.0613 | Learning Rate: 0.000691 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11641/12542 | Batch Loss: 1.2090 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11642/12542 | Batch Loss: 1.1170 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11643/12542 | Batch Loss: 0.8903 | Learning Rate: 0.000691 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11644/12542 | Batch Loss: 0.8046 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11645/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000691 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11646/12542 | Batch Loss: 0.8715 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11647/12542 | Batch Loss: 4.9323 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11648/12542 | Batch Loss: 1.6813 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11649/12542 | Batch Loss: 1.0117 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11650/12542 | Batch Loss: 1.4723 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11651/12542 | Batch Loss: 0.3911 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11652/12542 | Batch Loss: 0.8133 | Learning Rate: 0.000690 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11653/12542 | Batch Loss: 0.6509 | Learning Rate: 0.000690 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11654/12542 | Batch Loss: 1.3955 | Learning Rate: 0.000690 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11655/12542 | Batch Loss: 1.5274 | Learning Rate: 0.000690 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11656/12542 | Batch Loss: 1.6918 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11657/12542 | Batch Loss: 1.0217 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11658/12542 | Batch Loss: 1.1169 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11659/12542 | Batch Loss: 2.5757 | Learning Rate: 0.000690 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11660/12542 | Batch Loss: 1.1145 | Learning Rate: 0.000690 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11661/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000690 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11662/12542 | Batch Loss: 0.8604 | Learning Rate: 0.000690 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11663/12542 | Batch Loss: 1.7131 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11664/12542 | Batch Loss: 1.1575 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11665/12542 | Batch Loss: 0.9722 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11666/12542 | Batch Loss: 1.6783 | Learning Rate: 0.000690 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11667/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11668/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000690 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 11669/12542 | Batch Loss: 1.3060 | Learning Rate: 0.000690 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 11670/12542 | Batch Loss: 0.7686 | Learning Rate: 0.000690 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11671/12542 | Batch Loss: 1.9384 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11672/12542 | Batch Loss: 0.8513 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11673/12542 | Batch Loss: 1.3234 | Learning Rate: 0.000690 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11674/12542 | Batch Loss: 1.3755 | Learning Rate: 0.000690 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11675/12542 | Batch Loss: 0.8884 | Learning Rate: 0.000690 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11676/12542 | Batch Loss: 1.3569 | Learning Rate: 0.000690 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11677/12542 | Batch Loss: 1.7258 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11678/12542 | Batch Loss: 0.8261 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11679/12542 | Batch Loss: 1.0439 | Learning Rate: 0.000690 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11680/12542 | Batch Loss: 0.9231 | Learning Rate: 0.000690 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11681/12542 | Batch Loss: 0.9134 | Learning Rate: 0.000690 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11682/12542 | Batch Loss: 0.5534 | Learning Rate: 0.000690 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11683/12542 | Batch Loss: 1.6683 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11684/12542 | Batch Loss: 0.5971 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11685/12542 | Batch Loss: 1.2602 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11686/12542 | Batch Loss: 1.3292 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11687/12542 | Batch Loss: 0.9039 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11688/12542 | Batch Loss: 1.2564 | Learning Rate: 0.000689 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11689/12542 | Batch Loss: 1.3981 | Learning Rate: 0.000689 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11690/12542 | Batch Loss: 0.8771 | Learning Rate: 0.000689 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11691/12542 | Batch Loss: 1.7429 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11692/12542 | Batch Loss: 0.9812 | Learning Rate: 0.000689 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11693/12542 | Batch Loss: 0.8641 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11694/12542 | Batch Loss: 2.5179 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11695/12542 | Batch Loss: 1.9149 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11696/12542 | Batch Loss: 1.2331 | Learning Rate: 0.000689 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11697/12542 | Batch Loss: 1.3476 | Learning Rate: 0.000689 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11698/12542 | Batch Loss: 1.4436 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11699/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11700/12542 | Batch Loss: 1.4107 | Learning Rate: 0.000689 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11701/12542 | Batch Loss: 1.1917 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11702/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000689 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11703/12542 | Batch Loss: 0.7096 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11704/12542 | Batch Loss: 1.1237 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11705/12542 | Batch Loss: 1.9486 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11706/12542 | Batch Loss: 1.9508 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11707/12542 | Batch Loss: 0.4920 | Learning Rate: 0.000689 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11708/12542 | Batch Loss: 1.2653 | Learning Rate: 0.000689 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11709/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000689 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11710/12542 | Batch Loss: 1.7184 | Learning Rate: 0.000689 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11711/12542 | Batch Loss: 2.2648 | Learning Rate: 0.000689 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11712/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000689 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11713/12542 | Batch Loss: 1.5548 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11714/12542 | Batch Loss: 0.8668 | Learning Rate: 0.000689 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11715/12542 | Batch Loss: 1.5236 | Learning Rate: 0.000689 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11716/12542 | Batch Loss: 0.6696 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11717/12542 | Batch Loss: 0.6635 | Learning Rate: 0.000689 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11718/12542 | Batch Loss: 1.4259 | Learning Rate: 0.000689 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11719/12542 | Batch Loss: 2.5456 | Learning Rate: 0.000689 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11720/12542 | Batch Loss: 1.4385 | Learning Rate: 0.000689 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11721/12542 | Batch Loss: 0.8164 | Learning Rate: 0.000688 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11722/12542 | Batch Loss: 1.5670 | Learning Rate: 0.000688 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11723/12542 | Batch Loss: 0.4360 | Learning Rate: 0.000688 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11724/12542 | Batch Loss: 1.4794 | Learning Rate: 0.000688 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11725/12542 | Batch Loss: 2.6999 | Learning Rate: 0.000688 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11726/12542 | Batch Loss: 3.6620 | Learning Rate: 0.000688 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11727/12542 | Batch Loss: 1.1960 | Learning Rate: 0.000688 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11728/12542 | Batch Loss: 1.0800 | Learning Rate: 0.000688 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11729/12542 | Batch Loss: 2.4540 | Learning Rate: 0.000688 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11730/12542 | Batch Loss: 0.7798 | Learning Rate: 0.000688 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11731/12542 | Batch Loss: 1.8939 | Learning Rate: 0.000688 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11732/12542 | Batch Loss: 1.1788 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11733/12542 | Batch Loss: 1.0040 | Learning Rate: 0.000688 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11734/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000688 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11735/12542 | Batch Loss: 0.7596 | Learning Rate: 0.000688 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11736/12542 | Batch Loss: 0.7850 | Learning Rate: 0.000688 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11737/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000688 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11738/12542 | Batch Loss: 2.4019 | Learning Rate: 0.000688 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11739/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000688 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11740/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11741/12542 | Batch Loss: 1.0381 | Learning Rate: 0.000688 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11742/12542 | Batch Loss: 2.3087 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11743/12542 | Batch Loss: 1.2371 | Learning Rate: 0.000688 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11744/12542 | Batch Loss: 1.1620 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11745/12542 | Batch Loss: 1.1456 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11746/12542 | Batch Loss: 1.3015 | Learning Rate: 0.000688 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11747/12542 | Batch Loss: 0.6081 | Learning Rate: 0.000688 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11748/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000688 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11749/12542 | Batch Loss: 0.9716 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11750/12542 | Batch Loss: 0.7089 | Learning Rate: 0.000688 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11751/12542 | Batch Loss: 1.1224 | Learning Rate: 0.000688 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11752/12542 | Batch Loss: 0.7737 | Learning Rate: 0.000688 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11753/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000688 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11754/12542 | Batch Loss: 0.6781 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11755/12542 | Batch Loss: 0.6734 | Learning Rate: 0.000688 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11756/12542 | Batch Loss: 0.7817 | Learning Rate: 0.000688 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11757/12542 | Batch Loss: 1.1967 | Learning Rate: 0.000688 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11758/12542 | Batch Loss: 0.5512 | Learning Rate: 0.000688 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11759/12542 | Batch Loss: 0.7387 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11760/12542 | Batch Loss: 0.4616 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11761/12542 | Batch Loss: 0.4639 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11762/12542 | Batch Loss: 1.4297 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11763/12542 | Batch Loss: 3.2577 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11764/12542 | Batch Loss: 2.7612 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11765/12542 | Batch Loss: 1.1574 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11766/12542 | Batch Loss: 1.4357 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11767/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11768/12542 | Batch Loss: 1.4275 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11769/12542 | Batch Loss: 1.5380 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11770/12542 | Batch Loss: 1.0433 | Learning Rate: 0.000687 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11771/12542 | Batch Loss: 1.7237 | Learning Rate: 0.000687 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11772/12542 | Batch Loss: 1.3901 | Learning Rate: 0.000687 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11773/12542 | Batch Loss: 0.9202 | Learning Rate: 0.000687 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11774/12542 | Batch Loss: 1.1250 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11775/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11776/12542 | Batch Loss: 1.1429 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11777/12542 | Batch Loss: 1.4690 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11778/12542 | Batch Loss: 1.2019 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11779/12542 | Batch Loss: 0.8634 | Learning Rate: 0.000687 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11780/12542 | Batch Loss: 1.4952 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11781/12542 | Batch Loss: 1.8107 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11782/12542 | Batch Loss: 1.1794 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11783/12542 | Batch Loss: 1.2213 | Learning Rate: 0.000687 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11784/12542 | Batch Loss: 0.8299 | Learning Rate: 0.000687 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11785/12542 | Batch Loss: 1.2751 | Learning Rate: 0.000687 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11786/12542 | Batch Loss: 0.8942 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11787/12542 | Batch Loss: 2.2546 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11788/12542 | Batch Loss: 0.8696 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11789/12542 | Batch Loss: 0.7779 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11790/12542 | Batch Loss: 0.8885 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11791/12542 | Batch Loss: 1.1888 | Learning Rate: 0.000687 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11792/12542 | Batch Loss: 0.5173 | Learning Rate: 0.000687 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11793/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11794/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11795/12542 | Batch Loss: 1.7456 | Learning Rate: 0.000687 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11796/12542 | Batch Loss: 1.1669 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11797/12542 | Batch Loss: 0.8945 | Learning Rate: 0.000686 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11798/12542 | Batch Loss: 1.5992 | Learning Rate: 0.000686 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11799/12542 | Batch Loss: 1.1787 | Learning Rate: 0.000686 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11800/12542 | Batch Loss: 1.4948 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11801/12542 | Batch Loss: 2.1052 | Learning Rate: 0.000686 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11802/12542 | Batch Loss: 0.6284 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11803/12542 | Batch Loss: 1.7298 | Learning Rate: 0.000686 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11804/12542 | Batch Loss: 1.4659 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11805/12542 | Batch Loss: 1.3540 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11806/12542 | Batch Loss: 1.3873 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11807/12542 | Batch Loss: 1.1424 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11808/12542 | Batch Loss: 0.8863 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11809/12542 | Batch Loss: 1.9228 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11810/12542 | Batch Loss: 3.0061 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11811/12542 | Batch Loss: 1.5836 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11812/12542 | Batch Loss: 0.7888 | Learning Rate: 0.000686 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11813/12542 | Batch Loss: 2.0838 | Learning Rate: 0.000686 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11814/12542 | Batch Loss: 1.4887 | Learning Rate: 0.000686 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11815/12542 | Batch Loss: 1.0785 | Learning Rate: 0.000686 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11816/12542 | Batch Loss: 1.8004 | Learning Rate: 0.000686 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11817/12542 | Batch Loss: 0.8485 | Learning Rate: 0.000686 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11818/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11819/12542 | Batch Loss: 0.7232 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11820/12542 | Batch Loss: 1.9888 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11821/12542 | Batch Loss: 0.5192 | Learning Rate: 0.000686 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11822/12542 | Batch Loss: 0.7657 | Learning Rate: 0.000686 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11823/12542 | Batch Loss: 0.8195 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11824/12542 | Batch Loss: 1.2147 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11825/12542 | Batch Loss: 0.4600 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11826/12542 | Batch Loss: 1.1504 | Learning Rate: 0.000686 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11827/12542 | Batch Loss: 0.6064 | Learning Rate: 0.000686 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11828/12542 | Batch Loss: 1.5190 | Learning Rate: 0.000686 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11829/12542 | Batch Loss: 1.0791 | Learning Rate: 0.000686 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11830/12542 | Batch Loss: 2.0712 | Learning Rate: 0.000686 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11831/12542 | Batch Loss: 1.4862 | Learning Rate: 0.000686 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11832/12542 | Batch Loss: 1.4567 | Learning Rate: 0.000686 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11833/12542 | Batch Loss: 1.4575 | Learning Rate: 0.000686 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11834/12542 | Batch Loss: 1.4112 | Learning Rate: 0.000685 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11835/12542 | Batch Loss: 1.8563 | Learning Rate: 0.000685 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11836/12542 | Batch Loss: 1.5931 | Learning Rate: 0.000685 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11837/12542 | Batch Loss: 0.7548 | Learning Rate: 0.000685 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11838/12542 | Batch Loss: 1.3658 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11839/12542 | Batch Loss: 1.8676 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11840/12542 | Batch Loss: 1.4929 | Learning Rate: 0.000685 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11841/12542 | Batch Loss: 2.0340 | Learning Rate: 0.000685 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11842/12542 | Batch Loss: 1.5437 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11843/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000685 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11844/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11845/12542 | Batch Loss: 2.0293 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11846/12542 | Batch Loss: 1.0636 | Learning Rate: 0.000685 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11847/12542 | Batch Loss: 2.2381 | Learning Rate: 0.000685 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11848/12542 | Batch Loss: 1.0521 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11849/12542 | Batch Loss: 1.7216 | Learning Rate: 0.000685 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11850/12542 | Batch Loss: 1.1729 | Learning Rate: 0.000685 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11851/12542 | Batch Loss: 2.3116 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11852/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000685 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11853/12542 | Batch Loss: 0.7309 | Learning Rate: 0.000685 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11854/12542 | Batch Loss: 1.6911 | Learning Rate: 0.000685 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11855/12542 | Batch Loss: 1.1316 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11856/12542 | Batch Loss: 1.5315 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11857/12542 | Batch Loss: 0.6452 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11858/12542 | Batch Loss: 0.9537 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11859/12542 | Batch Loss: 0.4261 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11860/12542 | Batch Loss: 1.4928 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11861/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11862/12542 | Batch Loss: 1.1308 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11863/12542 | Batch Loss: 0.6830 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11864/12542 | Batch Loss: 0.6866 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11865/12542 | Batch Loss: 1.0236 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11866/12542 | Batch Loss: 1.3906 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11867/12542 | Batch Loss: 2.4563 | Learning Rate: 0.000685 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11868/12542 | Batch Loss: 1.0018 | Learning Rate: 0.000685 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11869/12542 | Batch Loss: 1.1894 | Learning Rate: 0.000685 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11870/12542 | Batch Loss: 1.4560 | Learning Rate: 0.000685 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11871/12542 | Batch Loss: 0.5409 | Learning Rate: 0.000685 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11872/12542 | Batch Loss: 1.8818 | Learning Rate: 0.000684 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11873/12542 | Batch Loss: 0.8805 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11874/12542 | Batch Loss: 2.3497 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11875/12542 | Batch Loss: 1.0425 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11876/12542 | Batch Loss: 1.0788 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11877/12542 | Batch Loss: 2.3372 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11878/12542 | Batch Loss: 0.9561 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11879/12542 | Batch Loss: 2.2116 | Learning Rate: 0.000684 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11880/12542 | Batch Loss: 0.4980 | Learning Rate: 0.000684 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11881/12542 | Batch Loss: 1.5782 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11882/12542 | Batch Loss: 1.7309 | Learning Rate: 0.000684 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11883/12542 | Batch Loss: 1.0390 | Learning Rate: 0.000684 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11884/12542 | Batch Loss: 0.8809 | Learning Rate: 0.000684 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11885/12542 | Batch Loss: 1.4831 | Learning Rate: 0.000684 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11886/12542 | Batch Loss: 1.7036 | Learning Rate: 0.000684 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11887/12542 | Batch Loss: 2.0583 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11888/12542 | Batch Loss: 1.2538 | Learning Rate: 0.000684 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11889/12542 | Batch Loss: 1.6796 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11890/12542 | Batch Loss: 3.0067 | Learning Rate: 0.000684 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11891/12542 | Batch Loss: 1.7291 | Learning Rate: 0.000684 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11892/12542 | Batch Loss: 1.6568 | Learning Rate: 0.000684 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11893/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000684 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11894/12542 | Batch Loss: 3.5700 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11895/12542 | Batch Loss: 2.1695 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11896/12542 | Batch Loss: 1.1517 | Learning Rate: 0.000684 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11897/12542 | Batch Loss: 3.2941 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11898/12542 | Batch Loss: 1.2690 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11899/12542 | Batch Loss: 0.5473 | Learning Rate: 0.000684 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11900/12542 | Batch Loss: 1.2953 | Learning Rate: 0.000684 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11901/12542 | Batch Loss: 1.5704 | Learning Rate: 0.000684 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11902/12542 | Batch Loss: 2.2463 | Learning Rate: 0.000684 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11903/12542 | Batch Loss: 1.5464 | Learning Rate: 0.000684 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11904/12542 | Batch Loss: 0.7637 | Learning Rate: 0.000684 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11905/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000684 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11906/12542 | Batch Loss: 1.6527 | Learning Rate: 0.000684 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11907/12542 | Batch Loss: 1.6740 | Learning Rate: 0.000684 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11908/12542 | Batch Loss: 1.9150 | Learning Rate: 0.000684 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11909/12542 | Batch Loss: 1.4511 | Learning Rate: 0.000683 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11910/12542 | Batch Loss: 0.9859 | Learning Rate: 0.000683 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11911/12542 | Batch Loss: 1.4465 | Learning Rate: 0.000683 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11912/12542 | Batch Loss: 0.8461 | Learning Rate: 0.000683 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11913/12542 | Batch Loss: 0.8215 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11914/12542 | Batch Loss: 2.4116 | Learning Rate: 0.000683 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11915/12542 | Batch Loss: 0.5810 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11916/12542 | Batch Loss: 1.7850 | Learning Rate: 0.000683 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11917/12542 | Batch Loss: 1.8371 | Learning Rate: 0.000683 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11918/12542 | Batch Loss: 0.8063 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11919/12542 | Batch Loss: 2.8657 | Learning Rate: 0.000683 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11920/12542 | Batch Loss: 1.7587 | Learning Rate: 0.000683 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11921/12542 | Batch Loss: 1.0882 | Learning Rate: 0.000683 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11922/12542 | Batch Loss: 2.2042 | Learning Rate: 0.000683 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11923/12542 | Batch Loss: 1.4160 | Learning Rate: 0.000683 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11924/12542 | Batch Loss: 1.2494 | Learning Rate: 0.000683 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11925/12542 | Batch Loss: 1.7503 | Learning Rate: 0.000683 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11926/12542 | Batch Loss: 2.1864 | Learning Rate: 0.000683 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11927/12542 | Batch Loss: 1.0351 | Learning Rate: 0.000683 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11928/12542 | Batch Loss: 1.3238 | Learning Rate: 0.000683 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11929/12542 | Batch Loss: 3.0398 | Learning Rate: 0.000683 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11930/12542 | Batch Loss: 2.0398 | Learning Rate: 0.000683 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11931/12542 | Batch Loss: 1.5564 | Learning Rate: 0.000683 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11932/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000683 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11933/12542 | Batch Loss: 1.4671 | Learning Rate: 0.000683 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11934/12542 | Batch Loss: 0.7610 | Learning Rate: 0.000683 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 11935/12542 | Batch Loss: 1.0600 | Learning Rate: 0.000683 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11936/12542 | Batch Loss: 2.8905 | Learning Rate: 0.000683 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11937/12542 | Batch Loss: 1.0886 | Learning Rate: 0.000683 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 11938/12542 | Batch Loss: 2.5217 | Learning Rate: 0.000683 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11939/12542 | Batch Loss: 1.7768 | Learning Rate: 0.000683 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11940/12542 | Batch Loss: 0.7415 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11941/12542 | Batch Loss: 0.8427 | Learning Rate: 0.000683 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 11942/12542 | Batch Loss: 1.6507 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11943/12542 | Batch Loss: 1.7843 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11944/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000683 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11945/12542 | Batch Loss: 1.1095 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11946/12542 | Batch Loss: 1.6347 | Learning Rate: 0.000683 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11947/12542 | Batch Loss: 1.2287 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11948/12542 | Batch Loss: 1.0173 | Learning Rate: 0.000682 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11949/12542 | Batch Loss: 2.8447 | Learning Rate: 0.000682 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11950/12542 | Batch Loss: 1.4741 | Learning Rate: 0.000682 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11951/12542 | Batch Loss: 1.3500 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11952/12542 | Batch Loss: 0.9371 | Learning Rate: 0.000682 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11953/12542 | Batch Loss: 2.2789 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11954/12542 | Batch Loss: 0.9302 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11955/12542 | Batch Loss: 0.7324 | Learning Rate: 0.000682 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11956/12542 | Batch Loss: 0.9836 | Learning Rate: 0.000682 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11957/12542 | Batch Loss: 1.4553 | Learning Rate: 0.000682 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 11958/12542 | Batch Loss: 0.8064 | Learning Rate: 0.000682 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11959/12542 | Batch Loss: 1.5315 | Learning Rate: 0.000682 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11960/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11961/12542 | Batch Loss: 0.5725 | Learning Rate: 0.000682 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11962/12542 | Batch Loss: 0.9079 | Learning Rate: 0.000682 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11963/12542 | Batch Loss: 1.1243 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11964/12542 | Batch Loss: 1.4678 | Learning Rate: 0.000682 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11965/12542 | Batch Loss: 1.3135 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11966/12542 | Batch Loss: 1.7261 | Learning Rate: 0.000682 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11967/12542 | Batch Loss: 0.7598 | Learning Rate: 0.000682 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11968/12542 | Batch Loss: 1.2029 | Learning Rate: 0.000682 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11969/12542 | Batch Loss: 1.4530 | Learning Rate: 0.000682 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11970/12542 | Batch Loss: 1.8529 | Learning Rate: 0.000682 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 11971/12542 | Batch Loss: 0.6120 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11972/12542 | Batch Loss: 0.8569 | Learning Rate: 0.000682 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11973/12542 | Batch Loss: 1.2945 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11974/12542 | Batch Loss: 0.4270 | Learning Rate: 0.000682 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11975/12542 | Batch Loss: 1.2595 | Learning Rate: 0.000682 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 11976/12542 | Batch Loss: 2.0494 | Learning Rate: 0.000682 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11977/12542 | Batch Loss: 1.6005 | Learning Rate: 0.000682 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 11978/12542 | Batch Loss: 1.7380 | Learning Rate: 0.000682 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11979/12542 | Batch Loss: 1.0416 | Learning Rate: 0.000682 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 11980/12542 | Batch Loss: 1.0321 | Learning Rate: 0.000682 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11981/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000682 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11982/12542 | Batch Loss: 1.3941 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11983/12542 | Batch Loss: 0.7381 | Learning Rate: 0.000682 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11984/12542 | Batch Loss: 3.1071 | Learning Rate: 0.000681 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11985/12542 | Batch Loss: 2.0219 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11986/12542 | Batch Loss: 1.6214 | Learning Rate: 0.000681 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 11987/12542 | Batch Loss: 0.4351 | Learning Rate: 0.000681 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11988/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000681 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 11989/12542 | Batch Loss: 0.8650 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11990/12542 | Batch Loss: 0.7641 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11991/12542 | Batch Loss: 1.3398 | Learning Rate: 0.000681 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 11992/12542 | Batch Loss: 1.6567 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11993/12542 | Batch Loss: 1.4715 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11994/12542 | Batch Loss: 0.6278 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11995/12542 | Batch Loss: 2.1720 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11996/12542 | Batch Loss: 0.9857 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11997/12542 | Batch Loss: 0.9020 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 11998/12542 | Batch Loss: 0.4967 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 11999/12542 | Batch Loss: 2.2045 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12000/12542 | Batch Loss: 1.8962 | Learning Rate: 0.000681 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12001/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000681 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12002/12542 | Batch Loss: 1.7921 | Learning Rate: 0.000681 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12003/12542 | Batch Loss: 1.1630 | Learning Rate: 0.000681 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12004/12542 | Batch Loss: 2.1227 | Learning Rate: 0.000681 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12005/12542 | Batch Loss: 0.4490 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12006/12542 | Batch Loss: 0.8625 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12007/12542 | Batch Loss: 1.1321 | Learning Rate: 0.000681 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12008/12542 | Batch Loss: 1.9629 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12009/12542 | Batch Loss: 1.0124 | Learning Rate: 0.000681 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12010/12542 | Batch Loss: 1.7830 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12011/12542 | Batch Loss: 1.6366 | Learning Rate: 0.000681 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12012/12542 | Batch Loss: 2.0274 | Learning Rate: 0.000681 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12013/12542 | Batch Loss: 1.0784 | Learning Rate: 0.000681 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12014/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000681 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12015/12542 | Batch Loss: 1.4882 | Learning Rate: 0.000681 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12016/12542 | Batch Loss: 0.7854 | Learning Rate: 0.000681 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12017/12542 | Batch Loss: 1.5280 | Learning Rate: 0.000681 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12018/12542 | Batch Loss: 0.8084 | Learning Rate: 0.000681 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12019/12542 | Batch Loss: 2.1819 | Learning Rate: 0.000681 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12020/12542 | Batch Loss: 0.7148 | Learning Rate: 0.000681 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12021/12542 | Batch Loss: 1.2719 | Learning Rate: 0.000681 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12022/12542 | Batch Loss: 0.7006 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12023/12542 | Batch Loss: 1.4162 | Learning Rate: 0.000680 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12024/12542 | Batch Loss: 0.9304 | Learning Rate: 0.000680 | Batch Time: 0.71s\n",
      "Epoch 1 | Step 12025/12542 | Batch Loss: 1.0882 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12026/12542 | Batch Loss: 1.1044 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12027/12542 | Batch Loss: 1.8659 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12028/12542 | Batch Loss: 1.3267 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12029/12542 | Batch Loss: 0.9923 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12030/12542 | Batch Loss: 1.1278 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12031/12542 | Batch Loss: 0.5876 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12032/12542 | Batch Loss: 1.1221 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12033/12542 | Batch Loss: 1.6512 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12034/12542 | Batch Loss: 1.9257 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12035/12542 | Batch Loss: 1.8997 | Learning Rate: 0.000680 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12036/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12037/12542 | Batch Loss: 1.3098 | Learning Rate: 0.000680 | Batch Time: 0.75s\n",
      "Epoch 1 | Step 12038/12542 | Batch Loss: 1.5225 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12039/12542 | Batch Loss: 0.7024 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12040/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12041/12542 | Batch Loss: 1.2985 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12042/12542 | Batch Loss: 2.3830 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12043/12542 | Batch Loss: 0.4486 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12044/12542 | Batch Loss: 1.5511 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12045/12542 | Batch Loss: 2.1077 | Learning Rate: 0.000680 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12046/12542 | Batch Loss: 2.3322 | Learning Rate: 0.000680 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12047/12542 | Batch Loss: 2.5284 | Learning Rate: 0.000680 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12048/12542 | Batch Loss: 1.4148 | Learning Rate: 0.000680 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12049/12542 | Batch Loss: 2.7015 | Learning Rate: 0.000680 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12050/12542 | Batch Loss: 0.6602 | Learning Rate: 0.000680 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12051/12542 | Batch Loss: 2.0042 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12052/12542 | Batch Loss: 0.4199 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12053/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12054/12542 | Batch Loss: 1.7912 | Learning Rate: 0.000680 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12055/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000680 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12056/12542 | Batch Loss: 1.1084 | Learning Rate: 0.000680 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12057/12542 | Batch Loss: 1.5569 | Learning Rate: 0.000680 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12058/12542 | Batch Loss: 1.9091 | Learning Rate: 0.000680 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12059/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000680 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12060/12542 | Batch Loss: 1.0110 | Learning Rate: 0.000679 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12061/12542 | Batch Loss: 0.9194 | Learning Rate: 0.000679 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12062/12542 | Batch Loss: 0.7178 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12063/12542 | Batch Loss: 0.6963 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12064/12542 | Batch Loss: 1.3305 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12065/12542 | Batch Loss: 1.3322 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12066/12542 | Batch Loss: 1.4995 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12067/12542 | Batch Loss: 1.3668 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12068/12542 | Batch Loss: 1.4245 | Learning Rate: 0.000679 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12069/12542 | Batch Loss: 2.8166 | Learning Rate: 0.000679 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12070/12542 | Batch Loss: 1.1060 | Learning Rate: 0.000679 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12071/12542 | Batch Loss: 0.7706 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12072/12542 | Batch Loss: 0.7127 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12073/12542 | Batch Loss: 1.4386 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12074/12542 | Batch Loss: 1.4066 | Learning Rate: 0.000679 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12075/12542 | Batch Loss: 2.7777 | Learning Rate: 0.000679 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12076/12542 | Batch Loss: 0.5933 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12077/12542 | Batch Loss: 0.7598 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12078/12542 | Batch Loss: 2.1304 | Learning Rate: 0.000679 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12079/12542 | Batch Loss: 2.7686 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12080/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12081/12542 | Batch Loss: 1.0187 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12082/12542 | Batch Loss: 0.8695 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12083/12542 | Batch Loss: 0.9922 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12084/12542 | Batch Loss: 1.9503 | Learning Rate: 0.000679 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12085/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12086/12542 | Batch Loss: 1.0251 | Learning Rate: 0.000679 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12087/12542 | Batch Loss: 1.0659 | Learning Rate: 0.000679 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12088/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12089/12542 | Batch Loss: 0.9321 | Learning Rate: 0.000679 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12090/12542 | Batch Loss: 1.3721 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12091/12542 | Batch Loss: 2.2280 | Learning Rate: 0.000679 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12092/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000679 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12093/12542 | Batch Loss: 1.4163 | Learning Rate: 0.000679 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12094/12542 | Batch Loss: 0.9794 | Learning Rate: 0.000679 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12095/12542 | Batch Loss: 2.3124 | Learning Rate: 0.000679 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12096/12542 | Batch Loss: 1.7280 | Learning Rate: 0.000679 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12097/12542 | Batch Loss: 0.5874 | Learning Rate: 0.000678 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12098/12542 | Batch Loss: 1.2603 | Learning Rate: 0.000678 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12099/12542 | Batch Loss: 2.7239 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12100/12542 | Batch Loss: 1.2639 | Learning Rate: 0.000678 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12101/12542 | Batch Loss: 3.6670 | Learning Rate: 0.000678 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12102/12542 | Batch Loss: 1.6231 | Learning Rate: 0.000678 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12103/12542 | Batch Loss: 1.4288 | Learning Rate: 0.000678 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12104/12542 | Batch Loss: 1.4486 | Learning Rate: 0.000678 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12105/12542 | Batch Loss: 1.2503 | Learning Rate: 0.000678 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12106/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000678 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12107/12542 | Batch Loss: 1.4475 | Learning Rate: 0.000678 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12108/12542 | Batch Loss: 1.0432 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12109/12542 | Batch Loss: 1.7860 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12110/12542 | Batch Loss: 1.6977 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12111/12542 | Batch Loss: 1.3514 | Learning Rate: 0.000678 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12112/12542 | Batch Loss: 0.5795 | Learning Rate: 0.000678 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12113/12542 | Batch Loss: 1.5584 | Learning Rate: 0.000678 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12114/12542 | Batch Loss: 0.6194 | Learning Rate: 0.000678 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12115/12542 | Batch Loss: 1.3871 | Learning Rate: 0.000678 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12116/12542 | Batch Loss: 0.3260 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12117/12542 | Batch Loss: 1.2736 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12118/12542 | Batch Loss: 1.1133 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12119/12542 | Batch Loss: 1.3836 | Learning Rate: 0.000678 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12120/12542 | Batch Loss: 0.6299 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12121/12542 | Batch Loss: 1.1637 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12122/12542 | Batch Loss: 0.9972 | Learning Rate: 0.000678 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12123/12542 | Batch Loss: 0.5516 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12124/12542 | Batch Loss: 0.6212 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12125/12542 | Batch Loss: 1.0257 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12126/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12127/12542 | Batch Loss: 0.8681 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12128/12542 | Batch Loss: 1.7465 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12129/12542 | Batch Loss: 0.8180 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12130/12542 | Batch Loss: 1.1933 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12131/12542 | Batch Loss: 0.9827 | Learning Rate: 0.000678 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12132/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12133/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000678 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12134/12542 | Batch Loss: 2.0297 | Learning Rate: 0.000678 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12135/12542 | Batch Loss: 0.9037 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12136/12542 | Batch Loss: 1.5166 | Learning Rate: 0.000677 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12137/12542 | Batch Loss: 2.7767 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12138/12542 | Batch Loss: 1.3605 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12139/12542 | Batch Loss: 2.2354 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12140/12542 | Batch Loss: 1.1757 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12141/12542 | Batch Loss: 0.6015 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12142/12542 | Batch Loss: 1.2746 | Learning Rate: 0.000677 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12143/12542 | Batch Loss: 1.1291 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12144/12542 | Batch Loss: 1.2565 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12145/12542 | Batch Loss: 1.0009 | Learning Rate: 0.000677 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12146/12542 | Batch Loss: 1.2285 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12147/12542 | Batch Loss: 0.8050 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12148/12542 | Batch Loss: 0.8840 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12149/12542 | Batch Loss: 2.1544 | Learning Rate: 0.000677 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12150/12542 | Batch Loss: 2.5435 | Learning Rate: 0.000677 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12151/12542 | Batch Loss: 2.1049 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12152/12542 | Batch Loss: 0.9788 | Learning Rate: 0.000677 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12153/12542 | Batch Loss: 2.0686 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12154/12542 | Batch Loss: 2.3357 | Learning Rate: 0.000677 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12155/12542 | Batch Loss: 2.6748 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12156/12542 | Batch Loss: 1.4393 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12157/12542 | Batch Loss: 1.5752 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12158/12542 | Batch Loss: 1.0165 | Learning Rate: 0.000677 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12159/12542 | Batch Loss: 0.8400 | Learning Rate: 0.000677 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12160/12542 | Batch Loss: 2.3812 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12161/12542 | Batch Loss: 2.2820 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12162/12542 | Batch Loss: 0.7519 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12163/12542 | Batch Loss: 1.3266 | Learning Rate: 0.000677 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12164/12542 | Batch Loss: 1.9194 | Learning Rate: 0.000677 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12165/12542 | Batch Loss: 1.6119 | Learning Rate: 0.000677 | Batch Time: 0.70s\n",
      "Epoch 1 | Step 12166/12542 | Batch Loss: 2.6102 | Learning Rate: 0.000677 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12167/12542 | Batch Loss: 1.8526 | Learning Rate: 0.000677 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12168/12542 | Batch Loss: 0.7249 | Learning Rate: 0.000677 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12169/12542 | Batch Loss: 0.8611 | Learning Rate: 0.000677 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12170/12542 | Batch Loss: 1.3694 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12171/12542 | Batch Loss: 1.0456 | Learning Rate: 0.000677 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12172/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000677 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12173/12542 | Batch Loss: 1.0874 | Learning Rate: 0.000676 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12174/12542 | Batch Loss: 1.1461 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12175/12542 | Batch Loss: 1.4490 | Learning Rate: 0.000676 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12176/12542 | Batch Loss: 1.7745 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12177/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12178/12542 | Batch Loss: 0.9683 | Learning Rate: 0.000676 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12179/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12180/12542 | Batch Loss: 0.8644 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12181/12542 | Batch Loss: 1.7500 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12182/12542 | Batch Loss: 1.7454 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12183/12542 | Batch Loss: 1.5780 | Learning Rate: 0.000676 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12184/12542 | Batch Loss: 1.9878 | Learning Rate: 0.000676 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12185/12542 | Batch Loss: 0.8609 | Learning Rate: 0.000676 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12186/12542 | Batch Loss: 2.2129 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12187/12542 | Batch Loss: 2.0907 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12188/12542 | Batch Loss: 0.9268 | Learning Rate: 0.000676 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12189/12542 | Batch Loss: 1.7038 | Learning Rate: 0.000676 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12190/12542 | Batch Loss: 1.2926 | Learning Rate: 0.000676 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12191/12542 | Batch Loss: 1.7437 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12192/12542 | Batch Loss: 2.9312 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12193/12542 | Batch Loss: 1.1506 | Learning Rate: 0.000676 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12194/12542 | Batch Loss: 1.6888 | Learning Rate: 0.000676 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12195/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000676 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12196/12542 | Batch Loss: 1.4980 | Learning Rate: 0.000676 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12197/12542 | Batch Loss: 1.2173 | Learning Rate: 0.000676 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12198/12542 | Batch Loss: 2.6885 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12199/12542 | Batch Loss: 1.1089 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12200/12542 | Batch Loss: 0.5632 | Learning Rate: 0.000676 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12201/12542 | Batch Loss: 0.8780 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12202/12542 | Batch Loss: 1.7345 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12203/12542 | Batch Loss: 1.3134 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12204/12542 | Batch Loss: 2.4083 | Learning Rate: 0.000676 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12205/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12206/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000676 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12207/12542 | Batch Loss: 0.6317 | Learning Rate: 0.000676 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12208/12542 | Batch Loss: 3.5941 | Learning Rate: 0.000676 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12209/12542 | Batch Loss: 2.0019 | Learning Rate: 0.000676 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12210/12542 | Batch Loss: 1.2452 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12211/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000675 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12212/12542 | Batch Loss: 2.5200 | Learning Rate: 0.000675 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12213/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000675 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12214/12542 | Batch Loss: 2.4346 | Learning Rate: 0.000675 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12215/12542 | Batch Loss: 1.4875 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12216/12542 | Batch Loss: 2.6390 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12217/12542 | Batch Loss: 1.4438 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12218/12542 | Batch Loss: 2.1844 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12219/12542 | Batch Loss: 1.1105 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12220/12542 | Batch Loss: 0.9152 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12221/12542 | Batch Loss: 0.5775 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12222/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12223/12542 | Batch Loss: 1.4205 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12224/12542 | Batch Loss: 0.9442 | Learning Rate: 0.000675 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12225/12542 | Batch Loss: 1.4170 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12226/12542 | Batch Loss: 0.6093 | Learning Rate: 0.000675 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12227/12542 | Batch Loss: 1.5677 | Learning Rate: 0.000675 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12228/12542 | Batch Loss: 0.7305 | Learning Rate: 0.000675 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12229/12542 | Batch Loss: 2.0615 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12230/12542 | Batch Loss: 1.2367 | Learning Rate: 0.000675 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12231/12542 | Batch Loss: 1.4505 | Learning Rate: 0.000675 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12232/12542 | Batch Loss: 0.5688 | Learning Rate: 0.000675 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12233/12542 | Batch Loss: 1.0481 | Learning Rate: 0.000675 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12234/12542 | Batch Loss: 1.3052 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12235/12542 | Batch Loss: 0.9908 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12236/12542 | Batch Loss: 0.7112 | Learning Rate: 0.000675 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12237/12542 | Batch Loss: 1.4867 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12238/12542 | Batch Loss: 1.7369 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12239/12542 | Batch Loss: 1.2408 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12240/12542 | Batch Loss: 0.8015 | Learning Rate: 0.000675 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12241/12542 | Batch Loss: 0.6446 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12242/12542 | Batch Loss: 2.5819 | Learning Rate: 0.000675 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12243/12542 | Batch Loss: 1.3926 | Learning Rate: 0.000675 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12244/12542 | Batch Loss: 2.1946 | Learning Rate: 0.000675 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12245/12542 | Batch Loss: 1.9447 | Learning Rate: 0.000675 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12246/12542 | Batch Loss: 1.9639 | Learning Rate: 0.000675 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12247/12542 | Batch Loss: 2.3045 | Learning Rate: 0.000675 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12248/12542 | Batch Loss: 1.6642 | Learning Rate: 0.000674 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12249/12542 | Batch Loss: 0.9909 | Learning Rate: 0.000674 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12250/12542 | Batch Loss: 1.6697 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12251/12542 | Batch Loss: 0.7785 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12252/12542 | Batch Loss: 1.1876 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12253/12542 | Batch Loss: 1.0202 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12254/12542 | Batch Loss: 0.8388 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12255/12542 | Batch Loss: 0.7786 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12256/12542 | Batch Loss: 0.9968 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12257/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12258/12542 | Batch Loss: 1.6002 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12259/12542 | Batch Loss: 1.1388 | Learning Rate: 0.000674 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12260/12542 | Batch Loss: 1.2287 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12261/12542 | Batch Loss: 1.1155 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12262/12542 | Batch Loss: 0.6447 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12263/12542 | Batch Loss: 0.7370 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12264/12542 | Batch Loss: 1.8842 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12265/12542 | Batch Loss: 1.6257 | Learning Rate: 0.000674 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12266/12542 | Batch Loss: 1.2709 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12267/12542 | Batch Loss: 1.2637 | Learning Rate: 0.000674 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12268/12542 | Batch Loss: 0.8813 | Learning Rate: 0.000674 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12269/12542 | Batch Loss: 0.7307 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12270/12542 | Batch Loss: 1.7033 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12271/12542 | Batch Loss: 0.9367 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12272/12542 | Batch Loss: 2.3462 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12273/12542 | Batch Loss: 1.9614 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12274/12542 | Batch Loss: 1.9627 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12275/12542 | Batch Loss: 0.6024 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12276/12542 | Batch Loss: 2.2520 | Learning Rate: 0.000674 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12277/12542 | Batch Loss: 1.3511 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12278/12542 | Batch Loss: 1.2754 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12279/12542 | Batch Loss: 1.5179 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12280/12542 | Batch Loss: 1.8076 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12281/12542 | Batch Loss: 2.2658 | Learning Rate: 0.000674 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12282/12542 | Batch Loss: 1.9495 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12283/12542 | Batch Loss: 1.6893 | Learning Rate: 0.000674 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12284/12542 | Batch Loss: 2.1829 | Learning Rate: 0.000674 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12285/12542 | Batch Loss: 0.5649 | Learning Rate: 0.000673 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12286/12542 | Batch Loss: 1.4820 | Learning Rate: 0.000673 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12287/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000673 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12288/12542 | Batch Loss: 2.0037 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12289/12542 | Batch Loss: 1.1108 | Learning Rate: 0.000673 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12290/12542 | Batch Loss: 1.1738 | Learning Rate: 0.000673 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12291/12542 | Batch Loss: 0.7103 | Learning Rate: 0.000673 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12292/12542 | Batch Loss: 2.4402 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12293/12542 | Batch Loss: 1.0724 | Learning Rate: 0.000673 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12294/12542 | Batch Loss: 1.9057 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12295/12542 | Batch Loss: 0.7105 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12296/12542 | Batch Loss: 0.9929 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12297/12542 | Batch Loss: 1.0862 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12298/12542 | Batch Loss: 1.6279 | Learning Rate: 0.000673 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12299/12542 | Batch Loss: 0.7266 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12300/12542 | Batch Loss: 0.7935 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12301/12542 | Batch Loss: 0.6636 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12302/12542 | Batch Loss: 1.9940 | Learning Rate: 0.000673 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12303/12542 | Batch Loss: 0.7050 | Learning Rate: 0.000673 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12304/12542 | Batch Loss: 2.0447 | Learning Rate: 0.000673 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12305/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000673 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12306/12542 | Batch Loss: 1.7107 | Learning Rate: 0.000673 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12307/12542 | Batch Loss: 2.1710 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12308/12542 | Batch Loss: 0.8526 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12309/12542 | Batch Loss: 1.7577 | Learning Rate: 0.000673 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12310/12542 | Batch Loss: 1.4786 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12311/12542 | Batch Loss: 1.2415 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12312/12542 | Batch Loss: 0.8037 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12313/12542 | Batch Loss: 2.3017 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12314/12542 | Batch Loss: 1.0558 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12315/12542 | Batch Loss: 0.5561 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12316/12542 | Batch Loss: 3.3423 | Learning Rate: 0.000673 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12317/12542 | Batch Loss: 1.0370 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12318/12542 | Batch Loss: 1.3136 | Learning Rate: 0.000673 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12319/12542 | Batch Loss: 2.3041 | Learning Rate: 0.000673 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12320/12542 | Batch Loss: 2.1011 | Learning Rate: 0.000673 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12321/12542 | Batch Loss: 1.1281 | Learning Rate: 0.000673 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12322/12542 | Batch Loss: 1.2181 | Learning Rate: 0.000673 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12323/12542 | Batch Loss: 0.6146 | Learning Rate: 0.000672 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12324/12542 | Batch Loss: 1.4545 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12325/12542 | Batch Loss: 1.3525 | Learning Rate: 0.000672 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12326/12542 | Batch Loss: 2.0165 | Learning Rate: 0.000672 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12327/12542 | Batch Loss: 1.1440 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12328/12542 | Batch Loss: 1.4409 | Learning Rate: 0.000672 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12329/12542 | Batch Loss: 1.2358 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12330/12542 | Batch Loss: 1.3452 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12331/12542 | Batch Loss: 2.0422 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12332/12542 | Batch Loss: 1.3988 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12333/12542 | Batch Loss: 1.0209 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12334/12542 | Batch Loss: 2.0487 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12335/12542 | Batch Loss: 1.4210 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12336/12542 | Batch Loss: 0.7902 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12337/12542 | Batch Loss: 0.6572 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12338/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12339/12542 | Batch Loss: 0.7975 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12340/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000672 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12341/12542 | Batch Loss: 0.5894 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12342/12542 | Batch Loss: 1.3302 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12343/12542 | Batch Loss: 1.0003 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12344/12542 | Batch Loss: 1.8401 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12345/12542 | Batch Loss: 1.0639 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12346/12542 | Batch Loss: 0.7596 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12347/12542 | Batch Loss: 0.6485 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12348/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12349/12542 | Batch Loss: 1.7069 | Learning Rate: 0.000672 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12350/12542 | Batch Loss: 0.6905 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12351/12542 | Batch Loss: 0.9199 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12352/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12353/12542 | Batch Loss: 0.7418 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12354/12542 | Batch Loss: 0.5285 | Learning Rate: 0.000672 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12355/12542 | Batch Loss: 1.0221 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12356/12542 | Batch Loss: 0.4517 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12357/12542 | Batch Loss: 1.4488 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12358/12542 | Batch Loss: 1.3255 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12359/12542 | Batch Loss: 1.0676 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12360/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000672 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12361/12542 | Batch Loss: 1.6881 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12362/12542 | Batch Loss: 0.7849 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12363/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12364/12542 | Batch Loss: 1.0022 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12365/12542 | Batch Loss: 0.6288 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12366/12542 | Batch Loss: 3.5079 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12367/12542 | Batch Loss: 1.6873 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12368/12542 | Batch Loss: 0.8271 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12369/12542 | Batch Loss: 1.2523 | Learning Rate: 0.000671 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12370/12542 | Batch Loss: 1.4555 | Learning Rate: 0.000671 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12371/12542 | Batch Loss: 3.7451 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12372/12542 | Batch Loss: 0.6751 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12373/12542 | Batch Loss: 0.8661 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12374/12542 | Batch Loss: 1.8595 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12375/12542 | Batch Loss: 1.2118 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12376/12542 | Batch Loss: 0.9240 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12377/12542 | Batch Loss: 1.9905 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12378/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12379/12542 | Batch Loss: 1.6404 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12380/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12381/12542 | Batch Loss: 1.9962 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12382/12542 | Batch Loss: 2.1603 | Learning Rate: 0.000671 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12383/12542 | Batch Loss: 1.1518 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12384/12542 | Batch Loss: 0.5223 | Learning Rate: 0.000671 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12385/12542 | Batch Loss: 1.2521 | Learning Rate: 0.000671 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12386/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000671 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12387/12542 | Batch Loss: 2.2175 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12388/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000671 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12389/12542 | Batch Loss: 0.7718 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12390/12542 | Batch Loss: 0.8690 | Learning Rate: 0.000671 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12391/12542 | Batch Loss: 1.6189 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12392/12542 | Batch Loss: 1.8108 | Learning Rate: 0.000671 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12393/12542 | Batch Loss: 1.4698 | Learning Rate: 0.000671 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12394/12542 | Batch Loss: 0.7827 | Learning Rate: 0.000671 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12395/12542 | Batch Loss: 1.4583 | Learning Rate: 0.000671 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12396/12542 | Batch Loss: 0.9489 | Learning Rate: 0.000671 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12397/12542 | Batch Loss: 2.4064 | Learning Rate: 0.000671 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12398/12542 | Batch Loss: 0.5891 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12399/12542 | Batch Loss: 1.6827 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12400/12542 | Batch Loss: 1.3496 | Learning Rate: 0.000670 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12401/12542 | Batch Loss: 1.8150 | Learning Rate: 0.000670 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12402/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000670 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12403/12542 | Batch Loss: 0.9430 | Learning Rate: 0.000670 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12404/12542 | Batch Loss: 1.5289 | Learning Rate: 0.000670 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12405/12542 | Batch Loss: 1.4287 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12406/12542 | Batch Loss: 0.7275 | Learning Rate: 0.000670 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12407/12542 | Batch Loss: 0.5638 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12408/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12409/12542 | Batch Loss: 0.7059 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12410/12542 | Batch Loss: 1.5095 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12411/12542 | Batch Loss: 1.5873 | Learning Rate: 0.000670 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12412/12542 | Batch Loss: 1.4945 | Learning Rate: 0.000670 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12413/12542 | Batch Loss: 3.6605 | Learning Rate: 0.000670 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12414/12542 | Batch Loss: 1.9926 | Learning Rate: 0.000670 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12415/12542 | Batch Loss: 1.2422 | Learning Rate: 0.000670 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12416/12542 | Batch Loss: 1.1446 | Learning Rate: 0.000670 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12417/12542 | Batch Loss: 1.0447 | Learning Rate: 0.000670 | Batch Time: 0.69s\n",
      "Epoch 1 | Step 12418/12542 | Batch Loss: 1.8616 | Learning Rate: 0.000670 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12419/12542 | Batch Loss: 0.6555 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12420/12542 | Batch Loss: 1.4557 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12421/12542 | Batch Loss: 1.7239 | Learning Rate: 0.000670 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12422/12542 | Batch Loss: 1.6993 | Learning Rate: 0.000670 | Batch Time: 0.66s\n",
      "Epoch 1 | Step 12423/12542 | Batch Loss: 0.8440 | Learning Rate: 0.000670 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12424/12542 | Batch Loss: 0.8401 | Learning Rate: 0.000670 | Batch Time: 0.68s\n",
      "Epoch 1 | Step 12425/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000670 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12426/12542 | Batch Loss: 0.9409 | Learning Rate: 0.000670 | Batch Time: 0.67s\n",
      "Epoch 1 | Step 12427/12542 | Batch Loss: 1.2814 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12428/12542 | Batch Loss: 0.9565 | Learning Rate: 0.000670 | Batch Time: 1.15s\n",
      "Epoch 1 | Step 12429/12542 | Batch Loss: 0.9029 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12430/12542 | Batch Loss: 0.5070 | Learning Rate: 0.000670 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12431/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12432/12542 | Batch Loss: 0.6870 | Learning Rate: 0.000670 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12433/12542 | Batch Loss: 0.9698 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12434/12542 | Batch Loss: 1.9106 | Learning Rate: 0.000670 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12435/12542 | Batch Loss: 0.8692 | Learning Rate: 0.000670 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12436/12542 | Batch Loss: 1.2439 | Learning Rate: 0.000669 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12437/12542 | Batch Loss: 1.4672 | Learning Rate: 0.000669 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12438/12542 | Batch Loss: 1.3437 | Learning Rate: 0.000669 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12439/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000669 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12440/12542 | Batch Loss: 0.8340 | Learning Rate: 0.000669 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12441/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12442/12542 | Batch Loss: 0.6874 | Learning Rate: 0.000669 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12443/12542 | Batch Loss: 2.9637 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12444/12542 | Batch Loss: 0.7039 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12445/12542 | Batch Loss: 2.5068 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12446/12542 | Batch Loss: 0.6911 | Learning Rate: 0.000669 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12447/12542 | Batch Loss: 1.2618 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12448/12542 | Batch Loss: 0.8987 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12449/12542 | Batch Loss: 0.5702 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12450/12542 | Batch Loss: 1.6594 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12451/12542 | Batch Loss: 1.4748 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12452/12542 | Batch Loss: 1.5854 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12453/12542 | Batch Loss: 1.4987 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12454/12542 | Batch Loss: 1.5633 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12455/12542 | Batch Loss: 3.1608 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12456/12542 | Batch Loss: 1.1294 | Learning Rate: 0.000669 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12457/12542 | Batch Loss: 2.2036 | Learning Rate: 0.000669 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12458/12542 | Batch Loss: 0.7735 | Learning Rate: 0.000669 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12459/12542 | Batch Loss: 1.4171 | Learning Rate: 0.000669 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12460/12542 | Batch Loss: 0.8113 | Learning Rate: 0.000669 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12461/12542 | Batch Loss: 0.7683 | Learning Rate: 0.000669 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 12462/12542 | Batch Loss: 0.7943 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12463/12542 | Batch Loss: 1.0899 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12464/12542 | Batch Loss: 0.7153 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12465/12542 | Batch Loss: 2.8326 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12466/12542 | Batch Loss: 2.3620 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12467/12542 | Batch Loss: 0.7707 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12468/12542 | Batch Loss: 1.6547 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12469/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12470/12542 | Batch Loss: 1.0924 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12471/12542 | Batch Loss: 1.0478 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12472/12542 | Batch Loss: 1.1130 | Learning Rate: 0.000669 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12473/12542 | Batch Loss: 0.9200 | Learning Rate: 0.000669 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12474/12542 | Batch Loss: 0.8077 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12475/12542 | Batch Loss: 1.5137 | Learning Rate: 0.000668 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12476/12542 | Batch Loss: 1.1126 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12477/12542 | Batch Loss: 1.7160 | Learning Rate: 0.000668 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12478/12542 | Batch Loss: 1.7302 | Learning Rate: 0.000668 | Batch Time: 0.64s\n",
      "Epoch 1 | Step 12479/12542 | Batch Loss: 1.6787 | Learning Rate: 0.000668 | Batch Time: 0.65s\n",
      "Epoch 1 | Step 12480/12542 | Batch Loss: 0.8197 | Learning Rate: 0.000668 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12481/12542 | Batch Loss: 0.7226 | Learning Rate: 0.000668 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12482/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000668 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12483/12542 | Batch Loss: 0.8658 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12484/12542 | Batch Loss: 2.6679 | Learning Rate: 0.000668 | Batch Time: 0.56s\n",
      "Epoch 1 | Step 12485/12542 | Batch Loss: 1.0375 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12486/12542 | Batch Loss: 2.9853 | Learning Rate: 0.000668 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12487/12542 | Batch Loss: 0.9838 | Learning Rate: 0.000668 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12488/12542 | Batch Loss: 1.1710 | Learning Rate: 0.000668 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12489/12542 | Batch Loss: 0.7448 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12490/12542 | Batch Loss: 1.4119 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12491/12542 | Batch Loss: 0.9325 | Learning Rate: 0.000668 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12492/12542 | Batch Loss: 0.7387 | Learning Rate: 0.000668 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12493/12542 | Batch Loss: 0.7245 | Learning Rate: 0.000668 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12494/12542 | Batch Loss: 1.3461 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12495/12542 | Batch Loss: 0.9396 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12496/12542 | Batch Loss: 0.6742 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12497/12542 | Batch Loss: 0.6670 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12498/12542 | Batch Loss: 0.5715 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12499/12542 | Batch Loss: 1.6605 | Learning Rate: 0.000668 | Batch Time: 0.57s\n",
      "Epoch 1 | Step 12500/12542 | Batch Loss: 3.2362 | Learning Rate: 0.000668 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12501/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000668 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12502/12542 | Batch Loss: 0.7725 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12503/12542 | Batch Loss: 0.4827 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12504/12542 | Batch Loss: 0.8497 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12505/12542 | Batch Loss: 2.5771 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12506/12542 | Batch Loss: 0.3644 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12507/12542 | Batch Loss: 2.0902 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12508/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12509/12542 | Batch Loss: 0.5501 | Learning Rate: 0.000668 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12510/12542 | Batch Loss: 1.8825 | Learning Rate: 0.000668 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12511/12542 | Batch Loss: 1.5455 | Learning Rate: 0.000667 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12512/12542 | Batch Loss: 2.0748 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12513/12542 | Batch Loss: 1.0927 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12514/12542 | Batch Loss: 2.2357 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12515/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000667 | Batch Time: 0.63s\n",
      "Epoch 1 | Step 12516/12542 | Batch Loss: 0.9872 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12517/12542 | Batch Loss: 1.1951 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12518/12542 | Batch Loss: 1.1664 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12519/12542 | Batch Loss: 1.9977 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12520/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12521/12542 | Batch Loss: 1.2248 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12522/12542 | Batch Loss: 0.4846 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12523/12542 | Batch Loss: 0.5568 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12524/12542 | Batch Loss: 1.0737 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12525/12542 | Batch Loss: 0.6232 | Learning Rate: 0.000667 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12526/12542 | Batch Loss: 0.9141 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12527/12542 | Batch Loss: 1.6962 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12528/12542 | Batch Loss: 1.2452 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12529/12542 | Batch Loss: 0.8127 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12530/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12531/12542 | Batch Loss: 1.1225 | Learning Rate: 0.000667 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12532/12542 | Batch Loss: 1.5874 | Learning Rate: 0.000667 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12533/12542 | Batch Loss: 1.0946 | Learning Rate: 0.000667 | Batch Time: 0.58s\n",
      "Epoch 1 | Step 12534/12542 | Batch Loss: 1.9587 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12535/12542 | Batch Loss: 1.8911 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12536/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000667 | Batch Time: 0.61s\n",
      "Epoch 1 | Step 12537/12542 | Batch Loss: 2.4967 | Learning Rate: 0.000667 | Batch Time: 0.62s\n",
      "Epoch 1 | Step 12538/12542 | Batch Loss: 0.8673 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12539/12542 | Batch Loss: 0.5071 | Learning Rate: 0.000667 | Batch Time: 0.60s\n",
      "Epoch 1 | Step 12540/12542 | Batch Loss: 2.0904 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12541/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000667 | Batch Time: 0.59s\n",
      "Epoch 1 | Step 12542/12542 | Batch Loss: 0.6210 | Learning Rate: 0.000667 | Batch Time: 0.21s\n",
      "Epoch 1 completed. Average Loss: 1.3999 | Epoch Time: 9713.06s\n",
      "Epoch 2/3\n",
      "Epoch 2 | Step 1/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000667 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2/12542 | Batch Loss: 1.6244 | Learning Rate: 0.000667 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3/12542 | Batch Loss: 1.3055 | Learning Rate: 0.000667 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4/12542 | Batch Loss: 0.7205 | Learning Rate: 0.000667 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5/12542 | Batch Loss: 2.2839 | Learning Rate: 0.000667 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6/12542 | Batch Loss: 0.8237 | Learning Rate: 0.000667 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7/12542 | Batch Loss: 1.0501 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8/12542 | Batch Loss: 1.1552 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9/12542 | Batch Loss: 0.6483 | Learning Rate: 0.000666 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10/12542 | Batch Loss: 0.6191 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11/12542 | Batch Loss: 1.9685 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12/12542 | Batch Loss: 0.9629 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 13/12542 | Batch Loss: 0.6030 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 14/12542 | Batch Loss: 0.9986 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 15/12542 | Batch Loss: 1.7119 | Learning Rate: 0.000666 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 16/12542 | Batch Loss: 1.2135 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 17/12542 | Batch Loss: 0.7125 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 18/12542 | Batch Loss: 3.0720 | Learning Rate: 0.000666 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 19/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000666 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 20/12542 | Batch Loss: 0.6603 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 21/12542 | Batch Loss: 1.0164 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 22/12542 | Batch Loss: 2.2233 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 23/12542 | Batch Loss: 2.0281 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 24/12542 | Batch Loss: 1.6908 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 25/12542 | Batch Loss: 1.1735 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 26/12542 | Batch Loss: 1.4989 | Learning Rate: 0.000666 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 27/12542 | Batch Loss: 1.6080 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 28/12542 | Batch Loss: 0.9297 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 29/12542 | Batch Loss: 1.3252 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 30/12542 | Batch Loss: 1.6742 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 31/12542 | Batch Loss: 1.5189 | Learning Rate: 0.000666 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 32/12542 | Batch Loss: 0.8866 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 33/12542 | Batch Loss: 0.8477 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 34/12542 | Batch Loss: 2.0570 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 35/12542 | Batch Loss: 0.6708 | Learning Rate: 0.000666 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 36/12542 | Batch Loss: 1.0079 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 37/12542 | Batch Loss: 0.8985 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 38/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 39/12542 | Batch Loss: 1.1482 | Learning Rate: 0.000666 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 40/12542 | Batch Loss: 0.5194 | Learning Rate: 0.000666 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 41/12542 | Batch Loss: 0.8809 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 42/12542 | Batch Loss: 0.6972 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 43/12542 | Batch Loss: 1.6005 | Learning Rate: 0.000666 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 44/12542 | Batch Loss: 1.7291 | Learning Rate: 0.000665 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 45/12542 | Batch Loss: 0.6954 | Learning Rate: 0.000665 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 46/12542 | Batch Loss: 0.7700 | Learning Rate: 0.000665 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 47/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000665 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 48/12542 | Batch Loss: 0.7987 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 49/12542 | Batch Loss: 1.5392 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 50/12542 | Batch Loss: 1.7516 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 51/12542 | Batch Loss: 1.7331 | Learning Rate: 0.000665 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 52/12542 | Batch Loss: 0.5499 | Learning Rate: 0.000665 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 53/12542 | Batch Loss: 0.5962 | Learning Rate: 0.000665 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 54/12542 | Batch Loss: 1.8700 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 55/12542 | Batch Loss: 1.1199 | Learning Rate: 0.000665 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 56/12542 | Batch Loss: 0.7280 | Learning Rate: 0.000665 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 57/12542 | Batch Loss: 1.3371 | Learning Rate: 0.000665 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 58/12542 | Batch Loss: 0.9826 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 59/12542 | Batch Loss: 1.0835 | Learning Rate: 0.000665 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 60/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 61/12542 | Batch Loss: 1.0942 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 62/12542 | Batch Loss: 1.4678 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 63/12542 | Batch Loss: 1.1633 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 64/12542 | Batch Loss: 0.8011 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 65/12542 | Batch Loss: 0.8608 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 66/12542 | Batch Loss: 2.8065 | Learning Rate: 0.000665 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 67/12542 | Batch Loss: 0.7967 | Learning Rate: 0.000665 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 68/12542 | Batch Loss: 1.5721 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 69/12542 | Batch Loss: 0.9739 | Learning Rate: 0.000665 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 70/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000665 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 71/12542 | Batch Loss: 1.0287 | Learning Rate: 0.000665 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 72/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 73/12542 | Batch Loss: 1.6862 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 74/12542 | Batch Loss: 1.0753 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 75/12542 | Batch Loss: 0.6020 | Learning Rate: 0.000665 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 76/12542 | Batch Loss: 0.6183 | Learning Rate: 0.000665 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 77/12542 | Batch Loss: 2.9756 | Learning Rate: 0.000665 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 78/12542 | Batch Loss: 1.5882 | Learning Rate: 0.000665 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 79/12542 | Batch Loss: 0.9982 | Learning Rate: 0.000665 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 80/12542 | Batch Loss: 0.9549 | Learning Rate: 0.000665 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 81/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000665 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 82/12542 | Batch Loss: 1.3835 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 83/12542 | Batch Loss: 1.3758 | Learning Rate: 0.000664 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 84/12542 | Batch Loss: 4.3330 | Learning Rate: 0.000664 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 85/12542 | Batch Loss: 0.8216 | Learning Rate: 0.000664 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 86/12542 | Batch Loss: 1.3597 | Learning Rate: 0.000664 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 87/12542 | Batch Loss: 1.9119 | Learning Rate: 0.000664 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 88/12542 | Batch Loss: 1.1945 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 89/12542 | Batch Loss: 2.2455 | Learning Rate: 0.000664 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 90/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 91/12542 | Batch Loss: 0.6035 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 92/12542 | Batch Loss: 1.5747 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 93/12542 | Batch Loss: 0.5595 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 94/12542 | Batch Loss: 1.7921 | Learning Rate: 0.000664 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 95/12542 | Batch Loss: 3.1124 | Learning Rate: 0.000664 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 96/12542 | Batch Loss: 0.7403 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 97/12542 | Batch Loss: 1.7727 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 98/12542 | Batch Loss: 0.4203 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 99/12542 | Batch Loss: 2.2038 | Learning Rate: 0.000664 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 100/12542 | Batch Loss: 1.6486 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 101/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 102/12542 | Batch Loss: 0.9058 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 103/12542 | Batch Loss: 0.5612 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 104/12542 | Batch Loss: 1.3906 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 105/12542 | Batch Loss: 1.1397 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 106/12542 | Batch Loss: 1.1474 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 107/12542 | Batch Loss: 2.7565 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 108/12542 | Batch Loss: 1.3076 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 109/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000664 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 110/12542 | Batch Loss: 1.3323 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 111/12542 | Batch Loss: 1.3972 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 112/12542 | Batch Loss: 3.5948 | Learning Rate: 0.000664 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 113/12542 | Batch Loss: 0.7333 | Learning Rate: 0.000664 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 114/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 115/12542 | Batch Loss: 1.0863 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 116/12542 | Batch Loss: 0.5943 | Learning Rate: 0.000664 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 117/12542 | Batch Loss: 1.9769 | Learning Rate: 0.000664 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 118/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 119/12542 | Batch Loss: 1.1219 | Learning Rate: 0.000664 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 120/12542 | Batch Loss: 2.0264 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 121/12542 | Batch Loss: 0.7191 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 122/12542 | Batch Loss: 1.0115 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 123/12542 | Batch Loss: 1.4465 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 124/12542 | Batch Loss: 0.7827 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 125/12542 | Batch Loss: 2.0921 | Learning Rate: 0.000663 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 126/12542 | Batch Loss: 2.1357 | Learning Rate: 0.000663 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 127/12542 | Batch Loss: 1.8989 | Learning Rate: 0.000663 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 128/12542 | Batch Loss: 1.5456 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 129/12542 | Batch Loss: 1.7981 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 130/12542 | Batch Loss: 1.7060 | Learning Rate: 0.000663 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 131/12542 | Batch Loss: 1.6654 | Learning Rate: 0.000663 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 132/12542 | Batch Loss: 0.6322 | Learning Rate: 0.000663 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 133/12542 | Batch Loss: 2.1296 | Learning Rate: 0.000663 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 134/12542 | Batch Loss: 1.2363 | Learning Rate: 0.000663 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 135/12542 | Batch Loss: 1.0836 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 136/12542 | Batch Loss: 1.3630 | Learning Rate: 0.000663 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 137/12542 | Batch Loss: 2.1410 | Learning Rate: 0.000663 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 138/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 139/12542 | Batch Loss: 2.8969 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 140/12542 | Batch Loss: 1.9639 | Learning Rate: 0.000663 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 141/12542 | Batch Loss: 1.4671 | Learning Rate: 0.000663 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 142/12542 | Batch Loss: 1.0804 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 143/12542 | Batch Loss: 0.8684 | Learning Rate: 0.000663 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 144/12542 | Batch Loss: 1.3592 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 145/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000663 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 146/12542 | Batch Loss: 1.2287 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 147/12542 | Batch Loss: 1.7866 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 148/12542 | Batch Loss: 0.9070 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 149/12542 | Batch Loss: 1.2669 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 150/12542 | Batch Loss: 1.1029 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 151/12542 | Batch Loss: 0.9290 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 152/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 153/12542 | Batch Loss: 0.7123 | Learning Rate: 0.000663 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 154/12542 | Batch Loss: 0.5495 | Learning Rate: 0.000663 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 155/12542 | Batch Loss: 1.0019 | Learning Rate: 0.000663 | Batch Time: 0.54s\n",
      "Epoch 2 | Step 156/12542 | Batch Loss: 0.7606 | Learning Rate: 0.000663 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 157/12542 | Batch Loss: 1.0121 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 158/12542 | Batch Loss: 2.8941 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 159/12542 | Batch Loss: 1.0174 | Learning Rate: 0.000662 | Batch Time: 0.55s\n",
      "Epoch 2 | Step 160/12542 | Batch Loss: 1.3184 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 161/12542 | Batch Loss: 1.8467 | Learning Rate: 0.000662 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 162/12542 | Batch Loss: 1.5035 | Learning Rate: 0.000662 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 163/12542 | Batch Loss: 2.0037 | Learning Rate: 0.000662 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 164/12542 | Batch Loss: 0.5675 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 165/12542 | Batch Loss: 0.4594 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 166/12542 | Batch Loss: 0.9694 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 167/12542 | Batch Loss: 2.0664 | Learning Rate: 0.000662 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 168/12542 | Batch Loss: 1.6082 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 169/12542 | Batch Loss: 0.8210 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 170/12542 | Batch Loss: 1.5933 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 171/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000662 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 172/12542 | Batch Loss: 1.5256 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 173/12542 | Batch Loss: 0.5856 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 174/12542 | Batch Loss: 1.5479 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 175/12542 | Batch Loss: 1.0000 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 176/12542 | Batch Loss: 1.2605 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 177/12542 | Batch Loss: 0.9427 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 178/12542 | Batch Loss: 1.0705 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 179/12542 | Batch Loss: 1.6064 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 180/12542 | Batch Loss: 0.7543 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 181/12542 | Batch Loss: 0.6013 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 182/12542 | Batch Loss: 0.9922 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 183/12542 | Batch Loss: 2.0671 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 184/12542 | Batch Loss: 2.0847 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 185/12542 | Batch Loss: 1.1115 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 186/12542 | Batch Loss: 2.1744 | Learning Rate: 0.000662 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 187/12542 | Batch Loss: 0.8764 | Learning Rate: 0.000662 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 188/12542 | Batch Loss: 0.9589 | Learning Rate: 0.000662 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 189/12542 | Batch Loss: 1.2710 | Learning Rate: 0.000662 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 190/12542 | Batch Loss: 0.8669 | Learning Rate: 0.000662 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 191/12542 | Batch Loss: 1.1138 | Learning Rate: 0.000662 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 192/12542 | Batch Loss: 1.0467 | Learning Rate: 0.000662 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 193/12542 | Batch Loss: 1.1557 | Learning Rate: 0.000662 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 194/12542 | Batch Loss: 0.9951 | Learning Rate: 0.000662 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 195/12542 | Batch Loss: 1.6686 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 196/12542 | Batch Loss: 1.7235 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 197/12542 | Batch Loss: 1.9833 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 198/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000661 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 199/12542 | Batch Loss: 1.5680 | Learning Rate: 0.000661 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 200/12542 | Batch Loss: 1.4325 | Learning Rate: 0.000661 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 201/12542 | Batch Loss: 1.2659 | Learning Rate: 0.000661 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 202/12542 | Batch Loss: 2.7551 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 203/12542 | Batch Loss: 1.4226 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 204/12542 | Batch Loss: 2.0596 | Learning Rate: 0.000661 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 205/12542 | Batch Loss: 0.5361 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 206/12542 | Batch Loss: 2.0538 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 207/12542 | Batch Loss: 0.5373 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 208/12542 | Batch Loss: 1.4435 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 209/12542 | Batch Loss: 0.8914 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 210/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 211/12542 | Batch Loss: 1.0867 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 212/12542 | Batch Loss: 1.4023 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 213/12542 | Batch Loss: 0.9321 | Learning Rate: 0.000661 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 214/12542 | Batch Loss: 0.9933 | Learning Rate: 0.000661 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 215/12542 | Batch Loss: 0.8159 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 216/12542 | Batch Loss: 1.6884 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 217/12542 | Batch Loss: 1.5656 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 218/12542 | Batch Loss: 1.3850 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 219/12542 | Batch Loss: 1.7984 | Learning Rate: 0.000661 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 220/12542 | Batch Loss: 2.0456 | Learning Rate: 0.000661 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 221/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 222/12542 | Batch Loss: 1.4278 | Learning Rate: 0.000661 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 223/12542 | Batch Loss: 1.3038 | Learning Rate: 0.000661 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 224/12542 | Batch Loss: 0.8336 | Learning Rate: 0.000661 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 225/12542 | Batch Loss: 1.7213 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 226/12542 | Batch Loss: 1.9021 | Learning Rate: 0.000661 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 227/12542 | Batch Loss: 0.7808 | Learning Rate: 0.000661 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 228/12542 | Batch Loss: 2.2768 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 229/12542 | Batch Loss: 2.1881 | Learning Rate: 0.000661 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 230/12542 | Batch Loss: 0.7020 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 231/12542 | Batch Loss: 0.4581 | Learning Rate: 0.000661 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 232/12542 | Batch Loss: 1.4203 | Learning Rate: 0.000661 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 233/12542 | Batch Loss: 2.9689 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 234/12542 | Batch Loss: 2.5971 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 235/12542 | Batch Loss: 0.6961 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 236/12542 | Batch Loss: 1.9594 | Learning Rate: 0.000660 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 237/12542 | Batch Loss: 1.1688 | Learning Rate: 0.000660 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 238/12542 | Batch Loss: 1.2063 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 239/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000660 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 240/12542 | Batch Loss: 0.7885 | Learning Rate: 0.000660 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 241/12542 | Batch Loss: 1.1586 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 242/12542 | Batch Loss: 0.8530 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 243/12542 | Batch Loss: 1.2304 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 244/12542 | Batch Loss: 0.8943 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 245/12542 | Batch Loss: 0.8952 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 246/12542 | Batch Loss: 1.5011 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 247/12542 | Batch Loss: 0.6912 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 248/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000660 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 249/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 250/12542 | Batch Loss: 0.6148 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 251/12542 | Batch Loss: 2.3622 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 252/12542 | Batch Loss: 1.5455 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 253/12542 | Batch Loss: 1.9233 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 254/12542 | Batch Loss: 1.0621 | Learning Rate: 0.000660 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 255/12542 | Batch Loss: 0.9783 | Learning Rate: 0.000660 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 256/12542 | Batch Loss: 1.2905 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 257/12542 | Batch Loss: 3.9236 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 258/12542 | Batch Loss: 1.3501 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 259/12542 | Batch Loss: 0.8815 | Learning Rate: 0.000660 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 260/12542 | Batch Loss: 1.4126 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 261/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000660 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 262/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000660 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 263/12542 | Batch Loss: 1.3192 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 264/12542 | Batch Loss: 1.4313 | Learning Rate: 0.000660 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 265/12542 | Batch Loss: 0.7245 | Learning Rate: 0.000660 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 266/12542 | Batch Loss: 2.0553 | Learning Rate: 0.000660 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 267/12542 | Batch Loss: 2.5170 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 268/12542 | Batch Loss: 0.8137 | Learning Rate: 0.000660 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 269/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000660 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 270/12542 | Batch Loss: 1.2716 | Learning Rate: 0.000659 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 271/12542 | Batch Loss: 1.2482 | Learning Rate: 0.000659 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 272/12542 | Batch Loss: 1.4371 | Learning Rate: 0.000659 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 273/12542 | Batch Loss: 1.0770 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 274/12542 | Batch Loss: 0.5981 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 275/12542 | Batch Loss: 1.0056 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 276/12542 | Batch Loss: 0.9598 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 277/12542 | Batch Loss: 1.1603 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 278/12542 | Batch Loss: 1.4472 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 279/12542 | Batch Loss: 1.1227 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 280/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 281/12542 | Batch Loss: 1.6075 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 282/12542 | Batch Loss: 1.3261 | Learning Rate: 0.000659 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 283/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000659 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 284/12542 | Batch Loss: 0.7974 | Learning Rate: 0.000659 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 285/12542 | Batch Loss: 0.6685 | Learning Rate: 0.000659 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 286/12542 | Batch Loss: 0.6505 | Learning Rate: 0.000659 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 287/12542 | Batch Loss: 0.5789 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 288/12542 | Batch Loss: 0.8965 | Learning Rate: 0.000659 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 289/12542 | Batch Loss: 1.2294 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 290/12542 | Batch Loss: 1.6207 | Learning Rate: 0.000659 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 291/12542 | Batch Loss: 1.0120 | Learning Rate: 0.000659 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 292/12542 | Batch Loss: 2.3033 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 293/12542 | Batch Loss: 0.7960 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 294/12542 | Batch Loss: 1.2575 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 295/12542 | Batch Loss: 1.4475 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 296/12542 | Batch Loss: 1.2256 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 297/12542 | Batch Loss: 1.6630 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 298/12542 | Batch Loss: 2.1822 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 299/12542 | Batch Loss: 1.3741 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 300/12542 | Batch Loss: 1.5366 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 301/12542 | Batch Loss: 0.9321 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 302/12542 | Batch Loss: 1.1686 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 303/12542 | Batch Loss: 1.3697 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 304/12542 | Batch Loss: 0.9465 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 305/12542 | Batch Loss: 1.3447 | Learning Rate: 0.000659 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 306/12542 | Batch Loss: 0.9080 | Learning Rate: 0.000659 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 307/12542 | Batch Loss: 0.7847 | Learning Rate: 0.000659 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 308/12542 | Batch Loss: 2.8266 | Learning Rate: 0.000658 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 309/12542 | Batch Loss: 2.1981 | Learning Rate: 0.000658 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 310/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 311/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 312/12542 | Batch Loss: 0.7456 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 313/12542 | Batch Loss: 0.6367 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 314/12542 | Batch Loss: 1.6093 | Learning Rate: 0.000658 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 315/12542 | Batch Loss: 1.1426 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 316/12542 | Batch Loss: 0.9006 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 317/12542 | Batch Loss: 1.1425 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 318/12542 | Batch Loss: 1.2250 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 319/12542 | Batch Loss: 2.3340 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 320/12542 | Batch Loss: 3.2828 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 321/12542 | Batch Loss: 0.6038 | Learning Rate: 0.000658 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 322/12542 | Batch Loss: 1.8405 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 323/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000658 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 324/12542 | Batch Loss: 1.0065 | Learning Rate: 0.000658 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 325/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000658 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 326/12542 | Batch Loss: 1.8368 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 327/12542 | Batch Loss: 1.9319 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 328/12542 | Batch Loss: 0.4933 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 329/12542 | Batch Loss: 1.4097 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 330/12542 | Batch Loss: 1.1437 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 331/12542 | Batch Loss: 1.5093 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 332/12542 | Batch Loss: 0.6367 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 333/12542 | Batch Loss: 2.5012 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 334/12542 | Batch Loss: 0.6239 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 335/12542 | Batch Loss: 0.7474 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 336/12542 | Batch Loss: 0.9105 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 337/12542 | Batch Loss: 1.9226 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 338/12542 | Batch Loss: 1.2018 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 339/12542 | Batch Loss: 1.9238 | Learning Rate: 0.000658 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 340/12542 | Batch Loss: 1.3575 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 341/12542 | Batch Loss: 1.9121 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 342/12542 | Batch Loss: 0.8752 | Learning Rate: 0.000658 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 343/12542 | Batch Loss: 1.1644 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 344/12542 | Batch Loss: 2.1431 | Learning Rate: 0.000658 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 345/12542 | Batch Loss: 2.0547 | Learning Rate: 0.000657 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 346/12542 | Batch Loss: 1.2948 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 347/12542 | Batch Loss: 1.5822 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 348/12542 | Batch Loss: 0.8234 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 349/12542 | Batch Loss: 0.7230 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 350/12542 | Batch Loss: 1.5209 | Learning Rate: 0.000657 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 351/12542 | Batch Loss: 1.2736 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 352/12542 | Batch Loss: 0.8587 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 353/12542 | Batch Loss: 1.0118 | Learning Rate: 0.000657 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 354/12542 | Batch Loss: 1.8401 | Learning Rate: 0.000657 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 355/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000657 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 356/12542 | Batch Loss: 2.4614 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 357/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 358/12542 | Batch Loss: 1.8489 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 359/12542 | Batch Loss: 2.3490 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 360/12542 | Batch Loss: 1.2834 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 361/12542 | Batch Loss: 2.0600 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 362/12542 | Batch Loss: 0.7676 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 363/12542 | Batch Loss: 2.0603 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 364/12542 | Batch Loss: 1.7902 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 365/12542 | Batch Loss: 1.4100 | Learning Rate: 0.000657 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 366/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 367/12542 | Batch Loss: 0.3479 | Learning Rate: 0.000657 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 368/12542 | Batch Loss: 1.8594 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 369/12542 | Batch Loss: 1.0715 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 370/12542 | Batch Loss: 0.8076 | Learning Rate: 0.000657 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 371/12542 | Batch Loss: 0.5845 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 372/12542 | Batch Loss: 1.3570 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 373/12542 | Batch Loss: 0.8337 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 374/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 375/12542 | Batch Loss: 0.8391 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 376/12542 | Batch Loss: 3.6527 | Learning Rate: 0.000657 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 377/12542 | Batch Loss: 1.1211 | Learning Rate: 0.000657 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 378/12542 | Batch Loss: 2.2018 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 379/12542 | Batch Loss: 1.1907 | Learning Rate: 0.000657 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 380/12542 | Batch Loss: 0.6448 | Learning Rate: 0.000657 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 381/12542 | Batch Loss: 1.0704 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 382/12542 | Batch Loss: 1.8938 | Learning Rate: 0.000657 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 383/12542 | Batch Loss: 0.6457 | Learning Rate: 0.000656 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 384/12542 | Batch Loss: 1.4603 | Learning Rate: 0.000656 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 385/12542 | Batch Loss: 0.5890 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 386/12542 | Batch Loss: 1.5373 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 387/12542 | Batch Loss: 0.9828 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 388/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 389/12542 | Batch Loss: 1.6919 | Learning Rate: 0.000656 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 390/12542 | Batch Loss: 0.8217 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 391/12542 | Batch Loss: 1.0915 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 392/12542 | Batch Loss: 2.2773 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 393/12542 | Batch Loss: 1.5165 | Learning Rate: 0.000656 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 394/12542 | Batch Loss: 0.7356 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 395/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 396/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 397/12542 | Batch Loss: 0.8400 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 398/12542 | Batch Loss: 2.3670 | Learning Rate: 0.000656 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 399/12542 | Batch Loss: 0.9888 | Learning Rate: 0.000656 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 400/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 401/12542 | Batch Loss: 2.1423 | Learning Rate: 0.000656 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 402/12542 | Batch Loss: 0.9487 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 403/12542 | Batch Loss: 1.9585 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 404/12542 | Batch Loss: 0.8396 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 405/12542 | Batch Loss: 1.0802 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 406/12542 | Batch Loss: 0.7602 | Learning Rate: 0.000656 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 407/12542 | Batch Loss: 0.6516 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 408/12542 | Batch Loss: 1.3105 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 409/12542 | Batch Loss: 0.8441 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 410/12542 | Batch Loss: 1.0355 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 411/12542 | Batch Loss: 1.9834 | Learning Rate: 0.000656 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 412/12542 | Batch Loss: 1.4262 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 413/12542 | Batch Loss: 1.9395 | Learning Rate: 0.000656 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 414/12542 | Batch Loss: 0.7868 | Learning Rate: 0.000656 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 415/12542 | Batch Loss: 1.3673 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 416/12542 | Batch Loss: 1.3193 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 417/12542 | Batch Loss: 1.8988 | Learning Rate: 0.000656 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 418/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000656 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 419/12542 | Batch Loss: 1.2615 | Learning Rate: 0.000656 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 420/12542 | Batch Loss: 0.7799 | Learning Rate: 0.000656 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 421/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 422/12542 | Batch Loss: 1.4465 | Learning Rate: 0.000655 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 423/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000655 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 424/12542 | Batch Loss: 3.1804 | Learning Rate: 0.000655 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 425/12542 | Batch Loss: 0.8410 | Learning Rate: 0.000655 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 426/12542 | Batch Loss: 2.4313 | Learning Rate: 0.000655 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 427/12542 | Batch Loss: 0.6296 | Learning Rate: 0.000655 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 428/12542 | Batch Loss: 1.6051 | Learning Rate: 0.000655 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 429/12542 | Batch Loss: 1.8133 | Learning Rate: 0.000655 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 430/12542 | Batch Loss: 2.2518 | Learning Rate: 0.000655 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 431/12542 | Batch Loss: 1.4720 | Learning Rate: 0.000655 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 432/12542 | Batch Loss: 0.8212 | Learning Rate: 0.000655 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 433/12542 | Batch Loss: 1.1103 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 434/12542 | Batch Loss: 0.7780 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 435/12542 | Batch Loss: 1.8809 | Learning Rate: 0.000655 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 436/12542 | Batch Loss: 1.2879 | Learning Rate: 0.000655 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 437/12542 | Batch Loss: 1.0181 | Learning Rate: 0.000655 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 438/12542 | Batch Loss: 1.0851 | Learning Rate: 0.000655 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 439/12542 | Batch Loss: 0.7968 | Learning Rate: 0.000655 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 440/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000655 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 441/12542 | Batch Loss: 1.4642 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 442/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 443/12542 | Batch Loss: 3.0111 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 444/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 445/12542 | Batch Loss: 1.6001 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 446/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000655 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 447/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 448/12542 | Batch Loss: 0.8896 | Learning Rate: 0.000655 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 449/12542 | Batch Loss: 0.8484 | Learning Rate: 0.000655 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 450/12542 | Batch Loss: 2.5325 | Learning Rate: 0.000655 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 451/12542 | Batch Loss: 1.8394 | Learning Rate: 0.000655 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 452/12542 | Batch Loss: 2.0107 | Learning Rate: 0.000655 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 453/12542 | Batch Loss: 1.6175 | Learning Rate: 0.000655 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 454/12542 | Batch Loss: 1.0687 | Learning Rate: 0.000655 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 455/12542 | Batch Loss: 0.7315 | Learning Rate: 0.000655 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 456/12542 | Batch Loss: 1.3895 | Learning Rate: 0.000655 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 457/12542 | Batch Loss: 1.5264 | Learning Rate: 0.000655 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 458/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000654 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 459/12542 | Batch Loss: 1.6718 | Learning Rate: 0.000654 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 460/12542 | Batch Loss: 1.0895 | Learning Rate: 0.000654 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 461/12542 | Batch Loss: 0.7178 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 462/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000654 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 463/12542 | Batch Loss: 2.3011 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 464/12542 | Batch Loss: 3.4908 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 465/12542 | Batch Loss: 1.2796 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 466/12542 | Batch Loss: 0.9775 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 467/12542 | Batch Loss: 0.9082 | Learning Rate: 0.000654 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 468/12542 | Batch Loss: 3.0261 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 469/12542 | Batch Loss: 1.4972 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 470/12542 | Batch Loss: 2.8303 | Learning Rate: 0.000654 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 471/12542 | Batch Loss: 2.4664 | Learning Rate: 0.000654 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 472/12542 | Batch Loss: 0.8592 | Learning Rate: 0.000654 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 473/12542 | Batch Loss: 1.1638 | Learning Rate: 0.000654 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 474/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000654 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 475/12542 | Batch Loss: 2.0423 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 476/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000654 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 477/12542 | Batch Loss: 1.8667 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 478/12542 | Batch Loss: 0.7653 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 479/12542 | Batch Loss: 1.1486 | Learning Rate: 0.000654 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 480/12542 | Batch Loss: 1.1291 | Learning Rate: 0.000654 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 481/12542 | Batch Loss: 1.4215 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 482/12542 | Batch Loss: 1.3444 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 483/12542 | Batch Loss: 0.7028 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 484/12542 | Batch Loss: 0.5252 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 485/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 486/12542 | Batch Loss: 1.3816 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 487/12542 | Batch Loss: 1.6482 | Learning Rate: 0.000654 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 488/12542 | Batch Loss: 2.2750 | Learning Rate: 0.000654 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 489/12542 | Batch Loss: 0.7939 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 490/12542 | Batch Loss: 1.8783 | Learning Rate: 0.000654 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 491/12542 | Batch Loss: 0.8700 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 492/12542 | Batch Loss: 0.5140 | Learning Rate: 0.000654 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 493/12542 | Batch Loss: 0.9194 | Learning Rate: 0.000654 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 494/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000654 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 495/12542 | Batch Loss: 1.5945 | Learning Rate: 0.000654 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 496/12542 | Batch Loss: 2.2462 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 497/12542 | Batch Loss: 1.5474 | Learning Rate: 0.000653 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 498/12542 | Batch Loss: 2.1918 | Learning Rate: 0.000653 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 499/12542 | Batch Loss: 1.9258 | Learning Rate: 0.000653 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 500/12542 | Batch Loss: 1.6213 | Learning Rate: 0.000653 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 501/12542 | Batch Loss: 0.8602 | Learning Rate: 0.000653 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 502/12542 | Batch Loss: 1.2818 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 503/12542 | Batch Loss: 1.5207 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 504/12542 | Batch Loss: 1.2574 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 505/12542 | Batch Loss: 1.6750 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 506/12542 | Batch Loss: 0.5310 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 507/12542 | Batch Loss: 1.8046 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 508/12542 | Batch Loss: 0.8659 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 509/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000653 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 510/12542 | Batch Loss: 0.6147 | Learning Rate: 0.000653 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 511/12542 | Batch Loss: 2.1573 | Learning Rate: 0.000653 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 512/12542 | Batch Loss: 0.9271 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 513/12542 | Batch Loss: 0.8696 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 514/12542 | Batch Loss: 1.3005 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 515/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000653 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 516/12542 | Batch Loss: 0.6280 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 517/12542 | Batch Loss: 1.4034 | Learning Rate: 0.000653 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 518/12542 | Batch Loss: 0.6224 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 519/12542 | Batch Loss: 2.0601 | Learning Rate: 0.000653 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 520/12542 | Batch Loss: 2.3803 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 521/12542 | Batch Loss: 0.5829 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 522/12542 | Batch Loss: 1.5285 | Learning Rate: 0.000653 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 523/12542 | Batch Loss: 0.8775 | Learning Rate: 0.000653 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 524/12542 | Batch Loss: 1.8763 | Learning Rate: 0.000653 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 525/12542 | Batch Loss: 1.8065 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 526/12542 | Batch Loss: 0.7420 | Learning Rate: 0.000653 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 527/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000653 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 528/12542 | Batch Loss: 0.7577 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 529/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 530/12542 | Batch Loss: 2.5691 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 531/12542 | Batch Loss: 1.5994 | Learning Rate: 0.000653 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 532/12542 | Batch Loss: 0.8331 | Learning Rate: 0.000653 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 533/12542 | Batch Loss: 0.8147 | Learning Rate: 0.000653 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 534/12542 | Batch Loss: 1.3162 | Learning Rate: 0.000652 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 535/12542 | Batch Loss: 1.5977 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 536/12542 | Batch Loss: 3.5651 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 537/12542 | Batch Loss: 3.3531 | Learning Rate: 0.000652 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 538/12542 | Batch Loss: 0.8386 | Learning Rate: 0.000652 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 539/12542 | Batch Loss: 0.9068 | Learning Rate: 0.000652 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 540/12542 | Batch Loss: 1.3417 | Learning Rate: 0.000652 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 541/12542 | Batch Loss: 1.7092 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 542/12542 | Batch Loss: 1.2105 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 543/12542 | Batch Loss: 1.4056 | Learning Rate: 0.000652 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 544/12542 | Batch Loss: 1.1753 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 545/12542 | Batch Loss: 0.6535 | Learning Rate: 0.000652 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 546/12542 | Batch Loss: 1.4022 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 547/12542 | Batch Loss: 1.1388 | Learning Rate: 0.000652 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 548/12542 | Batch Loss: 0.6746 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 549/12542 | Batch Loss: 0.7299 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 550/12542 | Batch Loss: 2.0149 | Learning Rate: 0.000652 | Batch Time: 0.56s\n",
      "Epoch 2 | Step 551/12542 | Batch Loss: 1.3438 | Learning Rate: 0.000652 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 552/12542 | Batch Loss: 1.3410 | Learning Rate: 0.000652 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 553/12542 | Batch Loss: 2.4351 | Learning Rate: 0.000652 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 554/12542 | Batch Loss: 2.2748 | Learning Rate: 0.000652 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 555/12542 | Batch Loss: 0.6307 | Learning Rate: 0.000652 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 556/12542 | Batch Loss: 0.7593 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 557/12542 | Batch Loss: 1.0729 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 558/12542 | Batch Loss: 0.9843 | Learning Rate: 0.000652 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 559/12542 | Batch Loss: 0.8138 | Learning Rate: 0.000652 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 560/12542 | Batch Loss: 0.9941 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 561/12542 | Batch Loss: 0.8321 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 562/12542 | Batch Loss: 1.1435 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 563/12542 | Batch Loss: 1.0186 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 564/12542 | Batch Loss: 1.2173 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 565/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000652 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 566/12542 | Batch Loss: 1.8053 | Learning Rate: 0.000652 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 567/12542 | Batch Loss: 0.8396 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 568/12542 | Batch Loss: 1.8307 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 569/12542 | Batch Loss: 2.7395 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 570/12542 | Batch Loss: 1.3811 | Learning Rate: 0.000652 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 571/12542 | Batch Loss: 1.1319 | Learning Rate: 0.000651 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 572/12542 | Batch Loss: 0.6225 | Learning Rate: 0.000651 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 573/12542 | Batch Loss: 2.3800 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 574/12542 | Batch Loss: 2.3440 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 575/12542 | Batch Loss: 1.0742 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 576/12542 | Batch Loss: 0.8082 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 577/12542 | Batch Loss: 0.9278 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 578/12542 | Batch Loss: 1.6209 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 579/12542 | Batch Loss: 0.5726 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 580/12542 | Batch Loss: 1.0310 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 581/12542 | Batch Loss: 1.6844 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 582/12542 | Batch Loss: 1.9171 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 583/12542 | Batch Loss: 0.8285 | Learning Rate: 0.000651 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 584/12542 | Batch Loss: 1.4325 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 585/12542 | Batch Loss: 0.5558 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 586/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 587/12542 | Batch Loss: 1.0351 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 588/12542 | Batch Loss: 1.4045 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 589/12542 | Batch Loss: 1.0998 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 590/12542 | Batch Loss: 2.0097 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 591/12542 | Batch Loss: 1.1227 | Learning Rate: 0.000651 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 592/12542 | Batch Loss: 0.6898 | Learning Rate: 0.000651 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 593/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000651 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 594/12542 | Batch Loss: 1.7991 | Learning Rate: 0.000651 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 595/12542 | Batch Loss: 1.0774 | Learning Rate: 0.000651 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 596/12542 | Batch Loss: 0.5256 | Learning Rate: 0.000651 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 597/12542 | Batch Loss: 1.4108 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 598/12542 | Batch Loss: 0.7931 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 599/12542 | Batch Loss: 0.8433 | Learning Rate: 0.000651 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 600/12542 | Batch Loss: 0.8684 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 601/12542 | Batch Loss: 1.1774 | Learning Rate: 0.000651 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 602/12542 | Batch Loss: 2.0150 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 603/12542 | Batch Loss: 0.9828 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 604/12542 | Batch Loss: 1.0089 | Learning Rate: 0.000651 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 605/12542 | Batch Loss: 1.9784 | Learning Rate: 0.000651 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 606/12542 | Batch Loss: 1.4349 | Learning Rate: 0.000651 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 607/12542 | Batch Loss: 1.5078 | Learning Rate: 0.000651 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 608/12542 | Batch Loss: 1.2214 | Learning Rate: 0.000651 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 609/12542 | Batch Loss: 0.9168 | Learning Rate: 0.000650 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 610/12542 | Batch Loss: 1.4091 | Learning Rate: 0.000650 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 611/12542 | Batch Loss: 1.6238 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 612/12542 | Batch Loss: 1.4889 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 613/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000650 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 614/12542 | Batch Loss: 2.7551 | Learning Rate: 0.000650 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 615/12542 | Batch Loss: 2.1783 | Learning Rate: 0.000650 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 616/12542 | Batch Loss: 1.1781 | Learning Rate: 0.000650 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 617/12542 | Batch Loss: 1.3747 | Learning Rate: 0.000650 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 618/12542 | Batch Loss: 1.1951 | Learning Rate: 0.000650 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 619/12542 | Batch Loss: 1.0273 | Learning Rate: 0.000650 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 620/12542 | Batch Loss: 1.4646 | Learning Rate: 0.000650 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 621/12542 | Batch Loss: 2.4449 | Learning Rate: 0.000650 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 622/12542 | Batch Loss: 0.7720 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 623/12542 | Batch Loss: 1.7483 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 624/12542 | Batch Loss: 2.1280 | Learning Rate: 0.000650 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 625/12542 | Batch Loss: 1.7274 | Learning Rate: 0.000650 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 626/12542 | Batch Loss: 1.7611 | Learning Rate: 0.000650 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 627/12542 | Batch Loss: 0.7152 | Learning Rate: 0.000650 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 628/12542 | Batch Loss: 0.6982 | Learning Rate: 0.000650 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 629/12542 | Batch Loss: 1.4682 | Learning Rate: 0.000650 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 630/12542 | Batch Loss: 0.9717 | Learning Rate: 0.000650 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 631/12542 | Batch Loss: 1.2516 | Learning Rate: 0.000650 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 632/12542 | Batch Loss: 2.5458 | Learning Rate: 0.000650 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 633/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 634/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000650 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 635/12542 | Batch Loss: 2.6473 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 636/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000650 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 637/12542 | Batch Loss: 0.7758 | Learning Rate: 0.000650 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 638/12542 | Batch Loss: 1.1207 | Learning Rate: 0.000650 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 639/12542 | Batch Loss: 1.2636 | Learning Rate: 0.000650 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 640/12542 | Batch Loss: 0.7981 | Learning Rate: 0.000650 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 641/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000650 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 642/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000650 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 643/12542 | Batch Loss: 2.2108 | Learning Rate: 0.000650 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 644/12542 | Batch Loss: 0.7403 | Learning Rate: 0.000650 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 645/12542 | Batch Loss: 0.6972 | Learning Rate: 0.000650 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 646/12542 | Batch Loss: 1.6782 | Learning Rate: 0.000649 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 647/12542 | Batch Loss: 2.0703 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 648/12542 | Batch Loss: 1.0704 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 649/12542 | Batch Loss: 1.3219 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 650/12542 | Batch Loss: 0.8478 | Learning Rate: 0.000649 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 651/12542 | Batch Loss: 1.0849 | Learning Rate: 0.000649 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 652/12542 | Batch Loss: 1.6004 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 653/12542 | Batch Loss: 1.8727 | Learning Rate: 0.000649 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 654/12542 | Batch Loss: 0.8425 | Learning Rate: 0.000649 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 655/12542 | Batch Loss: 1.2307 | Learning Rate: 0.000649 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 656/12542 | Batch Loss: 1.0534 | Learning Rate: 0.000649 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 657/12542 | Batch Loss: 1.6039 | Learning Rate: 0.000649 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 658/12542 | Batch Loss: 1.7379 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 659/12542 | Batch Loss: 2.1922 | Learning Rate: 0.000649 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 660/12542 | Batch Loss: 1.7207 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 661/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000649 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 662/12542 | Batch Loss: 1.2972 | Learning Rate: 0.000649 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 663/12542 | Batch Loss: 0.7766 | Learning Rate: 0.000649 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 664/12542 | Batch Loss: 2.1726 | Learning Rate: 0.000649 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 665/12542 | Batch Loss: 1.5926 | Learning Rate: 0.000649 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 666/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000649 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 667/12542 | Batch Loss: 1.9423 | Learning Rate: 0.000649 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 668/12542 | Batch Loss: 0.6888 | Learning Rate: 0.000649 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 669/12542 | Batch Loss: 0.3572 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 670/12542 | Batch Loss: 2.0307 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 671/12542 | Batch Loss: 1.4777 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 672/12542 | Batch Loss: 2.3322 | Learning Rate: 0.000649 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 673/12542 | Batch Loss: 1.6436 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 674/12542 | Batch Loss: 1.1033 | Learning Rate: 0.000649 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 675/12542 | Batch Loss: 2.5253 | Learning Rate: 0.000649 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 676/12542 | Batch Loss: 0.2860 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 677/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000649 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 678/12542 | Batch Loss: 1.3657 | Learning Rate: 0.000649 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 679/12542 | Batch Loss: 1.0193 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 680/12542 | Batch Loss: 0.8241 | Learning Rate: 0.000649 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 681/12542 | Batch Loss: 0.4049 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 682/12542 | Batch Loss: 1.3236 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 683/12542 | Batch Loss: 1.0616 | Learning Rate: 0.000649 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 684/12542 | Batch Loss: 0.9815 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 685/12542 | Batch Loss: 1.2433 | Learning Rate: 0.000648 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 686/12542 | Batch Loss: 1.2642 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 687/12542 | Batch Loss: 1.6159 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 688/12542 | Batch Loss: 0.7902 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 689/12542 | Batch Loss: 2.2052 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 690/12542 | Batch Loss: 1.3894 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 691/12542 | Batch Loss: 1.0217 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 692/12542 | Batch Loss: 1.6462 | Learning Rate: 0.000648 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 693/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000648 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 694/12542 | Batch Loss: 0.6079 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 695/12542 | Batch Loss: 1.6632 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 696/12542 | Batch Loss: 2.6823 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 697/12542 | Batch Loss: 1.7585 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 698/12542 | Batch Loss: 1.2505 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 699/12542 | Batch Loss: 1.1377 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 700/12542 | Batch Loss: 0.6977 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 701/12542 | Batch Loss: 1.6767 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 702/12542 | Batch Loss: 2.4695 | Learning Rate: 0.000648 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 703/12542 | Batch Loss: 1.2190 | Learning Rate: 0.000648 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 704/12542 | Batch Loss: 0.9722 | Learning Rate: 0.000648 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 705/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000648 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 706/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000648 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 707/12542 | Batch Loss: 0.7971 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 708/12542 | Batch Loss: 1.0064 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 709/12542 | Batch Loss: 1.2580 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 710/12542 | Batch Loss: 0.4983 | Learning Rate: 0.000648 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 711/12542 | Batch Loss: 0.4387 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 712/12542 | Batch Loss: 0.9982 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 713/12542 | Batch Loss: 1.7080 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 714/12542 | Batch Loss: 0.4277 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 715/12542 | Batch Loss: 0.9332 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 716/12542 | Batch Loss: 1.1104 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 717/12542 | Batch Loss: 1.5570 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 718/12542 | Batch Loss: 2.4636 | Learning Rate: 0.000648 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 719/12542 | Batch Loss: 1.5429 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 720/12542 | Batch Loss: 0.4640 | Learning Rate: 0.000648 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 721/12542 | Batch Loss: 1.9909 | Learning Rate: 0.000648 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 722/12542 | Batch Loss: 1.3870 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 723/12542 | Batch Loss: 1.5055 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 724/12542 | Batch Loss: 1.0808 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 725/12542 | Batch Loss: 1.1886 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 726/12542 | Batch Loss: 0.8794 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 727/12542 | Batch Loss: 1.4485 | Learning Rate: 0.000647 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 728/12542 | Batch Loss: 3.4267 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 729/12542 | Batch Loss: 1.4595 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 730/12542 | Batch Loss: 2.0725 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 731/12542 | Batch Loss: 0.4490 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 732/12542 | Batch Loss: 1.3215 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 733/12542 | Batch Loss: 0.9063 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 734/12542 | Batch Loss: 1.4323 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 735/12542 | Batch Loss: 0.7576 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 736/12542 | Batch Loss: 0.7937 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 737/12542 | Batch Loss: 1.5564 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 738/12542 | Batch Loss: 0.8979 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 739/12542 | Batch Loss: 2.0245 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 740/12542 | Batch Loss: 0.7938 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 741/12542 | Batch Loss: 0.5349 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 742/12542 | Batch Loss: 1.2721 | Learning Rate: 0.000647 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 743/12542 | Batch Loss: 1.8304 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 744/12542 | Batch Loss: 1.1836 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 745/12542 | Batch Loss: 1.2864 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 746/12542 | Batch Loss: 0.5964 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 747/12542 | Batch Loss: 1.7139 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 748/12542 | Batch Loss: 1.2954 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 749/12542 | Batch Loss: 1.3296 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 750/12542 | Batch Loss: 0.8071 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 751/12542 | Batch Loss: 0.9370 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 752/12542 | Batch Loss: 1.8596 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 753/12542 | Batch Loss: 0.6831 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 754/12542 | Batch Loss: 1.6351 | Learning Rate: 0.000647 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 755/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 756/12542 | Batch Loss: 1.0362 | Learning Rate: 0.000647 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 757/12542 | Batch Loss: 0.9289 | Learning Rate: 0.000647 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 758/12542 | Batch Loss: 1.4926 | Learning Rate: 0.000647 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 759/12542 | Batch Loss: 0.6361 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 760/12542 | Batch Loss: 1.3215 | Learning Rate: 0.000646 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 761/12542 | Batch Loss: 2.2495 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 762/12542 | Batch Loss: 1.2837 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 763/12542 | Batch Loss: 0.9368 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 764/12542 | Batch Loss: 2.3596 | Learning Rate: 0.000646 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 765/12542 | Batch Loss: 1.3385 | Learning Rate: 0.000646 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 766/12542 | Batch Loss: 0.8901 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 767/12542 | Batch Loss: 1.6822 | Learning Rate: 0.000646 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 768/12542 | Batch Loss: 1.0533 | Learning Rate: 0.000646 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 769/12542 | Batch Loss: 2.4027 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 770/12542 | Batch Loss: 1.4216 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 771/12542 | Batch Loss: 0.8923 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 772/12542 | Batch Loss: 1.1229 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 773/12542 | Batch Loss: 1.0835 | Learning Rate: 0.000646 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 774/12542 | Batch Loss: 1.6824 | Learning Rate: 0.000646 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 775/12542 | Batch Loss: 0.7257 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 776/12542 | Batch Loss: 2.0563 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 777/12542 | Batch Loss: 1.5438 | Learning Rate: 0.000646 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 778/12542 | Batch Loss: 1.2892 | Learning Rate: 0.000646 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 779/12542 | Batch Loss: 1.0158 | Learning Rate: 0.000646 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 780/12542 | Batch Loss: 1.4632 | Learning Rate: 0.000646 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 781/12542 | Batch Loss: 0.6043 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 782/12542 | Batch Loss: 1.5067 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 783/12542 | Batch Loss: 1.4549 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 784/12542 | Batch Loss: 1.9915 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 785/12542 | Batch Loss: 0.8771 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 786/12542 | Batch Loss: 0.9345 | Learning Rate: 0.000646 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 787/12542 | Batch Loss: 0.9594 | Learning Rate: 0.000646 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 788/12542 | Batch Loss: 1.0500 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 789/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 790/12542 | Batch Loss: 1.9121 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 791/12542 | Batch Loss: 2.1302 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 792/12542 | Batch Loss: 1.0208 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 793/12542 | Batch Loss: 2.0081 | Learning Rate: 0.000646 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 794/12542 | Batch Loss: 1.0495 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 795/12542 | Batch Loss: 1.4841 | Learning Rate: 0.000646 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 796/12542 | Batch Loss: 0.6956 | Learning Rate: 0.000646 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 797/12542 | Batch Loss: 1.1154 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 798/12542 | Batch Loss: 2.1450 | Learning Rate: 0.000645 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 799/12542 | Batch Loss: 1.2620 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 800/12542 | Batch Loss: 0.8120 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 801/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000645 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 802/12542 | Batch Loss: 1.0616 | Learning Rate: 0.000645 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 803/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000645 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 804/12542 | Batch Loss: 0.9175 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 805/12542 | Batch Loss: 0.7761 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 806/12542 | Batch Loss: 1.5002 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 807/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 808/12542 | Batch Loss: 0.5019 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 809/12542 | Batch Loss: 1.3692 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 810/12542 | Batch Loss: 1.0732 | Learning Rate: 0.000645 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 811/12542 | Batch Loss: 0.5381 | Learning Rate: 0.000645 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 812/12542 | Batch Loss: 1.5536 | Learning Rate: 0.000645 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 813/12542 | Batch Loss: 2.1778 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 814/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 815/12542 | Batch Loss: 3.0728 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 816/12542 | Batch Loss: 0.7615 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 817/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 818/12542 | Batch Loss: 0.6750 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 819/12542 | Batch Loss: 0.9843 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 820/12542 | Batch Loss: 1.0232 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 821/12542 | Batch Loss: 1.8614 | Learning Rate: 0.000645 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 822/12542 | Batch Loss: 1.7981 | Learning Rate: 0.000645 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 823/12542 | Batch Loss: 1.2880 | Learning Rate: 0.000645 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 824/12542 | Batch Loss: 1.0664 | Learning Rate: 0.000645 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 825/12542 | Batch Loss: 0.6372 | Learning Rate: 0.000645 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 826/12542 | Batch Loss: 1.4745 | Learning Rate: 0.000645 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 827/12542 | Batch Loss: 1.2795 | Learning Rate: 0.000645 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 828/12542 | Batch Loss: 2.5248 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 829/12542 | Batch Loss: 1.4018 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 830/12542 | Batch Loss: 0.6651 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 831/12542 | Batch Loss: 1.3341 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 832/12542 | Batch Loss: 4.3130 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 833/12542 | Batch Loss: 1.0900 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 834/12542 | Batch Loss: 1.8124 | Learning Rate: 0.000645 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 835/12542 | Batch Loss: 0.6665 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 836/12542 | Batch Loss: 1.4213 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 837/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 838/12542 | Batch Loss: 1.2636 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 839/12542 | Batch Loss: 2.2111 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 840/12542 | Batch Loss: 1.3205 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 841/12542 | Batch Loss: 1.0315 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 842/12542 | Batch Loss: 1.2629 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 843/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 844/12542 | Batch Loss: 0.9698 | Learning Rate: 0.000644 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 845/12542 | Batch Loss: 1.6319 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 846/12542 | Batch Loss: 1.3649 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 847/12542 | Batch Loss: 1.4782 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 848/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 849/12542 | Batch Loss: 0.6636 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 850/12542 | Batch Loss: 2.1644 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 851/12542 | Batch Loss: 0.4779 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 852/12542 | Batch Loss: 0.6174 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 853/12542 | Batch Loss: 0.6666 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 854/12542 | Batch Loss: 1.4816 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 855/12542 | Batch Loss: 1.3086 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 856/12542 | Batch Loss: 2.0258 | Learning Rate: 0.000644 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 857/12542 | Batch Loss: 2.2528 | Learning Rate: 0.000644 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 858/12542 | Batch Loss: 1.2847 | Learning Rate: 0.000644 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 859/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000644 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 860/12542 | Batch Loss: 1.3119 | Learning Rate: 0.000644 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 861/12542 | Batch Loss: 1.0924 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 862/12542 | Batch Loss: 1.7298 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 863/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 864/12542 | Batch Loss: 0.7987 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 865/12542 | Batch Loss: 1.3815 | Learning Rate: 0.000644 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 866/12542 | Batch Loss: 0.7121 | Learning Rate: 0.000644 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 867/12542 | Batch Loss: 1.2849 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 868/12542 | Batch Loss: 2.1132 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 869/12542 | Batch Loss: 0.7219 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 870/12542 | Batch Loss: 1.1927 | Learning Rate: 0.000644 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 871/12542 | Batch Loss: 0.3780 | Learning Rate: 0.000644 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 872/12542 | Batch Loss: 0.6884 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 873/12542 | Batch Loss: 0.6690 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 874/12542 | Batch Loss: 2.1184 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 875/12542 | Batch Loss: 0.6585 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 876/12542 | Batch Loss: 1.1679 | Learning Rate: 0.000643 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 877/12542 | Batch Loss: 1.3310 | Learning Rate: 0.000643 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 878/12542 | Batch Loss: 0.5180 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 879/12542 | Batch Loss: 2.1940 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 880/12542 | Batch Loss: 1.1183 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 881/12542 | Batch Loss: 1.5335 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 882/12542 | Batch Loss: 1.9301 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 883/12542 | Batch Loss: 0.7411 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 884/12542 | Batch Loss: 1.5417 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 885/12542 | Batch Loss: 1.4003 | Learning Rate: 0.000643 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 886/12542 | Batch Loss: 1.8897 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 887/12542 | Batch Loss: 1.3618 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 888/12542 | Batch Loss: 0.7847 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 889/12542 | Batch Loss: 0.4619 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 890/12542 | Batch Loss: 0.2792 | Learning Rate: 0.000643 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 891/12542 | Batch Loss: 0.7588 | Learning Rate: 0.000643 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 892/12542 | Batch Loss: 1.8420 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 893/12542 | Batch Loss: 0.8448 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 894/12542 | Batch Loss: 1.6689 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 895/12542 | Batch Loss: 0.9327 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 896/12542 | Batch Loss: 1.4650 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 897/12542 | Batch Loss: 1.7233 | Learning Rate: 0.000643 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 898/12542 | Batch Loss: 2.0246 | Learning Rate: 0.000643 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 899/12542 | Batch Loss: 0.7348 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 900/12542 | Batch Loss: 0.9890 | Learning Rate: 0.000643 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 901/12542 | Batch Loss: 1.3998 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 902/12542 | Batch Loss: 0.9874 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 903/12542 | Batch Loss: 0.6585 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 904/12542 | Batch Loss: 1.0056 | Learning Rate: 0.000643 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 905/12542 | Batch Loss: 1.4035 | Learning Rate: 0.000643 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 906/12542 | Batch Loss: 2.9699 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 907/12542 | Batch Loss: 1.6007 | Learning Rate: 0.000643 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 908/12542 | Batch Loss: 0.7306 | Learning Rate: 0.000643 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 909/12542 | Batch Loss: 0.9400 | Learning Rate: 0.000643 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 910/12542 | Batch Loss: 1.5761 | Learning Rate: 0.000642 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 911/12542 | Batch Loss: 1.3746 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 912/12542 | Batch Loss: 1.4254 | Learning Rate: 0.000642 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 913/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 914/12542 | Batch Loss: 1.6657 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 915/12542 | Batch Loss: 1.1576 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 916/12542 | Batch Loss: 1.4399 | Learning Rate: 0.000642 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 917/12542 | Batch Loss: 1.2669 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 918/12542 | Batch Loss: 0.7709 | Learning Rate: 0.000642 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 919/12542 | Batch Loss: 0.6007 | Learning Rate: 0.000642 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 920/12542 | Batch Loss: 1.4313 | Learning Rate: 0.000642 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 921/12542 | Batch Loss: 0.8675 | Learning Rate: 0.000642 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 922/12542 | Batch Loss: 1.1281 | Learning Rate: 0.000642 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 923/12542 | Batch Loss: 1.8797 | Learning Rate: 0.000642 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 924/12542 | Batch Loss: 1.3645 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 925/12542 | Batch Loss: 1.6617 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 926/12542 | Batch Loss: 0.6826 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 927/12542 | Batch Loss: 3.1379 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 928/12542 | Batch Loss: 2.0967 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 929/12542 | Batch Loss: 1.2475 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 930/12542 | Batch Loss: 2.4249 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 931/12542 | Batch Loss: 0.7266 | Learning Rate: 0.000642 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 932/12542 | Batch Loss: 1.4655 | Learning Rate: 0.000642 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 933/12542 | Batch Loss: 0.6956 | Learning Rate: 0.000642 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 934/12542 | Batch Loss: 0.8150 | Learning Rate: 0.000642 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 935/12542 | Batch Loss: 0.9027 | Learning Rate: 0.000642 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 936/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 937/12542 | Batch Loss: 0.9094 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 938/12542 | Batch Loss: 1.1582 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 939/12542 | Batch Loss: 0.8367 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 940/12542 | Batch Loss: 2.0197 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 941/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 942/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 943/12542 | Batch Loss: 0.7835 | Learning Rate: 0.000642 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 944/12542 | Batch Loss: 0.3953 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 945/12542 | Batch Loss: 2.7845 | Learning Rate: 0.000642 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 946/12542 | Batch Loss: 0.6666 | Learning Rate: 0.000642 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 947/12542 | Batch Loss: 1.0989 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 948/12542 | Batch Loss: 1.1659 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 949/12542 | Batch Loss: 1.5194 | Learning Rate: 0.000641 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 950/12542 | Batch Loss: 0.9584 | Learning Rate: 0.000641 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 951/12542 | Batch Loss: 1.6548 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 952/12542 | Batch Loss: 2.2939 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 953/12542 | Batch Loss: 1.2412 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 954/12542 | Batch Loss: 2.0734 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 955/12542 | Batch Loss: 1.8182 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 956/12542 | Batch Loss: 1.0075 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 957/12542 | Batch Loss: 1.2187 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 958/12542 | Batch Loss: 0.8965 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 959/12542 | Batch Loss: 1.1524 | Learning Rate: 0.000641 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 960/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 961/12542 | Batch Loss: 1.9323 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 962/12542 | Batch Loss: 1.5733 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 963/12542 | Batch Loss: 1.7260 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 964/12542 | Batch Loss: 0.9001 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 965/12542 | Batch Loss: 1.6286 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 966/12542 | Batch Loss: 0.9080 | Learning Rate: 0.000641 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 967/12542 | Batch Loss: 1.6575 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 968/12542 | Batch Loss: 0.8526 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 969/12542 | Batch Loss: 0.4098 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 970/12542 | Batch Loss: 1.2416 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 971/12542 | Batch Loss: 1.9158 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 972/12542 | Batch Loss: 0.8444 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 973/12542 | Batch Loss: 1.2836 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 974/12542 | Batch Loss: 1.2481 | Learning Rate: 0.000641 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 975/12542 | Batch Loss: 0.3659 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 976/12542 | Batch Loss: 0.8301 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 977/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 978/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 979/12542 | Batch Loss: 0.8073 | Learning Rate: 0.000641 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 980/12542 | Batch Loss: 2.6997 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 981/12542 | Batch Loss: 0.7807 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 982/12542 | Batch Loss: 0.7087 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 983/12542 | Batch Loss: 0.5211 | Learning Rate: 0.000641 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 984/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000641 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 985/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 986/12542 | Batch Loss: 3.2853 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 987/12542 | Batch Loss: 2.0185 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 988/12542 | Batch Loss: 0.9207 | Learning Rate: 0.000640 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 989/12542 | Batch Loss: 1.5021 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 990/12542 | Batch Loss: 1.2330 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 991/12542 | Batch Loss: 2.0555 | Learning Rate: 0.000640 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 992/12542 | Batch Loss: 1.2018 | Learning Rate: 0.000640 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 993/12542 | Batch Loss: 0.8123 | Learning Rate: 0.000640 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 994/12542 | Batch Loss: 0.8301 | Learning Rate: 0.000640 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 995/12542 | Batch Loss: 0.8134 | Learning Rate: 0.000640 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 996/12542 | Batch Loss: 2.0458 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 997/12542 | Batch Loss: 1.7907 | Learning Rate: 0.000640 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 998/12542 | Batch Loss: 2.0901 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 999/12542 | Batch Loss: 0.7266 | Learning Rate: 0.000640 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1000/12542 | Batch Loss: 1.0017 | Learning Rate: 0.000640 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1001/12542 | Batch Loss: 0.6641 | Learning Rate: 0.000640 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1002/12542 | Batch Loss: 1.7266 | Learning Rate: 0.000640 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1003/12542 | Batch Loss: 1.2735 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1004/12542 | Batch Loss: 0.7992 | Learning Rate: 0.000640 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1005/12542 | Batch Loss: 3.5838 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1006/12542 | Batch Loss: 1.2105 | Learning Rate: 0.000640 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1007/12542 | Batch Loss: 1.2231 | Learning Rate: 0.000640 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1008/12542 | Batch Loss: 0.3284 | Learning Rate: 0.000640 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1009/12542 | Batch Loss: 0.5559 | Learning Rate: 0.000640 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1010/12542 | Batch Loss: 1.0218 | Learning Rate: 0.000640 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1011/12542 | Batch Loss: 0.6147 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1012/12542 | Batch Loss: 0.8903 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1013/12542 | Batch Loss: 1.0248 | Learning Rate: 0.000640 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1014/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000640 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1015/12542 | Batch Loss: 1.1751 | Learning Rate: 0.000640 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1016/12542 | Batch Loss: 0.6472 | Learning Rate: 0.000640 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1017/12542 | Batch Loss: 0.5904 | Learning Rate: 0.000640 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1018/12542 | Batch Loss: 0.9032 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1019/12542 | Batch Loss: 0.9649 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1020/12542 | Batch Loss: 0.7277 | Learning Rate: 0.000640 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1021/12542 | Batch Loss: 0.7474 | Learning Rate: 0.000640 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1022/12542 | Batch Loss: 2.7116 | Learning Rate: 0.000640 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1023/12542 | Batch Loss: 0.6064 | Learning Rate: 0.000639 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1024/12542 | Batch Loss: 2.0555 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1025/12542 | Batch Loss: 1.0129 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1026/12542 | Batch Loss: 1.2056 | Learning Rate: 0.000639 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1027/12542 | Batch Loss: 0.7695 | Learning Rate: 0.000639 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1028/12542 | Batch Loss: 0.5731 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1029/12542 | Batch Loss: 1.9882 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1030/12542 | Batch Loss: 1.6819 | Learning Rate: 0.000639 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1031/12542 | Batch Loss: 1.3038 | Learning Rate: 0.000639 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1032/12542 | Batch Loss: 0.9226 | Learning Rate: 0.000639 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1033/12542 | Batch Loss: 1.9297 | Learning Rate: 0.000639 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1034/12542 | Batch Loss: 0.7316 | Learning Rate: 0.000639 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1035/12542 | Batch Loss: 2.3302 | Learning Rate: 0.000639 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1036/12542 | Batch Loss: 1.3404 | Learning Rate: 0.000639 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1037/12542 | Batch Loss: 1.2452 | Learning Rate: 0.000639 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1038/12542 | Batch Loss: 2.1348 | Learning Rate: 0.000639 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1039/12542 | Batch Loss: 0.6702 | Learning Rate: 0.000639 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1040/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000639 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1041/12542 | Batch Loss: 3.5368 | Learning Rate: 0.000639 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1042/12542 | Batch Loss: 1.3548 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1043/12542 | Batch Loss: 1.6022 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1044/12542 | Batch Loss: 1.7374 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1045/12542 | Batch Loss: 1.3168 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1046/12542 | Batch Loss: 1.0064 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1047/12542 | Batch Loss: 2.6646 | Learning Rate: 0.000639 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1048/12542 | Batch Loss: 0.6065 | Learning Rate: 0.000639 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1049/12542 | Batch Loss: 2.0786 | Learning Rate: 0.000639 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1050/12542 | Batch Loss: 0.6378 | Learning Rate: 0.000639 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1051/12542 | Batch Loss: 2.3323 | Learning Rate: 0.000639 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1052/12542 | Batch Loss: 0.8332 | Learning Rate: 0.000639 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1053/12542 | Batch Loss: 1.1926 | Learning Rate: 0.000639 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1054/12542 | Batch Loss: 1.0712 | Learning Rate: 0.000639 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1055/12542 | Batch Loss: 0.6622 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1056/12542 | Batch Loss: 1.0026 | Learning Rate: 0.000639 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1057/12542 | Batch Loss: 0.5729 | Learning Rate: 0.000639 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1058/12542 | Batch Loss: 0.6945 | Learning Rate: 0.000639 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1059/12542 | Batch Loss: 2.8205 | Learning Rate: 0.000639 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1060/12542 | Batch Loss: 1.0391 | Learning Rate: 0.000638 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1061/12542 | Batch Loss: 1.0622 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1062/12542 | Batch Loss: 1.4226 | Learning Rate: 0.000638 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1063/12542 | Batch Loss: 1.0757 | Learning Rate: 0.000638 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1064/12542 | Batch Loss: 1.5621 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1065/12542 | Batch Loss: 2.3250 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1066/12542 | Batch Loss: 0.5397 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1067/12542 | Batch Loss: 2.2694 | Learning Rate: 0.000638 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1068/12542 | Batch Loss: 1.3997 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1069/12542 | Batch Loss: 2.0825 | Learning Rate: 0.000638 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1070/12542 | Batch Loss: 0.8255 | Learning Rate: 0.000638 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1071/12542 | Batch Loss: 1.8272 | Learning Rate: 0.000638 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1072/12542 | Batch Loss: 1.5008 | Learning Rate: 0.000638 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1073/12542 | Batch Loss: 0.6095 | Learning Rate: 0.000638 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1074/12542 | Batch Loss: 3.3908 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1075/12542 | Batch Loss: 1.0260 | Learning Rate: 0.000638 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1076/12542 | Batch Loss: 0.9660 | Learning Rate: 0.000638 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1077/12542 | Batch Loss: 1.1101 | Learning Rate: 0.000638 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1078/12542 | Batch Loss: 0.8559 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1079/12542 | Batch Loss: 1.6810 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1080/12542 | Batch Loss: 1.5077 | Learning Rate: 0.000638 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1081/12542 | Batch Loss: 2.3265 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1082/12542 | Batch Loss: 1.4549 | Learning Rate: 0.000638 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1083/12542 | Batch Loss: 1.5183 | Learning Rate: 0.000638 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1084/12542 | Batch Loss: 1.1900 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1085/12542 | Batch Loss: 0.7504 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1086/12542 | Batch Loss: 1.3413 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1087/12542 | Batch Loss: 1.8410 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1088/12542 | Batch Loss: 1.3435 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1089/12542 | Batch Loss: 1.8957 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1090/12542 | Batch Loss: 0.7221 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1091/12542 | Batch Loss: 2.1739 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1092/12542 | Batch Loss: 1.0181 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1093/12542 | Batch Loss: 3.2358 | Learning Rate: 0.000638 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1094/12542 | Batch Loss: 1.9486 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1095/12542 | Batch Loss: 0.9385 | Learning Rate: 0.000638 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1096/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000638 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1097/12542 | Batch Loss: 0.9812 | Learning Rate: 0.000638 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1098/12542 | Batch Loss: 1.1986 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1099/12542 | Batch Loss: 0.7152 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1100/12542 | Batch Loss: 1.9937 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1101/12542 | Batch Loss: 0.7214 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1102/12542 | Batch Loss: 0.6684 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1103/12542 | Batch Loss: 0.7148 | Learning Rate: 0.000637 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1104/12542 | Batch Loss: 0.8191 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1105/12542 | Batch Loss: 1.8231 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1106/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1107/12542 | Batch Loss: 2.5764 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1108/12542 | Batch Loss: 2.2168 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1109/12542 | Batch Loss: 0.9062 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1110/12542 | Batch Loss: 1.3065 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1111/12542 | Batch Loss: 1.8645 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1112/12542 | Batch Loss: 0.4804 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1113/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1114/12542 | Batch Loss: 0.5447 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1115/12542 | Batch Loss: 1.8359 | Learning Rate: 0.000637 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1116/12542 | Batch Loss: 0.8338 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1117/12542 | Batch Loss: 1.1378 | Learning Rate: 0.000637 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1118/12542 | Batch Loss: 0.9792 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1119/12542 | Batch Loss: 1.5946 | Learning Rate: 0.000637 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1120/12542 | Batch Loss: 1.5924 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1121/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1122/12542 | Batch Loss: 1.7367 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1123/12542 | Batch Loss: 1.4894 | Learning Rate: 0.000637 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1124/12542 | Batch Loss: 0.7934 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1125/12542 | Batch Loss: 1.2350 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1126/12542 | Batch Loss: 1.4897 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1127/12542 | Batch Loss: 0.9404 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1128/12542 | Batch Loss: 2.1706 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1129/12542 | Batch Loss: 1.3536 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1130/12542 | Batch Loss: 2.4945 | Learning Rate: 0.000637 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1131/12542 | Batch Loss: 0.4733 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1132/12542 | Batch Loss: 2.2848 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1133/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000637 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1134/12542 | Batch Loss: 1.2412 | Learning Rate: 0.000637 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1135/12542 | Batch Loss: 1.7827 | Learning Rate: 0.000637 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1136/12542 | Batch Loss: 1.0114 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1137/12542 | Batch Loss: 1.4944 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1138/12542 | Batch Loss: 2.0212 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1139/12542 | Batch Loss: 1.2270 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1140/12542 | Batch Loss: 1.4693 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1141/12542 | Batch Loss: 1.8990 | Learning Rate: 0.000636 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1142/12542 | Batch Loss: 1.0260 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1143/12542 | Batch Loss: 1.4772 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1144/12542 | Batch Loss: 0.5851 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1145/12542 | Batch Loss: 0.7422 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1146/12542 | Batch Loss: 1.2591 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1147/12542 | Batch Loss: 1.9124 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1148/12542 | Batch Loss: 1.9024 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1149/12542 | Batch Loss: 1.2154 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1150/12542 | Batch Loss: 1.2540 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1151/12542 | Batch Loss: 2.5070 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1152/12542 | Batch Loss: 1.5230 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1153/12542 | Batch Loss: 0.5752 | Learning Rate: 0.000636 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1154/12542 | Batch Loss: 1.3835 | Learning Rate: 0.000636 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1155/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000636 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1156/12542 | Batch Loss: 1.2757 | Learning Rate: 0.000636 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1157/12542 | Batch Loss: 1.5092 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1158/12542 | Batch Loss: 1.3861 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1159/12542 | Batch Loss: 1.5481 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1160/12542 | Batch Loss: 0.5760 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1161/12542 | Batch Loss: 2.6740 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1162/12542 | Batch Loss: 1.0478 | Learning Rate: 0.000636 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1163/12542 | Batch Loss: 1.6492 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1164/12542 | Batch Loss: 2.1228 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1165/12542 | Batch Loss: 1.6027 | Learning Rate: 0.000636 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1166/12542 | Batch Loss: 1.1782 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1167/12542 | Batch Loss: 1.6224 | Learning Rate: 0.000636 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1168/12542 | Batch Loss: 1.7257 | Learning Rate: 0.000636 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1169/12542 | Batch Loss: 2.1151 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1170/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000636 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1171/12542 | Batch Loss: 2.3192 | Learning Rate: 0.000636 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1172/12542 | Batch Loss: 1.8219 | Learning Rate: 0.000636 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1173/12542 | Batch Loss: 1.1787 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1174/12542 | Batch Loss: 2.4843 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1175/12542 | Batch Loss: 2.0109 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1176/12542 | Batch Loss: 1.4080 | Learning Rate: 0.000635 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1177/12542 | Batch Loss: 1.1266 | Learning Rate: 0.000635 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1178/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000635 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1179/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1180/12542 | Batch Loss: 0.6583 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1181/12542 | Batch Loss: 1.0836 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1182/12542 | Batch Loss: 2.0919 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1183/12542 | Batch Loss: 0.6340 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1184/12542 | Batch Loss: 1.1484 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1185/12542 | Batch Loss: 3.2067 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1186/12542 | Batch Loss: 2.9651 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1187/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1188/12542 | Batch Loss: 0.7207 | Learning Rate: 0.000635 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1189/12542 | Batch Loss: 1.9591 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1190/12542 | Batch Loss: 2.1139 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1191/12542 | Batch Loss: 1.2842 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1192/12542 | Batch Loss: 2.4473 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1193/12542 | Batch Loss: 0.8867 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1194/12542 | Batch Loss: 1.0187 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1195/12542 | Batch Loss: 1.6729 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1196/12542 | Batch Loss: 1.3147 | Learning Rate: 0.000635 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1197/12542 | Batch Loss: 2.2451 | Learning Rate: 0.000635 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1198/12542 | Batch Loss: 2.1696 | Learning Rate: 0.000635 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1199/12542 | Batch Loss: 0.9954 | Learning Rate: 0.000635 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1200/12542 | Batch Loss: 0.6941 | Learning Rate: 0.000635 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1201/12542 | Batch Loss: 1.7289 | Learning Rate: 0.000635 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1202/12542 | Batch Loss: 0.5340 | Learning Rate: 0.000635 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1203/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000635 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1204/12542 | Batch Loss: 1.1963 | Learning Rate: 0.000635 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1205/12542 | Batch Loss: 1.1833 | Learning Rate: 0.000635 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1206/12542 | Batch Loss: 0.9643 | Learning Rate: 0.000635 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1207/12542 | Batch Loss: 1.5222 | Learning Rate: 0.000635 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1208/12542 | Batch Loss: 0.8131 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1209/12542 | Batch Loss: 0.5657 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1210/12542 | Batch Loss: 1.5296 | Learning Rate: 0.000635 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1211/12542 | Batch Loss: 1.3241 | Learning Rate: 0.000634 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1212/12542 | Batch Loss: 1.1508 | Learning Rate: 0.000634 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1213/12542 | Batch Loss: 0.5346 | Learning Rate: 0.000634 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1214/12542 | Batch Loss: 1.1407 | Learning Rate: 0.000634 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1215/12542 | Batch Loss: 2.4440 | Learning Rate: 0.000634 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1216/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000634 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1217/12542 | Batch Loss: 0.8821 | Learning Rate: 0.000634 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1218/12542 | Batch Loss: 1.3063 | Learning Rate: 0.000634 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1219/12542 | Batch Loss: 1.0349 | Learning Rate: 0.000634 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1220/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000634 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1221/12542 | Batch Loss: 1.0728 | Learning Rate: 0.000634 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1222/12542 | Batch Loss: 1.6227 | Learning Rate: 0.000634 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 1223/12542 | Batch Loss: 2.0594 | Learning Rate: 0.000634 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1224/12542 | Batch Loss: 0.8859 | Learning Rate: 0.000634 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1225/12542 | Batch Loss: 1.1108 | Learning Rate: 0.000634 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1226/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000634 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1227/12542 | Batch Loss: 0.6124 | Learning Rate: 0.000634 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1228/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000634 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1229/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000634 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1230/12542 | Batch Loss: 1.8854 | Learning Rate: 0.000634 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1231/12542 | Batch Loss: 1.4153 | Learning Rate: 0.000634 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1232/12542 | Batch Loss: 1.8956 | Learning Rate: 0.000634 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1233/12542 | Batch Loss: 0.7935 | Learning Rate: 0.000634 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1234/12542 | Batch Loss: 0.7787 | Learning Rate: 0.000634 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1235/12542 | Batch Loss: 1.4838 | Learning Rate: 0.000634 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1236/12542 | Batch Loss: 2.2138 | Learning Rate: 0.000634 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1237/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000634 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1238/12542 | Batch Loss: 1.3898 | Learning Rate: 0.000634 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 1239/12542 | Batch Loss: 3.8946 | Learning Rate: 0.000634 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1240/12542 | Batch Loss: 1.2933 | Learning Rate: 0.000634 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1241/12542 | Batch Loss: 1.5822 | Learning Rate: 0.000634 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1242/12542 | Batch Loss: 1.4150 | Learning Rate: 0.000634 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1243/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000634 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1244/12542 | Batch Loss: 2.5810 | Learning Rate: 0.000634 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1245/12542 | Batch Loss: 1.2628 | Learning Rate: 0.000634 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1246/12542 | Batch Loss: 1.7218 | Learning Rate: 0.000634 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1247/12542 | Batch Loss: 1.3251 | Learning Rate: 0.000634 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1248/12542 | Batch Loss: 1.8062 | Learning Rate: 0.000633 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1249/12542 | Batch Loss: 1.6032 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1250/12542 | Batch Loss: 0.6203 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1251/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1252/12542 | Batch Loss: 0.8761 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1253/12542 | Batch Loss: 0.8394 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1254/12542 | Batch Loss: 3.8989 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1255/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1256/12542 | Batch Loss: 0.6658 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1257/12542 | Batch Loss: 1.9935 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1258/12542 | Batch Loss: 1.8793 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1259/12542 | Batch Loss: 2.5561 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1260/12542 | Batch Loss: 1.2487 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1261/12542 | Batch Loss: 1.7126 | Learning Rate: 0.000633 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1262/12542 | Batch Loss: 1.5775 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1263/12542 | Batch Loss: 1.8592 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1264/12542 | Batch Loss: 2.3143 | Learning Rate: 0.000633 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1265/12542 | Batch Loss: 1.3157 | Learning Rate: 0.000633 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1266/12542 | Batch Loss: 1.6095 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1267/12542 | Batch Loss: 1.1268 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1268/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1269/12542 | Batch Loss: 1.6452 | Learning Rate: 0.000633 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1270/12542 | Batch Loss: 1.9404 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1271/12542 | Batch Loss: 0.6303 | Learning Rate: 0.000633 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1272/12542 | Batch Loss: 0.3625 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1273/12542 | Batch Loss: 2.2057 | Learning Rate: 0.000633 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1274/12542 | Batch Loss: 2.1420 | Learning Rate: 0.000633 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1275/12542 | Batch Loss: 0.3817 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1276/12542 | Batch Loss: 2.7306 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1277/12542 | Batch Loss: 1.0521 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1278/12542 | Batch Loss: 1.3115 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1279/12542 | Batch Loss: 0.6365 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1280/12542 | Batch Loss: 0.6469 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1281/12542 | Batch Loss: 1.5187 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1282/12542 | Batch Loss: 1.0381 | Learning Rate: 0.000633 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1283/12542 | Batch Loss: 1.6542 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1284/12542 | Batch Loss: 1.4608 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1285/12542 | Batch Loss: 2.1385 | Learning Rate: 0.000633 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1286/12542 | Batch Loss: 2.0170 | Learning Rate: 0.000632 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1287/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000632 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1288/12542 | Batch Loss: 1.5005 | Learning Rate: 0.000632 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1289/12542 | Batch Loss: 1.6039 | Learning Rate: 0.000632 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1290/12542 | Batch Loss: 1.2986 | Learning Rate: 0.000632 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1291/12542 | Batch Loss: 0.7260 | Learning Rate: 0.000632 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1292/12542 | Batch Loss: 1.9464 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1293/12542 | Batch Loss: 1.2573 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1294/12542 | Batch Loss: 1.5839 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1295/12542 | Batch Loss: 1.1191 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1296/12542 | Batch Loss: 1.0078 | Learning Rate: 0.000632 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1297/12542 | Batch Loss: 0.6824 | Learning Rate: 0.000632 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1298/12542 | Batch Loss: 0.8932 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1299/12542 | Batch Loss: 1.1711 | Learning Rate: 0.000632 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1300/12542 | Batch Loss: 1.6683 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1301/12542 | Batch Loss: 0.9192 | Learning Rate: 0.000632 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1302/12542 | Batch Loss: 0.5894 | Learning Rate: 0.000632 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1303/12542 | Batch Loss: 1.9338 | Learning Rate: 0.000632 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1304/12542 | Batch Loss: 1.3314 | Learning Rate: 0.000632 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1305/12542 | Batch Loss: 0.8542 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1306/12542 | Batch Loss: 0.3960 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1307/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1308/12542 | Batch Loss: 1.7728 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1309/12542 | Batch Loss: 2.1909 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1310/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000632 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1311/12542 | Batch Loss: 0.8407 | Learning Rate: 0.000632 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1312/12542 | Batch Loss: 0.4893 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1313/12542 | Batch Loss: 1.6367 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1314/12542 | Batch Loss: 2.5132 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1315/12542 | Batch Loss: 1.2214 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1316/12542 | Batch Loss: 1.2753 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1317/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1318/12542 | Batch Loss: 0.6158 | Learning Rate: 0.000632 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1319/12542 | Batch Loss: 0.8267 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1320/12542 | Batch Loss: 1.3952 | Learning Rate: 0.000632 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1321/12542 | Batch Loss: 2.0068 | Learning Rate: 0.000632 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1322/12542 | Batch Loss: 0.8951 | Learning Rate: 0.000632 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1323/12542 | Batch Loss: 1.6780 | Learning Rate: 0.000632 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1324/12542 | Batch Loss: 1.3976 | Learning Rate: 0.000631 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1325/12542 | Batch Loss: 1.0261 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1326/12542 | Batch Loss: 1.1915 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1327/12542 | Batch Loss: 0.7414 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1328/12542 | Batch Loss: 1.4411 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1329/12542 | Batch Loss: 0.6293 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1330/12542 | Batch Loss: 0.6193 | Learning Rate: 0.000631 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1331/12542 | Batch Loss: 2.0383 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1332/12542 | Batch Loss: 0.9703 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1333/12542 | Batch Loss: 2.4633 | Learning Rate: 0.000631 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1334/12542 | Batch Loss: 1.3394 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1335/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000631 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1336/12542 | Batch Loss: 1.5679 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1337/12542 | Batch Loss: 1.8560 | Learning Rate: 0.000631 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1338/12542 | Batch Loss: 1.4971 | Learning Rate: 0.000631 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1339/12542 | Batch Loss: 1.7515 | Learning Rate: 0.000631 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1340/12542 | Batch Loss: 1.7881 | Learning Rate: 0.000631 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1341/12542 | Batch Loss: 0.9556 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1342/12542 | Batch Loss: 1.5666 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1343/12542 | Batch Loss: 1.4232 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1344/12542 | Batch Loss: 1.3140 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1345/12542 | Batch Loss: 0.7601 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1346/12542 | Batch Loss: 0.8664 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1347/12542 | Batch Loss: 2.1279 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1348/12542 | Batch Loss: 3.8266 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1349/12542 | Batch Loss: 1.4598 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1350/12542 | Batch Loss: 1.0422 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1351/12542 | Batch Loss: 0.6914 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1352/12542 | Batch Loss: 1.2670 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1353/12542 | Batch Loss: 1.7614 | Learning Rate: 0.000631 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1354/12542 | Batch Loss: 0.9896 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1355/12542 | Batch Loss: 1.3688 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1356/12542 | Batch Loss: 1.8179 | Learning Rate: 0.000631 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1357/12542 | Batch Loss: 0.9254 | Learning Rate: 0.000631 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1358/12542 | Batch Loss: 0.8047 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1359/12542 | Batch Loss: 0.6317 | Learning Rate: 0.000631 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1360/12542 | Batch Loss: 1.7501 | Learning Rate: 0.000631 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1361/12542 | Batch Loss: 1.3991 | Learning Rate: 0.000630 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1362/12542 | Batch Loss: 1.3034 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1363/12542 | Batch Loss: 1.2329 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1364/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1365/12542 | Batch Loss: 2.6522 | Learning Rate: 0.000630 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1366/12542 | Batch Loss: 2.0048 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1367/12542 | Batch Loss: 1.3071 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1368/12542 | Batch Loss: 2.1895 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1369/12542 | Batch Loss: 1.6085 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1370/12542 | Batch Loss: 0.6758 | Learning Rate: 0.000630 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1371/12542 | Batch Loss: 0.9611 | Learning Rate: 0.000630 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1372/12542 | Batch Loss: 1.3302 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1373/12542 | Batch Loss: 1.6403 | Learning Rate: 0.000630 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1374/12542 | Batch Loss: 1.6691 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1375/12542 | Batch Loss: 0.5269 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1376/12542 | Batch Loss: 1.3558 | Learning Rate: 0.000630 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1377/12542 | Batch Loss: 2.0923 | Learning Rate: 0.000630 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1378/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1379/12542 | Batch Loss: 0.7276 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1380/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1381/12542 | Batch Loss: 1.8276 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1382/12542 | Batch Loss: 1.0525 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1383/12542 | Batch Loss: 1.3437 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1384/12542 | Batch Loss: 0.7486 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1385/12542 | Batch Loss: 0.5998 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1386/12542 | Batch Loss: 0.7179 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1387/12542 | Batch Loss: 1.4168 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1388/12542 | Batch Loss: 1.3268 | Learning Rate: 0.000630 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1389/12542 | Batch Loss: 1.5255 | Learning Rate: 0.000630 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1390/12542 | Batch Loss: 1.7125 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1391/12542 | Batch Loss: 1.5520 | Learning Rate: 0.000630 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1392/12542 | Batch Loss: 1.4045 | Learning Rate: 0.000630 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1393/12542 | Batch Loss: 1.1126 | Learning Rate: 0.000630 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1394/12542 | Batch Loss: 1.7876 | Learning Rate: 0.000630 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1395/12542 | Batch Loss: 0.5960 | Learning Rate: 0.000630 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1396/12542 | Batch Loss: 1.8770 | Learning Rate: 0.000630 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1397/12542 | Batch Loss: 1.3185 | Learning Rate: 0.000630 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1398/12542 | Batch Loss: 2.1795 | Learning Rate: 0.000630 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1399/12542 | Batch Loss: 1.1678 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1400/12542 | Batch Loss: 0.9192 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1401/12542 | Batch Loss: 0.9234 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1402/12542 | Batch Loss: 0.5960 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1403/12542 | Batch Loss: 1.8650 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1404/12542 | Batch Loss: 0.9131 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1405/12542 | Batch Loss: 0.5111 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1406/12542 | Batch Loss: 1.1126 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1407/12542 | Batch Loss: 2.2446 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1408/12542 | Batch Loss: 1.4368 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1409/12542 | Batch Loss: 0.8394 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1410/12542 | Batch Loss: 1.0808 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1411/12542 | Batch Loss: 0.7773 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1412/12542 | Batch Loss: 1.3809 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1413/12542 | Batch Loss: 0.6674 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1414/12542 | Batch Loss: 1.2474 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1415/12542 | Batch Loss: 2.9473 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1416/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000629 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1417/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1418/12542 | Batch Loss: 1.8427 | Learning Rate: 0.000629 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1419/12542 | Batch Loss: 1.9438 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1420/12542 | Batch Loss: 1.2489 | Learning Rate: 0.000629 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1421/12542 | Batch Loss: 1.2006 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1422/12542 | Batch Loss: 1.0664 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1423/12542 | Batch Loss: 3.0983 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1424/12542 | Batch Loss: 1.5813 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1425/12542 | Batch Loss: 1.8406 | Learning Rate: 0.000629 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1426/12542 | Batch Loss: 0.7926 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1427/12542 | Batch Loss: 1.0505 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1428/12542 | Batch Loss: 0.7310 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1429/12542 | Batch Loss: 1.2245 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1430/12542 | Batch Loss: 1.5221 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1431/12542 | Batch Loss: 2.6190 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1432/12542 | Batch Loss: 0.5814 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1433/12542 | Batch Loss: 0.9903 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1434/12542 | Batch Loss: 1.7539 | Learning Rate: 0.000629 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1435/12542 | Batch Loss: 1.2408 | Learning Rate: 0.000629 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1436/12542 | Batch Loss: 1.1503 | Learning Rate: 0.000629 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1437/12542 | Batch Loss: 1.9220 | Learning Rate: 0.000628 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1438/12542 | Batch Loss: 1.7963 | Learning Rate: 0.000628 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1439/12542 | Batch Loss: 0.9000 | Learning Rate: 0.000628 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1440/12542 | Batch Loss: 2.8495 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1441/12542 | Batch Loss: 1.7241 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1442/12542 | Batch Loss: 0.7778 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1443/12542 | Batch Loss: 0.6280 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1444/12542 | Batch Loss: 1.0580 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1445/12542 | Batch Loss: 1.0978 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1446/12542 | Batch Loss: 0.5995 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1447/12542 | Batch Loss: 0.9522 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1448/12542 | Batch Loss: 1.5109 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1449/12542 | Batch Loss: 1.6719 | Learning Rate: 0.000628 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1450/12542 | Batch Loss: 0.8798 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1451/12542 | Batch Loss: 1.3101 | Learning Rate: 0.000628 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1452/12542 | Batch Loss: 1.6359 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1453/12542 | Batch Loss: 1.0174 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1454/12542 | Batch Loss: 0.9373 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1455/12542 | Batch Loss: 0.5240 | Learning Rate: 0.000628 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1456/12542 | Batch Loss: 3.0550 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1457/12542 | Batch Loss: 1.1466 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1458/12542 | Batch Loss: 2.3333 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1459/12542 | Batch Loss: 0.9346 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1460/12542 | Batch Loss: 1.8508 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1461/12542 | Batch Loss: 1.1002 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1462/12542 | Batch Loss: 1.0712 | Learning Rate: 0.000628 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1463/12542 | Batch Loss: 1.6686 | Learning Rate: 0.000628 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1464/12542 | Batch Loss: 1.4084 | Learning Rate: 0.000628 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1465/12542 | Batch Loss: 0.7549 | Learning Rate: 0.000628 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1466/12542 | Batch Loss: 2.4423 | Learning Rate: 0.000628 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1467/12542 | Batch Loss: 2.2075 | Learning Rate: 0.000628 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1468/12542 | Batch Loss: 0.4385 | Learning Rate: 0.000628 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1469/12542 | Batch Loss: 1.9501 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1470/12542 | Batch Loss: 2.1976 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1471/12542 | Batch Loss: 1.3244 | Learning Rate: 0.000628 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1472/12542 | Batch Loss: 1.4213 | Learning Rate: 0.000628 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1473/12542 | Batch Loss: 1.0385 | Learning Rate: 0.000628 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1474/12542 | Batch Loss: 1.2749 | Learning Rate: 0.000627 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1475/12542 | Batch Loss: 0.8597 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1476/12542 | Batch Loss: 2.8451 | Learning Rate: 0.000627 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1477/12542 | Batch Loss: 0.6991 | Learning Rate: 0.000627 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1478/12542 | Batch Loss: 1.5404 | Learning Rate: 0.000627 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1479/12542 | Batch Loss: 1.4231 | Learning Rate: 0.000627 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1480/12542 | Batch Loss: 1.7960 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1481/12542 | Batch Loss: 0.9136 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1482/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1483/12542 | Batch Loss: 1.3938 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1484/12542 | Batch Loss: 0.7491 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1485/12542 | Batch Loss: 2.3821 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1486/12542 | Batch Loss: 1.4195 | Learning Rate: 0.000627 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1487/12542 | Batch Loss: 0.7468 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1488/12542 | Batch Loss: 0.7252 | Learning Rate: 0.000627 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1489/12542 | Batch Loss: 1.1829 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1490/12542 | Batch Loss: 1.9904 | Learning Rate: 0.000627 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1491/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000627 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1492/12542 | Batch Loss: 0.9396 | Learning Rate: 0.000627 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1493/12542 | Batch Loss: 2.6944 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1494/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1495/12542 | Batch Loss: 2.4205 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1496/12542 | Batch Loss: 0.6661 | Learning Rate: 0.000627 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1497/12542 | Batch Loss: 1.1879 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1498/12542 | Batch Loss: 2.0685 | Learning Rate: 0.000627 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1499/12542 | Batch Loss: 0.8575 | Learning Rate: 0.000627 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1500/12542 | Batch Loss: 2.3236 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1501/12542 | Batch Loss: 1.9062 | Learning Rate: 0.000627 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1502/12542 | Batch Loss: 3.2100 | Learning Rate: 0.000627 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1503/12542 | Batch Loss: 0.9954 | Learning Rate: 0.000627 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1504/12542 | Batch Loss: 2.3097 | Learning Rate: 0.000627 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1505/12542 | Batch Loss: 0.9578 | Learning Rate: 0.000627 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1506/12542 | Batch Loss: 1.7050 | Learning Rate: 0.000627 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1507/12542 | Batch Loss: 1.4125 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1508/12542 | Batch Loss: 1.6516 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1509/12542 | Batch Loss: 0.9495 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1510/12542 | Batch Loss: 1.6352 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1511/12542 | Batch Loss: 3.5219 | Learning Rate: 0.000627 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1512/12542 | Batch Loss: 2.1540 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1513/12542 | Batch Loss: 0.9574 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1514/12542 | Batch Loss: 0.4687 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1515/12542 | Batch Loss: 0.8036 | Learning Rate: 0.000626 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1516/12542 | Batch Loss: 1.4608 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1517/12542 | Batch Loss: 1.1665 | Learning Rate: 0.000626 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1518/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1519/12542 | Batch Loss: 3.3254 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1520/12542 | Batch Loss: 1.1263 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1521/12542 | Batch Loss: 1.7238 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1522/12542 | Batch Loss: 0.7079 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1523/12542 | Batch Loss: 1.1811 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1524/12542 | Batch Loss: 2.6283 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1525/12542 | Batch Loss: 1.3165 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1526/12542 | Batch Loss: 1.2104 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1527/12542 | Batch Loss: 0.9044 | Learning Rate: 0.000626 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1528/12542 | Batch Loss: 0.9519 | Learning Rate: 0.000626 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1529/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1530/12542 | Batch Loss: 0.4494 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1531/12542 | Batch Loss: 1.1964 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1532/12542 | Batch Loss: 2.1896 | Learning Rate: 0.000626 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1533/12542 | Batch Loss: 1.4822 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1534/12542 | Batch Loss: 0.9157 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1535/12542 | Batch Loss: 1.3506 | Learning Rate: 0.000626 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1536/12542 | Batch Loss: 1.0992 | Learning Rate: 0.000626 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1537/12542 | Batch Loss: 0.7259 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1538/12542 | Batch Loss: 0.4415 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1539/12542 | Batch Loss: 2.5467 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1540/12542 | Batch Loss: 1.9433 | Learning Rate: 0.000626 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 1541/12542 | Batch Loss: 0.8201 | Learning Rate: 0.000626 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1542/12542 | Batch Loss: 1.0125 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1543/12542 | Batch Loss: 0.8541 | Learning Rate: 0.000626 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1544/12542 | Batch Loss: 0.6895 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1545/12542 | Batch Loss: 1.1001 | Learning Rate: 0.000626 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1546/12542 | Batch Loss: 0.4249 | Learning Rate: 0.000626 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1547/12542 | Batch Loss: 1.8037 | Learning Rate: 0.000626 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1548/12542 | Batch Loss: 0.9603 | Learning Rate: 0.000626 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1549/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000625 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1550/12542 | Batch Loss: 1.8465 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1551/12542 | Batch Loss: 3.4237 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1552/12542 | Batch Loss: 1.2937 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1553/12542 | Batch Loss: 1.7100 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1554/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1555/12542 | Batch Loss: 0.7548 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1556/12542 | Batch Loss: 2.3095 | Learning Rate: 0.000625 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1557/12542 | Batch Loss: 1.4740 | Learning Rate: 0.000625 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1558/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000625 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1559/12542 | Batch Loss: 1.1831 | Learning Rate: 0.000625 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1560/12542 | Batch Loss: 1.2013 | Learning Rate: 0.000625 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1561/12542 | Batch Loss: 1.3819 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1562/12542 | Batch Loss: 1.2550 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1563/12542 | Batch Loss: 0.6245 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1564/12542 | Batch Loss: 1.6381 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1565/12542 | Batch Loss: 2.0421 | Learning Rate: 0.000625 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1566/12542 | Batch Loss: 1.8483 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1567/12542 | Batch Loss: 1.1169 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1568/12542 | Batch Loss: 1.0687 | Learning Rate: 0.000625 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1569/12542 | Batch Loss: 1.5453 | Learning Rate: 0.000625 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1570/12542 | Batch Loss: 1.3234 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1571/12542 | Batch Loss: 1.6645 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1572/12542 | Batch Loss: 0.7783 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1573/12542 | Batch Loss: 0.6588 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1574/12542 | Batch Loss: 0.7233 | Learning Rate: 0.000625 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1575/12542 | Batch Loss: 0.9143 | Learning Rate: 0.000625 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1576/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1577/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1578/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1579/12542 | Batch Loss: 0.9979 | Learning Rate: 0.000625 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1580/12542 | Batch Loss: 0.6016 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1581/12542 | Batch Loss: 1.6508 | Learning Rate: 0.000625 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1582/12542 | Batch Loss: 1.6838 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1583/12542 | Batch Loss: 0.6381 | Learning Rate: 0.000625 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1584/12542 | Batch Loss: 2.0474 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1585/12542 | Batch Loss: 1.6357 | Learning Rate: 0.000625 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1586/12542 | Batch Loss: 1.5199 | Learning Rate: 0.000625 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1587/12542 | Batch Loss: 1.6075 | Learning Rate: 0.000624 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1588/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000624 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1589/12542 | Batch Loss: 1.3646 | Learning Rate: 0.000624 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1590/12542 | Batch Loss: 0.8041 | Learning Rate: 0.000624 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1591/12542 | Batch Loss: 0.7332 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1592/12542 | Batch Loss: 1.7126 | Learning Rate: 0.000624 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1593/12542 | Batch Loss: 1.3175 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1594/12542 | Batch Loss: 2.4044 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1595/12542 | Batch Loss: 1.1705 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1596/12542 | Batch Loss: 1.4198 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1597/12542 | Batch Loss: 1.3665 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1598/12542 | Batch Loss: 0.8724 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1599/12542 | Batch Loss: 1.9395 | Learning Rate: 0.000624 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1600/12542 | Batch Loss: 1.2677 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1601/12542 | Batch Loss: 1.0705 | Learning Rate: 0.000624 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1602/12542 | Batch Loss: 1.0796 | Learning Rate: 0.000624 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1603/12542 | Batch Loss: 0.8701 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1604/12542 | Batch Loss: 0.9789 | Learning Rate: 0.000624 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1605/12542 | Batch Loss: 0.3113 | Learning Rate: 0.000624 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1606/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1607/12542 | Batch Loss: 1.5271 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1608/12542 | Batch Loss: 0.8068 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1609/12542 | Batch Loss: 0.5823 | Learning Rate: 0.000624 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1610/12542 | Batch Loss: 1.3483 | Learning Rate: 0.000624 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1611/12542 | Batch Loss: 1.0462 | Learning Rate: 0.000624 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1612/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000624 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1613/12542 | Batch Loss: 0.9017 | Learning Rate: 0.000624 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1614/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000624 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1615/12542 | Batch Loss: 1.6213 | Learning Rate: 0.000624 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1616/12542 | Batch Loss: 1.6852 | Learning Rate: 0.000624 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1617/12542 | Batch Loss: 1.4162 | Learning Rate: 0.000624 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1618/12542 | Batch Loss: 0.8093 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1619/12542 | Batch Loss: 1.2348 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1620/12542 | Batch Loss: 1.8551 | Learning Rate: 0.000624 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1621/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000624 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1622/12542 | Batch Loss: 0.3742 | Learning Rate: 0.000624 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1623/12542 | Batch Loss: 1.3845 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1624/12542 | Batch Loss: 2.6413 | Learning Rate: 0.000624 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1625/12542 | Batch Loss: 0.9200 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1626/12542 | Batch Loss: 1.0575 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1627/12542 | Batch Loss: 1.2387 | Learning Rate: 0.000623 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1628/12542 | Batch Loss: 1.2165 | Learning Rate: 0.000623 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1629/12542 | Batch Loss: 1.0744 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1630/12542 | Batch Loss: 1.5028 | Learning Rate: 0.000623 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1631/12542 | Batch Loss: 0.2770 | Learning Rate: 0.000623 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1632/12542 | Batch Loss: 0.7554 | Learning Rate: 0.000623 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1633/12542 | Batch Loss: 1.4260 | Learning Rate: 0.000623 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1634/12542 | Batch Loss: 1.1932 | Learning Rate: 0.000623 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1635/12542 | Batch Loss: 1.3677 | Learning Rate: 0.000623 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1636/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1637/12542 | Batch Loss: 1.6119 | Learning Rate: 0.000623 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1638/12542 | Batch Loss: 1.0594 | Learning Rate: 0.000623 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1639/12542 | Batch Loss: 1.3829 | Learning Rate: 0.000623 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1640/12542 | Batch Loss: 1.2190 | Learning Rate: 0.000623 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1641/12542 | Batch Loss: 1.5735 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1642/12542 | Batch Loss: 3.6734 | Learning Rate: 0.000623 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1643/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000623 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1644/12542 | Batch Loss: 2.2211 | Learning Rate: 0.000623 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1645/12542 | Batch Loss: 0.9895 | Learning Rate: 0.000623 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1646/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1647/12542 | Batch Loss: 2.4183 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1648/12542 | Batch Loss: 1.4540 | Learning Rate: 0.000623 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1649/12542 | Batch Loss: 2.2377 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1650/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000623 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1651/12542 | Batch Loss: 2.7826 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1652/12542 | Batch Loss: 2.0011 | Learning Rate: 0.000623 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1653/12542 | Batch Loss: 0.7177 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1654/12542 | Batch Loss: 1.1119 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1655/12542 | Batch Loss: 0.4936 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1656/12542 | Batch Loss: 1.3743 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1657/12542 | Batch Loss: 1.1499 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1658/12542 | Batch Loss: 3.6764 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1659/12542 | Batch Loss: 1.7856 | Learning Rate: 0.000623 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1660/12542 | Batch Loss: 0.8255 | Learning Rate: 0.000623 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1661/12542 | Batch Loss: 0.8821 | Learning Rate: 0.000623 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1662/12542 | Batch Loss: 0.9279 | Learning Rate: 0.000622 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1663/12542 | Batch Loss: 3.5317 | Learning Rate: 0.000622 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1664/12542 | Batch Loss: 2.6469 | Learning Rate: 0.000622 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1665/12542 | Batch Loss: 0.7749 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1666/12542 | Batch Loss: 2.2189 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1667/12542 | Batch Loss: 1.0713 | Learning Rate: 0.000622 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1668/12542 | Batch Loss: 1.3557 | Learning Rate: 0.000622 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1669/12542 | Batch Loss: 0.7958 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1670/12542 | Batch Loss: 0.5526 | Learning Rate: 0.000622 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1671/12542 | Batch Loss: 0.5308 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1672/12542 | Batch Loss: 1.0407 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1673/12542 | Batch Loss: 2.8476 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1674/12542 | Batch Loss: 1.6030 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1675/12542 | Batch Loss: 1.4651 | Learning Rate: 0.000622 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1676/12542 | Batch Loss: 0.6783 | Learning Rate: 0.000622 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1677/12542 | Batch Loss: 1.6359 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1678/12542 | Batch Loss: 2.1760 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1679/12542 | Batch Loss: 1.0375 | Learning Rate: 0.000622 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1680/12542 | Batch Loss: 1.3395 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1681/12542 | Batch Loss: 2.1958 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1682/12542 | Batch Loss: 1.9712 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1683/12542 | Batch Loss: 1.3690 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1684/12542 | Batch Loss: 1.1899 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1685/12542 | Batch Loss: 1.0514 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1686/12542 | Batch Loss: 2.6362 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1687/12542 | Batch Loss: 2.3105 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1688/12542 | Batch Loss: 1.0783 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1689/12542 | Batch Loss: 1.9670 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1690/12542 | Batch Loss: 1.1662 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1691/12542 | Batch Loss: 2.2581 | Learning Rate: 0.000622 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1692/12542 | Batch Loss: 1.9062 | Learning Rate: 0.000622 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1693/12542 | Batch Loss: 1.3535 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1694/12542 | Batch Loss: 1.4602 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1695/12542 | Batch Loss: 0.5310 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1696/12542 | Batch Loss: 2.0319 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1697/12542 | Batch Loss: 1.7145 | Learning Rate: 0.000622 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1698/12542 | Batch Loss: 1.8252 | Learning Rate: 0.000622 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1699/12542 | Batch Loss: 0.9183 | Learning Rate: 0.000622 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1700/12542 | Batch Loss: 1.0978 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1701/12542 | Batch Loss: 1.0803 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1702/12542 | Batch Loss: 1.2389 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1703/12542 | Batch Loss: 0.7786 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1704/12542 | Batch Loss: 0.3689 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1705/12542 | Batch Loss: 1.5483 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1706/12542 | Batch Loss: 1.7360 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1707/12542 | Batch Loss: 1.3265 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1708/12542 | Batch Loss: 1.8688 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1709/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1710/12542 | Batch Loss: 2.0790 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1711/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1712/12542 | Batch Loss: 1.7401 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1713/12542 | Batch Loss: 0.6982 | Learning Rate: 0.000621 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1714/12542 | Batch Loss: 1.2719 | Learning Rate: 0.000621 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1715/12542 | Batch Loss: 2.6304 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1716/12542 | Batch Loss: 1.7633 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1717/12542 | Batch Loss: 1.2164 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1718/12542 | Batch Loss: 1.4534 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1719/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1720/12542 | Batch Loss: 0.9222 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1721/12542 | Batch Loss: 0.7879 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1722/12542 | Batch Loss: 1.0867 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1723/12542 | Batch Loss: 1.1867 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1724/12542 | Batch Loss: 1.8821 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1725/12542 | Batch Loss: 1.3847 | Learning Rate: 0.000621 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1726/12542 | Batch Loss: 1.1752 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1727/12542 | Batch Loss: 0.9512 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1728/12542 | Batch Loss: 1.4716 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1729/12542 | Batch Loss: 1.3692 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1730/12542 | Batch Loss: 0.6921 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1731/12542 | Batch Loss: 1.2141 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1732/12542 | Batch Loss: 2.1284 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1733/12542 | Batch Loss: 1.3503 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1734/12542 | Batch Loss: 0.6557 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1735/12542 | Batch Loss: 1.6851 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1736/12542 | Batch Loss: 1.0702 | Learning Rate: 0.000621 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1737/12542 | Batch Loss: 0.5788 | Learning Rate: 0.000621 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1738/12542 | Batch Loss: 1.3485 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1739/12542 | Batch Loss: 2.2060 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1740/12542 | Batch Loss: 1.7549 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1741/12542 | Batch Loss: 1.3682 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1742/12542 | Batch Loss: 1.6394 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1743/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000620 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1744/12542 | Batch Loss: 1.9680 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1745/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1746/12542 | Batch Loss: 2.2355 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1747/12542 | Batch Loss: 0.8590 | Learning Rate: 0.000620 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1748/12542 | Batch Loss: 1.0518 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1749/12542 | Batch Loss: 1.1079 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1750/12542 | Batch Loss: 0.5438 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1751/12542 | Batch Loss: 1.3555 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1752/12542 | Batch Loss: 1.2610 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1753/12542 | Batch Loss: 0.6076 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1754/12542 | Batch Loss: 2.6614 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1755/12542 | Batch Loss: 2.0136 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1756/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1757/12542 | Batch Loss: 1.7544 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1758/12542 | Batch Loss: 1.8784 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1759/12542 | Batch Loss: 1.1463 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1760/12542 | Batch Loss: 2.2063 | Learning Rate: 0.000620 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1761/12542 | Batch Loss: 1.1182 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1762/12542 | Batch Loss: 1.6511 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1763/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1764/12542 | Batch Loss: 1.3936 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1765/12542 | Batch Loss: 1.5093 | Learning Rate: 0.000620 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1766/12542 | Batch Loss: 1.0231 | Learning Rate: 0.000620 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1767/12542 | Batch Loss: 1.6400 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1768/12542 | Batch Loss: 2.4892 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1769/12542 | Batch Loss: 1.4518 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1770/12542 | Batch Loss: 1.9703 | Learning Rate: 0.000620 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1771/12542 | Batch Loss: 0.9876 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1772/12542 | Batch Loss: 1.1024 | Learning Rate: 0.000620 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1773/12542 | Batch Loss: 1.8484 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1774/12542 | Batch Loss: 1.7208 | Learning Rate: 0.000620 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1775/12542 | Batch Loss: 1.1686 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1776/12542 | Batch Loss: 0.7340 | Learning Rate: 0.000619 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1777/12542 | Batch Loss: 0.7866 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1778/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000619 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1779/12542 | Batch Loss: 1.5072 | Learning Rate: 0.000619 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1780/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000619 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1781/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1782/12542 | Batch Loss: 1.3574 | Learning Rate: 0.000619 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1783/12542 | Batch Loss: 1.5341 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1784/12542 | Batch Loss: 1.6563 | Learning Rate: 0.000619 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 1785/12542 | Batch Loss: 1.2477 | Learning Rate: 0.000619 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1786/12542 | Batch Loss: 0.5068 | Learning Rate: 0.000619 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1787/12542 | Batch Loss: 2.2879 | Learning Rate: 0.000619 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1788/12542 | Batch Loss: 1.6116 | Learning Rate: 0.000619 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1789/12542 | Batch Loss: 1.6687 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1790/12542 | Batch Loss: 0.9257 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1791/12542 | Batch Loss: 2.0663 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1792/12542 | Batch Loss: 0.3677 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1793/12542 | Batch Loss: 0.6878 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1794/12542 | Batch Loss: 1.2139 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1795/12542 | Batch Loss: 0.9669 | Learning Rate: 0.000619 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1796/12542 | Batch Loss: 1.6810 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1797/12542 | Batch Loss: 2.8422 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1798/12542 | Batch Loss: 1.1312 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1799/12542 | Batch Loss: 2.2420 | Learning Rate: 0.000619 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1800/12542 | Batch Loss: 0.8111 | Learning Rate: 0.000619 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1801/12542 | Batch Loss: 0.7103 | Learning Rate: 0.000619 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1802/12542 | Batch Loss: 1.2752 | Learning Rate: 0.000619 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 1803/12542 | Batch Loss: 1.0736 | Learning Rate: 0.000619 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1804/12542 | Batch Loss: 0.4592 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1805/12542 | Batch Loss: 0.9097 | Learning Rate: 0.000619 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1806/12542 | Batch Loss: 1.7454 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1807/12542 | Batch Loss: 1.2064 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1808/12542 | Batch Loss: 1.0673 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1809/12542 | Batch Loss: 0.5132 | Learning Rate: 0.000619 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1810/12542 | Batch Loss: 1.3736 | Learning Rate: 0.000619 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1811/12542 | Batch Loss: 1.5639 | Learning Rate: 0.000619 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1812/12542 | Batch Loss: 1.0508 | Learning Rate: 0.000619 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1813/12542 | Batch Loss: 1.3104 | Learning Rate: 0.000618 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1814/12542 | Batch Loss: 1.5856 | Learning Rate: 0.000618 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1815/12542 | Batch Loss: 2.3835 | Learning Rate: 0.000618 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1816/12542 | Batch Loss: 3.1947 | Learning Rate: 0.000618 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1817/12542 | Batch Loss: 0.7382 | Learning Rate: 0.000618 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1818/12542 | Batch Loss: 3.4260 | Learning Rate: 0.000618 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1819/12542 | Batch Loss: 2.1508 | Learning Rate: 0.000618 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1820/12542 | Batch Loss: 1.2417 | Learning Rate: 0.000618 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1821/12542 | Batch Loss: 1.0474 | Learning Rate: 0.000618 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1822/12542 | Batch Loss: 0.9003 | Learning Rate: 0.000618 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1823/12542 | Batch Loss: 0.3381 | Learning Rate: 0.000618 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1824/12542 | Batch Loss: 1.1326 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1825/12542 | Batch Loss: 1.4420 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1826/12542 | Batch Loss: 2.0311 | Learning Rate: 0.000618 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1827/12542 | Batch Loss: 1.1301 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1828/12542 | Batch Loss: 1.4912 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1829/12542 | Batch Loss: 1.3572 | Learning Rate: 0.000618 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1830/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1831/12542 | Batch Loss: 1.3650 | Learning Rate: 0.000618 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1832/12542 | Batch Loss: 0.9003 | Learning Rate: 0.000618 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1833/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1834/12542 | Batch Loss: 0.8431 | Learning Rate: 0.000618 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1835/12542 | Batch Loss: 1.3312 | Learning Rate: 0.000618 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1836/12542 | Batch Loss: 2.5270 | Learning Rate: 0.000618 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1837/12542 | Batch Loss: 1.7416 | Learning Rate: 0.000618 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1838/12542 | Batch Loss: 1.4458 | Learning Rate: 0.000618 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1839/12542 | Batch Loss: 1.7267 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1840/12542 | Batch Loss: 0.8894 | Learning Rate: 0.000618 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1841/12542 | Batch Loss: 1.1187 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1842/12542 | Batch Loss: 1.7074 | Learning Rate: 0.000618 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1843/12542 | Batch Loss: 1.8414 | Learning Rate: 0.000618 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1844/12542 | Batch Loss: 0.8610 | Learning Rate: 0.000618 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1845/12542 | Batch Loss: 1.5141 | Learning Rate: 0.000618 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1846/12542 | Batch Loss: 2.6464 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1847/12542 | Batch Loss: 1.2847 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1848/12542 | Batch Loss: 1.1733 | Learning Rate: 0.000618 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1849/12542 | Batch Loss: 0.8516 | Learning Rate: 0.000618 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1850/12542 | Batch Loss: 1.1749 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1851/12542 | Batch Loss: 1.9340 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1852/12542 | Batch Loss: 0.8548 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1853/12542 | Batch Loss: 1.2347 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1854/12542 | Batch Loss: 1.5127 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1855/12542 | Batch Loss: 0.9861 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1856/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1857/12542 | Batch Loss: 1.4457 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1858/12542 | Batch Loss: 1.4383 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1859/12542 | Batch Loss: 1.0145 | Learning Rate: 0.000617 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1860/12542 | Batch Loss: 0.6440 | Learning Rate: 0.000617 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1861/12542 | Batch Loss: 2.7432 | Learning Rate: 0.000617 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1862/12542 | Batch Loss: 1.1619 | Learning Rate: 0.000617 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1863/12542 | Batch Loss: 0.6784 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1864/12542 | Batch Loss: 0.5412 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1865/12542 | Batch Loss: 0.6194 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1866/12542 | Batch Loss: 0.5493 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1867/12542 | Batch Loss: 1.1155 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1868/12542 | Batch Loss: 1.5154 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1869/12542 | Batch Loss: 1.4850 | Learning Rate: 0.000617 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1870/12542 | Batch Loss: 2.6997 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1871/12542 | Batch Loss: 0.8133 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1872/12542 | Batch Loss: 1.1815 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1873/12542 | Batch Loss: 1.3106 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1874/12542 | Batch Loss: 0.9772 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1875/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1876/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1877/12542 | Batch Loss: 1.0176 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1878/12542 | Batch Loss: 1.0325 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1879/12542 | Batch Loss: 1.4417 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1880/12542 | Batch Loss: 1.9308 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1881/12542 | Batch Loss: 1.4094 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1882/12542 | Batch Loss: 5.6130 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1883/12542 | Batch Loss: 1.2569 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1884/12542 | Batch Loss: 2.9008 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1885/12542 | Batch Loss: 0.8017 | Learning Rate: 0.000617 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1886/12542 | Batch Loss: 1.3893 | Learning Rate: 0.000617 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1887/12542 | Batch Loss: 1.5658 | Learning Rate: 0.000617 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1888/12542 | Batch Loss: 1.2760 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1889/12542 | Batch Loss: 1.3706 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1890/12542 | Batch Loss: 1.7312 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1891/12542 | Batch Loss: 1.2509 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1892/12542 | Batch Loss: 1.6269 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1893/12542 | Batch Loss: 0.6597 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1894/12542 | Batch Loss: 1.9931 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1895/12542 | Batch Loss: 0.9521 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1896/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1897/12542 | Batch Loss: 0.7799 | Learning Rate: 0.000616 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1898/12542 | Batch Loss: 0.5247 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1899/12542 | Batch Loss: 0.4001 | Learning Rate: 0.000616 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1900/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1901/12542 | Batch Loss: 1.3489 | Learning Rate: 0.000616 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1902/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000616 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1903/12542 | Batch Loss: 1.8363 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1904/12542 | Batch Loss: 1.2890 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1905/12542 | Batch Loss: 1.2824 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1906/12542 | Batch Loss: 1.6285 | Learning Rate: 0.000616 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1907/12542 | Batch Loss: 1.1825 | Learning Rate: 0.000616 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1908/12542 | Batch Loss: 1.7041 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1909/12542 | Batch Loss: 0.9880 | Learning Rate: 0.000616 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1910/12542 | Batch Loss: 0.4268 | Learning Rate: 0.000616 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1911/12542 | Batch Loss: 1.4368 | Learning Rate: 0.000616 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1912/12542 | Batch Loss: 0.8341 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1913/12542 | Batch Loss: 1.7239 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1914/12542 | Batch Loss: 1.1189 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1915/12542 | Batch Loss: 1.4986 | Learning Rate: 0.000616 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1916/12542 | Batch Loss: 1.9208 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1917/12542 | Batch Loss: 1.5731 | Learning Rate: 0.000616 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1918/12542 | Batch Loss: 0.5619 | Learning Rate: 0.000616 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1919/12542 | Batch Loss: 0.8055 | Learning Rate: 0.000616 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1920/12542 | Batch Loss: 0.4979 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1921/12542 | Batch Loss: 1.4253 | Learning Rate: 0.000616 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1922/12542 | Batch Loss: 1.2008 | Learning Rate: 0.000616 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1923/12542 | Batch Loss: 2.5696 | Learning Rate: 0.000616 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1924/12542 | Batch Loss: 1.3568 | Learning Rate: 0.000616 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1925/12542 | Batch Loss: 2.1460 | Learning Rate: 0.000616 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1926/12542 | Batch Loss: 0.9617 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1927/12542 | Batch Loss: 1.1304 | Learning Rate: 0.000615 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1928/12542 | Batch Loss: 1.3339 | Learning Rate: 0.000615 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 1929/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1930/12542 | Batch Loss: 1.2483 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1931/12542 | Batch Loss: 0.5633 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1932/12542 | Batch Loss: 0.3424 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1933/12542 | Batch Loss: 0.7024 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1934/12542 | Batch Loss: 0.5780 | Learning Rate: 0.000615 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1935/12542 | Batch Loss: 1.2112 | Learning Rate: 0.000615 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1936/12542 | Batch Loss: 0.7083 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1937/12542 | Batch Loss: 3.0172 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1938/12542 | Batch Loss: 0.6723 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1939/12542 | Batch Loss: 1.5919 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1940/12542 | Batch Loss: 1.3203 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1941/12542 | Batch Loss: 1.3437 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1942/12542 | Batch Loss: 1.2732 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1943/12542 | Batch Loss: 1.0598 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1944/12542 | Batch Loss: 1.2400 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1945/12542 | Batch Loss: 0.7451 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1946/12542 | Batch Loss: 1.1052 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1947/12542 | Batch Loss: 1.8399 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1948/12542 | Batch Loss: 1.2570 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1949/12542 | Batch Loss: 0.7488 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1950/12542 | Batch Loss: 3.2960 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1951/12542 | Batch Loss: 0.6420 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1952/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1953/12542 | Batch Loss: 0.6456 | Learning Rate: 0.000615 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1954/12542 | Batch Loss: 1.7928 | Learning Rate: 0.000615 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1955/12542 | Batch Loss: 1.2600 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1956/12542 | Batch Loss: 1.3777 | Learning Rate: 0.000615 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1957/12542 | Batch Loss: 0.9153 | Learning Rate: 0.000615 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1958/12542 | Batch Loss: 1.2293 | Learning Rate: 0.000615 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1959/12542 | Batch Loss: 1.5917 | Learning Rate: 0.000615 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 1960/12542 | Batch Loss: 1.8514 | Learning Rate: 0.000615 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1961/12542 | Batch Loss: 0.9964 | Learning Rate: 0.000615 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1962/12542 | Batch Loss: 1.3028 | Learning Rate: 0.000615 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1963/12542 | Batch Loss: 1.1071 | Learning Rate: 0.000614 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 1964/12542 | Batch Loss: 1.9488 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1965/12542 | Batch Loss: 0.8963 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1966/12542 | Batch Loss: 0.8512 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1967/12542 | Batch Loss: 1.2435 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1968/12542 | Batch Loss: 1.2414 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1969/12542 | Batch Loss: 1.4675 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1970/12542 | Batch Loss: 1.8441 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1971/12542 | Batch Loss: 1.1692 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1972/12542 | Batch Loss: 0.4878 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1973/12542 | Batch Loss: 1.2092 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1974/12542 | Batch Loss: 0.5724 | Learning Rate: 0.000614 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1975/12542 | Batch Loss: 0.8998 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1976/12542 | Batch Loss: 1.1557 | Learning Rate: 0.000614 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1977/12542 | Batch Loss: 0.5958 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1978/12542 | Batch Loss: 2.2470 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1979/12542 | Batch Loss: 1.6333 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1980/12542 | Batch Loss: 2.9091 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1981/12542 | Batch Loss: 1.1251 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1982/12542 | Batch Loss: 1.8318 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1983/12542 | Batch Loss: 0.7390 | Learning Rate: 0.000614 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 1984/12542 | Batch Loss: 1.6332 | Learning Rate: 0.000614 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 1985/12542 | Batch Loss: 0.9033 | Learning Rate: 0.000614 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 1986/12542 | Batch Loss: 1.7448 | Learning Rate: 0.000614 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 1987/12542 | Batch Loss: 1.4867 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1988/12542 | Batch Loss: 1.2547 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1989/12542 | Batch Loss: 0.7622 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1990/12542 | Batch Loss: 1.1939 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1991/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1992/12542 | Batch Loss: 1.1054 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 1993/12542 | Batch Loss: 1.9425 | Learning Rate: 0.000614 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 1994/12542 | Batch Loss: 0.9253 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1995/12542 | Batch Loss: 0.8791 | Learning Rate: 0.000614 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 1996/12542 | Batch Loss: 2.5064 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 1997/12542 | Batch Loss: 0.7409 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1998/12542 | Batch Loss: 0.7832 | Learning Rate: 0.000614 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 1999/12542 | Batch Loss: 1.2342 | Learning Rate: 0.000614 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2000/12542 | Batch Loss: 1.2222 | Learning Rate: 0.000614 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2001/12542 | Batch Loss: 1.2370 | Learning Rate: 0.000613 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2002/12542 | Batch Loss: 1.1066 | Learning Rate: 0.000613 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2003/12542 | Batch Loss: 1.3070 | Learning Rate: 0.000613 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2004/12542 | Batch Loss: 1.2982 | Learning Rate: 0.000613 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2005/12542 | Batch Loss: 1.4381 | Learning Rate: 0.000613 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2006/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000613 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2007/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000613 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2008/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2009/12542 | Batch Loss: 1.0287 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2010/12542 | Batch Loss: 2.7078 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2011/12542 | Batch Loss: 0.5377 | Learning Rate: 0.000613 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2012/12542 | Batch Loss: 1.7534 | Learning Rate: 0.000613 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2013/12542 | Batch Loss: 1.7877 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2014/12542 | Batch Loss: 1.6729 | Learning Rate: 0.000613 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2015/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2016/12542 | Batch Loss: 1.3905 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2017/12542 | Batch Loss: 1.5647 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2018/12542 | Batch Loss: 1.0076 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2019/12542 | Batch Loss: 1.3256 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2020/12542 | Batch Loss: 1.1699 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2021/12542 | Batch Loss: 0.9368 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2022/12542 | Batch Loss: 0.3767 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2023/12542 | Batch Loss: 1.5089 | Learning Rate: 0.000613 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2024/12542 | Batch Loss: 0.8282 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2025/12542 | Batch Loss: 1.4259 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2026/12542 | Batch Loss: 0.6723 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2027/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2028/12542 | Batch Loss: 1.3140 | Learning Rate: 0.000613 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2029/12542 | Batch Loss: 1.5630 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2030/12542 | Batch Loss: 1.3158 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2031/12542 | Batch Loss: 2.0917 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2032/12542 | Batch Loss: 1.0762 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2033/12542 | Batch Loss: 1.3205 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2034/12542 | Batch Loss: 1.3389 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2035/12542 | Batch Loss: 1.9452 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2036/12542 | Batch Loss: 2.4634 | Learning Rate: 0.000613 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2037/12542 | Batch Loss: 0.9414 | Learning Rate: 0.000613 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2038/12542 | Batch Loss: 0.8707 | Learning Rate: 0.000613 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2039/12542 | Batch Loss: 1.4160 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2040/12542 | Batch Loss: 1.2038 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2041/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2042/12542 | Batch Loss: 1.3231 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2043/12542 | Batch Loss: 0.6012 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2044/12542 | Batch Loss: 1.3978 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2045/12542 | Batch Loss: 1.5972 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2046/12542 | Batch Loss: 0.6366 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2047/12542 | Batch Loss: 0.7005 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2048/12542 | Batch Loss: 1.5374 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2049/12542 | Batch Loss: 1.7798 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2050/12542 | Batch Loss: 1.2425 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2051/12542 | Batch Loss: 1.3664 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2052/12542 | Batch Loss: 2.0672 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2053/12542 | Batch Loss: 3.1017 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2054/12542 | Batch Loss: 2.2085 | Learning Rate: 0.000612 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2055/12542 | Batch Loss: 0.9280 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2056/12542 | Batch Loss: 0.8015 | Learning Rate: 0.000612 | Batch Time: 0.56s\n",
      "Epoch 2 | Step 2057/12542 | Batch Loss: 2.8665 | Learning Rate: 0.000612 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2058/12542 | Batch Loss: 0.7662 | Learning Rate: 0.000612 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2059/12542 | Batch Loss: 0.8083 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2060/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2061/12542 | Batch Loss: 2.1856 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2062/12542 | Batch Loss: 1.0896 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2063/12542 | Batch Loss: 1.2230 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2064/12542 | Batch Loss: 2.2814 | Learning Rate: 0.000612 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2065/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000612 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2066/12542 | Batch Loss: 1.3757 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2067/12542 | Batch Loss: 1.7806 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2068/12542 | Batch Loss: 1.9059 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2069/12542 | Batch Loss: 0.9630 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2070/12542 | Batch Loss: 1.6940 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2071/12542 | Batch Loss: 2.2273 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2072/12542 | Batch Loss: 1.1656 | Learning Rate: 0.000612 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2073/12542 | Batch Loss: 0.6993 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2074/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000612 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2075/12542 | Batch Loss: 2.0537 | Learning Rate: 0.000612 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2076/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000611 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2077/12542 | Batch Loss: 1.6416 | Learning Rate: 0.000611 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2078/12542 | Batch Loss: 0.5953 | Learning Rate: 0.000611 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2079/12542 | Batch Loss: 0.9070 | Learning Rate: 0.000611 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2080/12542 | Batch Loss: 2.8958 | Learning Rate: 0.000611 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2081/12542 | Batch Loss: 1.2207 | Learning Rate: 0.000611 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2082/12542 | Batch Loss: 0.8666 | Learning Rate: 0.000611 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2083/12542 | Batch Loss: 2.0255 | Learning Rate: 0.000611 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2084/12542 | Batch Loss: 1.4167 | Learning Rate: 0.000611 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2085/12542 | Batch Loss: 0.6644 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2086/12542 | Batch Loss: 2.4621 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2087/12542 | Batch Loss: 0.7841 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2088/12542 | Batch Loss: 1.4738 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2089/12542 | Batch Loss: 0.7451 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2090/12542 | Batch Loss: 1.8174 | Learning Rate: 0.000611 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2091/12542 | Batch Loss: 1.4355 | Learning Rate: 0.000611 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2092/12542 | Batch Loss: 2.1532 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2093/12542 | Batch Loss: 1.2229 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2094/12542 | Batch Loss: 0.4982 | Learning Rate: 0.000611 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2095/12542 | Batch Loss: 0.9833 | Learning Rate: 0.000611 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2096/12542 | Batch Loss: 1.3926 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2097/12542 | Batch Loss: 1.7782 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2098/12542 | Batch Loss: 1.8624 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2099/12542 | Batch Loss: 1.9554 | Learning Rate: 0.000611 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2100/12542 | Batch Loss: 0.7089 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2101/12542 | Batch Loss: 1.2951 | Learning Rate: 0.000611 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2102/12542 | Batch Loss: 0.9936 | Learning Rate: 0.000611 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2103/12542 | Batch Loss: 0.9060 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2104/12542 | Batch Loss: 1.6964 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2105/12542 | Batch Loss: 1.6572 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2106/12542 | Batch Loss: 1.5293 | Learning Rate: 0.000611 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 2107/12542 | Batch Loss: 1.5390 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2108/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000611 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2109/12542 | Batch Loss: 1.8009 | Learning Rate: 0.000611 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2110/12542 | Batch Loss: 1.2747 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2111/12542 | Batch Loss: 0.3775 | Learning Rate: 0.000611 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2112/12542 | Batch Loss: 2.7029 | Learning Rate: 0.000611 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2113/12542 | Batch Loss: 0.6242 | Learning Rate: 0.000611 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2114/12542 | Batch Loss: 0.8469 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2115/12542 | Batch Loss: 1.0451 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2116/12542 | Batch Loss: 0.6465 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2117/12542 | Batch Loss: 1.2940 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2118/12542 | Batch Loss: 1.9822 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2119/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2120/12542 | Batch Loss: 1.4447 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2121/12542 | Batch Loss: 1.4325 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2122/12542 | Batch Loss: 2.4792 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2123/12542 | Batch Loss: 0.9371 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2124/12542 | Batch Loss: 0.8985 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2125/12542 | Batch Loss: 1.0525 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2126/12542 | Batch Loss: 2.0141 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2127/12542 | Batch Loss: 1.5363 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2128/12542 | Batch Loss: 1.0102 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2129/12542 | Batch Loss: 1.1324 | Learning Rate: 0.000610 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2130/12542 | Batch Loss: 2.4711 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2131/12542 | Batch Loss: 2.3249 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2132/12542 | Batch Loss: 0.9503 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2133/12542 | Batch Loss: 0.8212 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2134/12542 | Batch Loss: 1.5113 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2135/12542 | Batch Loss: 1.0999 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2136/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2137/12542 | Batch Loss: 1.3026 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2138/12542 | Batch Loss: 2.8330 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2139/12542 | Batch Loss: 2.2961 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2140/12542 | Batch Loss: 0.6441 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2141/12542 | Batch Loss: 0.7424 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2142/12542 | Batch Loss: 0.8479 | Learning Rate: 0.000610 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2143/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2144/12542 | Batch Loss: 1.4946 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2145/12542 | Batch Loss: 1.0512 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2146/12542 | Batch Loss: 1.1554 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2147/12542 | Batch Loss: 2.3821 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2148/12542 | Batch Loss: 2.7740 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2149/12542 | Batch Loss: 1.5549 | Learning Rate: 0.000610 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2150/12542 | Batch Loss: 2.0959 | Learning Rate: 0.000610 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2151/12542 | Batch Loss: 0.3487 | Learning Rate: 0.000609 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2152/12542 | Batch Loss: 0.8717 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2153/12542 | Batch Loss: 0.8454 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2154/12542 | Batch Loss: 1.8777 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2155/12542 | Batch Loss: 2.4290 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2156/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2157/12542 | Batch Loss: 1.6227 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2158/12542 | Batch Loss: 0.6181 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2159/12542 | Batch Loss: 1.4840 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2160/12542 | Batch Loss: 0.8100 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2161/12542 | Batch Loss: 1.8260 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2162/12542 | Batch Loss: 1.5499 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2163/12542 | Batch Loss: 1.1031 | Learning Rate: 0.000609 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2164/12542 | Batch Loss: 3.1302 | Learning Rate: 0.000609 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2165/12542 | Batch Loss: 0.7654 | Learning Rate: 0.000609 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2166/12542 | Batch Loss: 1.6285 | Learning Rate: 0.000609 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2167/12542 | Batch Loss: 2.5140 | Learning Rate: 0.000609 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2168/12542 | Batch Loss: 1.2904 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2169/12542 | Batch Loss: 1.1783 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2170/12542 | Batch Loss: 1.2522 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2171/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2172/12542 | Batch Loss: 1.7422 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2173/12542 | Batch Loss: 0.8199 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2174/12542 | Batch Loss: 0.8911 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2175/12542 | Batch Loss: 0.6557 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2176/12542 | Batch Loss: 0.5048 | Learning Rate: 0.000609 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2177/12542 | Batch Loss: 1.0806 | Learning Rate: 0.000609 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2178/12542 | Batch Loss: 2.2401 | Learning Rate: 0.000609 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2179/12542 | Batch Loss: 1.1294 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2180/12542 | Batch Loss: 1.2569 | Learning Rate: 0.000609 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2181/12542 | Batch Loss: 0.8734 | Learning Rate: 0.000609 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2182/12542 | Batch Loss: 0.2532 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2183/12542 | Batch Loss: 1.2789 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2184/12542 | Batch Loss: 1.0154 | Learning Rate: 0.000609 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2185/12542 | Batch Loss: 2.3915 | Learning Rate: 0.000609 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2186/12542 | Batch Loss: 1.2526 | Learning Rate: 0.000609 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2187/12542 | Batch Loss: 2.8268 | Learning Rate: 0.000609 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2188/12542 | Batch Loss: 0.9526 | Learning Rate: 0.000609 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2189/12542 | Batch Loss: 1.4727 | Learning Rate: 0.000608 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2190/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000608 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2191/12542 | Batch Loss: 1.5622 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2192/12542 | Batch Loss: 1.7268 | Learning Rate: 0.000608 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2193/12542 | Batch Loss: 0.6978 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2194/12542 | Batch Loss: 1.5574 | Learning Rate: 0.000608 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2195/12542 | Batch Loss: 0.9998 | Learning Rate: 0.000608 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2196/12542 | Batch Loss: 0.5416 | Learning Rate: 0.000608 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2197/12542 | Batch Loss: 1.0029 | Learning Rate: 0.000608 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2198/12542 | Batch Loss: 1.1101 | Learning Rate: 0.000608 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2199/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000608 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2200/12542 | Batch Loss: 1.8211 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2201/12542 | Batch Loss: 1.0856 | Learning Rate: 0.000608 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2202/12542 | Batch Loss: 0.7400 | Learning Rate: 0.000608 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2203/12542 | Batch Loss: 2.0219 | Learning Rate: 0.000608 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2204/12542 | Batch Loss: 2.6378 | Learning Rate: 0.000608 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2205/12542 | Batch Loss: 0.4327 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2206/12542 | Batch Loss: 1.1133 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2207/12542 | Batch Loss: 0.8998 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2208/12542 | Batch Loss: 1.6989 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2209/12542 | Batch Loss: 1.0418 | Learning Rate: 0.000608 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2210/12542 | Batch Loss: 0.7931 | Learning Rate: 0.000608 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2211/12542 | Batch Loss: 0.8422 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2212/12542 | Batch Loss: 2.8515 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2213/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2214/12542 | Batch Loss: 1.9906 | Learning Rate: 0.000608 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2215/12542 | Batch Loss: 1.0858 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2216/12542 | Batch Loss: 1.2642 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2217/12542 | Batch Loss: 1.4498 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2218/12542 | Batch Loss: 1.3237 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2219/12542 | Batch Loss: 1.0549 | Learning Rate: 0.000608 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2220/12542 | Batch Loss: 2.7542 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2221/12542 | Batch Loss: 1.4854 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2222/12542 | Batch Loss: 1.7437 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2223/12542 | Batch Loss: 0.9075 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2224/12542 | Batch Loss: 2.4687 | Learning Rate: 0.000608 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2225/12542 | Batch Loss: 2.0965 | Learning Rate: 0.000608 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2226/12542 | Batch Loss: 0.7484 | Learning Rate: 0.000608 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2227/12542 | Batch Loss: 1.0000 | Learning Rate: 0.000607 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2228/12542 | Batch Loss: 0.5968 | Learning Rate: 0.000607 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2229/12542 | Batch Loss: 3.5314 | Learning Rate: 0.000607 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2230/12542 | Batch Loss: 0.8962 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2231/12542 | Batch Loss: 1.5791 | Learning Rate: 0.000607 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2232/12542 | Batch Loss: 1.1540 | Learning Rate: 0.000607 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2233/12542 | Batch Loss: 1.9810 | Learning Rate: 0.000607 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2234/12542 | Batch Loss: 1.2216 | Learning Rate: 0.000607 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2235/12542 | Batch Loss: 1.9582 | Learning Rate: 0.000607 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2236/12542 | Batch Loss: 1.0292 | Learning Rate: 0.000607 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2237/12542 | Batch Loss: 0.9634 | Learning Rate: 0.000607 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2238/12542 | Batch Loss: 1.7927 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2239/12542 | Batch Loss: 0.8272 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2240/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000607 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2241/12542 | Batch Loss: 1.1115 | Learning Rate: 0.000607 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2242/12542 | Batch Loss: 1.6244 | Learning Rate: 0.000607 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2243/12542 | Batch Loss: 0.5346 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2244/12542 | Batch Loss: 0.6142 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2245/12542 | Batch Loss: 1.3936 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2246/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2247/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2248/12542 | Batch Loss: 0.6153 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2249/12542 | Batch Loss: 1.4207 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2250/12542 | Batch Loss: 1.0790 | Learning Rate: 0.000607 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2251/12542 | Batch Loss: 0.7493 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2252/12542 | Batch Loss: 1.3316 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2253/12542 | Batch Loss: 0.3449 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2254/12542 | Batch Loss: 1.7903 | Learning Rate: 0.000607 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2255/12542 | Batch Loss: 1.0008 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2256/12542 | Batch Loss: 1.2846 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2257/12542 | Batch Loss: 2.3895 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2258/12542 | Batch Loss: 1.4851 | Learning Rate: 0.000607 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2259/12542 | Batch Loss: 1.6171 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2260/12542 | Batch Loss: 1.8516 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2261/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000607 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2262/12542 | Batch Loss: 3.7016 | Learning Rate: 0.000607 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2263/12542 | Batch Loss: 0.5266 | Learning Rate: 0.000607 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2264/12542 | Batch Loss: 1.0968 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2265/12542 | Batch Loss: 1.5696 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2266/12542 | Batch Loss: 1.4579 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2267/12542 | Batch Loss: 0.9815 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2268/12542 | Batch Loss: 2.1363 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2269/12542 | Batch Loss: 1.0189 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2270/12542 | Batch Loss: 1.2690 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2271/12542 | Batch Loss: 1.3478 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2272/12542 | Batch Loss: 1.1477 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2273/12542 | Batch Loss: 1.4077 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2274/12542 | Batch Loss: 1.6057 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2275/12542 | Batch Loss: 1.1666 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2276/12542 | Batch Loss: 2.4779 | Learning Rate: 0.000606 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2277/12542 | Batch Loss: 0.8513 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2278/12542 | Batch Loss: 1.7942 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2279/12542 | Batch Loss: 0.8838 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2280/12542 | Batch Loss: 0.8670 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2281/12542 | Batch Loss: 0.8481 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2282/12542 | Batch Loss: 1.2054 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2283/12542 | Batch Loss: 1.0622 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2284/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000606 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2285/12542 | Batch Loss: 2.6320 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2286/12542 | Batch Loss: 1.9356 | Learning Rate: 0.000606 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 2287/12542 | Batch Loss: 0.6701 | Learning Rate: 0.000606 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2288/12542 | Batch Loss: 1.3063 | Learning Rate: 0.000606 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2289/12542 | Batch Loss: 1.2657 | Learning Rate: 0.000606 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2290/12542 | Batch Loss: 0.5967 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2291/12542 | Batch Loss: 1.6116 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2292/12542 | Batch Loss: 0.9133 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2293/12542 | Batch Loss: 0.6139 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2294/12542 | Batch Loss: 0.7661 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2295/12542 | Batch Loss: 1.6330 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2296/12542 | Batch Loss: 1.3180 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2297/12542 | Batch Loss: 1.4868 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2298/12542 | Batch Loss: 0.5934 | Learning Rate: 0.000606 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2299/12542 | Batch Loss: 1.6635 | Learning Rate: 0.000606 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2300/12542 | Batch Loss: 0.8431 | Learning Rate: 0.000606 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2301/12542 | Batch Loss: 1.6304 | Learning Rate: 0.000606 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2302/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000605 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2303/12542 | Batch Loss: 0.8132 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2304/12542 | Batch Loss: 0.8062 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2305/12542 | Batch Loss: 0.6030 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2306/12542 | Batch Loss: 2.2327 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2307/12542 | Batch Loss: 0.5177 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2308/12542 | Batch Loss: 2.0530 | Learning Rate: 0.000605 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2309/12542 | Batch Loss: 1.7472 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2310/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000605 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2311/12542 | Batch Loss: 2.6287 | Learning Rate: 0.000605 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2312/12542 | Batch Loss: 2.0874 | Learning Rate: 0.000605 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2313/12542 | Batch Loss: 1.5772 | Learning Rate: 0.000605 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2314/12542 | Batch Loss: 1.4128 | Learning Rate: 0.000605 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2315/12542 | Batch Loss: 0.8397 | Learning Rate: 0.000605 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2316/12542 | Batch Loss: 0.7778 | Learning Rate: 0.000605 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2317/12542 | Batch Loss: 1.7239 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2318/12542 | Batch Loss: 1.7767 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2319/12542 | Batch Loss: 2.4271 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2320/12542 | Batch Loss: 1.1364 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2321/12542 | Batch Loss: 0.5235 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2322/12542 | Batch Loss: 1.2566 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2323/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2324/12542 | Batch Loss: 0.8780 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2325/12542 | Batch Loss: 1.2116 | Learning Rate: 0.000605 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2326/12542 | Batch Loss: 1.7774 | Learning Rate: 0.000605 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2327/12542 | Batch Loss: 1.2957 | Learning Rate: 0.000605 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2328/12542 | Batch Loss: 0.5374 | Learning Rate: 0.000605 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2329/12542 | Batch Loss: 0.5553 | Learning Rate: 0.000605 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2330/12542 | Batch Loss: 0.6979 | Learning Rate: 0.000605 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2331/12542 | Batch Loss: 0.7429 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2332/12542 | Batch Loss: 1.7031 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2333/12542 | Batch Loss: 1.2442 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2334/12542 | Batch Loss: 0.8067 | Learning Rate: 0.000605 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2335/12542 | Batch Loss: 3.5843 | Learning Rate: 0.000605 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2336/12542 | Batch Loss: 3.0503 | Learning Rate: 0.000605 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2337/12542 | Batch Loss: 1.2926 | Learning Rate: 0.000605 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2338/12542 | Batch Loss: 0.7285 | Learning Rate: 0.000605 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2339/12542 | Batch Loss: 1.4603 | Learning Rate: 0.000605 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2340/12542 | Batch Loss: 0.6985 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2341/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2342/12542 | Batch Loss: 0.7107 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2343/12542 | Batch Loss: 0.8368 | Learning Rate: 0.000604 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2344/12542 | Batch Loss: 1.1676 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2345/12542 | Batch Loss: 1.0498 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2346/12542 | Batch Loss: 1.4951 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2347/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2348/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000604 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2349/12542 | Batch Loss: 1.0419 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2350/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000604 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2351/12542 | Batch Loss: 0.7366 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2352/12542 | Batch Loss: 0.8553 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2353/12542 | Batch Loss: 1.1541 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2354/12542 | Batch Loss: 2.2686 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2355/12542 | Batch Loss: 0.6490 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2356/12542 | Batch Loss: 1.5624 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2357/12542 | Batch Loss: 0.5674 | Learning Rate: 0.000604 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2358/12542 | Batch Loss: 0.6127 | Learning Rate: 0.000604 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2359/12542 | Batch Loss: 0.5808 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2360/12542 | Batch Loss: 0.8300 | Learning Rate: 0.000604 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2361/12542 | Batch Loss: 1.5134 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2362/12542 | Batch Loss: 2.4833 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2363/12542 | Batch Loss: 0.7004 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2364/12542 | Batch Loss: 0.4677 | Learning Rate: 0.000604 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2365/12542 | Batch Loss: 0.9789 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2366/12542 | Batch Loss: 1.1047 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2367/12542 | Batch Loss: 0.5769 | Learning Rate: 0.000604 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2368/12542 | Batch Loss: 1.8953 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2369/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000604 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2370/12542 | Batch Loss: 1.1243 | Learning Rate: 0.000604 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2371/12542 | Batch Loss: 1.2204 | Learning Rate: 0.000604 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2372/12542 | Batch Loss: 0.7358 | Learning Rate: 0.000604 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2373/12542 | Batch Loss: 1.6404 | Learning Rate: 0.000604 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2374/12542 | Batch Loss: 1.5387 | Learning Rate: 0.000604 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2375/12542 | Batch Loss: 0.8121 | Learning Rate: 0.000604 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2376/12542 | Batch Loss: 0.7536 | Learning Rate: 0.000604 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2377/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000603 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2378/12542 | Batch Loss: 1.1478 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2379/12542 | Batch Loss: 1.0111 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2380/12542 | Batch Loss: 1.0405 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2381/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2382/12542 | Batch Loss: 1.5034 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2383/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000603 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2384/12542 | Batch Loss: 1.5607 | Learning Rate: 0.000603 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2385/12542 | Batch Loss: 1.5188 | Learning Rate: 0.000603 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2386/12542 | Batch Loss: 1.1405 | Learning Rate: 0.000603 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2387/12542 | Batch Loss: 2.0270 | Learning Rate: 0.000603 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2388/12542 | Batch Loss: 4.0620 | Learning Rate: 0.000603 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2389/12542 | Batch Loss: 1.7438 | Learning Rate: 0.000603 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2390/12542 | Batch Loss: 2.4679 | Learning Rate: 0.000603 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2391/12542 | Batch Loss: 1.5665 | Learning Rate: 0.000603 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2392/12542 | Batch Loss: 1.2540 | Learning Rate: 0.000603 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 2393/12542 | Batch Loss: 1.6608 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2394/12542 | Batch Loss: 0.6945 | Learning Rate: 0.000603 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2395/12542 | Batch Loss: 1.0262 | Learning Rate: 0.000603 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2396/12542 | Batch Loss: 1.1986 | Learning Rate: 0.000603 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2397/12542 | Batch Loss: 0.9101 | Learning Rate: 0.000603 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2398/12542 | Batch Loss: 2.1827 | Learning Rate: 0.000603 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 2399/12542 | Batch Loss: 2.5284 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2400/12542 | Batch Loss: 0.9902 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2401/12542 | Batch Loss: 0.9074 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2402/12542 | Batch Loss: 1.8705 | Learning Rate: 0.000603 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2403/12542 | Batch Loss: 2.1510 | Learning Rate: 0.000603 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2404/12542 | Batch Loss: 0.9100 | Learning Rate: 0.000603 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2405/12542 | Batch Loss: 1.9194 | Learning Rate: 0.000603 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2406/12542 | Batch Loss: 0.7834 | Learning Rate: 0.000603 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2407/12542 | Batch Loss: 0.4042 | Learning Rate: 0.000603 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2408/12542 | Batch Loss: 4.4060 | Learning Rate: 0.000603 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2409/12542 | Batch Loss: 1.6158 | Learning Rate: 0.000603 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2410/12542 | Batch Loss: 1.6688 | Learning Rate: 0.000603 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2411/12542 | Batch Loss: 0.9192 | Learning Rate: 0.000603 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2412/12542 | Batch Loss: 0.6524 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2413/12542 | Batch Loss: 0.6904 | Learning Rate: 0.000603 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2414/12542 | Batch Loss: 1.0886 | Learning Rate: 0.000603 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2415/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000602 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2416/12542 | Batch Loss: 1.7506 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2417/12542 | Batch Loss: 0.4778 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2418/12542 | Batch Loss: 1.3265 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2419/12542 | Batch Loss: 0.7411 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2420/12542 | Batch Loss: 1.7060 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2421/12542 | Batch Loss: 1.1303 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2422/12542 | Batch Loss: 0.5869 | Learning Rate: 0.000602 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2423/12542 | Batch Loss: 1.5805 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2424/12542 | Batch Loss: 0.9359 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2425/12542 | Batch Loss: 1.8364 | Learning Rate: 0.000602 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2426/12542 | Batch Loss: 1.6526 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2427/12542 | Batch Loss: 1.3662 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2428/12542 | Batch Loss: 2.2471 | Learning Rate: 0.000602 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2429/12542 | Batch Loss: 1.1103 | Learning Rate: 0.000602 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2430/12542 | Batch Loss: 2.2329 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2431/12542 | Batch Loss: 0.8790 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2432/12542 | Batch Loss: 1.3125 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2433/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2434/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2435/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000602 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2436/12542 | Batch Loss: 0.8954 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2437/12542 | Batch Loss: 1.5108 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2438/12542 | Batch Loss: 1.2170 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2439/12542 | Batch Loss: 1.6022 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2440/12542 | Batch Loss: 1.1334 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2441/12542 | Batch Loss: 0.8381 | Learning Rate: 0.000602 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2442/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2443/12542 | Batch Loss: 1.4318 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2444/12542 | Batch Loss: 1.6362 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2445/12542 | Batch Loss: 1.6798 | Learning Rate: 0.000602 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2446/12542 | Batch Loss: 1.4575 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2447/12542 | Batch Loss: 1.7027 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2448/12542 | Batch Loss: 1.6518 | Learning Rate: 0.000602 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2449/12542 | Batch Loss: 1.9211 | Learning Rate: 0.000602 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2450/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2451/12542 | Batch Loss: 1.7893 | Learning Rate: 0.000602 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2452/12542 | Batch Loss: 1.3126 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2453/12542 | Batch Loss: 1.2407 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2454/12542 | Batch Loss: 2.0105 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2455/12542 | Batch Loss: 2.6357 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2456/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2457/12542 | Batch Loss: 0.8039 | Learning Rate: 0.000601 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2458/12542 | Batch Loss: 1.5033 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2459/12542 | Batch Loss: 0.9989 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2460/12542 | Batch Loss: 2.1484 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2461/12542 | Batch Loss: 0.7284 | Learning Rate: 0.000601 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2462/12542 | Batch Loss: 0.8569 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2463/12542 | Batch Loss: 1.7605 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2464/12542 | Batch Loss: 0.6001 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2465/12542 | Batch Loss: 2.7454 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2466/12542 | Batch Loss: 1.4018 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2467/12542 | Batch Loss: 0.9636 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2468/12542 | Batch Loss: 0.8932 | Learning Rate: 0.000601 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2469/12542 | Batch Loss: 2.7839 | Learning Rate: 0.000601 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2470/12542 | Batch Loss: 2.0824 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2471/12542 | Batch Loss: 0.9358 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2472/12542 | Batch Loss: 0.7283 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2473/12542 | Batch Loss: 1.0598 | Learning Rate: 0.000601 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2474/12542 | Batch Loss: 0.9767 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2475/12542 | Batch Loss: 1.0638 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2476/12542 | Batch Loss: 1.5157 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2477/12542 | Batch Loss: 1.9968 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2478/12542 | Batch Loss: 1.7805 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2479/12542 | Batch Loss: 1.3509 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2480/12542 | Batch Loss: 1.4002 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2481/12542 | Batch Loss: 1.4812 | Learning Rate: 0.000601 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2482/12542 | Batch Loss: 2.5712 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2483/12542 | Batch Loss: 0.6653 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2484/12542 | Batch Loss: 1.3953 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2485/12542 | Batch Loss: 0.6243 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2486/12542 | Batch Loss: 1.9790 | Learning Rate: 0.000601 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2487/12542 | Batch Loss: 1.3758 | Learning Rate: 0.000601 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2488/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000601 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2489/12542 | Batch Loss: 1.3162 | Learning Rate: 0.000601 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2490/12542 | Batch Loss: 1.0171 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2491/12542 | Batch Loss: 2.2189 | Learning Rate: 0.000600 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2492/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000600 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2493/12542 | Batch Loss: 1.2721 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2494/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000600 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2495/12542 | Batch Loss: 1.4948 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2496/12542 | Batch Loss: 1.7321 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2497/12542 | Batch Loss: 0.6262 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2498/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2499/12542 | Batch Loss: 1.4240 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2500/12542 | Batch Loss: 0.3313 | Learning Rate: 0.000600 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2501/12542 | Batch Loss: 0.9495 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2502/12542 | Batch Loss: 0.5320 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2503/12542 | Batch Loss: 1.6786 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2504/12542 | Batch Loss: 1.3151 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2505/12542 | Batch Loss: 1.8037 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2506/12542 | Batch Loss: 1.6683 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2507/12542 | Batch Loss: 1.7340 | Learning Rate: 0.000600 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2508/12542 | Batch Loss: 0.7034 | Learning Rate: 0.000600 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2509/12542 | Batch Loss: 2.0126 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2510/12542 | Batch Loss: 1.5208 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2511/12542 | Batch Loss: 0.9949 | Learning Rate: 0.000600 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2512/12542 | Batch Loss: 2.4440 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2513/12542 | Batch Loss: 1.7601 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2514/12542 | Batch Loss: 1.7782 | Learning Rate: 0.000600 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2515/12542 | Batch Loss: 0.7462 | Learning Rate: 0.000600 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2516/12542 | Batch Loss: 2.0845 | Learning Rate: 0.000600 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2517/12542 | Batch Loss: 0.9740 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2518/12542 | Batch Loss: 1.0400 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2519/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000600 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2520/12542 | Batch Loss: 1.4311 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2521/12542 | Batch Loss: 0.5270 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2522/12542 | Batch Loss: 0.9400 | Learning Rate: 0.000600 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2523/12542 | Batch Loss: 1.6981 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2524/12542 | Batch Loss: 0.8145 | Learning Rate: 0.000600 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2525/12542 | Batch Loss: 1.1676 | Learning Rate: 0.000600 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2526/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000600 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2527/12542 | Batch Loss: 1.2581 | Learning Rate: 0.000600 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2528/12542 | Batch Loss: 1.4610 | Learning Rate: 0.000599 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2529/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000599 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2530/12542 | Batch Loss: 0.9610 | Learning Rate: 0.000599 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2531/12542 | Batch Loss: 1.1646 | Learning Rate: 0.000599 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2532/12542 | Batch Loss: 0.7427 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2533/12542 | Batch Loss: 0.6368 | Learning Rate: 0.000599 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2534/12542 | Batch Loss: 1.2345 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2535/12542 | Batch Loss: 1.3354 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2536/12542 | Batch Loss: 1.5839 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2537/12542 | Batch Loss: 3.0768 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2538/12542 | Batch Loss: 0.5168 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2539/12542 | Batch Loss: 1.3945 | Learning Rate: 0.000599 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2540/12542 | Batch Loss: 0.9680 | Learning Rate: 0.000599 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2541/12542 | Batch Loss: 0.7879 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2542/12542 | Batch Loss: 1.1283 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2543/12542 | Batch Loss: 0.7005 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2544/12542 | Batch Loss: 1.9221 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2545/12542 | Batch Loss: 1.0855 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2546/12542 | Batch Loss: 1.6306 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2547/12542 | Batch Loss: 0.9895 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2548/12542 | Batch Loss: 1.0267 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2549/12542 | Batch Loss: 2.3722 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2550/12542 | Batch Loss: 0.9711 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2551/12542 | Batch Loss: 1.6037 | Learning Rate: 0.000599 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2552/12542 | Batch Loss: 1.5409 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2553/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000599 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2554/12542 | Batch Loss: 2.7530 | Learning Rate: 0.000599 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2555/12542 | Batch Loss: 1.5269 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2556/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000599 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2557/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000599 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2558/12542 | Batch Loss: 1.3081 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2559/12542 | Batch Loss: 1.7987 | Learning Rate: 0.000599 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2560/12542 | Batch Loss: 2.0276 | Learning Rate: 0.000599 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2561/12542 | Batch Loss: 2.0351 | Learning Rate: 0.000599 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2562/12542 | Batch Loss: 2.1924 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2563/12542 | Batch Loss: 0.8531 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2564/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000599 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2565/12542 | Batch Loss: 2.4659 | Learning Rate: 0.000598 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2566/12542 | Batch Loss: 0.8757 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2567/12542 | Batch Loss: 3.4337 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2568/12542 | Batch Loss: 1.9762 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2569/12542 | Batch Loss: 1.1285 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2570/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2571/12542 | Batch Loss: 1.4273 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2572/12542 | Batch Loss: 1.0653 | Learning Rate: 0.000598 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2573/12542 | Batch Loss: 1.5757 | Learning Rate: 0.000598 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2574/12542 | Batch Loss: 1.9617 | Learning Rate: 0.000598 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2575/12542 | Batch Loss: 1.5658 | Learning Rate: 0.000598 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2576/12542 | Batch Loss: 1.5768 | Learning Rate: 0.000598 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2577/12542 | Batch Loss: 1.0763 | Learning Rate: 0.000598 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2578/12542 | Batch Loss: 0.4098 | Learning Rate: 0.000598 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2579/12542 | Batch Loss: 1.0779 | Learning Rate: 0.000598 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2580/12542 | Batch Loss: 0.8065 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2581/12542 | Batch Loss: 0.9007 | Learning Rate: 0.000598 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2582/12542 | Batch Loss: 2.3959 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2583/12542 | Batch Loss: 1.2065 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2584/12542 | Batch Loss: 1.5504 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2585/12542 | Batch Loss: 0.6328 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2586/12542 | Batch Loss: 2.2374 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2587/12542 | Batch Loss: 0.8349 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2588/12542 | Batch Loss: 1.0302 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2589/12542 | Batch Loss: 1.7547 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2590/12542 | Batch Loss: 1.0781 | Learning Rate: 0.000598 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2591/12542 | Batch Loss: 2.2248 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2592/12542 | Batch Loss: 1.2965 | Learning Rate: 0.000598 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2593/12542 | Batch Loss: 0.5744 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2594/12542 | Batch Loss: 2.1585 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2595/12542 | Batch Loss: 3.7691 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2596/12542 | Batch Loss: 0.7820 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2597/12542 | Batch Loss: 0.9267 | Learning Rate: 0.000598 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2598/12542 | Batch Loss: 0.9748 | Learning Rate: 0.000598 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2599/12542 | Batch Loss: 2.0561 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2600/12542 | Batch Loss: 0.9936 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2601/12542 | Batch Loss: 1.6522 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2602/12542 | Batch Loss: 1.2746 | Learning Rate: 0.000598 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2603/12542 | Batch Loss: 2.0498 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2604/12542 | Batch Loss: 1.1080 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2605/12542 | Batch Loss: 1.4680 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2606/12542 | Batch Loss: 3.5641 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2607/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2608/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000597 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2609/12542 | Batch Loss: 1.0013 | Learning Rate: 0.000597 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2610/12542 | Batch Loss: 1.1540 | Learning Rate: 0.000597 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2611/12542 | Batch Loss: 0.7289 | Learning Rate: 0.000597 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2612/12542 | Batch Loss: 1.4066 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2613/12542 | Batch Loss: 1.2274 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2614/12542 | Batch Loss: 1.3035 | Learning Rate: 0.000597 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2615/12542 | Batch Loss: 1.5801 | Learning Rate: 0.000597 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2616/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000597 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2617/12542 | Batch Loss: 0.6533 | Learning Rate: 0.000597 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2618/12542 | Batch Loss: 3.4168 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2619/12542 | Batch Loss: 1.4279 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2620/12542 | Batch Loss: 1.1010 | Learning Rate: 0.000597 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2621/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000597 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2622/12542 | Batch Loss: 2.1609 | Learning Rate: 0.000597 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2623/12542 | Batch Loss: 1.5618 | Learning Rate: 0.000597 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2624/12542 | Batch Loss: 1.8178 | Learning Rate: 0.000597 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2625/12542 | Batch Loss: 1.5052 | Learning Rate: 0.000597 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2626/12542 | Batch Loss: 1.0411 | Learning Rate: 0.000597 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2627/12542 | Batch Loss: 1.5154 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2628/12542 | Batch Loss: 0.9148 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2629/12542 | Batch Loss: 0.9970 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2630/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2631/12542 | Batch Loss: 0.8855 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2632/12542 | Batch Loss: 0.8066 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2633/12542 | Batch Loss: 1.7219 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2634/12542 | Batch Loss: 0.6553 | Learning Rate: 0.000597 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2635/12542 | Batch Loss: 1.3865 | Learning Rate: 0.000597 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2636/12542 | Batch Loss: 1.6931 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2637/12542 | Batch Loss: 1.4970 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2638/12542 | Batch Loss: 1.3118 | Learning Rate: 0.000597 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2639/12542 | Batch Loss: 0.8089 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2640/12542 | Batch Loss: 1.7258 | Learning Rate: 0.000597 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2641/12542 | Batch Loss: 1.5534 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2642/12542 | Batch Loss: 1.4232 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2643/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000596 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2644/12542 | Batch Loss: 0.9925 | Learning Rate: 0.000596 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2645/12542 | Batch Loss: 2.4620 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2646/12542 | Batch Loss: 0.7334 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2647/12542 | Batch Loss: 1.2255 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2648/12542 | Batch Loss: 0.5304 | Learning Rate: 0.000596 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2649/12542 | Batch Loss: 0.6326 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2650/12542 | Batch Loss: 2.7670 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2651/12542 | Batch Loss: 0.6365 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2652/12542 | Batch Loss: 1.0059 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2653/12542 | Batch Loss: 1.2012 | Learning Rate: 0.000596 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2654/12542 | Batch Loss: 1.9180 | Learning Rate: 0.000596 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2655/12542 | Batch Loss: 1.5343 | Learning Rate: 0.000596 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2656/12542 | Batch Loss: 2.2364 | Learning Rate: 0.000596 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2657/12542 | Batch Loss: 1.0022 | Learning Rate: 0.000596 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2658/12542 | Batch Loss: 1.4196 | Learning Rate: 0.000596 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2659/12542 | Batch Loss: 0.5671 | Learning Rate: 0.000596 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2660/12542 | Batch Loss: 0.6333 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2661/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000596 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2662/12542 | Batch Loss: 0.9403 | Learning Rate: 0.000596 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2663/12542 | Batch Loss: 1.2907 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2664/12542 | Batch Loss: 1.7461 | Learning Rate: 0.000596 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2665/12542 | Batch Loss: 1.9603 | Learning Rate: 0.000596 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2666/12542 | Batch Loss: 1.6196 | Learning Rate: 0.000596 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2667/12542 | Batch Loss: 1.9111 | Learning Rate: 0.000596 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2668/12542 | Batch Loss: 1.6676 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2669/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2670/12542 | Batch Loss: 1.2539 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2671/12542 | Batch Loss: 0.8943 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2672/12542 | Batch Loss: 0.8474 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2673/12542 | Batch Loss: 0.9867 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2674/12542 | Batch Loss: 1.1259 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2675/12542 | Batch Loss: 1.3561 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2676/12542 | Batch Loss: 1.7550 | Learning Rate: 0.000596 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2677/12542 | Batch Loss: 1.3588 | Learning Rate: 0.000596 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2678/12542 | Batch Loss: 1.7163 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2679/12542 | Batch Loss: 0.7101 | Learning Rate: 0.000595 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2680/12542 | Batch Loss: 1.6747 | Learning Rate: 0.000595 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2681/12542 | Batch Loss: 0.5165 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2682/12542 | Batch Loss: 1.2938 | Learning Rate: 0.000595 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2683/12542 | Batch Loss: 1.7617 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2684/12542 | Batch Loss: 0.9521 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2685/12542 | Batch Loss: 1.6815 | Learning Rate: 0.000595 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2686/12542 | Batch Loss: 0.9758 | Learning Rate: 0.000595 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2687/12542 | Batch Loss: 1.3091 | Learning Rate: 0.000595 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2688/12542 | Batch Loss: 1.6135 | Learning Rate: 0.000595 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2689/12542 | Batch Loss: 2.2803 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2690/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2691/12542 | Batch Loss: 0.9206 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2692/12542 | Batch Loss: 1.9081 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2693/12542 | Batch Loss: 1.9106 | Learning Rate: 0.000595 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2694/12542 | Batch Loss: 2.4457 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2695/12542 | Batch Loss: 1.1424 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2696/12542 | Batch Loss: 0.9180 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2697/12542 | Batch Loss: 1.2564 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2698/12542 | Batch Loss: 1.8626 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2699/12542 | Batch Loss: 0.7581 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2700/12542 | Batch Loss: 1.6718 | Learning Rate: 0.000595 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2701/12542 | Batch Loss: 0.6914 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2702/12542 | Batch Loss: 1.2318 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2703/12542 | Batch Loss: 2.2121 | Learning Rate: 0.000595 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2704/12542 | Batch Loss: 1.0441 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2705/12542 | Batch Loss: 2.4187 | Learning Rate: 0.000595 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2706/12542 | Batch Loss: 2.4569 | Learning Rate: 0.000595 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2707/12542 | Batch Loss: 0.8166 | Learning Rate: 0.000595 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2708/12542 | Batch Loss: 2.1153 | Learning Rate: 0.000595 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 2709/12542 | Batch Loss: 1.0462 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2710/12542 | Batch Loss: 1.3323 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2711/12542 | Batch Loss: 2.9258 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2712/12542 | Batch Loss: 0.8956 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2713/12542 | Batch Loss: 1.5423 | Learning Rate: 0.000595 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2714/12542 | Batch Loss: 1.7638 | Learning Rate: 0.000595 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2715/12542 | Batch Loss: 1.2337 | Learning Rate: 0.000595 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2716/12542 | Batch Loss: 1.3772 | Learning Rate: 0.000594 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2717/12542 | Batch Loss: 0.8804 | Learning Rate: 0.000594 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2718/12542 | Batch Loss: 0.9796 | Learning Rate: 0.000594 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2719/12542 | Batch Loss: 0.9693 | Learning Rate: 0.000594 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2720/12542 | Batch Loss: 1.8515 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2721/12542 | Batch Loss: 1.7408 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2722/12542 | Batch Loss: 2.1132 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2723/12542 | Batch Loss: 1.1117 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2724/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2725/12542 | Batch Loss: 0.7197 | Learning Rate: 0.000594 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2726/12542 | Batch Loss: 2.8168 | Learning Rate: 0.000594 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2727/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2728/12542 | Batch Loss: 0.5599 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2729/12542 | Batch Loss: 0.8679 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2730/12542 | Batch Loss: 1.5544 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2731/12542 | Batch Loss: 0.7433 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2732/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2733/12542 | Batch Loss: 2.3231 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2734/12542 | Batch Loss: 1.5551 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2735/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000594 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2736/12542 | Batch Loss: 1.6525 | Learning Rate: 0.000594 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2737/12542 | Batch Loss: 2.4567 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2738/12542 | Batch Loss: 1.7105 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2739/12542 | Batch Loss: 1.5545 | Learning Rate: 0.000594 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2740/12542 | Batch Loss: 0.7324 | Learning Rate: 0.000594 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2741/12542 | Batch Loss: 1.2367 | Learning Rate: 0.000594 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2742/12542 | Batch Loss: 0.9495 | Learning Rate: 0.000594 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2743/12542 | Batch Loss: 1.4605 | Learning Rate: 0.000594 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2744/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2745/12542 | Batch Loss: 1.4573 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2746/12542 | Batch Loss: 2.0189 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2747/12542 | Batch Loss: 1.1341 | Learning Rate: 0.000594 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2748/12542 | Batch Loss: 1.3445 | Learning Rate: 0.000594 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2749/12542 | Batch Loss: 0.8309 | Learning Rate: 0.000594 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2750/12542 | Batch Loss: 2.3906 | Learning Rate: 0.000594 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2751/12542 | Batch Loss: 1.1379 | Learning Rate: 0.000594 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2752/12542 | Batch Loss: 1.9696 | Learning Rate: 0.000594 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2753/12542 | Batch Loss: 1.3582 | Learning Rate: 0.000593 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2754/12542 | Batch Loss: 1.1752 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2755/12542 | Batch Loss: 1.2049 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2756/12542 | Batch Loss: 0.4435 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2757/12542 | Batch Loss: 0.8021 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2758/12542 | Batch Loss: 1.2584 | Learning Rate: 0.000593 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2759/12542 | Batch Loss: 0.9269 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2760/12542 | Batch Loss: 1.4058 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2761/12542 | Batch Loss: 0.6093 | Learning Rate: 0.000593 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2762/12542 | Batch Loss: 0.8268 | Learning Rate: 0.000593 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2763/12542 | Batch Loss: 0.7189 | Learning Rate: 0.000593 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2764/12542 | Batch Loss: 0.9029 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2765/12542 | Batch Loss: 1.6304 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2766/12542 | Batch Loss: 1.9532 | Learning Rate: 0.000593 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2767/12542 | Batch Loss: 1.2353 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2768/12542 | Batch Loss: 1.2928 | Learning Rate: 0.000593 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2769/12542 | Batch Loss: 2.2576 | Learning Rate: 0.000593 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2770/12542 | Batch Loss: 1.6182 | Learning Rate: 0.000593 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2771/12542 | Batch Loss: 1.6625 | Learning Rate: 0.000593 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2772/12542 | Batch Loss: 0.3293 | Learning Rate: 0.000593 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 2773/12542 | Batch Loss: 1.5971 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2774/12542 | Batch Loss: 1.8251 | Learning Rate: 0.000593 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2775/12542 | Batch Loss: 1.2947 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2776/12542 | Batch Loss: 0.9691 | Learning Rate: 0.000593 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2777/12542 | Batch Loss: 2.7562 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2778/12542 | Batch Loss: 0.7035 | Learning Rate: 0.000593 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2779/12542 | Batch Loss: 0.9457 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2780/12542 | Batch Loss: 2.8340 | Learning Rate: 0.000593 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2781/12542 | Batch Loss: 1.4424 | Learning Rate: 0.000593 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2782/12542 | Batch Loss: 3.7454 | Learning Rate: 0.000593 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2783/12542 | Batch Loss: 1.1518 | Learning Rate: 0.000593 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2784/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000593 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2785/12542 | Batch Loss: 1.6798 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2786/12542 | Batch Loss: 1.2841 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2787/12542 | Batch Loss: 3.5024 | Learning Rate: 0.000593 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2788/12542 | Batch Loss: 1.0905 | Learning Rate: 0.000593 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2789/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000593 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2790/12542 | Batch Loss: 0.9753 | Learning Rate: 0.000593 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2791/12542 | Batch Loss: 0.3959 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2792/12542 | Batch Loss: 1.8640 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2793/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2794/12542 | Batch Loss: 2.1366 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2795/12542 | Batch Loss: 1.7965 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2796/12542 | Batch Loss: 1.8575 | Learning Rate: 0.000592 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2797/12542 | Batch Loss: 0.7286 | Learning Rate: 0.000592 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2798/12542 | Batch Loss: 1.0925 | Learning Rate: 0.000592 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2799/12542 | Batch Loss: 1.1114 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2800/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2801/12542 | Batch Loss: 1.6736 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2802/12542 | Batch Loss: 1.4452 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2803/12542 | Batch Loss: 1.0541 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2804/12542 | Batch Loss: 1.9169 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2805/12542 | Batch Loss: 0.9558 | Learning Rate: 0.000592 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2806/12542 | Batch Loss: 1.3741 | Learning Rate: 0.000592 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2807/12542 | Batch Loss: 0.6936 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2808/12542 | Batch Loss: 0.7722 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2809/12542 | Batch Loss: 1.3040 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2810/12542 | Batch Loss: 1.1455 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2811/12542 | Batch Loss: 2.2052 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2812/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2813/12542 | Batch Loss: 2.1243 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2814/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000592 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2815/12542 | Batch Loss: 1.5537 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2816/12542 | Batch Loss: 0.7178 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2817/12542 | Batch Loss: 1.4600 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2818/12542 | Batch Loss: 0.4051 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2819/12542 | Batch Loss: 0.7871 | Learning Rate: 0.000592 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2820/12542 | Batch Loss: 0.9958 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2821/12542 | Batch Loss: 2.0904 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2822/12542 | Batch Loss: 1.1453 | Learning Rate: 0.000592 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2823/12542 | Batch Loss: 1.1055 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2824/12542 | Batch Loss: 0.9051 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2825/12542 | Batch Loss: 2.5927 | Learning Rate: 0.000592 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2826/12542 | Batch Loss: 1.3517 | Learning Rate: 0.000592 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2827/12542 | Batch Loss: 1.2097 | Learning Rate: 0.000592 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2828/12542 | Batch Loss: 1.6431 | Learning Rate: 0.000592 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2829/12542 | Batch Loss: 0.8249 | Learning Rate: 0.000591 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2830/12542 | Batch Loss: 1.3478 | Learning Rate: 0.000591 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2831/12542 | Batch Loss: 1.5306 | Learning Rate: 0.000591 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2832/12542 | Batch Loss: 0.7179 | Learning Rate: 0.000591 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2833/12542 | Batch Loss: 2.0194 | Learning Rate: 0.000591 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2834/12542 | Batch Loss: 1.0377 | Learning Rate: 0.000591 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2835/12542 | Batch Loss: 1.2742 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2836/12542 | Batch Loss: 1.5577 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2837/12542 | Batch Loss: 1.7115 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2838/12542 | Batch Loss: 0.9523 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2839/12542 | Batch Loss: 1.0045 | Learning Rate: 0.000591 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2840/12542 | Batch Loss: 1.3655 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2841/12542 | Batch Loss: 1.6207 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2842/12542 | Batch Loss: 1.4031 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2843/12542 | Batch Loss: 1.8029 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2844/12542 | Batch Loss: 0.9664 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2845/12542 | Batch Loss: 2.0524 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2846/12542 | Batch Loss: 0.6892 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2847/12542 | Batch Loss: 1.2854 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2848/12542 | Batch Loss: 1.9335 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2849/12542 | Batch Loss: 1.1353 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2850/12542 | Batch Loss: 0.9190 | Learning Rate: 0.000591 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2851/12542 | Batch Loss: 0.9765 | Learning Rate: 0.000591 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2852/12542 | Batch Loss: 0.7955 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2853/12542 | Batch Loss: 1.8343 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2854/12542 | Batch Loss: 1.1137 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2855/12542 | Batch Loss: 0.6745 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2856/12542 | Batch Loss: 1.6162 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2857/12542 | Batch Loss: 1.5403 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2858/12542 | Batch Loss: 1.0708 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2859/12542 | Batch Loss: 1.0799 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2860/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000591 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2861/12542 | Batch Loss: 2.5582 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2862/12542 | Batch Loss: 0.8528 | Learning Rate: 0.000591 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2863/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2864/12542 | Batch Loss: 1.1108 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2865/12542 | Batch Loss: 1.0267 | Learning Rate: 0.000591 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2866/12542 | Batch Loss: 0.6871 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2867/12542 | Batch Loss: 0.8233 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2868/12542 | Batch Loss: 1.7141 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2869/12542 | Batch Loss: 1.4212 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2870/12542 | Batch Loss: 2.0356 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2871/12542 | Batch Loss: 1.6813 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2872/12542 | Batch Loss: 1.4349 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2873/12542 | Batch Loss: 2.8106 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2874/12542 | Batch Loss: 1.5141 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2875/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2876/12542 | Batch Loss: 1.9735 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2877/12542 | Batch Loss: 0.8042 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2878/12542 | Batch Loss: 1.8280 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2879/12542 | Batch Loss: 1.2201 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2880/12542 | Batch Loss: 0.8982 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2881/12542 | Batch Loss: 2.7779 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2882/12542 | Batch Loss: 0.7874 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2883/12542 | Batch Loss: 0.8087 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2884/12542 | Batch Loss: 1.0657 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2885/12542 | Batch Loss: 1.0771 | Learning Rate: 0.000590 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2886/12542 | Batch Loss: 2.4971 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2887/12542 | Batch Loss: 1.5041 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2888/12542 | Batch Loss: 1.3856 | Learning Rate: 0.000590 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2889/12542 | Batch Loss: 0.9007 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2890/12542 | Batch Loss: 1.4203 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2891/12542 | Batch Loss: 0.5741 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2892/12542 | Batch Loss: 1.9703 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2893/12542 | Batch Loss: 1.1827 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2894/12542 | Batch Loss: 2.5793 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2895/12542 | Batch Loss: 1.1294 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2896/12542 | Batch Loss: 1.4747 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2897/12542 | Batch Loss: 1.8081 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2898/12542 | Batch Loss: 0.7063 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2899/12542 | Batch Loss: 1.8026 | Learning Rate: 0.000590 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2900/12542 | Batch Loss: 1.1629 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2901/12542 | Batch Loss: 1.5602 | Learning Rate: 0.000590 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2902/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000590 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2903/12542 | Batch Loss: 1.6568 | Learning Rate: 0.000590 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2904/12542 | Batch Loss: 1.8258 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2905/12542 | Batch Loss: 1.7352 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2906/12542 | Batch Loss: 1.0938 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2907/12542 | Batch Loss: 1.1819 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2908/12542 | Batch Loss: 2.2222 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2909/12542 | Batch Loss: 1.3272 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2910/12542 | Batch Loss: 0.9725 | Learning Rate: 0.000589 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2911/12542 | Batch Loss: 1.8775 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2912/12542 | Batch Loss: 1.5095 | Learning Rate: 0.000589 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2913/12542 | Batch Loss: 1.6140 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2914/12542 | Batch Loss: 0.8623 | Learning Rate: 0.000589 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2915/12542 | Batch Loss: 0.7848 | Learning Rate: 0.000589 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2916/12542 | Batch Loss: 2.1117 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2917/12542 | Batch Loss: 2.9012 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2918/12542 | Batch Loss: 1.6043 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2919/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000589 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2920/12542 | Batch Loss: 1.4960 | Learning Rate: 0.000589 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2921/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000589 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2922/12542 | Batch Loss: 0.7897 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2923/12542 | Batch Loss: 2.7107 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2924/12542 | Batch Loss: 1.3471 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2925/12542 | Batch Loss: 1.4186 | Learning Rate: 0.000589 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2926/12542 | Batch Loss: 2.4814 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2927/12542 | Batch Loss: 0.9902 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2928/12542 | Batch Loss: 1.4317 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2929/12542 | Batch Loss: 1.0454 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2930/12542 | Batch Loss: 1.3188 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2931/12542 | Batch Loss: 2.3587 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2932/12542 | Batch Loss: 0.8128 | Learning Rate: 0.000589 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2933/12542 | Batch Loss: 1.0450 | Learning Rate: 0.000589 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2934/12542 | Batch Loss: 0.9443 | Learning Rate: 0.000589 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2935/12542 | Batch Loss: 0.7547 | Learning Rate: 0.000589 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2936/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000589 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2937/12542 | Batch Loss: 1.3518 | Learning Rate: 0.000589 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2938/12542 | Batch Loss: 1.3718 | Learning Rate: 0.000589 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2939/12542 | Batch Loss: 0.9323 | Learning Rate: 0.000589 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2940/12542 | Batch Loss: 1.4976 | Learning Rate: 0.000589 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2941/12542 | Batch Loss: 1.6430 | Learning Rate: 0.000589 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2942/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000588 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2943/12542 | Batch Loss: 0.6156 | Learning Rate: 0.000588 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2944/12542 | Batch Loss: 3.2340 | Learning Rate: 0.000588 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2945/12542 | Batch Loss: 1.4250 | Learning Rate: 0.000588 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2946/12542 | Batch Loss: 1.4344 | Learning Rate: 0.000588 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2947/12542 | Batch Loss: 0.8086 | Learning Rate: 0.000588 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2948/12542 | Batch Loss: 0.6459 | Learning Rate: 0.000588 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2949/12542 | Batch Loss: 1.8573 | Learning Rate: 0.000588 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2950/12542 | Batch Loss: 1.4971 | Learning Rate: 0.000588 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2951/12542 | Batch Loss: 1.5813 | Learning Rate: 0.000588 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2952/12542 | Batch Loss: 1.0803 | Learning Rate: 0.000588 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2953/12542 | Batch Loss: 2.4369 | Learning Rate: 0.000588 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 2954/12542 | Batch Loss: 1.3152 | Learning Rate: 0.000588 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2955/12542 | Batch Loss: 1.2484 | Learning Rate: 0.000588 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 2956/12542 | Batch Loss: 0.9011 | Learning Rate: 0.000588 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2957/12542 | Batch Loss: 2.0987 | Learning Rate: 0.000588 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2958/12542 | Batch Loss: 0.9458 | Learning Rate: 0.000588 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 2959/12542 | Batch Loss: 0.6655 | Learning Rate: 0.000588 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2960/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000588 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2961/12542 | Batch Loss: 1.4263 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2962/12542 | Batch Loss: 3.0427 | Learning Rate: 0.000588 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 2963/12542 | Batch Loss: 1.3912 | Learning Rate: 0.000588 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2964/12542 | Batch Loss: 1.2768 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2965/12542 | Batch Loss: 1.0388 | Learning Rate: 0.000588 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2966/12542 | Batch Loss: 1.8792 | Learning Rate: 0.000588 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2967/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2968/12542 | Batch Loss: 0.8309 | Learning Rate: 0.000588 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2969/12542 | Batch Loss: 2.6467 | Learning Rate: 0.000588 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2970/12542 | Batch Loss: 0.5039 | Learning Rate: 0.000588 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2971/12542 | Batch Loss: 1.2531 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2972/12542 | Batch Loss: 1.5272 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2973/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000588 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2974/12542 | Batch Loss: 1.0189 | Learning Rate: 0.000588 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2975/12542 | Batch Loss: 1.3962 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2976/12542 | Batch Loss: 1.2687 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2977/12542 | Batch Loss: 1.1542 | Learning Rate: 0.000588 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2978/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000588 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2979/12542 | Batch Loss: 1.5674 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2980/12542 | Batch Loss: 1.9853 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2981/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000587 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 2982/12542 | Batch Loss: 0.9453 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2983/12542 | Batch Loss: 1.5017 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2984/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2985/12542 | Batch Loss: 2.0796 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2986/12542 | Batch Loss: 1.3580 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2987/12542 | Batch Loss: 1.2507 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2988/12542 | Batch Loss: 1.2325 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2989/12542 | Batch Loss: 0.5796 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2990/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 2991/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 2992/12542 | Batch Loss: 1.5217 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2993/12542 | Batch Loss: 1.1954 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 2994/12542 | Batch Loss: 1.0042 | Learning Rate: 0.000587 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 2995/12542 | Batch Loss: 1.2562 | Learning Rate: 0.000587 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 2996/12542 | Batch Loss: 1.1135 | Learning Rate: 0.000587 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 2997/12542 | Batch Loss: 2.1256 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2998/12542 | Batch Loss: 0.8836 | Learning Rate: 0.000587 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 2999/12542 | Batch Loss: 0.8961 | Learning Rate: 0.000587 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3000/12542 | Batch Loss: 1.0004 | Learning Rate: 0.000587 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3001/12542 | Batch Loss: 1.0399 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3002/12542 | Batch Loss: 1.0726 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3003/12542 | Batch Loss: 0.9580 | Learning Rate: 0.000587 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3004/12542 | Batch Loss: 1.2921 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3005/12542 | Batch Loss: 1.7621 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3006/12542 | Batch Loss: 1.6150 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3007/12542 | Batch Loss: 0.7374 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3008/12542 | Batch Loss: 1.1764 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3009/12542 | Batch Loss: 1.3819 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3010/12542 | Batch Loss: 0.4504 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3011/12542 | Batch Loss: 2.3070 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3012/12542 | Batch Loss: 1.2763 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3013/12542 | Batch Loss: 0.7376 | Learning Rate: 0.000587 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3014/12542 | Batch Loss: 1.0887 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3015/12542 | Batch Loss: 1.9979 | Learning Rate: 0.000587 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3016/12542 | Batch Loss: 1.4985 | Learning Rate: 0.000587 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3017/12542 | Batch Loss: 2.8354 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3018/12542 | Batch Loss: 0.6112 | Learning Rate: 0.000586 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3019/12542 | Batch Loss: 0.5709 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3020/12542 | Batch Loss: 1.5623 | Learning Rate: 0.000586 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3021/12542 | Batch Loss: 1.3185 | Learning Rate: 0.000586 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3022/12542 | Batch Loss: 0.7194 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3023/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3024/12542 | Batch Loss: 1.4308 | Learning Rate: 0.000586 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3025/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3026/12542 | Batch Loss: 2.0182 | Learning Rate: 0.000586 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3027/12542 | Batch Loss: 1.5958 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3028/12542 | Batch Loss: 0.8292 | Learning Rate: 0.000586 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3029/12542 | Batch Loss: 0.6821 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3030/12542 | Batch Loss: 1.2339 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3031/12542 | Batch Loss: 1.8398 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3032/12542 | Batch Loss: 1.1891 | Learning Rate: 0.000586 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3033/12542 | Batch Loss: 0.8641 | Learning Rate: 0.000586 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3034/12542 | Batch Loss: 2.1070 | Learning Rate: 0.000586 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3035/12542 | Batch Loss: 0.7715 | Learning Rate: 0.000586 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3036/12542 | Batch Loss: 0.2848 | Learning Rate: 0.000586 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3037/12542 | Batch Loss: 1.9191 | Learning Rate: 0.000586 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3038/12542 | Batch Loss: 1.8743 | Learning Rate: 0.000586 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3039/12542 | Batch Loss: 0.8911 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3040/12542 | Batch Loss: 0.9461 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3041/12542 | Batch Loss: 1.8835 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3042/12542 | Batch Loss: 1.5130 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3043/12542 | Batch Loss: 1.0166 | Learning Rate: 0.000586 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3044/12542 | Batch Loss: 1.1578 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3045/12542 | Batch Loss: 1.7547 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3046/12542 | Batch Loss: 0.7312 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3047/12542 | Batch Loss: 0.9369 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3048/12542 | Batch Loss: 1.5452 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3049/12542 | Batch Loss: 1.6853 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3050/12542 | Batch Loss: 1.9114 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3051/12542 | Batch Loss: 1.0484 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3052/12542 | Batch Loss: 1.1563 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3053/12542 | Batch Loss: 2.0044 | Learning Rate: 0.000586 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3054/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3055/12542 | Batch Loss: 0.8369 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3056/12542 | Batch Loss: 1.3832 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3057/12542 | Batch Loss: 1.1016 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3058/12542 | Batch Loss: 1.8955 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3059/12542 | Batch Loss: 1.2154 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3060/12542 | Batch Loss: 0.8171 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3061/12542 | Batch Loss: 1.0704 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3062/12542 | Batch Loss: 1.2584 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3063/12542 | Batch Loss: 1.7542 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3064/12542 | Batch Loss: 0.8812 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3065/12542 | Batch Loss: 1.0300 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3066/12542 | Batch Loss: 0.7925 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3067/12542 | Batch Loss: 1.2805 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3068/12542 | Batch Loss: 3.6884 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3069/12542 | Batch Loss: 1.0886 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3070/12542 | Batch Loss: 0.8475 | Learning Rate: 0.000585 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3071/12542 | Batch Loss: 1.5583 | Learning Rate: 0.000585 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3072/12542 | Batch Loss: 0.9318 | Learning Rate: 0.000585 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3073/12542 | Batch Loss: 2.4168 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3074/12542 | Batch Loss: 0.8499 | Learning Rate: 0.000585 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3075/12542 | Batch Loss: 1.4648 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3076/12542 | Batch Loss: 1.3694 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3077/12542 | Batch Loss: 2.4012 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3078/12542 | Batch Loss: 1.4727 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3079/12542 | Batch Loss: 1.6388 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3080/12542 | Batch Loss: 0.7624 | Learning Rate: 0.000585 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3081/12542 | Batch Loss: 1.0464 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3082/12542 | Batch Loss: 2.0000 | Learning Rate: 0.000585 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3083/12542 | Batch Loss: 0.6960 | Learning Rate: 0.000585 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3084/12542 | Batch Loss: 0.6290 | Learning Rate: 0.000585 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3085/12542 | Batch Loss: 1.4436 | Learning Rate: 0.000585 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3086/12542 | Batch Loss: 2.2119 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3087/12542 | Batch Loss: 1.2529 | Learning Rate: 0.000585 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3088/12542 | Batch Loss: 1.5544 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3089/12542 | Batch Loss: 1.4455 | Learning Rate: 0.000585 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3090/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000585 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3091/12542 | Batch Loss: 1.8103 | Learning Rate: 0.000585 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3092/12542 | Batch Loss: 1.4011 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3093/12542 | Batch Loss: 1.9816 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3094/12542 | Batch Loss: 1.9887 | Learning Rate: 0.000584 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3095/12542 | Batch Loss: 1.7197 | Learning Rate: 0.000584 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3096/12542 | Batch Loss: 0.7476 | Learning Rate: 0.000584 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3097/12542 | Batch Loss: 1.5287 | Learning Rate: 0.000584 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3098/12542 | Batch Loss: 1.7140 | Learning Rate: 0.000584 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3099/12542 | Batch Loss: 0.6099 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3100/12542 | Batch Loss: 1.3582 | Learning Rate: 0.000584 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 3101/12542 | Batch Loss: 2.6982 | Learning Rate: 0.000584 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3102/12542 | Batch Loss: 1.7403 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3103/12542 | Batch Loss: 0.6255 | Learning Rate: 0.000584 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3104/12542 | Batch Loss: 0.9291 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3105/12542 | Batch Loss: 0.6962 | Learning Rate: 0.000584 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3106/12542 | Batch Loss: 1.3724 | Learning Rate: 0.000584 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3107/12542 | Batch Loss: 0.7677 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3108/12542 | Batch Loss: 1.0483 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3109/12542 | Batch Loss: 1.5071 | Learning Rate: 0.000584 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3110/12542 | Batch Loss: 0.5549 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3111/12542 | Batch Loss: 1.8332 | Learning Rate: 0.000584 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3112/12542 | Batch Loss: 0.7726 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3113/12542 | Batch Loss: 1.3432 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3114/12542 | Batch Loss: 0.8887 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3115/12542 | Batch Loss: 1.1075 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3116/12542 | Batch Loss: 1.6410 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3117/12542 | Batch Loss: 0.5171 | Learning Rate: 0.000584 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3118/12542 | Batch Loss: 1.3958 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3119/12542 | Batch Loss: 0.8744 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3120/12542 | Batch Loss: 0.8998 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3121/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3122/12542 | Batch Loss: 0.4700 | Learning Rate: 0.000584 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3123/12542 | Batch Loss: 3.6601 | Learning Rate: 0.000584 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3124/12542 | Batch Loss: 1.3902 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3125/12542 | Batch Loss: 1.6722 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3126/12542 | Batch Loss: 1.3288 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3127/12542 | Batch Loss: 1.7148 | Learning Rate: 0.000584 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3128/12542 | Batch Loss: 1.6154 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3129/12542 | Batch Loss: 0.3714 | Learning Rate: 0.000584 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3130/12542 | Batch Loss: 1.6434 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3131/12542 | Batch Loss: 1.4038 | Learning Rate: 0.000583 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3132/12542 | Batch Loss: 0.8937 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3133/12542 | Batch Loss: 2.0532 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3134/12542 | Batch Loss: 1.3710 | Learning Rate: 0.000583 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3135/12542 | Batch Loss: 1.3376 | Learning Rate: 0.000583 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3136/12542 | Batch Loss: 1.9690 | Learning Rate: 0.000583 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3137/12542 | Batch Loss: 2.7148 | Learning Rate: 0.000583 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3138/12542 | Batch Loss: 1.2970 | Learning Rate: 0.000583 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3139/12542 | Batch Loss: 1.8495 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3140/12542 | Batch Loss: 1.2927 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3141/12542 | Batch Loss: 1.4251 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3142/12542 | Batch Loss: 2.3192 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3143/12542 | Batch Loss: 0.8590 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3144/12542 | Batch Loss: 1.3503 | Learning Rate: 0.000583 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3145/12542 | Batch Loss: 1.5662 | Learning Rate: 0.000583 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3146/12542 | Batch Loss: 1.1853 | Learning Rate: 0.000583 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 3147/12542 | Batch Loss: 1.0172 | Learning Rate: 0.000583 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3148/12542 | Batch Loss: 1.0442 | Learning Rate: 0.000583 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3149/12542 | Batch Loss: 1.3466 | Learning Rate: 0.000583 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3150/12542 | Batch Loss: 1.1405 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3151/12542 | Batch Loss: 0.9816 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3152/12542 | Batch Loss: 1.2273 | Learning Rate: 0.000583 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3153/12542 | Batch Loss: 0.5940 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3154/12542 | Batch Loss: 0.6853 | Learning Rate: 0.000583 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3155/12542 | Batch Loss: 0.8353 | Learning Rate: 0.000583 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3156/12542 | Batch Loss: 1.5565 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3157/12542 | Batch Loss: 1.7501 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3158/12542 | Batch Loss: 1.4100 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3159/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000583 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3160/12542 | Batch Loss: 0.6192 | Learning Rate: 0.000583 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3161/12542 | Batch Loss: 1.5326 | Learning Rate: 0.000583 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3162/12542 | Batch Loss: 0.5514 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3163/12542 | Batch Loss: 2.8720 | Learning Rate: 0.000583 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3164/12542 | Batch Loss: 1.7054 | Learning Rate: 0.000583 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3165/12542 | Batch Loss: 1.7092 | Learning Rate: 0.000583 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3166/12542 | Batch Loss: 0.4721 | Learning Rate: 0.000583 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3167/12542 | Batch Loss: 1.1258 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3168/12542 | Batch Loss: 1.0805 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3169/12542 | Batch Loss: 3.0876 | Learning Rate: 0.000582 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3170/12542 | Batch Loss: 1.1203 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3171/12542 | Batch Loss: 1.6783 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3172/12542 | Batch Loss: 1.1800 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3173/12542 | Batch Loss: 1.7026 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3174/12542 | Batch Loss: 1.9032 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3175/12542 | Batch Loss: 0.5161 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3176/12542 | Batch Loss: 0.9283 | Learning Rate: 0.000582 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3177/12542 | Batch Loss: 0.9338 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3178/12542 | Batch Loss: 1.6331 | Learning Rate: 0.000582 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3179/12542 | Batch Loss: 1.4187 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3180/12542 | Batch Loss: 1.9076 | Learning Rate: 0.000582 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3181/12542 | Batch Loss: 1.1377 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3182/12542 | Batch Loss: 1.0419 | Learning Rate: 0.000582 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3183/12542 | Batch Loss: 0.5013 | Learning Rate: 0.000582 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3184/12542 | Batch Loss: 1.0322 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3185/12542 | Batch Loss: 1.9576 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3186/12542 | Batch Loss: 2.5237 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3187/12542 | Batch Loss: 1.0367 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3188/12542 | Batch Loss: 1.8506 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3189/12542 | Batch Loss: 1.1807 | Learning Rate: 0.000582 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3190/12542 | Batch Loss: 1.4015 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3191/12542 | Batch Loss: 1.2845 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3192/12542 | Batch Loss: 1.3160 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3193/12542 | Batch Loss: 1.6579 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3194/12542 | Batch Loss: 0.9902 | Learning Rate: 0.000582 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3195/12542 | Batch Loss: 1.7131 | Learning Rate: 0.000582 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3196/12542 | Batch Loss: 1.0020 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3197/12542 | Batch Loss: 0.8723 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3198/12542 | Batch Loss: 1.3847 | Learning Rate: 0.000582 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3199/12542 | Batch Loss: 1.1047 | Learning Rate: 0.000582 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3200/12542 | Batch Loss: 1.6159 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3201/12542 | Batch Loss: 1.5171 | Learning Rate: 0.000582 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3202/12542 | Batch Loss: 1.2899 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3203/12542 | Batch Loss: 1.2762 | Learning Rate: 0.000582 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3204/12542 | Batch Loss: 0.8793 | Learning Rate: 0.000582 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3205/12542 | Batch Loss: 0.6731 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3206/12542 | Batch Loss: 1.1115 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3207/12542 | Batch Loss: 0.9392 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3208/12542 | Batch Loss: 0.5683 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3209/12542 | Batch Loss: 0.6630 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3210/12542 | Batch Loss: 2.0985 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3211/12542 | Batch Loss: 0.9998 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3212/12542 | Batch Loss: 0.8749 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3213/12542 | Batch Loss: 1.3136 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3214/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3215/12542 | Batch Loss: 1.5600 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3216/12542 | Batch Loss: 1.1300 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3217/12542 | Batch Loss: 0.9893 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3218/12542 | Batch Loss: 0.7114 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3219/12542 | Batch Loss: 1.2310 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3220/12542 | Batch Loss: 0.8621 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3221/12542 | Batch Loss: 1.8694 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3222/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3223/12542 | Batch Loss: 0.9458 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3224/12542 | Batch Loss: 1.4609 | Learning Rate: 0.000581 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3225/12542 | Batch Loss: 1.3587 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3226/12542 | Batch Loss: 1.4315 | Learning Rate: 0.000581 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3227/12542 | Batch Loss: 0.8523 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3228/12542 | Batch Loss: 0.8434 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3229/12542 | Batch Loss: 1.4404 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3230/12542 | Batch Loss: 1.6970 | Learning Rate: 0.000581 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3231/12542 | Batch Loss: 0.9434 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3232/12542 | Batch Loss: 0.6322 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3233/12542 | Batch Loss: 0.8870 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3234/12542 | Batch Loss: 1.6233 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3235/12542 | Batch Loss: 1.5115 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3236/12542 | Batch Loss: 2.0849 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3237/12542 | Batch Loss: 3.0163 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3238/12542 | Batch Loss: 1.2511 | Learning Rate: 0.000581 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3239/12542 | Batch Loss: 0.7464 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3240/12542 | Batch Loss: 2.9881 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3241/12542 | Batch Loss: 0.8025 | Learning Rate: 0.000581 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3242/12542 | Batch Loss: 1.6927 | Learning Rate: 0.000581 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3243/12542 | Batch Loss: 1.7511 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3244/12542 | Batch Loss: 2.1109 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3245/12542 | Batch Loss: 1.2606 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3246/12542 | Batch Loss: 1.4225 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3247/12542 | Batch Loss: 2.9203 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3248/12542 | Batch Loss: 1.2963 | Learning Rate: 0.000580 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3249/12542 | Batch Loss: 1.1777 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3250/12542 | Batch Loss: 0.8256 | Learning Rate: 0.000580 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3251/12542 | Batch Loss: 2.0483 | Learning Rate: 0.000580 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3252/12542 | Batch Loss: 1.3487 | Learning Rate: 0.000580 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3253/12542 | Batch Loss: 1.9977 | Learning Rate: 0.000580 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3254/12542 | Batch Loss: 0.7863 | Learning Rate: 0.000580 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3255/12542 | Batch Loss: 2.2995 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3256/12542 | Batch Loss: 1.6016 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3257/12542 | Batch Loss: 1.8842 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3258/12542 | Batch Loss: 1.2040 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3259/12542 | Batch Loss: 2.2959 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3260/12542 | Batch Loss: 0.8903 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3261/12542 | Batch Loss: 0.6551 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3262/12542 | Batch Loss: 2.3669 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3263/12542 | Batch Loss: 1.1035 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3264/12542 | Batch Loss: 0.9976 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3265/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3266/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3267/12542 | Batch Loss: 1.7301 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3268/12542 | Batch Loss: 0.8074 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3269/12542 | Batch Loss: 0.8832 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3270/12542 | Batch Loss: 0.7849 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3271/12542 | Batch Loss: 0.5627 | Learning Rate: 0.000580 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3272/12542 | Batch Loss: 0.7680 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3273/12542 | Batch Loss: 0.8521 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3274/12542 | Batch Loss: 0.5891 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3275/12542 | Batch Loss: 2.3255 | Learning Rate: 0.000580 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3276/12542 | Batch Loss: 0.8570 | Learning Rate: 0.000580 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 3277/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3278/12542 | Batch Loss: 1.5201 | Learning Rate: 0.000580 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3279/12542 | Batch Loss: 1.6379 | Learning Rate: 0.000580 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3280/12542 | Batch Loss: 0.4613 | Learning Rate: 0.000579 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3281/12542 | Batch Loss: 1.1643 | Learning Rate: 0.000579 | Batch Time: 0.54s\n",
      "Epoch 2 | Step 3282/12542 | Batch Loss: 0.4828 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3283/12542 | Batch Loss: 1.5582 | Learning Rate: 0.000579 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3284/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3285/12542 | Batch Loss: 0.8129 | Learning Rate: 0.000579 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3286/12542 | Batch Loss: 1.8550 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3287/12542 | Batch Loss: 1.1414 | Learning Rate: 0.000579 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3288/12542 | Batch Loss: 2.1904 | Learning Rate: 0.000579 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 3289/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3290/12542 | Batch Loss: 1.0737 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3291/12542 | Batch Loss: 1.6570 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3292/12542 | Batch Loss: 2.0073 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3293/12542 | Batch Loss: 1.2765 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3294/12542 | Batch Loss: 1.1215 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3295/12542 | Batch Loss: 2.4236 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3296/12542 | Batch Loss: 1.5846 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3297/12542 | Batch Loss: 1.2094 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3298/12542 | Batch Loss: 1.2909 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3299/12542 | Batch Loss: 0.7962 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3300/12542 | Batch Loss: 0.9161 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3301/12542 | Batch Loss: 2.3156 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3302/12542 | Batch Loss: 1.0504 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3303/12542 | Batch Loss: 0.9158 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3304/12542 | Batch Loss: 1.7031 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3305/12542 | Batch Loss: 2.0525 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3306/12542 | Batch Loss: 1.1193 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3307/12542 | Batch Loss: 0.8352 | Learning Rate: 0.000579 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3308/12542 | Batch Loss: 1.1680 | Learning Rate: 0.000579 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3309/12542 | Batch Loss: 2.1222 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3310/12542 | Batch Loss: 1.4676 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3311/12542 | Batch Loss: 3.0960 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3312/12542 | Batch Loss: 3.6458 | Learning Rate: 0.000579 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3313/12542 | Batch Loss: 0.6513 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3314/12542 | Batch Loss: 0.9008 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3315/12542 | Batch Loss: 1.0799 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3316/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000579 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3317/12542 | Batch Loss: 1.6881 | Learning Rate: 0.000579 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3318/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000578 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3319/12542 | Batch Loss: 1.3711 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3320/12542 | Batch Loss: 0.7846 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3321/12542 | Batch Loss: 1.7317 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3322/12542 | Batch Loss: 2.2146 | Learning Rate: 0.000578 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3323/12542 | Batch Loss: 0.9956 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3324/12542 | Batch Loss: 2.0386 | Learning Rate: 0.000578 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3325/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000578 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3326/12542 | Batch Loss: 1.5027 | Learning Rate: 0.000578 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3327/12542 | Batch Loss: 0.7583 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3328/12542 | Batch Loss: 1.5366 | Learning Rate: 0.000578 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3329/12542 | Batch Loss: 1.2132 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3330/12542 | Batch Loss: 1.0618 | Learning Rate: 0.000578 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3331/12542 | Batch Loss: 1.5826 | Learning Rate: 0.000578 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3332/12542 | Batch Loss: 0.5785 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3333/12542 | Batch Loss: 1.2754 | Learning Rate: 0.000578 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3334/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000578 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3335/12542 | Batch Loss: 0.5487 | Learning Rate: 0.000578 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3336/12542 | Batch Loss: 1.6260 | Learning Rate: 0.000578 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3337/12542 | Batch Loss: 0.7424 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3338/12542 | Batch Loss: 1.6361 | Learning Rate: 0.000578 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3339/12542 | Batch Loss: 1.4750 | Learning Rate: 0.000578 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3340/12542 | Batch Loss: 0.5438 | Learning Rate: 0.000578 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3341/12542 | Batch Loss: 1.3863 | Learning Rate: 0.000578 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3342/12542 | Batch Loss: 2.0054 | Learning Rate: 0.000578 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3343/12542 | Batch Loss: 1.1390 | Learning Rate: 0.000578 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3344/12542 | Batch Loss: 1.5127 | Learning Rate: 0.000578 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3345/12542 | Batch Loss: 0.8591 | Learning Rate: 0.000578 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3346/12542 | Batch Loss: 1.3367 | Learning Rate: 0.000578 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3347/12542 | Batch Loss: 1.4167 | Learning Rate: 0.000578 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3348/12542 | Batch Loss: 1.5419 | Learning Rate: 0.000578 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3349/12542 | Batch Loss: 1.6530 | Learning Rate: 0.000578 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3350/12542 | Batch Loss: 1.0796 | Learning Rate: 0.000578 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3351/12542 | Batch Loss: 1.7161 | Learning Rate: 0.000578 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3352/12542 | Batch Loss: 2.1882 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3353/12542 | Batch Loss: 1.0268 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3354/12542 | Batch Loss: 1.5828 | Learning Rate: 0.000578 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3355/12542 | Batch Loss: 2.0309 | Learning Rate: 0.000577 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3356/12542 | Batch Loss: 0.7661 | Learning Rate: 0.000577 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3357/12542 | Batch Loss: 1.2648 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3358/12542 | Batch Loss: 1.4144 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3359/12542 | Batch Loss: 1.2922 | Learning Rate: 0.000577 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3360/12542 | Batch Loss: 1.5327 | Learning Rate: 0.000577 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3361/12542 | Batch Loss: 1.3732 | Learning Rate: 0.000577 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3362/12542 | Batch Loss: 0.9611 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3363/12542 | Batch Loss: 1.6313 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3364/12542 | Batch Loss: 0.6462 | Learning Rate: 0.000577 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3365/12542 | Batch Loss: 1.5462 | Learning Rate: 0.000577 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3366/12542 | Batch Loss: 0.6412 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3367/12542 | Batch Loss: 0.7595 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3368/12542 | Batch Loss: 1.1654 | Learning Rate: 0.000577 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3369/12542 | Batch Loss: 1.4139 | Learning Rate: 0.000577 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3370/12542 | Batch Loss: 1.8314 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3371/12542 | Batch Loss: 4.4275 | Learning Rate: 0.000577 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3372/12542 | Batch Loss: 1.7265 | Learning Rate: 0.000577 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3373/12542 | Batch Loss: 2.8582 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3374/12542 | Batch Loss: 1.8840 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3375/12542 | Batch Loss: 1.9269 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3376/12542 | Batch Loss: 3.2654 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3377/12542 | Batch Loss: 1.3612 | Learning Rate: 0.000577 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3378/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3379/12542 | Batch Loss: 1.9444 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3380/12542 | Batch Loss: 2.0186 | Learning Rate: 0.000577 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3381/12542 | Batch Loss: 1.7376 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3382/12542 | Batch Loss: 1.2053 | Learning Rate: 0.000577 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3383/12542 | Batch Loss: 1.1171 | Learning Rate: 0.000577 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3384/12542 | Batch Loss: 1.2154 | Learning Rate: 0.000577 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3385/12542 | Batch Loss: 1.1924 | Learning Rate: 0.000577 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3386/12542 | Batch Loss: 1.5202 | Learning Rate: 0.000577 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3387/12542 | Batch Loss: 2.4351 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3388/12542 | Batch Loss: 1.7611 | Learning Rate: 0.000577 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3389/12542 | Batch Loss: 0.9473 | Learning Rate: 0.000577 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3390/12542 | Batch Loss: 2.5445 | Learning Rate: 0.000577 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3391/12542 | Batch Loss: 1.0352 | Learning Rate: 0.000577 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3392/12542 | Batch Loss: 1.3736 | Learning Rate: 0.000577 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3393/12542 | Batch Loss: 1.5244 | Learning Rate: 0.000576 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3394/12542 | Batch Loss: 1.7148 | Learning Rate: 0.000576 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3395/12542 | Batch Loss: 2.1415 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3396/12542 | Batch Loss: 1.9376 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3397/12542 | Batch Loss: 2.4374 | Learning Rate: 0.000576 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3398/12542 | Batch Loss: 1.6599 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3399/12542 | Batch Loss: 0.9761 | Learning Rate: 0.000576 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3400/12542 | Batch Loss: 3.0687 | Learning Rate: 0.000576 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3401/12542 | Batch Loss: 1.1947 | Learning Rate: 0.000576 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3402/12542 | Batch Loss: 1.4333 | Learning Rate: 0.000576 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3403/12542 | Batch Loss: 1.4548 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3404/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000576 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3405/12542 | Batch Loss: 1.1001 | Learning Rate: 0.000576 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3406/12542 | Batch Loss: 2.0518 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3407/12542 | Batch Loss: 1.8300 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3408/12542 | Batch Loss: 1.3217 | Learning Rate: 0.000576 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3409/12542 | Batch Loss: 0.7303 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3410/12542 | Batch Loss: 2.0971 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3411/12542 | Batch Loss: 1.7067 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3412/12542 | Batch Loss: 1.1670 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3413/12542 | Batch Loss: 1.2024 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3414/12542 | Batch Loss: 1.6900 | Learning Rate: 0.000576 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3415/12542 | Batch Loss: 1.3739 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3416/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3417/12542 | Batch Loss: 1.7509 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3418/12542 | Batch Loss: 3.2844 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3419/12542 | Batch Loss: 0.6812 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3420/12542 | Batch Loss: 2.7258 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3421/12542 | Batch Loss: 1.1443 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3422/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000576 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3423/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000576 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3424/12542 | Batch Loss: 1.1336 | Learning Rate: 0.000576 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3425/12542 | Batch Loss: 0.9868 | Learning Rate: 0.000576 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3426/12542 | Batch Loss: 0.7869 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3427/12542 | Batch Loss: 1.7667 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3428/12542 | Batch Loss: 2.7333 | Learning Rate: 0.000576 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3429/12542 | Batch Loss: 1.9249 | Learning Rate: 0.000576 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3430/12542 | Batch Loss: 0.6751 | Learning Rate: 0.000576 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3431/12542 | Batch Loss: 1.2963 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3432/12542 | Batch Loss: 1.7090 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3433/12542 | Batch Loss: 0.9701 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3434/12542 | Batch Loss: 1.4347 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3435/12542 | Batch Loss: 0.7249 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3436/12542 | Batch Loss: 2.1994 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3437/12542 | Batch Loss: 0.4014 | Learning Rate: 0.000575 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3438/12542 | Batch Loss: 2.0370 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3439/12542 | Batch Loss: 0.8159 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3440/12542 | Batch Loss: 1.0799 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3441/12542 | Batch Loss: 1.0181 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3442/12542 | Batch Loss: 0.5644 | Learning Rate: 0.000575 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3443/12542 | Batch Loss: 1.0496 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3444/12542 | Batch Loss: 1.1470 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3445/12542 | Batch Loss: 1.1513 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3446/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3447/12542 | Batch Loss: 1.6385 | Learning Rate: 0.000575 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3448/12542 | Batch Loss: 1.6380 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3449/12542 | Batch Loss: 0.9673 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3450/12542 | Batch Loss: 0.4697 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3451/12542 | Batch Loss: 1.2803 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3452/12542 | Batch Loss: 1.7066 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3453/12542 | Batch Loss: 1.7087 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3454/12542 | Batch Loss: 0.6410 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3455/12542 | Batch Loss: 0.8267 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3456/12542 | Batch Loss: 1.4569 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3457/12542 | Batch Loss: 0.7169 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3458/12542 | Batch Loss: 0.6828 | Learning Rate: 0.000575 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3459/12542 | Batch Loss: 0.2953 | Learning Rate: 0.000575 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3460/12542 | Batch Loss: 2.4204 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3461/12542 | Batch Loss: 1.1241 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3462/12542 | Batch Loss: 1.4158 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3463/12542 | Batch Loss: 0.9774 | Learning Rate: 0.000575 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3464/12542 | Batch Loss: 0.8141 | Learning Rate: 0.000575 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3465/12542 | Batch Loss: 1.2240 | Learning Rate: 0.000575 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3466/12542 | Batch Loss: 2.2768 | Learning Rate: 0.000575 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3467/12542 | Batch Loss: 0.8707 | Learning Rate: 0.000575 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3468/12542 | Batch Loss: 0.6870 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3469/12542 | Batch Loss: 2.6907 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3470/12542 | Batch Loss: 1.1533 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3471/12542 | Batch Loss: 1.8013 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3472/12542 | Batch Loss: 0.6895 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3473/12542 | Batch Loss: 1.5445 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3474/12542 | Batch Loss: 0.6608 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3475/12542 | Batch Loss: 1.5055 | Learning Rate: 0.000574 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3476/12542 | Batch Loss: 0.6919 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3477/12542 | Batch Loss: 1.0813 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3478/12542 | Batch Loss: 0.6423 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3479/12542 | Batch Loss: 1.7577 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3480/12542 | Batch Loss: 1.6870 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3481/12542 | Batch Loss: 0.7269 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3482/12542 | Batch Loss: 0.8238 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3483/12542 | Batch Loss: 1.0058 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3484/12542 | Batch Loss: 1.1908 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3485/12542 | Batch Loss: 2.0875 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3486/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3487/12542 | Batch Loss: 1.6155 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3488/12542 | Batch Loss: 1.2251 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3489/12542 | Batch Loss: 2.4128 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3490/12542 | Batch Loss: 0.4587 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3491/12542 | Batch Loss: 1.0975 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3492/12542 | Batch Loss: 0.9489 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3493/12542 | Batch Loss: 1.7335 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3494/12542 | Batch Loss: 0.6289 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3495/12542 | Batch Loss: 0.5332 | Learning Rate: 0.000574 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3496/12542 | Batch Loss: 1.1780 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3497/12542 | Batch Loss: 1.4662 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3498/12542 | Batch Loss: 2.6109 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3499/12542 | Batch Loss: 1.3544 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3500/12542 | Batch Loss: 0.6059 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3501/12542 | Batch Loss: 0.9916 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3502/12542 | Batch Loss: 1.6406 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3503/12542 | Batch Loss: 1.2594 | Learning Rate: 0.000574 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3504/12542 | Batch Loss: 1.1752 | Learning Rate: 0.000574 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3505/12542 | Batch Loss: 0.7283 | Learning Rate: 0.000574 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3506/12542 | Batch Loss: 2.2113 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3507/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3508/12542 | Batch Loss: 1.3438 | Learning Rate: 0.000573 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3509/12542 | Batch Loss: 0.5373 | Learning Rate: 0.000573 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3510/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000573 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3511/12542 | Batch Loss: 1.1292 | Learning Rate: 0.000573 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3512/12542 | Batch Loss: 1.6496 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3513/12542 | Batch Loss: 1.4550 | Learning Rate: 0.000573 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3514/12542 | Batch Loss: 0.4708 | Learning Rate: 0.000573 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3515/12542 | Batch Loss: 1.7565 | Learning Rate: 0.000573 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3516/12542 | Batch Loss: 1.8765 | Learning Rate: 0.000573 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3517/12542 | Batch Loss: 0.9963 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3518/12542 | Batch Loss: 1.5820 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3519/12542 | Batch Loss: 1.5129 | Learning Rate: 0.000573 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3520/12542 | Batch Loss: 1.5618 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3521/12542 | Batch Loss: 1.6318 | Learning Rate: 0.000573 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3522/12542 | Batch Loss: 1.1488 | Learning Rate: 0.000573 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3523/12542 | Batch Loss: 2.7640 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3524/12542 | Batch Loss: 1.7014 | Learning Rate: 0.000573 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3525/12542 | Batch Loss: 2.2342 | Learning Rate: 0.000573 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3526/12542 | Batch Loss: 1.4495 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3527/12542 | Batch Loss: 1.5133 | Learning Rate: 0.000573 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3528/12542 | Batch Loss: 1.3800 | Learning Rate: 0.000573 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3529/12542 | Batch Loss: 1.5206 | Learning Rate: 0.000573 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3530/12542 | Batch Loss: 1.8922 | Learning Rate: 0.000573 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3531/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000573 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3532/12542 | Batch Loss: 0.6963 | Learning Rate: 0.000573 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3533/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000573 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3534/12542 | Batch Loss: 1.4029 | Learning Rate: 0.000573 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3535/12542 | Batch Loss: 1.1275 | Learning Rate: 0.000573 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3536/12542 | Batch Loss: 0.8873 | Learning Rate: 0.000573 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3537/12542 | Batch Loss: 1.0237 | Learning Rate: 0.000573 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3538/12542 | Batch Loss: 1.0891 | Learning Rate: 0.000573 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3539/12542 | Batch Loss: 1.3245 | Learning Rate: 0.000573 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3540/12542 | Batch Loss: 0.8105 | Learning Rate: 0.000573 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3541/12542 | Batch Loss: 1.4830 | Learning Rate: 0.000573 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3542/12542 | Batch Loss: 1.4616 | Learning Rate: 0.000573 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3543/12542 | Batch Loss: 1.3198 | Learning Rate: 0.000573 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3544/12542 | Batch Loss: 0.6115 | Learning Rate: 0.000572 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3545/12542 | Batch Loss: 0.8724 | Learning Rate: 0.000572 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3546/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000572 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3547/12542 | Batch Loss: 1.3579 | Learning Rate: 0.000572 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3548/12542 | Batch Loss: 0.5167 | Learning Rate: 0.000572 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 3549/12542 | Batch Loss: 1.3471 | Learning Rate: 0.000572 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 3550/12542 | Batch Loss: 1.6046 | Learning Rate: 0.000572 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3551/12542 | Batch Loss: 1.5066 | Learning Rate: 0.000572 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3552/12542 | Batch Loss: 0.8884 | Learning Rate: 0.000572 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3553/12542 | Batch Loss: 1.3605 | Learning Rate: 0.000572 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3554/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000572 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3555/12542 | Batch Loss: 1.1578 | Learning Rate: 0.000572 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3556/12542 | Batch Loss: 3.0185 | Learning Rate: 0.000572 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3557/12542 | Batch Loss: 1.3983 | Learning Rate: 0.000572 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3558/12542 | Batch Loss: 1.4478 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3559/12542 | Batch Loss: 1.1437 | Learning Rate: 0.000572 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3560/12542 | Batch Loss: 2.4594 | Learning Rate: 0.000572 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3561/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000572 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3562/12542 | Batch Loss: 2.3899 | Learning Rate: 0.000572 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3563/12542 | Batch Loss: 1.7787 | Learning Rate: 0.000572 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3564/12542 | Batch Loss: 1.2934 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3565/12542 | Batch Loss: 1.3536 | Learning Rate: 0.000572 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3566/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000572 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3567/12542 | Batch Loss: 1.4658 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3568/12542 | Batch Loss: 1.1235 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3569/12542 | Batch Loss: 1.6506 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3570/12542 | Batch Loss: 2.2656 | Learning Rate: 0.000572 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3571/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000572 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3572/12542 | Batch Loss: 1.4732 | Learning Rate: 0.000572 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3573/12542 | Batch Loss: 1.2173 | Learning Rate: 0.000572 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3574/12542 | Batch Loss: 1.9965 | Learning Rate: 0.000572 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3575/12542 | Batch Loss: 0.7543 | Learning Rate: 0.000572 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3576/12542 | Batch Loss: 0.9769 | Learning Rate: 0.000572 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3577/12542 | Batch Loss: 1.7319 | Learning Rate: 0.000572 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3578/12542 | Batch Loss: 2.6596 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3579/12542 | Batch Loss: 2.5970 | Learning Rate: 0.000572 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3580/12542 | Batch Loss: 0.8132 | Learning Rate: 0.000572 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3581/12542 | Batch Loss: 1.3115 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3582/12542 | Batch Loss: 1.1246 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3583/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3584/12542 | Batch Loss: 1.0949 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3585/12542 | Batch Loss: 2.1938 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3586/12542 | Batch Loss: 1.1209 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3587/12542 | Batch Loss: 0.7746 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3588/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3589/12542 | Batch Loss: 1.1144 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3590/12542 | Batch Loss: 1.3243 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3591/12542 | Batch Loss: 1.2754 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3592/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000571 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3593/12542 | Batch Loss: 0.6578 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3594/12542 | Batch Loss: 0.8729 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3595/12542 | Batch Loss: 2.2873 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3596/12542 | Batch Loss: 1.5676 | Learning Rate: 0.000571 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3597/12542 | Batch Loss: 0.7334 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3598/12542 | Batch Loss: 1.1053 | Learning Rate: 0.000571 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3599/12542 | Batch Loss: 0.6373 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3600/12542 | Batch Loss: 1.4317 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3601/12542 | Batch Loss: 0.7510 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3602/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3603/12542 | Batch Loss: 2.2639 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3604/12542 | Batch Loss: 2.0448 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3605/12542 | Batch Loss: 2.0520 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3606/12542 | Batch Loss: 0.9089 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3607/12542 | Batch Loss: 0.9867 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3608/12542 | Batch Loss: 2.5042 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3609/12542 | Batch Loss: 1.1465 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3610/12542 | Batch Loss: 1.0191 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3611/12542 | Batch Loss: 1.0529 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3612/12542 | Batch Loss: 3.1300 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3613/12542 | Batch Loss: 0.9431 | Learning Rate: 0.000571 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3614/12542 | Batch Loss: 0.4420 | Learning Rate: 0.000571 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3615/12542 | Batch Loss: 0.6744 | Learning Rate: 0.000571 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3616/12542 | Batch Loss: 1.7323 | Learning Rate: 0.000571 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3617/12542 | Batch Loss: 0.9783 | Learning Rate: 0.000571 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3618/12542 | Batch Loss: 1.4240 | Learning Rate: 0.000571 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 3619/12542 | Batch Loss: 1.1562 | Learning Rate: 0.000570 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3620/12542 | Batch Loss: 1.1729 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3621/12542 | Batch Loss: 1.0585 | Learning Rate: 0.000570 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3622/12542 | Batch Loss: 0.6748 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3623/12542 | Batch Loss: 1.1852 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3624/12542 | Batch Loss: 0.7726 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3625/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000570 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3626/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3627/12542 | Batch Loss: 1.5519 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3628/12542 | Batch Loss: 1.0192 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3629/12542 | Batch Loss: 1.3733 | Learning Rate: 0.000570 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3630/12542 | Batch Loss: 1.2708 | Learning Rate: 0.000570 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3631/12542 | Batch Loss: 1.2974 | Learning Rate: 0.000570 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3632/12542 | Batch Loss: 0.9901 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3633/12542 | Batch Loss: 1.4041 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3634/12542 | Batch Loss: 3.7135 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3635/12542 | Batch Loss: 1.5570 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3636/12542 | Batch Loss: 2.0660 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3637/12542 | Batch Loss: 1.6725 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3638/12542 | Batch Loss: 2.6668 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3639/12542 | Batch Loss: 1.7423 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3640/12542 | Batch Loss: 1.2584 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3641/12542 | Batch Loss: 0.7730 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3642/12542 | Batch Loss: 1.4907 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3643/12542 | Batch Loss: 2.1364 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3644/12542 | Batch Loss: 0.9889 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3645/12542 | Batch Loss: 1.0011 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3646/12542 | Batch Loss: 0.9857 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3647/12542 | Batch Loss: 0.3615 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3648/12542 | Batch Loss: 0.8703 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3649/12542 | Batch Loss: 1.4215 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3650/12542 | Batch Loss: 1.7163 | Learning Rate: 0.000570 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3651/12542 | Batch Loss: 1.3435 | Learning Rate: 0.000570 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3652/12542 | Batch Loss: 0.9812 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3653/12542 | Batch Loss: 0.4907 | Learning Rate: 0.000570 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3654/12542 | Batch Loss: 0.5796 | Learning Rate: 0.000570 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3655/12542 | Batch Loss: 2.5576 | Learning Rate: 0.000570 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3656/12542 | Batch Loss: 1.5674 | Learning Rate: 0.000569 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3657/12542 | Batch Loss: 1.1957 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3658/12542 | Batch Loss: 1.7448 | Learning Rate: 0.000569 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3659/12542 | Batch Loss: 0.9890 | Learning Rate: 0.000569 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3660/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000569 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3661/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000569 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3662/12542 | Batch Loss: 1.4713 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3663/12542 | Batch Loss: 0.8911 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3664/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000569 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3665/12542 | Batch Loss: 0.8864 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3666/12542 | Batch Loss: 2.1752 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3667/12542 | Batch Loss: 2.6389 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3668/12542 | Batch Loss: 1.4433 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3669/12542 | Batch Loss: 0.9866 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3670/12542 | Batch Loss: 2.0001 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3671/12542 | Batch Loss: 0.7884 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3672/12542 | Batch Loss: 1.1007 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3673/12542 | Batch Loss: 2.0141 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3674/12542 | Batch Loss: 1.0225 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3675/12542 | Batch Loss: 1.2974 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3676/12542 | Batch Loss: 1.4584 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3677/12542 | Batch Loss: 0.8073 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3678/12542 | Batch Loss: 1.1178 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3679/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3680/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000569 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3681/12542 | Batch Loss: 1.2594 | Learning Rate: 0.000569 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3682/12542 | Batch Loss: 2.0804 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3683/12542 | Batch Loss: 1.1518 | Learning Rate: 0.000569 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3684/12542 | Batch Loss: 1.8810 | Learning Rate: 0.000569 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3685/12542 | Batch Loss: 1.2799 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3686/12542 | Batch Loss: 1.0441 | Learning Rate: 0.000569 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3687/12542 | Batch Loss: 1.5919 | Learning Rate: 0.000569 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3688/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000569 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3689/12542 | Batch Loss: 1.6143 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3690/12542 | Batch Loss: 1.6211 | Learning Rate: 0.000569 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3691/12542 | Batch Loss: 0.8080 | Learning Rate: 0.000569 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3692/12542 | Batch Loss: 2.1067 | Learning Rate: 0.000569 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3693/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000569 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3694/12542 | Batch Loss: 2.5969 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3695/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000568 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3696/12542 | Batch Loss: 1.6078 | Learning Rate: 0.000568 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3697/12542 | Batch Loss: 1.3996 | Learning Rate: 0.000568 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3698/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000568 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3699/12542 | Batch Loss: 0.9374 | Learning Rate: 0.000568 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3700/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3701/12542 | Batch Loss: 0.6932 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3702/12542 | Batch Loss: 0.6688 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3703/12542 | Batch Loss: 2.1180 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3704/12542 | Batch Loss: 1.0912 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3705/12542 | Batch Loss: 1.5414 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3706/12542 | Batch Loss: 0.5323 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3707/12542 | Batch Loss: 1.3004 | Learning Rate: 0.000568 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3708/12542 | Batch Loss: 1.0592 | Learning Rate: 0.000568 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3709/12542 | Batch Loss: 1.9401 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3710/12542 | Batch Loss: 0.6480 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3711/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3712/12542 | Batch Loss: 0.8572 | Learning Rate: 0.000568 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3713/12542 | Batch Loss: 1.5289 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3714/12542 | Batch Loss: 1.9853 | Learning Rate: 0.000568 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3715/12542 | Batch Loss: 0.8145 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3716/12542 | Batch Loss: 3.0455 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3717/12542 | Batch Loss: 0.8822 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3718/12542 | Batch Loss: 0.8698 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3719/12542 | Batch Loss: 1.2613 | Learning Rate: 0.000568 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3720/12542 | Batch Loss: 2.6422 | Learning Rate: 0.000568 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3721/12542 | Batch Loss: 0.8425 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3722/12542 | Batch Loss: 2.2890 | Learning Rate: 0.000568 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3723/12542 | Batch Loss: 1.4842 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3724/12542 | Batch Loss: 1.1838 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3725/12542 | Batch Loss: 1.8790 | Learning Rate: 0.000568 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3726/12542 | Batch Loss: 0.9771 | Learning Rate: 0.000568 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3727/12542 | Batch Loss: 0.5263 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3728/12542 | Batch Loss: 1.5373 | Learning Rate: 0.000568 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3729/12542 | Batch Loss: 1.2021 | Learning Rate: 0.000568 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3730/12542 | Batch Loss: 1.1305 | Learning Rate: 0.000568 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3731/12542 | Batch Loss: 1.3701 | Learning Rate: 0.000568 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3732/12542 | Batch Loss: 1.1012 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3733/12542 | Batch Loss: 0.6441 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3734/12542 | Batch Loss: 1.9330 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3735/12542 | Batch Loss: 1.4656 | Learning Rate: 0.000567 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3736/12542 | Batch Loss: 3.4739 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3737/12542 | Batch Loss: 1.0731 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3738/12542 | Batch Loss: 0.8690 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3739/12542 | Batch Loss: 0.8593 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3740/12542 | Batch Loss: 0.8012 | Learning Rate: 0.000567 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 3741/12542 | Batch Loss: 0.7014 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3742/12542 | Batch Loss: 1.4748 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3743/12542 | Batch Loss: 3.1867 | Learning Rate: 0.000567 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3744/12542 | Batch Loss: 1.5480 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3745/12542 | Batch Loss: 2.0813 | Learning Rate: 0.000567 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3746/12542 | Batch Loss: 0.7972 | Learning Rate: 0.000567 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3747/12542 | Batch Loss: 0.9140 | Learning Rate: 0.000567 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3748/12542 | Batch Loss: 0.9437 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3749/12542 | Batch Loss: 1.5295 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3750/12542 | Batch Loss: 1.4856 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3751/12542 | Batch Loss: 0.6655 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3752/12542 | Batch Loss: 0.9953 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3753/12542 | Batch Loss: 1.1448 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3754/12542 | Batch Loss: 1.6541 | Learning Rate: 0.000567 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3755/12542 | Batch Loss: 2.3257 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3756/12542 | Batch Loss: 2.1023 | Learning Rate: 0.000567 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3757/12542 | Batch Loss: 0.8449 | Learning Rate: 0.000567 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3758/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000567 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3759/12542 | Batch Loss: 1.1456 | Learning Rate: 0.000567 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3760/12542 | Batch Loss: 1.0381 | Learning Rate: 0.000567 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3761/12542 | Batch Loss: 0.5738 | Learning Rate: 0.000567 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3762/12542 | Batch Loss: 1.2965 | Learning Rate: 0.000567 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3763/12542 | Batch Loss: 1.5482 | Learning Rate: 0.000567 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3764/12542 | Batch Loss: 2.2280 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3765/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3766/12542 | Batch Loss: 1.1872 | Learning Rate: 0.000567 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3767/12542 | Batch Loss: 1.9959 | Learning Rate: 0.000567 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3768/12542 | Batch Loss: 0.6367 | Learning Rate: 0.000567 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3769/12542 | Batch Loss: 0.5878 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3770/12542 | Batch Loss: 0.6141 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3771/12542 | Batch Loss: 1.4428 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3772/12542 | Batch Loss: 1.9267 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3773/12542 | Batch Loss: 1.8825 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3774/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3775/12542 | Batch Loss: 1.4247 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3776/12542 | Batch Loss: 2.0229 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3777/12542 | Batch Loss: 1.2243 | Learning Rate: 0.000566 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3778/12542 | Batch Loss: 1.8074 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3779/12542 | Batch Loss: 2.0094 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3780/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3781/12542 | Batch Loss: 4.2708 | Learning Rate: 0.000566 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3782/12542 | Batch Loss: 1.3743 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3783/12542 | Batch Loss: 1.0217 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3784/12542 | Batch Loss: 1.8262 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3785/12542 | Batch Loss: 1.1249 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3786/12542 | Batch Loss: 0.8314 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3787/12542 | Batch Loss: 1.4452 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3788/12542 | Batch Loss: 0.7675 | Learning Rate: 0.000566 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3789/12542 | Batch Loss: 0.7841 | Learning Rate: 0.000566 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3790/12542 | Batch Loss: 1.4357 | Learning Rate: 0.000566 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3791/12542 | Batch Loss: 1.6526 | Learning Rate: 0.000566 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3792/12542 | Batch Loss: 0.4860 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3793/12542 | Batch Loss: 0.8742 | Learning Rate: 0.000566 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3794/12542 | Batch Loss: 0.9556 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3795/12542 | Batch Loss: 0.7853 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3796/12542 | Batch Loss: 2.0832 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3797/12542 | Batch Loss: 1.4510 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3798/12542 | Batch Loss: 0.8097 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3799/12542 | Batch Loss: 0.7037 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3800/12542 | Batch Loss: 1.7887 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3801/12542 | Batch Loss: 0.6704 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3802/12542 | Batch Loss: 2.3810 | Learning Rate: 0.000566 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3803/12542 | Batch Loss: 3.8917 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3804/12542 | Batch Loss: 3.0373 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3805/12542 | Batch Loss: 1.7901 | Learning Rate: 0.000566 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3806/12542 | Batch Loss: 0.6188 | Learning Rate: 0.000566 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3807/12542 | Batch Loss: 0.9526 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3808/12542 | Batch Loss: 1.1152 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3809/12542 | Batch Loss: 3.3796 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3810/12542 | Batch Loss: 1.0282 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3811/12542 | Batch Loss: 2.7106 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3812/12542 | Batch Loss: 1.3220 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3813/12542 | Batch Loss: 1.3056 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3814/12542 | Batch Loss: 2.3535 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3815/12542 | Batch Loss: 0.9942 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3816/12542 | Batch Loss: 1.8639 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3817/12542 | Batch Loss: 1.6409 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3818/12542 | Batch Loss: 1.1146 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3819/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000565 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3820/12542 | Batch Loss: 1.1129 | Learning Rate: 0.000565 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3821/12542 | Batch Loss: 1.2092 | Learning Rate: 0.000565 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3822/12542 | Batch Loss: 0.7374 | Learning Rate: 0.000565 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3823/12542 | Batch Loss: 1.4133 | Learning Rate: 0.000565 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3824/12542 | Batch Loss: 1.7085 | Learning Rate: 0.000565 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3825/12542 | Batch Loss: 0.8920 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3826/12542 | Batch Loss: 1.9703 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3827/12542 | Batch Loss: 1.0753 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3828/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000565 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3829/12542 | Batch Loss: 1.0728 | Learning Rate: 0.000565 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3830/12542 | Batch Loss: 1.5957 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3831/12542 | Batch Loss: 1.5298 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3832/12542 | Batch Loss: 1.8158 | Learning Rate: 0.000565 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3833/12542 | Batch Loss: 2.0185 | Learning Rate: 0.000565 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3834/12542 | Batch Loss: 1.9681 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3835/12542 | Batch Loss: 0.5524 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3836/12542 | Batch Loss: 2.5169 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3837/12542 | Batch Loss: 2.8681 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3838/12542 | Batch Loss: 1.2530 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3839/12542 | Batch Loss: 0.6596 | Learning Rate: 0.000565 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3840/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3841/12542 | Batch Loss: 0.8236 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3842/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3843/12542 | Batch Loss: 0.7197 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3844/12542 | Batch Loss: 1.0612 | Learning Rate: 0.000565 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3845/12542 | Batch Loss: 1.1846 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3846/12542 | Batch Loss: 1.3420 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3847/12542 | Batch Loss: 1.5054 | Learning Rate: 0.000564 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3848/12542 | Batch Loss: 1.3154 | Learning Rate: 0.000564 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3849/12542 | Batch Loss: 1.5879 | Learning Rate: 0.000564 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3850/12542 | Batch Loss: 1.4590 | Learning Rate: 0.000564 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3851/12542 | Batch Loss: 1.2862 | Learning Rate: 0.000564 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3852/12542 | Batch Loss: 0.6422 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3853/12542 | Batch Loss: 0.3947 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3854/12542 | Batch Loss: 1.7834 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3855/12542 | Batch Loss: 0.7465 | Learning Rate: 0.000564 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3856/12542 | Batch Loss: 1.6671 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3857/12542 | Batch Loss: 1.4586 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3858/12542 | Batch Loss: 1.0881 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3859/12542 | Batch Loss: 1.8726 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3860/12542 | Batch Loss: 2.0841 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3861/12542 | Batch Loss: 1.7595 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3862/12542 | Batch Loss: 1.9965 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3863/12542 | Batch Loss: 0.8577 | Learning Rate: 0.000564 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3864/12542 | Batch Loss: 1.5077 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3865/12542 | Batch Loss: 1.0391 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3866/12542 | Batch Loss: 2.1613 | Learning Rate: 0.000564 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3867/12542 | Batch Loss: 0.5972 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3868/12542 | Batch Loss: 2.0808 | Learning Rate: 0.000564 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3869/12542 | Batch Loss: 0.4477 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3870/12542 | Batch Loss: 1.8747 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3871/12542 | Batch Loss: 1.5332 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3872/12542 | Batch Loss: 1.4614 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3873/12542 | Batch Loss: 0.9318 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3874/12542 | Batch Loss: 0.7561 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3875/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3876/12542 | Batch Loss: 0.5868 | Learning Rate: 0.000564 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3877/12542 | Batch Loss: 0.5867 | Learning Rate: 0.000564 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3878/12542 | Batch Loss: 0.8950 | Learning Rate: 0.000564 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3879/12542 | Batch Loss: 0.8957 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3880/12542 | Batch Loss: 1.3857 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3881/12542 | Batch Loss: 1.9492 | Learning Rate: 0.000564 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3882/12542 | Batch Loss: 1.8553 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3883/12542 | Batch Loss: 1.2430 | Learning Rate: 0.000563 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3884/12542 | Batch Loss: 0.6351 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3885/12542 | Batch Loss: 0.3144 | Learning Rate: 0.000563 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3886/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3887/12542 | Batch Loss: 2.3229 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3888/12542 | Batch Loss: 0.7592 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3889/12542 | Batch Loss: 1.2624 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3890/12542 | Batch Loss: 1.3267 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3891/12542 | Batch Loss: 1.2420 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3892/12542 | Batch Loss: 1.8561 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3893/12542 | Batch Loss: 1.6855 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3894/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3895/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3896/12542 | Batch Loss: 0.6526 | Learning Rate: 0.000563 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3897/12542 | Batch Loss: 2.5762 | Learning Rate: 0.000563 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3898/12542 | Batch Loss: 1.0020 | Learning Rate: 0.000563 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3899/12542 | Batch Loss: 0.4407 | Learning Rate: 0.000563 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3900/12542 | Batch Loss: 0.8089 | Learning Rate: 0.000563 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3901/12542 | Batch Loss: 1.4173 | Learning Rate: 0.000563 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3902/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3903/12542 | Batch Loss: 0.4818 | Learning Rate: 0.000563 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3904/12542 | Batch Loss: 2.6459 | Learning Rate: 0.000563 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3905/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000563 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3906/12542 | Batch Loss: 1.2440 | Learning Rate: 0.000563 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3907/12542 | Batch Loss: 0.6954 | Learning Rate: 0.000563 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3908/12542 | Batch Loss: 0.6387 | Learning Rate: 0.000563 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3909/12542 | Batch Loss: 2.1889 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3910/12542 | Batch Loss: 1.6075 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3911/12542 | Batch Loss: 1.7721 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3912/12542 | Batch Loss: 1.2577 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3913/12542 | Batch Loss: 1.5751 | Learning Rate: 0.000563 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3914/12542 | Batch Loss: 0.9390 | Learning Rate: 0.000563 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3915/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000563 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3916/12542 | Batch Loss: 2.6348 | Learning Rate: 0.000563 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3917/12542 | Batch Loss: 1.2296 | Learning Rate: 0.000563 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3918/12542 | Batch Loss: 2.3088 | Learning Rate: 0.000563 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3919/12542 | Batch Loss: 2.1221 | Learning Rate: 0.000563 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3920/12542 | Batch Loss: 1.3776 | Learning Rate: 0.000562 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3921/12542 | Batch Loss: 1.6244 | Learning Rate: 0.000562 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3922/12542 | Batch Loss: 2.0952 | Learning Rate: 0.000562 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3923/12542 | Batch Loss: 1.4464 | Learning Rate: 0.000562 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 3924/12542 | Batch Loss: 2.4623 | Learning Rate: 0.000562 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 3925/12542 | Batch Loss: 2.1873 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3926/12542 | Batch Loss: 0.9512 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3927/12542 | Batch Loss: 1.7131 | Learning Rate: 0.000562 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 3928/12542 | Batch Loss: 0.9894 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3929/12542 | Batch Loss: 1.0918 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3930/12542 | Batch Loss: 1.9173 | Learning Rate: 0.000562 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3931/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000562 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3932/12542 | Batch Loss: 0.9056 | Learning Rate: 0.000562 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3933/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3934/12542 | Batch Loss: 1.4199 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3935/12542 | Batch Loss: 1.6924 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3936/12542 | Batch Loss: 1.2541 | Learning Rate: 0.000562 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3937/12542 | Batch Loss: 0.5109 | Learning Rate: 0.000562 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3938/12542 | Batch Loss: 0.8072 | Learning Rate: 0.000562 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3939/12542 | Batch Loss: 0.8190 | Learning Rate: 0.000562 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3940/12542 | Batch Loss: 1.3737 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3941/12542 | Batch Loss: 0.9086 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3942/12542 | Batch Loss: 1.0079 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3943/12542 | Batch Loss: 1.3710 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3944/12542 | Batch Loss: 1.4423 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3945/12542 | Batch Loss: 1.1020 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3946/12542 | Batch Loss: 0.7685 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3947/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000562 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3948/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3949/12542 | Batch Loss: 1.5188 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3950/12542 | Batch Loss: 0.8804 | Learning Rate: 0.000562 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3951/12542 | Batch Loss: 0.8202 | Learning Rate: 0.000562 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3952/12542 | Batch Loss: 1.9309 | Learning Rate: 0.000562 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 3953/12542 | Batch Loss: 0.6668 | Learning Rate: 0.000562 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 3954/12542 | Batch Loss: 1.5707 | Learning Rate: 0.000562 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 3955/12542 | Batch Loss: 2.3124 | Learning Rate: 0.000562 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3956/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000562 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3957/12542 | Batch Loss: 1.7120 | Learning Rate: 0.000562 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3958/12542 | Batch Loss: 1.6543 | Learning Rate: 0.000561 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 3959/12542 | Batch Loss: 1.0858 | Learning Rate: 0.000561 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3960/12542 | Batch Loss: 1.8317 | Learning Rate: 0.000561 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3961/12542 | Batch Loss: 1.5913 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3962/12542 | Batch Loss: 2.0720 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3963/12542 | Batch Loss: 1.3656 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3964/12542 | Batch Loss: 1.7572 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3965/12542 | Batch Loss: 0.9175 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3966/12542 | Batch Loss: 2.5735 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3967/12542 | Batch Loss: 1.6228 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3968/12542 | Batch Loss: 1.7506 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3969/12542 | Batch Loss: 2.1241 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3970/12542 | Batch Loss: 2.1312 | Learning Rate: 0.000561 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 3971/12542 | Batch Loss: 1.6573 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3972/12542 | Batch Loss: 1.3308 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3973/12542 | Batch Loss: 0.8790 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3974/12542 | Batch Loss: 1.4892 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3975/12542 | Batch Loss: 1.8635 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3976/12542 | Batch Loss: 2.6592 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3977/12542 | Batch Loss: 1.3921 | Learning Rate: 0.000561 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 3978/12542 | Batch Loss: 1.0632 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3979/12542 | Batch Loss: 1.9661 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3980/12542 | Batch Loss: 1.1585 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3981/12542 | Batch Loss: 1.6680 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3982/12542 | Batch Loss: 1.7216 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3983/12542 | Batch Loss: 0.9525 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3984/12542 | Batch Loss: 1.0503 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3985/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3986/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000561 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3987/12542 | Batch Loss: 1.3134 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3988/12542 | Batch Loss: 1.2606 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3989/12542 | Batch Loss: 1.9436 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3990/12542 | Batch Loss: 0.7062 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3991/12542 | Batch Loss: 0.8583 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3992/12542 | Batch Loss: 3.0828 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3993/12542 | Batch Loss: 1.7845 | Learning Rate: 0.000561 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3994/12542 | Batch Loss: 0.8866 | Learning Rate: 0.000561 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 3995/12542 | Batch Loss: 1.3095 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3996/12542 | Batch Loss: 1.0344 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 3997/12542 | Batch Loss: 2.1451 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3998/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 3999/12542 | Batch Loss: 0.5584 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4000/12542 | Batch Loss: 1.3973 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4001/12542 | Batch Loss: 2.6558 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4002/12542 | Batch Loss: 1.4662 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4003/12542 | Batch Loss: 2.7301 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4004/12542 | Batch Loss: 1.0091 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4005/12542 | Batch Loss: 1.4571 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4006/12542 | Batch Loss: 0.6693 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4007/12542 | Batch Loss: 1.9076 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4008/12542 | Batch Loss: 0.9087 | Learning Rate: 0.000560 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4009/12542 | Batch Loss: 0.8117 | Learning Rate: 0.000560 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4010/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000560 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4011/12542 | Batch Loss: 0.6312 | Learning Rate: 0.000560 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4012/12542 | Batch Loss: 2.6109 | Learning Rate: 0.000560 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4013/12542 | Batch Loss: 1.3207 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4014/12542 | Batch Loss: 1.2824 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4015/12542 | Batch Loss: 0.9513 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4016/12542 | Batch Loss: 1.4322 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4017/12542 | Batch Loss: 1.5064 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4018/12542 | Batch Loss: 1.9138 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4019/12542 | Batch Loss: 0.7111 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4020/12542 | Batch Loss: 1.8704 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4021/12542 | Batch Loss: 0.5099 | Learning Rate: 0.000560 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4022/12542 | Batch Loss: 0.6555 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4023/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4024/12542 | Batch Loss: 0.3555 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4025/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4026/12542 | Batch Loss: 2.1259 | Learning Rate: 0.000560 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4027/12542 | Batch Loss: 1.6352 | Learning Rate: 0.000560 | Batch Time: 0.55s\n",
      "Epoch 2 | Step 4028/12542 | Batch Loss: 1.5962 | Learning Rate: 0.000560 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4029/12542 | Batch Loss: 2.0908 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4030/12542 | Batch Loss: 1.3643 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4031/12542 | Batch Loss: 0.7365 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4032/12542 | Batch Loss: 1.6430 | Learning Rate: 0.000560 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4033/12542 | Batch Loss: 0.6111 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4034/12542 | Batch Loss: 1.5869 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4035/12542 | Batch Loss: 0.7752 | Learning Rate: 0.000559 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4036/12542 | Batch Loss: 1.5049 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4037/12542 | Batch Loss: 1.7459 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4038/12542 | Batch Loss: 1.3410 | Learning Rate: 0.000559 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4039/12542 | Batch Loss: 1.1548 | Learning Rate: 0.000559 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4040/12542 | Batch Loss: 3.0723 | Learning Rate: 0.000559 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4041/12542 | Batch Loss: 1.2518 | Learning Rate: 0.000559 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4042/12542 | Batch Loss: 1.3997 | Learning Rate: 0.000559 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4043/12542 | Batch Loss: 1.4177 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4044/12542 | Batch Loss: 0.7391 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4045/12542 | Batch Loss: 0.6552 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4046/12542 | Batch Loss: 0.8686 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4047/12542 | Batch Loss: 0.7646 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4048/12542 | Batch Loss: 1.0254 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4049/12542 | Batch Loss: 0.4640 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4050/12542 | Batch Loss: 0.5737 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4051/12542 | Batch Loss: 1.5878 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4052/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4053/12542 | Batch Loss: 0.5713 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4054/12542 | Batch Loss: 2.2086 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4055/12542 | Batch Loss: 1.0655 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4056/12542 | Batch Loss: 1.1653 | Learning Rate: 0.000559 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4057/12542 | Batch Loss: 0.8285 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4058/12542 | Batch Loss: 0.2842 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4059/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4060/12542 | Batch Loss: 1.0993 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4061/12542 | Batch Loss: 0.8552 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4062/12542 | Batch Loss: 0.9450 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4063/12542 | Batch Loss: 0.5134 | Learning Rate: 0.000559 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4064/12542 | Batch Loss: 0.5180 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4065/12542 | Batch Loss: 0.8363 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4066/12542 | Batch Loss: 0.7625 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4067/12542 | Batch Loss: 0.4142 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4068/12542 | Batch Loss: 0.9478 | Learning Rate: 0.000559 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4069/12542 | Batch Loss: 0.8283 | Learning Rate: 0.000559 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4070/12542 | Batch Loss: 0.8340 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4071/12542 | Batch Loss: 0.5761 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4072/12542 | Batch Loss: 0.9715 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4073/12542 | Batch Loss: 2.7607 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4074/12542 | Batch Loss: 3.7550 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4075/12542 | Batch Loss: 1.0442 | Learning Rate: 0.000558 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4076/12542 | Batch Loss: 1.3581 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4077/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000558 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4078/12542 | Batch Loss: 2.0286 | Learning Rate: 0.000558 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4079/12542 | Batch Loss: 1.8244 | Learning Rate: 0.000558 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4080/12542 | Batch Loss: 0.9795 | Learning Rate: 0.000558 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4081/12542 | Batch Loss: 2.3784 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4082/12542 | Batch Loss: 1.2833 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4083/12542 | Batch Loss: 1.1720 | Learning Rate: 0.000558 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4084/12542 | Batch Loss: 1.5414 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4085/12542 | Batch Loss: 1.1853 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4086/12542 | Batch Loss: 1.0656 | Learning Rate: 0.000558 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4087/12542 | Batch Loss: 2.2641 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4088/12542 | Batch Loss: 1.2789 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4089/12542 | Batch Loss: 0.6787 | Learning Rate: 0.000558 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4090/12542 | Batch Loss: 1.2247 | Learning Rate: 0.000558 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4091/12542 | Batch Loss: 0.5607 | Learning Rate: 0.000558 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4092/12542 | Batch Loss: 0.9822 | Learning Rate: 0.000558 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4093/12542 | Batch Loss: 1.2891 | Learning Rate: 0.000558 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4094/12542 | Batch Loss: 2.1208 | Learning Rate: 0.000558 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4095/12542 | Batch Loss: 0.8319 | Learning Rate: 0.000558 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4096/12542 | Batch Loss: 3.1807 | Learning Rate: 0.000558 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4097/12542 | Batch Loss: 1.0176 | Learning Rate: 0.000558 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4098/12542 | Batch Loss: 1.6585 | Learning Rate: 0.000558 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4099/12542 | Batch Loss: 1.7095 | Learning Rate: 0.000558 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4100/12542 | Batch Loss: 1.9572 | Learning Rate: 0.000558 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4101/12542 | Batch Loss: 1.0497 | Learning Rate: 0.000558 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4102/12542 | Batch Loss: 3.2653 | Learning Rate: 0.000558 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4103/12542 | Batch Loss: 1.3328 | Learning Rate: 0.000558 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4104/12542 | Batch Loss: 1.0148 | Learning Rate: 0.000558 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4105/12542 | Batch Loss: 1.2394 | Learning Rate: 0.000558 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4106/12542 | Batch Loss: 2.6823 | Learning Rate: 0.000558 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4107/12542 | Batch Loss: 1.6662 | Learning Rate: 0.000558 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4108/12542 | Batch Loss: 1.1230 | Learning Rate: 0.000557 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 4109/12542 | Batch Loss: 0.9049 | Learning Rate: 0.000557 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4110/12542 | Batch Loss: 1.3102 | Learning Rate: 0.000557 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4111/12542 | Batch Loss: 1.4946 | Learning Rate: 0.000557 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4112/12542 | Batch Loss: 1.6720 | Learning Rate: 0.000557 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4113/12542 | Batch Loss: 1.3689 | Learning Rate: 0.000557 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4114/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000557 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4115/12542 | Batch Loss: 1.8108 | Learning Rate: 0.000557 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4116/12542 | Batch Loss: 1.3657 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4117/12542 | Batch Loss: 1.1860 | Learning Rate: 0.000557 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4118/12542 | Batch Loss: 0.9149 | Learning Rate: 0.000557 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4119/12542 | Batch Loss: 1.6925 | Learning Rate: 0.000557 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4120/12542 | Batch Loss: 1.7215 | Learning Rate: 0.000557 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4121/12542 | Batch Loss: 3.6215 | Learning Rate: 0.000557 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4122/12542 | Batch Loss: 1.1253 | Learning Rate: 0.000557 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4123/12542 | Batch Loss: 1.2189 | Learning Rate: 0.000557 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4124/12542 | Batch Loss: 1.8615 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4125/12542 | Batch Loss: 1.5201 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4126/12542 | Batch Loss: 1.4180 | Learning Rate: 0.000557 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4127/12542 | Batch Loss: 0.7719 | Learning Rate: 0.000557 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4128/12542 | Batch Loss: 1.1093 | Learning Rate: 0.000557 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4129/12542 | Batch Loss: 1.5350 | Learning Rate: 0.000557 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4130/12542 | Batch Loss: 0.6104 | Learning Rate: 0.000557 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4131/12542 | Batch Loss: 1.1536 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4132/12542 | Batch Loss: 1.4190 | Learning Rate: 0.000557 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4133/12542 | Batch Loss: 0.5706 | Learning Rate: 0.000557 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4134/12542 | Batch Loss: 1.4237 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4135/12542 | Batch Loss: 1.3685 | Learning Rate: 0.000557 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4136/12542 | Batch Loss: 1.3344 | Learning Rate: 0.000557 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4137/12542 | Batch Loss: 1.8267 | Learning Rate: 0.000557 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4138/12542 | Batch Loss: 2.0737 | Learning Rate: 0.000557 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4139/12542 | Batch Loss: 0.7922 | Learning Rate: 0.000557 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4140/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000557 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4141/12542 | Batch Loss: 0.6380 | Learning Rate: 0.000557 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4142/12542 | Batch Loss: 0.9873 | Learning Rate: 0.000557 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4143/12542 | Batch Loss: 1.4331 | Learning Rate: 0.000557 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4144/12542 | Batch Loss: 0.8673 | Learning Rate: 0.000557 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4145/12542 | Batch Loss: 1.2360 | Learning Rate: 0.000557 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4146/12542 | Batch Loss: 2.8820 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4147/12542 | Batch Loss: 0.9263 | Learning Rate: 0.000556 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4148/12542 | Batch Loss: 1.0720 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4149/12542 | Batch Loss: 0.8195 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4150/12542 | Batch Loss: 2.2255 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4151/12542 | Batch Loss: 1.1246 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4152/12542 | Batch Loss: 2.0422 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4153/12542 | Batch Loss: 1.4437 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4154/12542 | Batch Loss: 0.3948 | Learning Rate: 0.000556 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4155/12542 | Batch Loss: 1.4650 | Learning Rate: 0.000556 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4156/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4157/12542 | Batch Loss: 0.7225 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4158/12542 | Batch Loss: 1.0820 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4159/12542 | Batch Loss: 0.7160 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4160/12542 | Batch Loss: 1.1563 | Learning Rate: 0.000556 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4161/12542 | Batch Loss: 0.6543 | Learning Rate: 0.000556 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4162/12542 | Batch Loss: 1.3661 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4163/12542 | Batch Loss: 0.9246 | Learning Rate: 0.000556 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4164/12542 | Batch Loss: 1.9917 | Learning Rate: 0.000556 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4165/12542 | Batch Loss: 0.4091 | Learning Rate: 0.000556 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4166/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000556 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4167/12542 | Batch Loss: 1.5959 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4168/12542 | Batch Loss: 0.7976 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4169/12542 | Batch Loss: 0.7658 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4170/12542 | Batch Loss: 1.7242 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4171/12542 | Batch Loss: 2.0041 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4172/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000556 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4173/12542 | Batch Loss: 0.4825 | Learning Rate: 0.000556 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4174/12542 | Batch Loss: 1.1566 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4175/12542 | Batch Loss: 1.6970 | Learning Rate: 0.000556 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4176/12542 | Batch Loss: 1.4076 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4177/12542 | Batch Loss: 1.6648 | Learning Rate: 0.000556 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4178/12542 | Batch Loss: 0.6493 | Learning Rate: 0.000556 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4179/12542 | Batch Loss: 0.7866 | Learning Rate: 0.000556 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4180/12542 | Batch Loss: 1.3502 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4181/12542 | Batch Loss: 1.8968 | Learning Rate: 0.000556 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4182/12542 | Batch Loss: 1.5240 | Learning Rate: 0.000556 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4183/12542 | Batch Loss: 1.2568 | Learning Rate: 0.000555 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4184/12542 | Batch Loss: 1.2818 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4185/12542 | Batch Loss: 1.3087 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4186/12542 | Batch Loss: 1.0056 | Learning Rate: 0.000555 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4187/12542 | Batch Loss: 0.5550 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4188/12542 | Batch Loss: 2.0885 | Learning Rate: 0.000555 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4189/12542 | Batch Loss: 1.5098 | Learning Rate: 0.000555 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4190/12542 | Batch Loss: 2.4675 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4191/12542 | Batch Loss: 1.4432 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4192/12542 | Batch Loss: 0.7239 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4193/12542 | Batch Loss: 1.1792 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4194/12542 | Batch Loss: 1.4936 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4195/12542 | Batch Loss: 1.6062 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4196/12542 | Batch Loss: 1.5411 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4197/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4198/12542 | Batch Loss: 1.2482 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4199/12542 | Batch Loss: 2.0639 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4200/12542 | Batch Loss: 2.5204 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4201/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4202/12542 | Batch Loss: 1.5085 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4203/12542 | Batch Loss: 1.2041 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4204/12542 | Batch Loss: 0.7390 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4205/12542 | Batch Loss: 0.5807 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4206/12542 | Batch Loss: 1.0403 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4207/12542 | Batch Loss: 0.8841 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4208/12542 | Batch Loss: 1.3828 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4209/12542 | Batch Loss: 1.3256 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4210/12542 | Batch Loss: 2.2580 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4211/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4212/12542 | Batch Loss: 1.8026 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4213/12542 | Batch Loss: 0.6793 | Learning Rate: 0.000555 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4214/12542 | Batch Loss: 1.8602 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4215/12542 | Batch Loss: 1.9343 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4216/12542 | Batch Loss: 1.8987 | Learning Rate: 0.000555 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4217/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000555 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4218/12542 | Batch Loss: 1.0370 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4219/12542 | Batch Loss: 2.4339 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4220/12542 | Batch Loss: 1.2962 | Learning Rate: 0.000555 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4221/12542 | Batch Loss: 1.8636 | Learning Rate: 0.000554 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4222/12542 | Batch Loss: 0.5110 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4223/12542 | Batch Loss: 1.2089 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4224/12542 | Batch Loss: 0.6307 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4225/12542 | Batch Loss: 0.6836 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4226/12542 | Batch Loss: 1.8311 | Learning Rate: 0.000554 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4227/12542 | Batch Loss: 0.8276 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4228/12542 | Batch Loss: 1.1612 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4229/12542 | Batch Loss: 1.1267 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4230/12542 | Batch Loss: 2.6170 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4231/12542 | Batch Loss: 0.8600 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4232/12542 | Batch Loss: 1.0850 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4233/12542 | Batch Loss: 1.2315 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4234/12542 | Batch Loss: 1.5348 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4235/12542 | Batch Loss: 1.7498 | Learning Rate: 0.000554 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4236/12542 | Batch Loss: 0.4855 | Learning Rate: 0.000554 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4237/12542 | Batch Loss: 1.0647 | Learning Rate: 0.000554 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4238/12542 | Batch Loss: 1.3364 | Learning Rate: 0.000554 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4239/12542 | Batch Loss: 2.0985 | Learning Rate: 0.000554 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4240/12542 | Batch Loss: 2.4093 | Learning Rate: 0.000554 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4241/12542 | Batch Loss: 1.9034 | Learning Rate: 0.000554 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4242/12542 | Batch Loss: 0.5880 | Learning Rate: 0.000554 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4243/12542 | Batch Loss: 2.6790 | Learning Rate: 0.000554 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4244/12542 | Batch Loss: 0.5002 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4245/12542 | Batch Loss: 1.3679 | Learning Rate: 0.000554 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4246/12542 | Batch Loss: 1.4895 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4247/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4248/12542 | Batch Loss: 0.8529 | Learning Rate: 0.000554 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4249/12542 | Batch Loss: 1.1256 | Learning Rate: 0.000554 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4250/12542 | Batch Loss: 0.9944 | Learning Rate: 0.000554 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4251/12542 | Batch Loss: 1.0080 | Learning Rate: 0.000554 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4252/12542 | Batch Loss: 0.7628 | Learning Rate: 0.000554 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4253/12542 | Batch Loss: 0.7601 | Learning Rate: 0.000554 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4254/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4255/12542 | Batch Loss: 0.9209 | Learning Rate: 0.000554 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4256/12542 | Batch Loss: 1.0111 | Learning Rate: 0.000554 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4257/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4258/12542 | Batch Loss: 1.6450 | Learning Rate: 0.000554 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4259/12542 | Batch Loss: 1.6021 | Learning Rate: 0.000553 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4260/12542 | Batch Loss: 0.9454 | Learning Rate: 0.000553 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4261/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000553 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4262/12542 | Batch Loss: 0.8205 | Learning Rate: 0.000553 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4263/12542 | Batch Loss: 2.3920 | Learning Rate: 0.000553 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4264/12542 | Batch Loss: 0.5081 | Learning Rate: 0.000553 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4265/12542 | Batch Loss: 1.3195 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4266/12542 | Batch Loss: 1.4725 | Learning Rate: 0.000553 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4267/12542 | Batch Loss: 2.7126 | Learning Rate: 0.000553 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4268/12542 | Batch Loss: 1.4235 | Learning Rate: 0.000553 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4269/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000553 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4270/12542 | Batch Loss: 0.4346 | Learning Rate: 0.000553 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4271/12542 | Batch Loss: 1.2430 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4272/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000553 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4273/12542 | Batch Loss: 0.8420 | Learning Rate: 0.000553 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4274/12542 | Batch Loss: 2.2081 | Learning Rate: 0.000553 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4275/12542 | Batch Loss: 1.8304 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4276/12542 | Batch Loss: 0.9858 | Learning Rate: 0.000553 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4277/12542 | Batch Loss: 1.0804 | Learning Rate: 0.000553 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4278/12542 | Batch Loss: 0.8879 | Learning Rate: 0.000553 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4279/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000553 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4280/12542 | Batch Loss: 1.2442 | Learning Rate: 0.000553 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 4281/12542 | Batch Loss: 0.5072 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4282/12542 | Batch Loss: 2.2361 | Learning Rate: 0.000553 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4283/12542 | Batch Loss: 2.0051 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4284/12542 | Batch Loss: 1.1724 | Learning Rate: 0.000553 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4285/12542 | Batch Loss: 0.8998 | Learning Rate: 0.000553 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4286/12542 | Batch Loss: 1.2901 | Learning Rate: 0.000553 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4287/12542 | Batch Loss: 1.1244 | Learning Rate: 0.000553 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4288/12542 | Batch Loss: 3.3186 | Learning Rate: 0.000553 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4289/12542 | Batch Loss: 1.8296 | Learning Rate: 0.000553 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4290/12542 | Batch Loss: 0.9572 | Learning Rate: 0.000553 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4291/12542 | Batch Loss: 1.8873 | Learning Rate: 0.000553 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4292/12542 | Batch Loss: 0.6032 | Learning Rate: 0.000553 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4293/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000553 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4294/12542 | Batch Loss: 1.5917 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4295/12542 | Batch Loss: 1.8199 | Learning Rate: 0.000553 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4296/12542 | Batch Loss: 0.7322 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4297/12542 | Batch Loss: 1.7927 | Learning Rate: 0.000552 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4298/12542 | Batch Loss: 1.7366 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4299/12542 | Batch Loss: 1.6659 | Learning Rate: 0.000552 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4300/12542 | Batch Loss: 1.3720 | Learning Rate: 0.000552 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4301/12542 | Batch Loss: 1.4163 | Learning Rate: 0.000552 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4302/12542 | Batch Loss: 1.7940 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4303/12542 | Batch Loss: 1.1551 | Learning Rate: 0.000552 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4304/12542 | Batch Loss: 0.9740 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4305/12542 | Batch Loss: 1.8610 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4306/12542 | Batch Loss: 1.8852 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4307/12542 | Batch Loss: 3.5402 | Learning Rate: 0.000552 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4308/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000552 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4309/12542 | Batch Loss: 1.0340 | Learning Rate: 0.000552 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4310/12542 | Batch Loss: 1.0503 | Learning Rate: 0.000552 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4311/12542 | Batch Loss: 0.6677 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4312/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000552 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4313/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4314/12542 | Batch Loss: 1.4599 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4315/12542 | Batch Loss: 0.6260 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4316/12542 | Batch Loss: 1.1065 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4317/12542 | Batch Loss: 1.6901 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4318/12542 | Batch Loss: 0.5671 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4319/12542 | Batch Loss: 0.7790 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4320/12542 | Batch Loss: 1.2140 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4321/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4322/12542 | Batch Loss: 0.7743 | Learning Rate: 0.000552 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4323/12542 | Batch Loss: 1.2561 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4324/12542 | Batch Loss: 2.7958 | Learning Rate: 0.000552 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4325/12542 | Batch Loss: 0.8379 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4326/12542 | Batch Loss: 1.8609 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4327/12542 | Batch Loss: 1.7299 | Learning Rate: 0.000552 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4328/12542 | Batch Loss: 1.5120 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4329/12542 | Batch Loss: 1.8135 | Learning Rate: 0.000552 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4330/12542 | Batch Loss: 0.9263 | Learning Rate: 0.000552 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4331/12542 | Batch Loss: 0.9349 | Learning Rate: 0.000552 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4332/12542 | Batch Loss: 2.3161 | Learning Rate: 0.000552 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4333/12542 | Batch Loss: 1.1742 | Learning Rate: 0.000552 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4334/12542 | Batch Loss: 1.3449 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4335/12542 | Batch Loss: 0.7733 | Learning Rate: 0.000551 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4336/12542 | Batch Loss: 0.5360 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4337/12542 | Batch Loss: 1.2349 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4338/12542 | Batch Loss: 1.2542 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4339/12542 | Batch Loss: 1.2106 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4340/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4341/12542 | Batch Loss: 0.9470 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4342/12542 | Batch Loss: 0.6613 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4343/12542 | Batch Loss: 1.6705 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4344/12542 | Batch Loss: 0.5022 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4345/12542 | Batch Loss: 1.4374 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4346/12542 | Batch Loss: 1.3099 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4347/12542 | Batch Loss: 1.3145 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4348/12542 | Batch Loss: 1.6186 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4349/12542 | Batch Loss: 0.5639 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4350/12542 | Batch Loss: 2.2031 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4351/12542 | Batch Loss: 0.9868 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4352/12542 | Batch Loss: 1.3802 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4353/12542 | Batch Loss: 0.8201 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4354/12542 | Batch Loss: 0.7597 | Learning Rate: 0.000551 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4355/12542 | Batch Loss: 0.6244 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4356/12542 | Batch Loss: 0.7488 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4357/12542 | Batch Loss: 1.0192 | Learning Rate: 0.000551 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4358/12542 | Batch Loss: 1.9634 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4359/12542 | Batch Loss: 1.4504 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4360/12542 | Batch Loss: 1.2676 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4361/12542 | Batch Loss: 1.7962 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4362/12542 | Batch Loss: 1.3712 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4363/12542 | Batch Loss: 1.1750 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4364/12542 | Batch Loss: 1.6814 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4365/12542 | Batch Loss: 0.8715 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4366/12542 | Batch Loss: 1.9317 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4367/12542 | Batch Loss: 1.3937 | Learning Rate: 0.000551 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4368/12542 | Batch Loss: 0.7570 | Learning Rate: 0.000551 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4369/12542 | Batch Loss: 0.9056 | Learning Rate: 0.000551 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4370/12542 | Batch Loss: 1.9498 | Learning Rate: 0.000551 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4371/12542 | Batch Loss: 0.5097 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4372/12542 | Batch Loss: 0.9404 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4373/12542 | Batch Loss: 1.7602 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4374/12542 | Batch Loss: 1.2946 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4375/12542 | Batch Loss: 1.2037 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4376/12542 | Batch Loss: 1.0357 | Learning Rate: 0.000550 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4377/12542 | Batch Loss: 0.5902 | Learning Rate: 0.000550 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4378/12542 | Batch Loss: 0.5414 | Learning Rate: 0.000550 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4379/12542 | Batch Loss: 0.9107 | Learning Rate: 0.000550 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4380/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000550 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4381/12542 | Batch Loss: 1.7696 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4382/12542 | Batch Loss: 0.6897 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4383/12542 | Batch Loss: 1.0542 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4384/12542 | Batch Loss: 1.0653 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4385/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4386/12542 | Batch Loss: 1.0709 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4387/12542 | Batch Loss: 2.3930 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4388/12542 | Batch Loss: 0.7373 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4389/12542 | Batch Loss: 0.9283 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4390/12542 | Batch Loss: 1.3345 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4391/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4392/12542 | Batch Loss: 1.2058 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4393/12542 | Batch Loss: 0.6775 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4394/12542 | Batch Loss: 1.2328 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4395/12542 | Batch Loss: 1.1835 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4396/12542 | Batch Loss: 0.7051 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4397/12542 | Batch Loss: 0.9738 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4398/12542 | Batch Loss: 1.7166 | Learning Rate: 0.000550 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4399/12542 | Batch Loss: 1.2030 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4400/12542 | Batch Loss: 0.7623 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4401/12542 | Batch Loss: 0.6639 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4402/12542 | Batch Loss: 0.7499 | Learning Rate: 0.000550 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4403/12542 | Batch Loss: 1.5607 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4404/12542 | Batch Loss: 1.2656 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4405/12542 | Batch Loss: 0.7613 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4406/12542 | Batch Loss: 3.0088 | Learning Rate: 0.000550 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4407/12542 | Batch Loss: 0.3493 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4408/12542 | Batch Loss: 1.5083 | Learning Rate: 0.000550 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4409/12542 | Batch Loss: 1.0216 | Learning Rate: 0.000549 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4410/12542 | Batch Loss: 1.3367 | Learning Rate: 0.000549 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4411/12542 | Batch Loss: 3.0624 | Learning Rate: 0.000549 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4412/12542 | Batch Loss: 1.3538 | Learning Rate: 0.000549 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4413/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000549 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4414/12542 | Batch Loss: 0.6606 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4415/12542 | Batch Loss: 1.4128 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4416/12542 | Batch Loss: 1.4918 | Learning Rate: 0.000549 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4417/12542 | Batch Loss: 0.8802 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4418/12542 | Batch Loss: 1.0411 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4419/12542 | Batch Loss: 1.0490 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4420/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4421/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4422/12542 | Batch Loss: 1.2859 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4423/12542 | Batch Loss: 1.2183 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4424/12542 | Batch Loss: 2.7318 | Learning Rate: 0.000549 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4425/12542 | Batch Loss: 1.1353 | Learning Rate: 0.000549 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4426/12542 | Batch Loss: 1.4897 | Learning Rate: 0.000549 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4427/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4428/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4429/12542 | Batch Loss: 1.6758 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4430/12542 | Batch Loss: 0.8714 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4431/12542 | Batch Loss: 2.4433 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4432/12542 | Batch Loss: 0.8414 | Learning Rate: 0.000549 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4433/12542 | Batch Loss: 0.7006 | Learning Rate: 0.000549 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4434/12542 | Batch Loss: 1.2161 | Learning Rate: 0.000549 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4435/12542 | Batch Loss: 0.7603 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4436/12542 | Batch Loss: 1.2308 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4437/12542 | Batch Loss: 0.9423 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4438/12542 | Batch Loss: 1.3693 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4439/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4440/12542 | Batch Loss: 0.7298 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4441/12542 | Batch Loss: 2.3063 | Learning Rate: 0.000549 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4442/12542 | Batch Loss: 0.9229 | Learning Rate: 0.000549 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4443/12542 | Batch Loss: 0.9011 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4444/12542 | Batch Loss: 1.1249 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4445/12542 | Batch Loss: 1.9427 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4446/12542 | Batch Loss: 0.6660 | Learning Rate: 0.000549 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4447/12542 | Batch Loss: 0.5336 | Learning Rate: 0.000548 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4448/12542 | Batch Loss: 2.5348 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4449/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000548 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4450/12542 | Batch Loss: 1.0582 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4451/12542 | Batch Loss: 1.3969 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4452/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000548 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4453/12542 | Batch Loss: 0.8772 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4454/12542 | Batch Loss: 2.1777 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4455/12542 | Batch Loss: 1.5557 | Learning Rate: 0.000548 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4456/12542 | Batch Loss: 1.2312 | Learning Rate: 0.000548 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4457/12542 | Batch Loss: 2.4238 | Learning Rate: 0.000548 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4458/12542 | Batch Loss: 1.4178 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4459/12542 | Batch Loss: 2.6317 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4460/12542 | Batch Loss: 3.2474 | Learning Rate: 0.000548 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4461/12542 | Batch Loss: 1.2314 | Learning Rate: 0.000548 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4462/12542 | Batch Loss: 1.5055 | Learning Rate: 0.000548 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4463/12542 | Batch Loss: 1.5702 | Learning Rate: 0.000548 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4464/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000548 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4465/12542 | Batch Loss: 1.8578 | Learning Rate: 0.000548 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4466/12542 | Batch Loss: 1.6237 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4467/12542 | Batch Loss: 1.2967 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4468/12542 | Batch Loss: 0.9514 | Learning Rate: 0.000548 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4469/12542 | Batch Loss: 1.0729 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4470/12542 | Batch Loss: 1.2223 | Learning Rate: 0.000548 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4471/12542 | Batch Loss: 1.6567 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4472/12542 | Batch Loss: 0.5918 | Learning Rate: 0.000548 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4473/12542 | Batch Loss: 1.3591 | Learning Rate: 0.000548 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4474/12542 | Batch Loss: 1.7354 | Learning Rate: 0.000548 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4475/12542 | Batch Loss: 1.1143 | Learning Rate: 0.000548 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4476/12542 | Batch Loss: 0.7322 | Learning Rate: 0.000548 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4477/12542 | Batch Loss: 1.6578 | Learning Rate: 0.000548 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4478/12542 | Batch Loss: 1.7326 | Learning Rate: 0.000548 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4479/12542 | Batch Loss: 2.3266 | Learning Rate: 0.000548 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4480/12542 | Batch Loss: 0.6695 | Learning Rate: 0.000548 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4481/12542 | Batch Loss: 2.2684 | Learning Rate: 0.000548 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4482/12542 | Batch Loss: 1.3244 | Learning Rate: 0.000548 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4483/12542 | Batch Loss: 0.9452 | Learning Rate: 0.000548 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4484/12542 | Batch Loss: 2.2669 | Learning Rate: 0.000547 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4485/12542 | Batch Loss: 0.5522 | Learning Rate: 0.000547 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4486/12542 | Batch Loss: 0.9251 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4487/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4488/12542 | Batch Loss: 1.6029 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4489/12542 | Batch Loss: 0.3771 | Learning Rate: 0.000547 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4490/12542 | Batch Loss: 1.0373 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4491/12542 | Batch Loss: 0.6475 | Learning Rate: 0.000547 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4492/12542 | Batch Loss: 1.6341 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4493/12542 | Batch Loss: 1.7600 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4494/12542 | Batch Loss: 0.9624 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4495/12542 | Batch Loss: 0.5826 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4496/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000547 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4497/12542 | Batch Loss: 0.8896 | Learning Rate: 0.000547 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4498/12542 | Batch Loss: 3.1721 | Learning Rate: 0.000547 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4499/12542 | Batch Loss: 0.6241 | Learning Rate: 0.000547 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4500/12542 | Batch Loss: 0.9866 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4501/12542 | Batch Loss: 1.9677 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4502/12542 | Batch Loss: 0.9078 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4503/12542 | Batch Loss: 1.0898 | Learning Rate: 0.000547 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4504/12542 | Batch Loss: 1.0550 | Learning Rate: 0.000547 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4505/12542 | Batch Loss: 1.3059 | Learning Rate: 0.000547 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4506/12542 | Batch Loss: 0.3870 | Learning Rate: 0.000547 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4507/12542 | Batch Loss: 0.9424 | Learning Rate: 0.000547 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4508/12542 | Batch Loss: 0.9823 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4509/12542 | Batch Loss: 1.1806 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4510/12542 | Batch Loss: 1.6451 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4511/12542 | Batch Loss: 2.9152 | Learning Rate: 0.000547 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4512/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000547 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4513/12542 | Batch Loss: 0.9645 | Learning Rate: 0.000547 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4514/12542 | Batch Loss: 0.9055 | Learning Rate: 0.000547 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4515/12542 | Batch Loss: 1.7182 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4516/12542 | Batch Loss: 1.3406 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4517/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000547 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4518/12542 | Batch Loss: 0.7563 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4519/12542 | Batch Loss: 1.9663 | Learning Rate: 0.000547 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4520/12542 | Batch Loss: 0.8809 | Learning Rate: 0.000547 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4521/12542 | Batch Loss: 2.2053 | Learning Rate: 0.000547 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4522/12542 | Batch Loss: 0.6943 | Learning Rate: 0.000546 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4523/12542 | Batch Loss: 1.1558 | Learning Rate: 0.000546 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4524/12542 | Batch Loss: 0.7018 | Learning Rate: 0.000546 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4525/12542 | Batch Loss: 2.2515 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4526/12542 | Batch Loss: 3.1924 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4527/12542 | Batch Loss: 0.7573 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4528/12542 | Batch Loss: 1.0003 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4529/12542 | Batch Loss: 1.6284 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4530/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4531/12542 | Batch Loss: 1.3931 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4532/12542 | Batch Loss: 0.5708 | Learning Rate: 0.000546 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4533/12542 | Batch Loss: 1.8880 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4534/12542 | Batch Loss: 1.6075 | Learning Rate: 0.000546 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4535/12542 | Batch Loss: 1.2431 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4536/12542 | Batch Loss: 1.2068 | Learning Rate: 0.000546 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4537/12542 | Batch Loss: 2.4878 | Learning Rate: 0.000546 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4538/12542 | Batch Loss: 2.2807 | Learning Rate: 0.000546 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4539/12542 | Batch Loss: 0.6201 | Learning Rate: 0.000546 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4540/12542 | Batch Loss: 1.0624 | Learning Rate: 0.000546 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4541/12542 | Batch Loss: 0.9419 | Learning Rate: 0.000546 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4542/12542 | Batch Loss: 2.4766 | Learning Rate: 0.000546 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4543/12542 | Batch Loss: 1.2616 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4544/12542 | Batch Loss: 0.7024 | Learning Rate: 0.000546 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4545/12542 | Batch Loss: 1.3231 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4546/12542 | Batch Loss: 0.8395 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4547/12542 | Batch Loss: 1.4537 | Learning Rate: 0.000546 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4548/12542 | Batch Loss: 0.7700 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4549/12542 | Batch Loss: 0.5803 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4550/12542 | Batch Loss: 3.2708 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4551/12542 | Batch Loss: 1.1452 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4552/12542 | Batch Loss: 1.5252 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4553/12542 | Batch Loss: 1.7667 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4554/12542 | Batch Loss: 0.7455 | Learning Rate: 0.000546 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4555/12542 | Batch Loss: 1.0473 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4556/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000546 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4557/12542 | Batch Loss: 0.4650 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4558/12542 | Batch Loss: 0.6777 | Learning Rate: 0.000546 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4559/12542 | Batch Loss: 2.9960 | Learning Rate: 0.000546 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4560/12542 | Batch Loss: 0.5390 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4561/12542 | Batch Loss: 1.4723 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4562/12542 | Batch Loss: 1.1342 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4563/12542 | Batch Loss: 0.9566 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4564/12542 | Batch Loss: 1.1348 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4565/12542 | Batch Loss: 0.6372 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4566/12542 | Batch Loss: 0.5634 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4567/12542 | Batch Loss: 1.8831 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4568/12542 | Batch Loss: 1.3388 | Learning Rate: 0.000545 | Batch Time: 0.54s\n",
      "Epoch 2 | Step 4569/12542 | Batch Loss: 1.7898 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4570/12542 | Batch Loss: 1.4283 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4571/12542 | Batch Loss: 1.3250 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4572/12542 | Batch Loss: 0.7130 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4573/12542 | Batch Loss: 2.0674 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4574/12542 | Batch Loss: 1.9275 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4575/12542 | Batch Loss: 1.7127 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4576/12542 | Batch Loss: 0.9008 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4577/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4578/12542 | Batch Loss: 1.2475 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4579/12542 | Batch Loss: 0.5878 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4580/12542 | Batch Loss: 1.4422 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4581/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4582/12542 | Batch Loss: 0.8307 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4583/12542 | Batch Loss: 1.9484 | Learning Rate: 0.000545 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4584/12542 | Batch Loss: 1.0030 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4585/12542 | Batch Loss: 0.9577 | Learning Rate: 0.000545 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4586/12542 | Batch Loss: 0.8603 | Learning Rate: 0.000545 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4587/12542 | Batch Loss: 0.7702 | Learning Rate: 0.000545 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4588/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4589/12542 | Batch Loss: 0.7842 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4590/12542 | Batch Loss: 1.7554 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4591/12542 | Batch Loss: 1.2526 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4592/12542 | Batch Loss: 0.3814 | Learning Rate: 0.000545 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4593/12542 | Batch Loss: 1.4114 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4594/12542 | Batch Loss: 1.2419 | Learning Rate: 0.000545 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4595/12542 | Batch Loss: 1.0625 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4596/12542 | Batch Loss: 4.3015 | Learning Rate: 0.000545 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4597/12542 | Batch Loss: 0.6563 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4598/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4599/12542 | Batch Loss: 2.0096 | Learning Rate: 0.000544 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4600/12542 | Batch Loss: 1.3336 | Learning Rate: 0.000544 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 4601/12542 | Batch Loss: 1.1088 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4602/12542 | Batch Loss: 1.2336 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4603/12542 | Batch Loss: 0.9053 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4604/12542 | Batch Loss: 0.9868 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4605/12542 | Batch Loss: 1.2218 | Learning Rate: 0.000544 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4606/12542 | Batch Loss: 1.3848 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4607/12542 | Batch Loss: 1.2410 | Learning Rate: 0.000544 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4608/12542 | Batch Loss: 2.1502 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4609/12542 | Batch Loss: 0.8341 | Learning Rate: 0.000544 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4610/12542 | Batch Loss: 1.3359 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4611/12542 | Batch Loss: 2.6599 | Learning Rate: 0.000544 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4612/12542 | Batch Loss: 1.9023 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4613/12542 | Batch Loss: 1.2337 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4614/12542 | Batch Loss: 1.3266 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4615/12542 | Batch Loss: 1.0652 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4616/12542 | Batch Loss: 1.0758 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4617/12542 | Batch Loss: 1.4940 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4618/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4619/12542 | Batch Loss: 2.0451 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4620/12542 | Batch Loss: 1.2006 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4621/12542 | Batch Loss: 0.9247 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4622/12542 | Batch Loss: 0.8720 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4623/12542 | Batch Loss: 0.5818 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4624/12542 | Batch Loss: 1.3316 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4625/12542 | Batch Loss: 1.0107 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4626/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4627/12542 | Batch Loss: 1.1269 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4628/12542 | Batch Loss: 2.3463 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4629/12542 | Batch Loss: 1.0110 | Learning Rate: 0.000544 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4630/12542 | Batch Loss: 1.7211 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4631/12542 | Batch Loss: 0.7963 | Learning Rate: 0.000544 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4632/12542 | Batch Loss: 1.8216 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4633/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000544 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4634/12542 | Batch Loss: 2.2754 | Learning Rate: 0.000544 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4635/12542 | Batch Loss: 1.5558 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4636/12542 | Batch Loss: 0.9401 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4637/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4638/12542 | Batch Loss: 1.5176 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4639/12542 | Batch Loss: 1.0694 | Learning Rate: 0.000543 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4640/12542 | Batch Loss: 1.3651 | Learning Rate: 0.000543 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4641/12542 | Batch Loss: 1.0714 | Learning Rate: 0.000543 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4642/12542 | Batch Loss: 0.9462 | Learning Rate: 0.000543 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4643/12542 | Batch Loss: 0.9164 | Learning Rate: 0.000543 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4644/12542 | Batch Loss: 1.9251 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4645/12542 | Batch Loss: 1.0777 | Learning Rate: 0.000543 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4646/12542 | Batch Loss: 1.2273 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4647/12542 | Batch Loss: 0.8112 | Learning Rate: 0.000543 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4648/12542 | Batch Loss: 1.0964 | Learning Rate: 0.000543 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4649/12542 | Batch Loss: 1.0223 | Learning Rate: 0.000543 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4650/12542 | Batch Loss: 0.7611 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4651/12542 | Batch Loss: 0.5245 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4652/12542 | Batch Loss: 0.8745 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4653/12542 | Batch Loss: 0.8176 | Learning Rate: 0.000543 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4654/12542 | Batch Loss: 0.6800 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4655/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4656/12542 | Batch Loss: 1.3894 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4657/12542 | Batch Loss: 2.4009 | Learning Rate: 0.000543 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4658/12542 | Batch Loss: 1.1448 | Learning Rate: 0.000543 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4659/12542 | Batch Loss: 1.1753 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4660/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4661/12542 | Batch Loss: 1.3623 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4662/12542 | Batch Loss: 0.6946 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4663/12542 | Batch Loss: 0.5407 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4664/12542 | Batch Loss: 2.1504 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4665/12542 | Batch Loss: 1.8940 | Learning Rate: 0.000543 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4666/12542 | Batch Loss: 1.0359 | Learning Rate: 0.000543 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4667/12542 | Batch Loss: 0.7429 | Learning Rate: 0.000543 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4668/12542 | Batch Loss: 1.6069 | Learning Rate: 0.000543 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4669/12542 | Batch Loss: 1.4006 | Learning Rate: 0.000543 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4670/12542 | Batch Loss: 0.6115 | Learning Rate: 0.000543 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4671/12542 | Batch Loss: 1.9317 | Learning Rate: 0.000543 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4672/12542 | Batch Loss: 1.0161 | Learning Rate: 0.000542 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4673/12542 | Batch Loss: 0.9955 | Learning Rate: 0.000542 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4674/12542 | Batch Loss: 1.9185 | Learning Rate: 0.000542 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4675/12542 | Batch Loss: 1.7869 | Learning Rate: 0.000542 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4676/12542 | Batch Loss: 0.8241 | Learning Rate: 0.000542 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4677/12542 | Batch Loss: 1.5496 | Learning Rate: 0.000542 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4678/12542 | Batch Loss: 0.9010 | Learning Rate: 0.000542 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4679/12542 | Batch Loss: 1.5291 | Learning Rate: 0.000542 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4680/12542 | Batch Loss: 1.3167 | Learning Rate: 0.000542 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4681/12542 | Batch Loss: 1.6511 | Learning Rate: 0.000542 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4682/12542 | Batch Loss: 1.4224 | Learning Rate: 0.000542 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4683/12542 | Batch Loss: 0.5639 | Learning Rate: 0.000542 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4684/12542 | Batch Loss: 0.7865 | Learning Rate: 0.000542 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4685/12542 | Batch Loss: 1.3604 | Learning Rate: 0.000542 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4686/12542 | Batch Loss: 0.7523 | Learning Rate: 0.000542 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4687/12542 | Batch Loss: 1.1423 | Learning Rate: 0.000542 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4688/12542 | Batch Loss: 0.9713 | Learning Rate: 0.000542 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4689/12542 | Batch Loss: 1.4560 | Learning Rate: 0.000542 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4690/12542 | Batch Loss: 1.6240 | Learning Rate: 0.000542 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4691/12542 | Batch Loss: 1.1132 | Learning Rate: 0.000542 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4692/12542 | Batch Loss: 2.8288 | Learning Rate: 0.000542 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4693/12542 | Batch Loss: 0.6388 | Learning Rate: 0.000542 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4694/12542 | Batch Loss: 0.7814 | Learning Rate: 0.000542 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4695/12542 | Batch Loss: 1.2150 | Learning Rate: 0.000542 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4696/12542 | Batch Loss: 1.7262 | Learning Rate: 0.000542 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4697/12542 | Batch Loss: 1.6103 | Learning Rate: 0.000542 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4698/12542 | Batch Loss: 0.9703 | Learning Rate: 0.000542 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4699/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000542 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4700/12542 | Batch Loss: 1.7557 | Learning Rate: 0.000542 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4701/12542 | Batch Loss: 1.2668 | Learning Rate: 0.000542 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4702/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000542 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 4703/12542 | Batch Loss: 1.2880 | Learning Rate: 0.000542 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4704/12542 | Batch Loss: 1.6502 | Learning Rate: 0.000542 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 4705/12542 | Batch Loss: 1.1001 | Learning Rate: 0.000542 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4706/12542 | Batch Loss: 1.0100 | Learning Rate: 0.000542 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4707/12542 | Batch Loss: 0.9968 | Learning Rate: 0.000542 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4708/12542 | Batch Loss: 0.6249 | Learning Rate: 0.000542 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4709/12542 | Batch Loss: 1.7392 | Learning Rate: 0.000542 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4710/12542 | Batch Loss: 0.6699 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4711/12542 | Batch Loss: 0.7449 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4712/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4713/12542 | Batch Loss: 1.8186 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4714/12542 | Batch Loss: 0.7467 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4715/12542 | Batch Loss: 1.9654 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4716/12542 | Batch Loss: 1.4635 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4717/12542 | Batch Loss: 0.7907 | Learning Rate: 0.000541 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4718/12542 | Batch Loss: 0.7425 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4719/12542 | Batch Loss: 1.0836 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4720/12542 | Batch Loss: 0.9071 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4721/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000541 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4722/12542 | Batch Loss: 2.5615 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4723/12542 | Batch Loss: 1.1205 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4724/12542 | Batch Loss: 1.5261 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4725/12542 | Batch Loss: 0.9901 | Learning Rate: 0.000541 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4726/12542 | Batch Loss: 0.5893 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4727/12542 | Batch Loss: 1.9684 | Learning Rate: 0.000541 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4728/12542 | Batch Loss: 1.4959 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4729/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000541 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4730/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000541 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4731/12542 | Batch Loss: 2.2448 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4732/12542 | Batch Loss: 1.8436 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4733/12542 | Batch Loss: 0.8294 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4734/12542 | Batch Loss: 0.6537 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4735/12542 | Batch Loss: 1.3265 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4736/12542 | Batch Loss: 1.1128 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4737/12542 | Batch Loss: 1.0563 | Learning Rate: 0.000541 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4738/12542 | Batch Loss: 1.3236 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4739/12542 | Batch Loss: 3.1623 | Learning Rate: 0.000541 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4740/12542 | Batch Loss: 3.6916 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4741/12542 | Batch Loss: 1.5496 | Learning Rate: 0.000541 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4742/12542 | Batch Loss: 0.8291 | Learning Rate: 0.000541 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4743/12542 | Batch Loss: 1.5625 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4744/12542 | Batch Loss: 1.1297 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4745/12542 | Batch Loss: 1.0977 | Learning Rate: 0.000541 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4746/12542 | Batch Loss: 1.3351 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4747/12542 | Batch Loss: 2.5443 | Learning Rate: 0.000541 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4748/12542 | Batch Loss: 2.6043 | Learning Rate: 0.000540 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4749/12542 | Batch Loss: 1.8506 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4750/12542 | Batch Loss: 0.6961 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4751/12542 | Batch Loss: 1.3215 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4752/12542 | Batch Loss: 1.2209 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4753/12542 | Batch Loss: 2.3506 | Learning Rate: 0.000540 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4754/12542 | Batch Loss: 2.3303 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4755/12542 | Batch Loss: 0.6408 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4756/12542 | Batch Loss: 1.8091 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4757/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4758/12542 | Batch Loss: 0.9719 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4759/12542 | Batch Loss: 0.6528 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4760/12542 | Batch Loss: 0.4788 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4761/12542 | Batch Loss: 1.0631 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4762/12542 | Batch Loss: 1.7379 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4763/12542 | Batch Loss: 1.9697 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4764/12542 | Batch Loss: 1.5855 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4765/12542 | Batch Loss: 1.5768 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4766/12542 | Batch Loss: 0.4341 | Learning Rate: 0.000540 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 4767/12542 | Batch Loss: 1.6128 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4768/12542 | Batch Loss: 0.8401 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4769/12542 | Batch Loss: 1.6638 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4770/12542 | Batch Loss: 1.8743 | Learning Rate: 0.000540 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4771/12542 | Batch Loss: 1.7272 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4772/12542 | Batch Loss: 1.3288 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4773/12542 | Batch Loss: 1.7570 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4774/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000540 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4775/12542 | Batch Loss: 1.2353 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4776/12542 | Batch Loss: 1.0311 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4777/12542 | Batch Loss: 1.2341 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4778/12542 | Batch Loss: 1.9321 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4779/12542 | Batch Loss: 3.4820 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4780/12542 | Batch Loss: 1.2693 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4781/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4782/12542 | Batch Loss: 1.2114 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4783/12542 | Batch Loss: 2.7311 | Learning Rate: 0.000540 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4784/12542 | Batch Loss: 0.8660 | Learning Rate: 0.000540 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4785/12542 | Batch Loss: 1.1620 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4786/12542 | Batch Loss: 1.9100 | Learning Rate: 0.000539 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4787/12542 | Batch Loss: 1.0001 | Learning Rate: 0.000539 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 4788/12542 | Batch Loss: 1.6945 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4789/12542 | Batch Loss: 0.6761 | Learning Rate: 0.000539 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4790/12542 | Batch Loss: 1.6806 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4791/12542 | Batch Loss: 1.0756 | Learning Rate: 0.000539 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4792/12542 | Batch Loss: 1.1283 | Learning Rate: 0.000539 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4793/12542 | Batch Loss: 1.8266 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4794/12542 | Batch Loss: 1.0730 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4795/12542 | Batch Loss: 0.8123 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4796/12542 | Batch Loss: 1.2714 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4797/12542 | Batch Loss: 0.7018 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4798/12542 | Batch Loss: 3.2346 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4799/12542 | Batch Loss: 0.7586 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4800/12542 | Batch Loss: 0.7499 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4801/12542 | Batch Loss: 3.5444 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4802/12542 | Batch Loss: 0.9012 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4803/12542 | Batch Loss: 1.6303 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4804/12542 | Batch Loss: 0.9023 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4805/12542 | Batch Loss: 0.7725 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4806/12542 | Batch Loss: 2.4316 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4807/12542 | Batch Loss: 1.6385 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4808/12542 | Batch Loss: 0.5943 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4809/12542 | Batch Loss: 1.2707 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4810/12542 | Batch Loss: 2.7783 | Learning Rate: 0.000539 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4811/12542 | Batch Loss: 2.2405 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4812/12542 | Batch Loss: 1.2145 | Learning Rate: 0.000539 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4813/12542 | Batch Loss: 1.8207 | Learning Rate: 0.000539 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4814/12542 | Batch Loss: 1.4842 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4815/12542 | Batch Loss: 1.2466 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4816/12542 | Batch Loss: 2.6010 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4817/12542 | Batch Loss: 1.1853 | Learning Rate: 0.000539 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4818/12542 | Batch Loss: 0.8545 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4819/12542 | Batch Loss: 1.1277 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4820/12542 | Batch Loss: 1.6866 | Learning Rate: 0.000539 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4821/12542 | Batch Loss: 0.8590 | Learning Rate: 0.000539 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4822/12542 | Batch Loss: 1.1569 | Learning Rate: 0.000539 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4823/12542 | Batch Loss: 1.4674 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4824/12542 | Batch Loss: 1.2432 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4825/12542 | Batch Loss: 1.6484 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4826/12542 | Batch Loss: 1.8621 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4827/12542 | Batch Loss: 0.5263 | Learning Rate: 0.000538 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4828/12542 | Batch Loss: 0.7092 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4829/12542 | Batch Loss: 0.6836 | Learning Rate: 0.000538 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4830/12542 | Batch Loss: 0.6900 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4831/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4832/12542 | Batch Loss: 1.2976 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4833/12542 | Batch Loss: 1.0329 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4834/12542 | Batch Loss: 0.7833 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4835/12542 | Batch Loss: 2.7670 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4836/12542 | Batch Loss: 1.6078 | Learning Rate: 0.000538 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4837/12542 | Batch Loss: 1.2838 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4838/12542 | Batch Loss: 1.3332 | Learning Rate: 0.000538 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4839/12542 | Batch Loss: 0.7854 | Learning Rate: 0.000538 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4840/12542 | Batch Loss: 1.2548 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4841/12542 | Batch Loss: 1.1804 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4842/12542 | Batch Loss: 0.6859 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4843/12542 | Batch Loss: 1.0534 | Learning Rate: 0.000538 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4844/12542 | Batch Loss: 0.5108 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4845/12542 | Batch Loss: 1.4302 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4846/12542 | Batch Loss: 0.8137 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4847/12542 | Batch Loss: 0.5657 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4848/12542 | Batch Loss: 1.5339 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4849/12542 | Batch Loss: 1.3042 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4850/12542 | Batch Loss: 2.4053 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4851/12542 | Batch Loss: 1.2921 | Learning Rate: 0.000538 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4852/12542 | Batch Loss: 1.2566 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4853/12542 | Batch Loss: 2.8558 | Learning Rate: 0.000538 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4854/12542 | Batch Loss: 0.6519 | Learning Rate: 0.000538 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4855/12542 | Batch Loss: 0.7192 | Learning Rate: 0.000538 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4856/12542 | Batch Loss: 1.3878 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4857/12542 | Batch Loss: 1.3114 | Learning Rate: 0.000538 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4858/12542 | Batch Loss: 1.3202 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4859/12542 | Batch Loss: 1.7559 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4860/12542 | Batch Loss: 1.6990 | Learning Rate: 0.000538 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4861/12542 | Batch Loss: 1.0403 | Learning Rate: 0.000537 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4862/12542 | Batch Loss: 3.8345 | Learning Rate: 0.000537 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4863/12542 | Batch Loss: 1.4818 | Learning Rate: 0.000537 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 4864/12542 | Batch Loss: 2.5427 | Learning Rate: 0.000537 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4865/12542 | Batch Loss: 1.2873 | Learning Rate: 0.000537 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4866/12542 | Batch Loss: 1.1649 | Learning Rate: 0.000537 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4867/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4868/12542 | Batch Loss: 0.9269 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4869/12542 | Batch Loss: 1.2289 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4870/12542 | Batch Loss: 1.1376 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4871/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4872/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4873/12542 | Batch Loss: 0.8059 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4874/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4875/12542 | Batch Loss: 1.3695 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4876/12542 | Batch Loss: 2.5837 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4877/12542 | Batch Loss: 1.7736 | Learning Rate: 0.000537 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 4878/12542 | Batch Loss: 1.4542 | Learning Rate: 0.000537 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4879/12542 | Batch Loss: 1.7989 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4880/12542 | Batch Loss: 0.9661 | Learning Rate: 0.000537 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4881/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4882/12542 | Batch Loss: 2.3096 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4883/12542 | Batch Loss: 0.9960 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4884/12542 | Batch Loss: 1.0980 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4885/12542 | Batch Loss: 1.4249 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4886/12542 | Batch Loss: 1.0160 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4887/12542 | Batch Loss: 1.0094 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4888/12542 | Batch Loss: 1.6102 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4889/12542 | Batch Loss: 1.2662 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4890/12542 | Batch Loss: 0.8804 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4891/12542 | Batch Loss: 2.2175 | Learning Rate: 0.000537 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4892/12542 | Batch Loss: 1.2811 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4893/12542 | Batch Loss: 0.6465 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4894/12542 | Batch Loss: 1.2816 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4895/12542 | Batch Loss: 1.2191 | Learning Rate: 0.000537 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4896/12542 | Batch Loss: 0.6278 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4897/12542 | Batch Loss: 1.9693 | Learning Rate: 0.000537 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4898/12542 | Batch Loss: 0.6251 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4899/12542 | Batch Loss: 0.9071 | Learning Rate: 0.000536 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4900/12542 | Batch Loss: 2.0288 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4901/12542 | Batch Loss: 1.1665 | Learning Rate: 0.000536 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4902/12542 | Batch Loss: 1.3296 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4903/12542 | Batch Loss: 0.9919 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4904/12542 | Batch Loss: 0.8208 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4905/12542 | Batch Loss: 1.3952 | Learning Rate: 0.000536 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4906/12542 | Batch Loss: 1.7333 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4907/12542 | Batch Loss: 2.1938 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4908/12542 | Batch Loss: 1.4349 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4909/12542 | Batch Loss: 0.6400 | Learning Rate: 0.000536 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4910/12542 | Batch Loss: 0.9184 | Learning Rate: 0.000536 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4911/12542 | Batch Loss: 0.6791 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4912/12542 | Batch Loss: 1.2562 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4913/12542 | Batch Loss: 1.4180 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4914/12542 | Batch Loss: 1.7165 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4915/12542 | Batch Loss: 0.5624 | Learning Rate: 0.000536 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4916/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000536 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 4917/12542 | Batch Loss: 1.1275 | Learning Rate: 0.000536 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4918/12542 | Batch Loss: 2.4309 | Learning Rate: 0.000536 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4919/12542 | Batch Loss: 1.5220 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4920/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4921/12542 | Batch Loss: 2.2781 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4922/12542 | Batch Loss: 1.4093 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4923/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4924/12542 | Batch Loss: 0.6419 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4925/12542 | Batch Loss: 1.8590 | Learning Rate: 0.000536 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4926/12542 | Batch Loss: 1.2465 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4927/12542 | Batch Loss: 2.2970 | Learning Rate: 0.000536 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4928/12542 | Batch Loss: 1.0279 | Learning Rate: 0.000536 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4929/12542 | Batch Loss: 1.1314 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4930/12542 | Batch Loss: 0.3807 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4931/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4932/12542 | Batch Loss: 0.7292 | Learning Rate: 0.000536 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4933/12542 | Batch Loss: 2.2559 | Learning Rate: 0.000536 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4934/12542 | Batch Loss: 1.1582 | Learning Rate: 0.000536 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4935/12542 | Batch Loss: 1.6488 | Learning Rate: 0.000536 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4936/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4937/12542 | Batch Loss: 0.6378 | Learning Rate: 0.000535 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4938/12542 | Batch Loss: 1.5321 | Learning Rate: 0.000535 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4939/12542 | Batch Loss: 0.9289 | Learning Rate: 0.000535 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 4940/12542 | Batch Loss: 2.1113 | Learning Rate: 0.000535 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4941/12542 | Batch Loss: 1.1845 | Learning Rate: 0.000535 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 4942/12542 | Batch Loss: 1.1731 | Learning Rate: 0.000535 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4943/12542 | Batch Loss: 0.6340 | Learning Rate: 0.000535 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4944/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4945/12542 | Batch Loss: 1.0229 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4946/12542 | Batch Loss: 2.0534 | Learning Rate: 0.000535 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4947/12542 | Batch Loss: 1.2480 | Learning Rate: 0.000535 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4948/12542 | Batch Loss: 1.9086 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4949/12542 | Batch Loss: 1.2917 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4950/12542 | Batch Loss: 1.1896 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4951/12542 | Batch Loss: 1.3132 | Learning Rate: 0.000535 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4952/12542 | Batch Loss: 1.3987 | Learning Rate: 0.000535 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 4953/12542 | Batch Loss: 1.6231 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4954/12542 | Batch Loss: 1.0750 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4955/12542 | Batch Loss: 0.3929 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4956/12542 | Batch Loss: 1.0381 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4957/12542 | Batch Loss: 1.3487 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4958/12542 | Batch Loss: 1.2770 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4959/12542 | Batch Loss: 0.8199 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4960/12542 | Batch Loss: 1.8767 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4961/12542 | Batch Loss: 0.8945 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4962/12542 | Batch Loss: 1.8182 | Learning Rate: 0.000535 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 4963/12542 | Batch Loss: 1.4872 | Learning Rate: 0.000535 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4964/12542 | Batch Loss: 2.3392 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4965/12542 | Batch Loss: 0.6278 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4966/12542 | Batch Loss: 1.4081 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4967/12542 | Batch Loss: 1.6436 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4968/12542 | Batch Loss: 1.3728 | Learning Rate: 0.000535 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4969/12542 | Batch Loss: 1.2133 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4970/12542 | Batch Loss: 1.0340 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4971/12542 | Batch Loss: 1.2886 | Learning Rate: 0.000535 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4972/12542 | Batch Loss: 1.4210 | Learning Rate: 0.000535 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4973/12542 | Batch Loss: 1.2847 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4974/12542 | Batch Loss: 0.6924 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4975/12542 | Batch Loss: 0.9899 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4976/12542 | Batch Loss: 0.8018 | Learning Rate: 0.000534 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4977/12542 | Batch Loss: 1.3020 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4978/12542 | Batch Loss: 1.1663 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4979/12542 | Batch Loss: 0.9893 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4980/12542 | Batch Loss: 1.7708 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4981/12542 | Batch Loss: 1.6463 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4982/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4983/12542 | Batch Loss: 0.4463 | Learning Rate: 0.000534 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 4984/12542 | Batch Loss: 1.8587 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4985/12542 | Batch Loss: 1.1429 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4986/12542 | Batch Loss: 1.0346 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4987/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4988/12542 | Batch Loss: 1.9824 | Learning Rate: 0.000534 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 4989/12542 | Batch Loss: 1.8835 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4990/12542 | Batch Loss: 0.8371 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4991/12542 | Batch Loss: 1.1881 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4992/12542 | Batch Loss: 2.1250 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4993/12542 | Batch Loss: 1.9360 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4994/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4995/12542 | Batch Loss: 1.1459 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4996/12542 | Batch Loss: 0.8591 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 4997/12542 | Batch Loss: 0.6145 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 4998/12542 | Batch Loss: 0.8775 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 4999/12542 | Batch Loss: 0.7539 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5000/12542 | Batch Loss: 0.8097 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5001/12542 | Batch Loss: 1.4258 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5002/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5003/12542 | Batch Loss: 1.4447 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5004/12542 | Batch Loss: 0.6485 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5005/12542 | Batch Loss: 1.5401 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5006/12542 | Batch Loss: 1.3030 | Learning Rate: 0.000534 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5007/12542 | Batch Loss: 1.6855 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5008/12542 | Batch Loss: 1.7343 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5009/12542 | Batch Loss: 2.1198 | Learning Rate: 0.000534 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5010/12542 | Batch Loss: 0.8336 | Learning Rate: 0.000534 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5011/12542 | Batch Loss: 0.9656 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5012/12542 | Batch Loss: 0.3646 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5013/12542 | Batch Loss: 1.1336 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5014/12542 | Batch Loss: 0.6961 | Learning Rate: 0.000533 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5015/12542 | Batch Loss: 1.3861 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5016/12542 | Batch Loss: 2.7891 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5017/12542 | Batch Loss: 0.8170 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5018/12542 | Batch Loss: 1.0495 | Learning Rate: 0.000533 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5019/12542 | Batch Loss: 1.2293 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5020/12542 | Batch Loss: 0.9319 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5021/12542 | Batch Loss: 1.4188 | Learning Rate: 0.000533 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5022/12542 | Batch Loss: 2.0022 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5023/12542 | Batch Loss: 1.9007 | Learning Rate: 0.000533 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5024/12542 | Batch Loss: 1.1110 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5025/12542 | Batch Loss: 1.6349 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5026/12542 | Batch Loss: 1.4733 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5027/12542 | Batch Loss: 1.2073 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5028/12542 | Batch Loss: 1.7498 | Learning Rate: 0.000533 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5029/12542 | Batch Loss: 1.0867 | Learning Rate: 0.000533 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5030/12542 | Batch Loss: 1.5581 | Learning Rate: 0.000533 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5031/12542 | Batch Loss: 2.1839 | Learning Rate: 0.000533 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5032/12542 | Batch Loss: 1.0918 | Learning Rate: 0.000533 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5033/12542 | Batch Loss: 0.9943 | Learning Rate: 0.000533 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5034/12542 | Batch Loss: 1.6123 | Learning Rate: 0.000533 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5035/12542 | Batch Loss: 1.4408 | Learning Rate: 0.000533 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5036/12542 | Batch Loss: 2.7720 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5037/12542 | Batch Loss: 0.8773 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5038/12542 | Batch Loss: 1.2918 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5039/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5040/12542 | Batch Loss: 1.6189 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5041/12542 | Batch Loss: 2.0224 | Learning Rate: 0.000533 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5042/12542 | Batch Loss: 1.7856 | Learning Rate: 0.000533 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5043/12542 | Batch Loss: 0.9615 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5044/12542 | Batch Loss: 1.3020 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5045/12542 | Batch Loss: 1.2884 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5046/12542 | Batch Loss: 0.7550 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5047/12542 | Batch Loss: 1.7536 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5048/12542 | Batch Loss: 0.7506 | Learning Rate: 0.000533 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5049/12542 | Batch Loss: 1.6698 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5050/12542 | Batch Loss: 1.9890 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5051/12542 | Batch Loss: 0.7688 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5052/12542 | Batch Loss: 0.5784 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5053/12542 | Batch Loss: 1.0055 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5054/12542 | Batch Loss: 1.4388 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5055/12542 | Batch Loss: 1.7851 | Learning Rate: 0.000532 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5056/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000532 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5057/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5058/12542 | Batch Loss: 0.7815 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5059/12542 | Batch Loss: 0.6025 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5060/12542 | Batch Loss: 2.9325 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5061/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000532 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5062/12542 | Batch Loss: 1.0158 | Learning Rate: 0.000532 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5063/12542 | Batch Loss: 2.2678 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5064/12542 | Batch Loss: 0.6813 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5065/12542 | Batch Loss: 1.3255 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5066/12542 | Batch Loss: 1.1418 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5067/12542 | Batch Loss: 1.3189 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5068/12542 | Batch Loss: 1.8016 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5069/12542 | Batch Loss: 0.8527 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5070/12542 | Batch Loss: 1.5040 | Learning Rate: 0.000532 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5071/12542 | Batch Loss: 0.8770 | Learning Rate: 0.000532 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5072/12542 | Batch Loss: 0.8538 | Learning Rate: 0.000532 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5073/12542 | Batch Loss: 1.7819 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5074/12542 | Batch Loss: 1.7268 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5075/12542 | Batch Loss: 1.2673 | Learning Rate: 0.000532 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5076/12542 | Batch Loss: 1.5045 | Learning Rate: 0.000532 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5077/12542 | Batch Loss: 1.3009 | Learning Rate: 0.000532 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5078/12542 | Batch Loss: 1.1643 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5079/12542 | Batch Loss: 0.6675 | Learning Rate: 0.000532 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5080/12542 | Batch Loss: 1.3447 | Learning Rate: 0.000532 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5081/12542 | Batch Loss: 1.0736 | Learning Rate: 0.000532 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5082/12542 | Batch Loss: 0.9156 | Learning Rate: 0.000532 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5083/12542 | Batch Loss: 2.3323 | Learning Rate: 0.000532 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5084/12542 | Batch Loss: 1.5806 | Learning Rate: 0.000532 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5085/12542 | Batch Loss: 0.8065 | Learning Rate: 0.000532 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5086/12542 | Batch Loss: 0.4938 | Learning Rate: 0.000531 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5087/12542 | Batch Loss: 3.4180 | Learning Rate: 0.000531 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5088/12542 | Batch Loss: 1.2968 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5089/12542 | Batch Loss: 0.8711 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5090/12542 | Batch Loss: 1.1376 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5091/12542 | Batch Loss: 2.2801 | Learning Rate: 0.000531 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5092/12542 | Batch Loss: 0.8410 | Learning Rate: 0.000531 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5093/12542 | Batch Loss: 2.6073 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5094/12542 | Batch Loss: 1.3055 | Learning Rate: 0.000531 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5095/12542 | Batch Loss: 1.1680 | Learning Rate: 0.000531 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5096/12542 | Batch Loss: 2.0640 | Learning Rate: 0.000531 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5097/12542 | Batch Loss: 1.4929 | Learning Rate: 0.000531 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5098/12542 | Batch Loss: 0.9648 | Learning Rate: 0.000531 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5099/12542 | Batch Loss: 0.7852 | Learning Rate: 0.000531 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5100/12542 | Batch Loss: 2.3567 | Learning Rate: 0.000531 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5101/12542 | Batch Loss: 1.4789 | Learning Rate: 0.000531 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5102/12542 | Batch Loss: 0.5697 | Learning Rate: 0.000531 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5103/12542 | Batch Loss: 2.4673 | Learning Rate: 0.000531 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5104/12542 | Batch Loss: 1.4446 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5105/12542 | Batch Loss: 1.3466 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5106/12542 | Batch Loss: 1.2585 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5107/12542 | Batch Loss: 3.5880 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5108/12542 | Batch Loss: 1.5398 | Learning Rate: 0.000531 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5109/12542 | Batch Loss: 0.7227 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5110/12542 | Batch Loss: 1.4858 | Learning Rate: 0.000531 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5111/12542 | Batch Loss: 1.5457 | Learning Rate: 0.000531 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5112/12542 | Batch Loss: 1.5329 | Learning Rate: 0.000531 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5113/12542 | Batch Loss: 1.3186 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5114/12542 | Batch Loss: 2.4813 | Learning Rate: 0.000531 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5115/12542 | Batch Loss: 1.2335 | Learning Rate: 0.000531 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5116/12542 | Batch Loss: 2.9493 | Learning Rate: 0.000531 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5117/12542 | Batch Loss: 0.9058 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5118/12542 | Batch Loss: 0.9120 | Learning Rate: 0.000531 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5119/12542 | Batch Loss: 1.0819 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5120/12542 | Batch Loss: 1.6355 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5121/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5122/12542 | Batch Loss: 0.5351 | Learning Rate: 0.000531 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5123/12542 | Batch Loss: 0.9877 | Learning Rate: 0.000531 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5124/12542 | Batch Loss: 0.6170 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5125/12542 | Batch Loss: 0.8972 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5126/12542 | Batch Loss: 1.4108 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5127/12542 | Batch Loss: 2.0891 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5128/12542 | Batch Loss: 1.7298 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5129/12542 | Batch Loss: 1.6092 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5130/12542 | Batch Loss: 1.3148 | Learning Rate: 0.000530 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5131/12542 | Batch Loss: 0.9660 | Learning Rate: 0.000530 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5132/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000530 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5133/12542 | Batch Loss: 2.1683 | Learning Rate: 0.000530 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5134/12542 | Batch Loss: 1.1009 | Learning Rate: 0.000530 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5135/12542 | Batch Loss: 1.8907 | Learning Rate: 0.000530 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5136/12542 | Batch Loss: 0.6865 | Learning Rate: 0.000530 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5137/12542 | Batch Loss: 1.5719 | Learning Rate: 0.000530 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5138/12542 | Batch Loss: 0.4303 | Learning Rate: 0.000530 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5139/12542 | Batch Loss: 1.0822 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5140/12542 | Batch Loss: 1.6183 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5141/12542 | Batch Loss: 1.4879 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5142/12542 | Batch Loss: 1.3707 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5143/12542 | Batch Loss: 1.6902 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5144/12542 | Batch Loss: 0.8793 | Learning Rate: 0.000530 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5145/12542 | Batch Loss: 1.2622 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5146/12542 | Batch Loss: 1.8426 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5147/12542 | Batch Loss: 1.3829 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5148/12542 | Batch Loss: 3.1721 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5149/12542 | Batch Loss: 2.0026 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5150/12542 | Batch Loss: 0.9999 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5151/12542 | Batch Loss: 1.1208 | Learning Rate: 0.000530 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5152/12542 | Batch Loss: 2.4510 | Learning Rate: 0.000530 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5153/12542 | Batch Loss: 1.5871 | Learning Rate: 0.000530 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5154/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5155/12542 | Batch Loss: 1.3778 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5156/12542 | Batch Loss: 1.6089 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5157/12542 | Batch Loss: 1.4611 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5158/12542 | Batch Loss: 0.8893 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5159/12542 | Batch Loss: 3.1449 | Learning Rate: 0.000530 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5160/12542 | Batch Loss: 1.0409 | Learning Rate: 0.000530 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5161/12542 | Batch Loss: 3.0297 | Learning Rate: 0.000530 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5162/12542 | Batch Loss: 1.4496 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5163/12542 | Batch Loss: 1.8240 | Learning Rate: 0.000529 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5164/12542 | Batch Loss: 2.0120 | Learning Rate: 0.000529 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5165/12542 | Batch Loss: 0.8553 | Learning Rate: 0.000529 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5166/12542 | Batch Loss: 1.1302 | Learning Rate: 0.000529 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5167/12542 | Batch Loss: 1.2093 | Learning Rate: 0.000529 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5168/12542 | Batch Loss: 1.4888 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5169/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5170/12542 | Batch Loss: 1.4148 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5171/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5172/12542 | Batch Loss: 1.2864 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5173/12542 | Batch Loss: 1.1425 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5174/12542 | Batch Loss: 1.5285 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5175/12542 | Batch Loss: 1.0752 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5176/12542 | Batch Loss: 1.7661 | Learning Rate: 0.000529 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5177/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000529 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5178/12542 | Batch Loss: 2.2223 | Learning Rate: 0.000529 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5179/12542 | Batch Loss: 0.6065 | Learning Rate: 0.000529 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5180/12542 | Batch Loss: 1.3959 | Learning Rate: 0.000529 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5181/12542 | Batch Loss: 0.7439 | Learning Rate: 0.000529 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5182/12542 | Batch Loss: 2.3722 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5183/12542 | Batch Loss: 0.2175 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5184/12542 | Batch Loss: 0.6132 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5185/12542 | Batch Loss: 0.7326 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5186/12542 | Batch Loss: 1.6820 | Learning Rate: 0.000529 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5187/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5188/12542 | Batch Loss: 1.9124 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5189/12542 | Batch Loss: 1.3080 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5190/12542 | Batch Loss: 1.8970 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5191/12542 | Batch Loss: 3.4702 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5192/12542 | Batch Loss: 1.2209 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5193/12542 | Batch Loss: 1.6467 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5194/12542 | Batch Loss: 2.1585 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5195/12542 | Batch Loss: 0.6041 | Learning Rate: 0.000529 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5196/12542 | Batch Loss: 1.9712 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5197/12542 | Batch Loss: 3.1339 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5198/12542 | Batch Loss: 1.5716 | Learning Rate: 0.000529 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5199/12542 | Batch Loss: 1.8868 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5200/12542 | Batch Loss: 1.6345 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5201/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5202/12542 | Batch Loss: 2.0032 | Learning Rate: 0.000528 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5203/12542 | Batch Loss: 1.5175 | Learning Rate: 0.000528 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5204/12542 | Batch Loss: 1.2803 | Learning Rate: 0.000528 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5205/12542 | Batch Loss: 0.8992 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5206/12542 | Batch Loss: 0.7535 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5207/12542 | Batch Loss: 1.9190 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5208/12542 | Batch Loss: 0.5982 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5209/12542 | Batch Loss: 1.3129 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5210/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5211/12542 | Batch Loss: 0.9844 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5212/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5213/12542 | Batch Loss: 1.5110 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5214/12542 | Batch Loss: 2.7237 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5215/12542 | Batch Loss: 1.7835 | Learning Rate: 0.000528 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 5216/12542 | Batch Loss: 1.5362 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5217/12542 | Batch Loss: 1.5940 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5218/12542 | Batch Loss: 0.8935 | Learning Rate: 0.000528 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5219/12542 | Batch Loss: 0.9842 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5220/12542 | Batch Loss: 1.1604 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5221/12542 | Batch Loss: 2.1891 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5222/12542 | Batch Loss: 1.7391 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5223/12542 | Batch Loss: 1.0947 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5224/12542 | Batch Loss: 1.2440 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5225/12542 | Batch Loss: 2.7000 | Learning Rate: 0.000528 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5226/12542 | Batch Loss: 0.7977 | Learning Rate: 0.000528 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5227/12542 | Batch Loss: 0.9980 | Learning Rate: 0.000528 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5228/12542 | Batch Loss: 0.6152 | Learning Rate: 0.000528 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5229/12542 | Batch Loss: 1.3191 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5230/12542 | Batch Loss: 2.2311 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5231/12542 | Batch Loss: 1.1590 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5232/12542 | Batch Loss: 1.3960 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5233/12542 | Batch Loss: 1.6705 | Learning Rate: 0.000528 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5234/12542 | Batch Loss: 1.0723 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5235/12542 | Batch Loss: 1.0561 | Learning Rate: 0.000528 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5236/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000528 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5237/12542 | Batch Loss: 0.6723 | Learning Rate: 0.000527 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5238/12542 | Batch Loss: 1.8828 | Learning Rate: 0.000527 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5239/12542 | Batch Loss: 1.5109 | Learning Rate: 0.000527 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5240/12542 | Batch Loss: 0.7374 | Learning Rate: 0.000527 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5241/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000527 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5242/12542 | Batch Loss: 1.4987 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5243/12542 | Batch Loss: 1.4941 | Learning Rate: 0.000527 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5244/12542 | Batch Loss: 1.8584 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5245/12542 | Batch Loss: 2.2101 | Learning Rate: 0.000527 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5246/12542 | Batch Loss: 2.0189 | Learning Rate: 0.000527 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5247/12542 | Batch Loss: 2.1915 | Learning Rate: 0.000527 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5248/12542 | Batch Loss: 1.6916 | Learning Rate: 0.000527 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5249/12542 | Batch Loss: 1.2030 | Learning Rate: 0.000527 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5250/12542 | Batch Loss: 1.7290 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5251/12542 | Batch Loss: 1.6704 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5252/12542 | Batch Loss: 1.4825 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5253/12542 | Batch Loss: 1.6556 | Learning Rate: 0.000527 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5254/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000527 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5255/12542 | Batch Loss: 0.9760 | Learning Rate: 0.000527 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5256/12542 | Batch Loss: 1.9007 | Learning Rate: 0.000527 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5257/12542 | Batch Loss: 1.2393 | Learning Rate: 0.000527 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5258/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5259/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000527 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5260/12542 | Batch Loss: 1.5869 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5261/12542 | Batch Loss: 1.0526 | Learning Rate: 0.000527 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5262/12542 | Batch Loss: 1.5372 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5263/12542 | Batch Loss: 0.8595 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5264/12542 | Batch Loss: 0.8296 | Learning Rate: 0.000527 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5265/12542 | Batch Loss: 0.5986 | Learning Rate: 0.000527 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5266/12542 | Batch Loss: 0.9145 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5267/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5268/12542 | Batch Loss: 1.7112 | Learning Rate: 0.000527 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5269/12542 | Batch Loss: 1.3076 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5270/12542 | Batch Loss: 0.8907 | Learning Rate: 0.000527 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5271/12542 | Batch Loss: 2.4277 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5272/12542 | Batch Loss: 1.4928 | Learning Rate: 0.000527 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5273/12542 | Batch Loss: 0.8667 | Learning Rate: 0.000527 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5274/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000526 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5275/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000526 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5276/12542 | Batch Loss: 2.1187 | Learning Rate: 0.000526 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5277/12542 | Batch Loss: 0.7767 | Learning Rate: 0.000526 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5278/12542 | Batch Loss: 1.6047 | Learning Rate: 0.000526 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5279/12542 | Batch Loss: 0.3837 | Learning Rate: 0.000526 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5280/12542 | Batch Loss: 1.4682 | Learning Rate: 0.000526 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5281/12542 | Batch Loss: 0.8123 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5282/12542 | Batch Loss: 0.6018 | Learning Rate: 0.000526 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5283/12542 | Batch Loss: 1.4881 | Learning Rate: 0.000526 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5284/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000526 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5285/12542 | Batch Loss: 1.0573 | Learning Rate: 0.000526 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5286/12542 | Batch Loss: 1.1222 | Learning Rate: 0.000526 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5287/12542 | Batch Loss: 1.2087 | Learning Rate: 0.000526 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5288/12542 | Batch Loss: 0.7806 | Learning Rate: 0.000526 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5289/12542 | Batch Loss: 1.3396 | Learning Rate: 0.000526 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5290/12542 | Batch Loss: 1.2424 | Learning Rate: 0.000526 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5291/12542 | Batch Loss: 3.4193 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5292/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000526 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5293/12542 | Batch Loss: 1.3720 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5294/12542 | Batch Loss: 0.8654 | Learning Rate: 0.000526 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5295/12542 | Batch Loss: 1.4828 | Learning Rate: 0.000526 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5296/12542 | Batch Loss: 1.9416 | Learning Rate: 0.000526 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5297/12542 | Batch Loss: 0.4693 | Learning Rate: 0.000526 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5298/12542 | Batch Loss: 0.5923 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5299/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000526 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5300/12542 | Batch Loss: 0.9617 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5301/12542 | Batch Loss: 1.4937 | Learning Rate: 0.000526 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5302/12542 | Batch Loss: 1.3305 | Learning Rate: 0.000526 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5303/12542 | Batch Loss: 1.8269 | Learning Rate: 0.000526 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5304/12542 | Batch Loss: 1.1184 | Learning Rate: 0.000526 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5305/12542 | Batch Loss: 1.0100 | Learning Rate: 0.000526 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5306/12542 | Batch Loss: 1.0998 | Learning Rate: 0.000526 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5307/12542 | Batch Loss: 1.9425 | Learning Rate: 0.000526 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5308/12542 | Batch Loss: 2.2793 | Learning Rate: 0.000526 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5309/12542 | Batch Loss: 1.0016 | Learning Rate: 0.000526 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5310/12542 | Batch Loss: 0.8585 | Learning Rate: 0.000526 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5311/12542 | Batch Loss: 2.5618 | Learning Rate: 0.000526 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5312/12542 | Batch Loss: 2.8313 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5313/12542 | Batch Loss: 2.5743 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5314/12542 | Batch Loss: 1.4327 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5315/12542 | Batch Loss: 0.8404 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5316/12542 | Batch Loss: 1.1505 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5317/12542 | Batch Loss: 0.5155 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5318/12542 | Batch Loss: 0.8938 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5319/12542 | Batch Loss: 1.1770 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5320/12542 | Batch Loss: 0.9159 | Learning Rate: 0.000525 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5321/12542 | Batch Loss: 0.6183 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5322/12542 | Batch Loss: 0.6073 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5323/12542 | Batch Loss: 1.9686 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5324/12542 | Batch Loss: 2.6540 | Learning Rate: 0.000525 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5325/12542 | Batch Loss: 0.9376 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5326/12542 | Batch Loss: 1.4828 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5327/12542 | Batch Loss: 1.1690 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5328/12542 | Batch Loss: 1.0910 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5329/12542 | Batch Loss: 1.2729 | Learning Rate: 0.000525 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5330/12542 | Batch Loss: 0.8040 | Learning Rate: 0.000525 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5331/12542 | Batch Loss: 0.8484 | Learning Rate: 0.000525 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5332/12542 | Batch Loss: 1.5355 | Learning Rate: 0.000525 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5333/12542 | Batch Loss: 1.2644 | Learning Rate: 0.000525 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5334/12542 | Batch Loss: 1.5369 | Learning Rate: 0.000525 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5335/12542 | Batch Loss: 0.7375 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5336/12542 | Batch Loss: 0.5930 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5337/12542 | Batch Loss: 1.2534 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5338/12542 | Batch Loss: 0.9800 | Learning Rate: 0.000525 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5339/12542 | Batch Loss: 1.3232 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5340/12542 | Batch Loss: 2.0182 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5341/12542 | Batch Loss: 0.8052 | Learning Rate: 0.000525 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5342/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5343/12542 | Batch Loss: 0.9404 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5344/12542 | Batch Loss: 1.0537 | Learning Rate: 0.000525 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5345/12542 | Batch Loss: 1.6299 | Learning Rate: 0.000525 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5346/12542 | Batch Loss: 1.7682 | Learning Rate: 0.000525 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5347/12542 | Batch Loss: 1.6737 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5348/12542 | Batch Loss: 1.1660 | Learning Rate: 0.000525 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5349/12542 | Batch Loss: 1.3615 | Learning Rate: 0.000525 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5350/12542 | Batch Loss: 1.1933 | Learning Rate: 0.000524 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5351/12542 | Batch Loss: 3.9178 | Learning Rate: 0.000524 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5352/12542 | Batch Loss: 1.3732 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5353/12542 | Batch Loss: 1.4867 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5354/12542 | Batch Loss: 0.7682 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5355/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000524 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5356/12542 | Batch Loss: 0.9799 | Learning Rate: 0.000524 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5357/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000524 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5358/12542 | Batch Loss: 3.3391 | Learning Rate: 0.000524 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5359/12542 | Batch Loss: 1.7522 | Learning Rate: 0.000524 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5360/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000524 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5361/12542 | Batch Loss: 1.8778 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5362/12542 | Batch Loss: 2.2036 | Learning Rate: 0.000524 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5363/12542 | Batch Loss: 1.1189 | Learning Rate: 0.000524 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 5364/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000524 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5365/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000524 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5366/12542 | Batch Loss: 0.6449 | Learning Rate: 0.000524 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5367/12542 | Batch Loss: 0.3902 | Learning Rate: 0.000524 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5368/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000524 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5369/12542 | Batch Loss: 1.2369 | Learning Rate: 0.000524 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5370/12542 | Batch Loss: 0.4768 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5371/12542 | Batch Loss: 2.4563 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5372/12542 | Batch Loss: 1.9553 | Learning Rate: 0.000524 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5373/12542 | Batch Loss: 1.3216 | Learning Rate: 0.000524 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5374/12542 | Batch Loss: 0.4649 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5375/12542 | Batch Loss: 1.4013 | Learning Rate: 0.000524 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5376/12542 | Batch Loss: 0.6071 | Learning Rate: 0.000524 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5377/12542 | Batch Loss: 1.0496 | Learning Rate: 0.000524 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5378/12542 | Batch Loss: 3.1454 | Learning Rate: 0.000524 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5379/12542 | Batch Loss: 1.2332 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5380/12542 | Batch Loss: 1.8229 | Learning Rate: 0.000524 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5381/12542 | Batch Loss: 1.4924 | Learning Rate: 0.000524 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5382/12542 | Batch Loss: 1.3911 | Learning Rate: 0.000524 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5383/12542 | Batch Loss: 2.0215 | Learning Rate: 0.000524 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5384/12542 | Batch Loss: 2.9564 | Learning Rate: 0.000524 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5385/12542 | Batch Loss: 1.5647 | Learning Rate: 0.000524 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5386/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000524 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5387/12542 | Batch Loss: 2.2308 | Learning Rate: 0.000523 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5388/12542 | Batch Loss: 0.7693 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5389/12542 | Batch Loss: 1.4995 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5390/12542 | Batch Loss: 1.5546 | Learning Rate: 0.000523 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5391/12542 | Batch Loss: 1.0658 | Learning Rate: 0.000523 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5392/12542 | Batch Loss: 1.6204 | Learning Rate: 0.000523 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5393/12542 | Batch Loss: 1.1332 | Learning Rate: 0.000523 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5394/12542 | Batch Loss: 1.3797 | Learning Rate: 0.000523 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5395/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000523 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5396/12542 | Batch Loss: 0.7240 | Learning Rate: 0.000523 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5397/12542 | Batch Loss: 1.4085 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5398/12542 | Batch Loss: 0.5091 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5399/12542 | Batch Loss: 2.1238 | Learning Rate: 0.000523 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5400/12542 | Batch Loss: 1.2805 | Learning Rate: 0.000523 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5401/12542 | Batch Loss: 1.6723 | Learning Rate: 0.000523 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5402/12542 | Batch Loss: 1.4631 | Learning Rate: 0.000523 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5403/12542 | Batch Loss: 1.1373 | Learning Rate: 0.000523 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5404/12542 | Batch Loss: 2.0297 | Learning Rate: 0.000523 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5405/12542 | Batch Loss: 2.4075 | Learning Rate: 0.000523 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5406/12542 | Batch Loss: 0.6299 | Learning Rate: 0.000523 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5407/12542 | Batch Loss: 1.9802 | Learning Rate: 0.000523 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5408/12542 | Batch Loss: 1.2107 | Learning Rate: 0.000523 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5409/12542 | Batch Loss: 0.9750 | Learning Rate: 0.000523 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5410/12542 | Batch Loss: 1.7423 | Learning Rate: 0.000523 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5411/12542 | Batch Loss: 1.7945 | Learning Rate: 0.000523 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5412/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000523 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5413/12542 | Batch Loss: 1.0195 | Learning Rate: 0.000523 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5414/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000523 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5415/12542 | Batch Loss: 1.1188 | Learning Rate: 0.000523 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5416/12542 | Batch Loss: 0.9351 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5417/12542 | Batch Loss: 1.5610 | Learning Rate: 0.000523 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5418/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000523 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5419/12542 | Batch Loss: 1.7721 | Learning Rate: 0.000523 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5420/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000523 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5421/12542 | Batch Loss: 0.9776 | Learning Rate: 0.000523 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5422/12542 | Batch Loss: 0.7157 | Learning Rate: 0.000523 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5423/12542 | Batch Loss: 1.0819 | Learning Rate: 0.000523 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5424/12542 | Batch Loss: 1.5835 | Learning Rate: 0.000523 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5425/12542 | Batch Loss: 1.3860 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5426/12542 | Batch Loss: 1.1669 | Learning Rate: 0.000522 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5427/12542 | Batch Loss: 1.6055 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5428/12542 | Batch Loss: 0.7553 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5429/12542 | Batch Loss: 1.1797 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5430/12542 | Batch Loss: 1.1044 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5431/12542 | Batch Loss: 2.2163 | Learning Rate: 0.000522 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5432/12542 | Batch Loss: 1.7355 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5433/12542 | Batch Loss: 1.5593 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5434/12542 | Batch Loss: 0.9633 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5435/12542 | Batch Loss: 1.3990 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5436/12542 | Batch Loss: 0.7435 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5437/12542 | Batch Loss: 1.7143 | Learning Rate: 0.000522 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5438/12542 | Batch Loss: 1.2022 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5439/12542 | Batch Loss: 0.3922 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5440/12542 | Batch Loss: 1.4831 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5441/12542 | Batch Loss: 1.3253 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5442/12542 | Batch Loss: 1.7997 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5443/12542 | Batch Loss: 1.5590 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5444/12542 | Batch Loss: 1.1566 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5445/12542 | Batch Loss: 2.1306 | Learning Rate: 0.000522 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5446/12542 | Batch Loss: 0.6306 | Learning Rate: 0.000522 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5447/12542 | Batch Loss: 0.7133 | Learning Rate: 0.000522 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5448/12542 | Batch Loss: 0.7860 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5449/12542 | Batch Loss: 1.5024 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5450/12542 | Batch Loss: 1.0942 | Learning Rate: 0.000522 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5451/12542 | Batch Loss: 2.2680 | Learning Rate: 0.000522 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5452/12542 | Batch Loss: 0.5459 | Learning Rate: 0.000522 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5453/12542 | Batch Loss: 1.7411 | Learning Rate: 0.000522 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5454/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000522 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5455/12542 | Batch Loss: 1.7416 | Learning Rate: 0.000522 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5456/12542 | Batch Loss: 1.8738 | Learning Rate: 0.000522 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5457/12542 | Batch Loss: 2.2998 | Learning Rate: 0.000522 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5458/12542 | Batch Loss: 0.7602 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5459/12542 | Batch Loss: 1.3912 | Learning Rate: 0.000522 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5460/12542 | Batch Loss: 0.9459 | Learning Rate: 0.000522 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5461/12542 | Batch Loss: 1.4255 | Learning Rate: 0.000522 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5462/12542 | Batch Loss: 1.1283 | Learning Rate: 0.000522 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5463/12542 | Batch Loss: 1.5131 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5464/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000521 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5465/12542 | Batch Loss: 1.1817 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5466/12542 | Batch Loss: 1.5090 | Learning Rate: 0.000521 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5467/12542 | Batch Loss: 0.8287 | Learning Rate: 0.000521 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 5468/12542 | Batch Loss: 1.5976 | Learning Rate: 0.000521 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5469/12542 | Batch Loss: 1.3245 | Learning Rate: 0.000521 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5470/12542 | Batch Loss: 0.7569 | Learning Rate: 0.000521 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5471/12542 | Batch Loss: 0.9688 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5472/12542 | Batch Loss: 0.5000 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5473/12542 | Batch Loss: 2.1524 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5474/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5475/12542 | Batch Loss: 0.7568 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5476/12542 | Batch Loss: 0.8408 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5477/12542 | Batch Loss: 1.5222 | Learning Rate: 0.000521 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5478/12542 | Batch Loss: 0.5483 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5479/12542 | Batch Loss: 0.8798 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5480/12542 | Batch Loss: 1.9616 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5481/12542 | Batch Loss: 1.3846 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5482/12542 | Batch Loss: 0.8464 | Learning Rate: 0.000521 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5483/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000521 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5484/12542 | Batch Loss: 1.1853 | Learning Rate: 0.000521 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5485/12542 | Batch Loss: 1.8029 | Learning Rate: 0.000521 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5486/12542 | Batch Loss: 2.2441 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5487/12542 | Batch Loss: 2.0619 | Learning Rate: 0.000521 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5488/12542 | Batch Loss: 1.6860 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5489/12542 | Batch Loss: 1.4693 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5490/12542 | Batch Loss: 1.7665 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5491/12542 | Batch Loss: 1.3427 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5492/12542 | Batch Loss: 0.6773 | Learning Rate: 0.000521 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5493/12542 | Batch Loss: 1.0428 | Learning Rate: 0.000521 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5494/12542 | Batch Loss: 1.4249 | Learning Rate: 0.000521 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5495/12542 | Batch Loss: 0.8754 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5496/12542 | Batch Loss: 1.6887 | Learning Rate: 0.000521 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5497/12542 | Batch Loss: 1.0218 | Learning Rate: 0.000521 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5498/12542 | Batch Loss: 2.0327 | Learning Rate: 0.000521 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5499/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000521 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5500/12542 | Batch Loss: 1.8675 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5501/12542 | Batch Loss: 1.0356 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5502/12542 | Batch Loss: 0.8904 | Learning Rate: 0.000520 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5503/12542 | Batch Loss: 0.6672 | Learning Rate: 0.000520 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5504/12542 | Batch Loss: 0.8937 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5505/12542 | Batch Loss: 1.7684 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5506/12542 | Batch Loss: 1.5533 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5507/12542 | Batch Loss: 1.4482 | Learning Rate: 0.000520 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5508/12542 | Batch Loss: 0.6819 | Learning Rate: 0.000520 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5509/12542 | Batch Loss: 0.6281 | Learning Rate: 0.000520 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5510/12542 | Batch Loss: 1.3999 | Learning Rate: 0.000520 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5511/12542 | Batch Loss: 1.1832 | Learning Rate: 0.000520 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5512/12542 | Batch Loss: 1.8423 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5513/12542 | Batch Loss: 0.6221 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5514/12542 | Batch Loss: 2.5936 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5515/12542 | Batch Loss: 1.1294 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5516/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5517/12542 | Batch Loss: 1.6621 | Learning Rate: 0.000520 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5518/12542 | Batch Loss: 0.5845 | Learning Rate: 0.000520 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5519/12542 | Batch Loss: 1.3099 | Learning Rate: 0.000520 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5520/12542 | Batch Loss: 1.4023 | Learning Rate: 0.000520 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5521/12542 | Batch Loss: 0.5140 | Learning Rate: 0.000520 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5522/12542 | Batch Loss: 1.1284 | Learning Rate: 0.000520 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5523/12542 | Batch Loss: 1.0804 | Learning Rate: 0.000520 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5524/12542 | Batch Loss: 2.3846 | Learning Rate: 0.000520 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5525/12542 | Batch Loss: 1.4191 | Learning Rate: 0.000520 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5526/12542 | Batch Loss: 0.7598 | Learning Rate: 0.000520 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5527/12542 | Batch Loss: 0.9821 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5528/12542 | Batch Loss: 0.6748 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5529/12542 | Batch Loss: 0.9355 | Learning Rate: 0.000520 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5530/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5531/12542 | Batch Loss: 2.4702 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5532/12542 | Batch Loss: 0.9392 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5533/12542 | Batch Loss: 1.5613 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5534/12542 | Batch Loss: 2.9058 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5535/12542 | Batch Loss: 0.8247 | Learning Rate: 0.000520 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5536/12542 | Batch Loss: 2.4186 | Learning Rate: 0.000520 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5537/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000520 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5538/12542 | Batch Loss: 0.6191 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5539/12542 | Batch Loss: 0.5836 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5540/12542 | Batch Loss: 1.7290 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5541/12542 | Batch Loss: 1.1031 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5542/12542 | Batch Loss: 1.6261 | Learning Rate: 0.000519 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5543/12542 | Batch Loss: 1.1443 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5544/12542 | Batch Loss: 1.6353 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5545/12542 | Batch Loss: 1.7070 | Learning Rate: 0.000519 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5546/12542 | Batch Loss: 0.6043 | Learning Rate: 0.000519 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5547/12542 | Batch Loss: 0.8924 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5548/12542 | Batch Loss: 2.1355 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5549/12542 | Batch Loss: 0.8713 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5550/12542 | Batch Loss: 1.0823 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5551/12542 | Batch Loss: 1.2857 | Learning Rate: 0.000519 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5552/12542 | Batch Loss: 0.5323 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5553/12542 | Batch Loss: 1.0490 | Learning Rate: 0.000519 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5554/12542 | Batch Loss: 1.3556 | Learning Rate: 0.000519 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5555/12542 | Batch Loss: 1.0945 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5556/12542 | Batch Loss: 1.6663 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5557/12542 | Batch Loss: 0.5134 | Learning Rate: 0.000519 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5558/12542 | Batch Loss: 0.5984 | Learning Rate: 0.000519 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5559/12542 | Batch Loss: 3.2048 | Learning Rate: 0.000519 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5560/12542 | Batch Loss: 0.8589 | Learning Rate: 0.000519 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5561/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5562/12542 | Batch Loss: 1.2185 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5563/12542 | Batch Loss: 0.8961 | Learning Rate: 0.000519 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5564/12542 | Batch Loss: 2.0068 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5565/12542 | Batch Loss: 1.6331 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5566/12542 | Batch Loss: 1.4022 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5567/12542 | Batch Loss: 3.0690 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5568/12542 | Batch Loss: 1.6476 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5569/12542 | Batch Loss: 0.6804 | Learning Rate: 0.000519 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5570/12542 | Batch Loss: 1.2900 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5571/12542 | Batch Loss: 0.7499 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5572/12542 | Batch Loss: 2.0355 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5573/12542 | Batch Loss: 1.8771 | Learning Rate: 0.000519 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5574/12542 | Batch Loss: 1.2695 | Learning Rate: 0.000519 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5575/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5576/12542 | Batch Loss: 1.2122 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5577/12542 | Batch Loss: 1.6458 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5578/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000518 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5579/12542 | Batch Loss: 0.8283 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5580/12542 | Batch Loss: 1.0565 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5581/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5582/12542 | Batch Loss: 1.7247 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5583/12542 | Batch Loss: 1.0603 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5584/12542 | Batch Loss: 3.4165 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5585/12542 | Batch Loss: 0.8284 | Learning Rate: 0.000518 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5586/12542 | Batch Loss: 1.7565 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5587/12542 | Batch Loss: 0.8867 | Learning Rate: 0.000518 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5588/12542 | Batch Loss: 0.8740 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5589/12542 | Batch Loss: 2.2559 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5590/12542 | Batch Loss: 0.6779 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5591/12542 | Batch Loss: 2.2263 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5592/12542 | Batch Loss: 1.1012 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5593/12542 | Batch Loss: 1.1427 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5594/12542 | Batch Loss: 1.0343 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5595/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000518 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5596/12542 | Batch Loss: 0.4339 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5597/12542 | Batch Loss: 1.2269 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5598/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5599/12542 | Batch Loss: 1.2866 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5600/12542 | Batch Loss: 0.7486 | Learning Rate: 0.000518 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5601/12542 | Batch Loss: 1.5899 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5602/12542 | Batch Loss: 2.1920 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5603/12542 | Batch Loss: 1.3018 | Learning Rate: 0.000518 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5604/12542 | Batch Loss: 0.7335 | Learning Rate: 0.000518 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5605/12542 | Batch Loss: 1.0332 | Learning Rate: 0.000518 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5606/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000518 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5607/12542 | Batch Loss: 1.1474 | Learning Rate: 0.000518 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5608/12542 | Batch Loss: 2.9882 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5609/12542 | Batch Loss: 0.8742 | Learning Rate: 0.000518 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5610/12542 | Batch Loss: 2.0973 | Learning Rate: 0.000518 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5611/12542 | Batch Loss: 0.6065 | Learning Rate: 0.000518 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5612/12542 | Batch Loss: 0.6429 | Learning Rate: 0.000518 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5613/12542 | Batch Loss: 1.7498 | Learning Rate: 0.000517 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5614/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5615/12542 | Batch Loss: 1.6529 | Learning Rate: 0.000517 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5616/12542 | Batch Loss: 1.9303 | Learning Rate: 0.000517 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5617/12542 | Batch Loss: 1.5386 | Learning Rate: 0.000517 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5618/12542 | Batch Loss: 1.7613 | Learning Rate: 0.000517 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5619/12542 | Batch Loss: 0.5579 | Learning Rate: 0.000517 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5620/12542 | Batch Loss: 0.8911 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5621/12542 | Batch Loss: 1.0129 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5622/12542 | Batch Loss: 1.3740 | Learning Rate: 0.000517 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5623/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000517 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5624/12542 | Batch Loss: 1.1637 | Learning Rate: 0.000517 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5625/12542 | Batch Loss: 1.0884 | Learning Rate: 0.000517 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5626/12542 | Batch Loss: 0.5720 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5627/12542 | Batch Loss: 0.9891 | Learning Rate: 0.000517 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5628/12542 | Batch Loss: 1.2919 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5629/12542 | Batch Loss: 0.8027 | Learning Rate: 0.000517 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5630/12542 | Batch Loss: 2.8499 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5631/12542 | Batch Loss: 0.7957 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5632/12542 | Batch Loss: 1.3836 | Learning Rate: 0.000517 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5633/12542 | Batch Loss: 1.1583 | Learning Rate: 0.000517 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5634/12542 | Batch Loss: 1.3420 | Learning Rate: 0.000517 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5635/12542 | Batch Loss: 1.6900 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5636/12542 | Batch Loss: 0.9300 | Learning Rate: 0.000517 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5637/12542 | Batch Loss: 1.6856 | Learning Rate: 0.000517 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5638/12542 | Batch Loss: 0.5791 | Learning Rate: 0.000517 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5639/12542 | Batch Loss: 1.4634 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5640/12542 | Batch Loss: 1.2861 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5641/12542 | Batch Loss: 0.6443 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5642/12542 | Batch Loss: 1.6981 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5643/12542 | Batch Loss: 0.7387 | Learning Rate: 0.000517 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5644/12542 | Batch Loss: 1.1620 | Learning Rate: 0.000517 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5645/12542 | Batch Loss: 0.5523 | Learning Rate: 0.000517 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5646/12542 | Batch Loss: 1.1747 | Learning Rate: 0.000517 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5647/12542 | Batch Loss: 0.8268 | Learning Rate: 0.000517 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5648/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000517 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5649/12542 | Batch Loss: 1.1953 | Learning Rate: 0.000517 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5650/12542 | Batch Loss: 1.8490 | Learning Rate: 0.000517 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5651/12542 | Batch Loss: 0.4169 | Learning Rate: 0.000516 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5652/12542 | Batch Loss: 1.2021 | Learning Rate: 0.000516 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5653/12542 | Batch Loss: 1.2313 | Learning Rate: 0.000516 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5654/12542 | Batch Loss: 1.1622 | Learning Rate: 0.000516 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5655/12542 | Batch Loss: 1.6710 | Learning Rate: 0.000516 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5656/12542 | Batch Loss: 1.3656 | Learning Rate: 0.000516 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5657/12542 | Batch Loss: 1.4455 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5658/12542 | Batch Loss: 1.6313 | Learning Rate: 0.000516 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5659/12542 | Batch Loss: 1.3678 | Learning Rate: 0.000516 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5660/12542 | Batch Loss: 0.7201 | Learning Rate: 0.000516 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5661/12542 | Batch Loss: 1.5717 | Learning Rate: 0.000516 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5662/12542 | Batch Loss: 1.4363 | Learning Rate: 0.000516 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5663/12542 | Batch Loss: 0.7490 | Learning Rate: 0.000516 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5664/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000516 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5665/12542 | Batch Loss: 0.9124 | Learning Rate: 0.000516 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5666/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000516 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5667/12542 | Batch Loss: 0.5276 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5668/12542 | Batch Loss: 0.7811 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5669/12542 | Batch Loss: 2.1716 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5670/12542 | Batch Loss: 1.4156 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5671/12542 | Batch Loss: 1.6218 | Learning Rate: 0.000516 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5672/12542 | Batch Loss: 1.5451 | Learning Rate: 0.000516 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5673/12542 | Batch Loss: 0.8909 | Learning Rate: 0.000516 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5674/12542 | Batch Loss: 0.5677 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5675/12542 | Batch Loss: 0.8043 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5676/12542 | Batch Loss: 0.7357 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5677/12542 | Batch Loss: 1.0136 | Learning Rate: 0.000516 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5678/12542 | Batch Loss: 0.6551 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5679/12542 | Batch Loss: 1.2625 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5680/12542 | Batch Loss: 0.8970 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5681/12542 | Batch Loss: 0.8553 | Learning Rate: 0.000516 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5682/12542 | Batch Loss: 1.8411 | Learning Rate: 0.000516 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5683/12542 | Batch Loss: 0.8838 | Learning Rate: 0.000516 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5684/12542 | Batch Loss: 1.6335 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5685/12542 | Batch Loss: 3.1446 | Learning Rate: 0.000516 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5686/12542 | Batch Loss: 1.0639 | Learning Rate: 0.000516 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5687/12542 | Batch Loss: 1.1333 | Learning Rate: 0.000516 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5688/12542 | Batch Loss: 1.5793 | Learning Rate: 0.000515 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5689/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000515 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5690/12542 | Batch Loss: 0.4714 | Learning Rate: 0.000515 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5691/12542 | Batch Loss: 1.6277 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5692/12542 | Batch Loss: 1.3998 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5693/12542 | Batch Loss: 1.2537 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5694/12542 | Batch Loss: 1.2060 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5695/12542 | Batch Loss: 1.7028 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5696/12542 | Batch Loss: 0.4205 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5697/12542 | Batch Loss: 0.7357 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5698/12542 | Batch Loss: 1.1066 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5699/12542 | Batch Loss: 0.5774 | Learning Rate: 0.000515 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5700/12542 | Batch Loss: 0.7581 | Learning Rate: 0.000515 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5701/12542 | Batch Loss: 1.3451 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5702/12542 | Batch Loss: 0.9793 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5703/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000515 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5704/12542 | Batch Loss: 0.7187 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5705/12542 | Batch Loss: 2.2015 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5706/12542 | Batch Loss: 1.0176 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5707/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5708/12542 | Batch Loss: 1.6415 | Learning Rate: 0.000515 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5709/12542 | Batch Loss: 1.6393 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5710/12542 | Batch Loss: 0.7615 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5711/12542 | Batch Loss: 0.9592 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5712/12542 | Batch Loss: 2.0222 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5713/12542 | Batch Loss: 1.1953 | Learning Rate: 0.000515 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5714/12542 | Batch Loss: 1.2182 | Learning Rate: 0.000515 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5715/12542 | Batch Loss: 5.0959 | Learning Rate: 0.000515 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5716/12542 | Batch Loss: 1.9165 | Learning Rate: 0.000515 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5717/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000515 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5718/12542 | Batch Loss: 0.6561 | Learning Rate: 0.000515 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5719/12542 | Batch Loss: 0.9692 | Learning Rate: 0.000515 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5720/12542 | Batch Loss: 1.5454 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5721/12542 | Batch Loss: 1.4181 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5722/12542 | Batch Loss: 3.5458 | Learning Rate: 0.000515 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5723/12542 | Batch Loss: 0.5717 | Learning Rate: 0.000515 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5724/12542 | Batch Loss: 2.0218 | Learning Rate: 0.000515 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5725/12542 | Batch Loss: 1.3418 | Learning Rate: 0.000515 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5726/12542 | Batch Loss: 0.8233 | Learning Rate: 0.000514 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5727/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000514 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5728/12542 | Batch Loss: 3.2077 | Learning Rate: 0.000514 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5729/12542 | Batch Loss: 2.5587 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5730/12542 | Batch Loss: 1.8309 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5731/12542 | Batch Loss: 1.3269 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5732/12542 | Batch Loss: 1.9543 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5733/12542 | Batch Loss: 1.3460 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5734/12542 | Batch Loss: 1.4631 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5735/12542 | Batch Loss: 0.8251 | Learning Rate: 0.000514 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5736/12542 | Batch Loss: 1.9058 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5737/12542 | Batch Loss: 1.3118 | Learning Rate: 0.000514 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5738/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5739/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5740/12542 | Batch Loss: 1.3826 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5741/12542 | Batch Loss: 2.3670 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5742/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5743/12542 | Batch Loss: 1.9726 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5744/12542 | Batch Loss: 0.9652 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5745/12542 | Batch Loss: 1.5761 | Learning Rate: 0.000514 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5746/12542 | Batch Loss: 0.5138 | Learning Rate: 0.000514 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5747/12542 | Batch Loss: 1.8058 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5748/12542 | Batch Loss: 2.8361 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5749/12542 | Batch Loss: 3.2718 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5750/12542 | Batch Loss: 2.5848 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5751/12542 | Batch Loss: 0.5183 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5752/12542 | Batch Loss: 2.0452 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5753/12542 | Batch Loss: 1.2291 | Learning Rate: 0.000514 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5754/12542 | Batch Loss: 1.7638 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5755/12542 | Batch Loss: 1.5256 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5756/12542 | Batch Loss: 1.7366 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5757/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5758/12542 | Batch Loss: 1.3433 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5759/12542 | Batch Loss: 0.8289 | Learning Rate: 0.000514 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5760/12542 | Batch Loss: 1.2661 | Learning Rate: 0.000514 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5761/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000514 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5762/12542 | Batch Loss: 1.5539 | Learning Rate: 0.000514 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5763/12542 | Batch Loss: 1.8972 | Learning Rate: 0.000514 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5764/12542 | Batch Loss: 1.2677 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5765/12542 | Batch Loss: 1.0375 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5766/12542 | Batch Loss: 1.5449 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5767/12542 | Batch Loss: 0.7125 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5768/12542 | Batch Loss: 1.1006 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5769/12542 | Batch Loss: 1.3175 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5770/12542 | Batch Loss: 1.6975 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5771/12542 | Batch Loss: 0.4563 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5772/12542 | Batch Loss: 1.6677 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5773/12542 | Batch Loss: 1.5889 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5774/12542 | Batch Loss: 0.5176 | Learning Rate: 0.000513 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5775/12542 | Batch Loss: 1.6123 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5776/12542 | Batch Loss: 0.8474 | Learning Rate: 0.000513 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5777/12542 | Batch Loss: 2.6463 | Learning Rate: 0.000513 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5778/12542 | Batch Loss: 0.8190 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5779/12542 | Batch Loss: 0.8814 | Learning Rate: 0.000513 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5780/12542 | Batch Loss: 0.6788 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5781/12542 | Batch Loss: 1.0837 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5782/12542 | Batch Loss: 1.2382 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5783/12542 | Batch Loss: 1.6183 | Learning Rate: 0.000513 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5784/12542 | Batch Loss: 0.7137 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5785/12542 | Batch Loss: 1.7142 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5786/12542 | Batch Loss: 1.2911 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5787/12542 | Batch Loss: 0.9236 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5788/12542 | Batch Loss: 1.8007 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5789/12542 | Batch Loss: 1.8781 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5790/12542 | Batch Loss: 0.8071 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5791/12542 | Batch Loss: 1.2007 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5792/12542 | Batch Loss: 0.6260 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5793/12542 | Batch Loss: 1.1286 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5794/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5795/12542 | Batch Loss: 0.9703 | Learning Rate: 0.000513 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5796/12542 | Batch Loss: 3.4690 | Learning Rate: 0.000513 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5797/12542 | Batch Loss: 1.6521 | Learning Rate: 0.000513 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5798/12542 | Batch Loss: 1.0892 | Learning Rate: 0.000513 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5799/12542 | Batch Loss: 1.1075 | Learning Rate: 0.000513 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5800/12542 | Batch Loss: 0.3646 | Learning Rate: 0.000513 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5801/12542 | Batch Loss: 1.2503 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5802/12542 | Batch Loss: 1.7129 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5803/12542 | Batch Loss: 1.3492 | Learning Rate: 0.000512 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5804/12542 | Batch Loss: 1.9828 | Learning Rate: 0.000512 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5805/12542 | Batch Loss: 1.7244 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5806/12542 | Batch Loss: 1.0327 | Learning Rate: 0.000512 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5807/12542 | Batch Loss: 1.1333 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5808/12542 | Batch Loss: 1.3827 | Learning Rate: 0.000512 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5809/12542 | Batch Loss: 0.4352 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5810/12542 | Batch Loss: 0.9071 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5811/12542 | Batch Loss: 0.5105 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5812/12542 | Batch Loss: 0.6288 | Learning Rate: 0.000512 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5813/12542 | Batch Loss: 1.1304 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5814/12542 | Batch Loss: 1.2331 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5815/12542 | Batch Loss: 1.2441 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5816/12542 | Batch Loss: 2.9961 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5817/12542 | Batch Loss: 1.0132 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5818/12542 | Batch Loss: 1.3353 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5819/12542 | Batch Loss: 0.6205 | Learning Rate: 0.000512 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5820/12542 | Batch Loss: 1.5498 | Learning Rate: 0.000512 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5821/12542 | Batch Loss: 0.7670 | Learning Rate: 0.000512 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5822/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000512 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5823/12542 | Batch Loss: 1.3096 | Learning Rate: 0.000512 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5824/12542 | Batch Loss: 0.5889 | Learning Rate: 0.000512 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5825/12542 | Batch Loss: 0.9451 | Learning Rate: 0.000512 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5826/12542 | Batch Loss: 0.9641 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5827/12542 | Batch Loss: 1.0906 | Learning Rate: 0.000512 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5828/12542 | Batch Loss: 1.6917 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5829/12542 | Batch Loss: 0.6623 | Learning Rate: 0.000512 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5830/12542 | Batch Loss: 1.5152 | Learning Rate: 0.000512 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5831/12542 | Batch Loss: 1.5627 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5832/12542 | Batch Loss: 0.7715 | Learning Rate: 0.000512 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5833/12542 | Batch Loss: 0.8192 | Learning Rate: 0.000512 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5834/12542 | Batch Loss: 2.6621 | Learning Rate: 0.000512 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5835/12542 | Batch Loss: 1.0282 | Learning Rate: 0.000512 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5836/12542 | Batch Loss: 2.0318 | Learning Rate: 0.000512 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5837/12542 | Batch Loss: 2.5083 | Learning Rate: 0.000512 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5838/12542 | Batch Loss: 1.7646 | Learning Rate: 0.000512 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5839/12542 | Batch Loss: 3.7403 | Learning Rate: 0.000511 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5840/12542 | Batch Loss: 0.7277 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5841/12542 | Batch Loss: 1.8462 | Learning Rate: 0.000511 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5842/12542 | Batch Loss: 1.8640 | Learning Rate: 0.000511 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5843/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000511 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5844/12542 | Batch Loss: 0.7645 | Learning Rate: 0.000511 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5845/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5846/12542 | Batch Loss: 1.2577 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5847/12542 | Batch Loss: 1.0795 | Learning Rate: 0.000511 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5848/12542 | Batch Loss: 0.8851 | Learning Rate: 0.000511 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5849/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000511 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5850/12542 | Batch Loss: 0.9716 | Learning Rate: 0.000511 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5851/12542 | Batch Loss: 0.4913 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5852/12542 | Batch Loss: 0.8135 | Learning Rate: 0.000511 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5853/12542 | Batch Loss: 1.5375 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5854/12542 | Batch Loss: 0.5583 | Learning Rate: 0.000511 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5855/12542 | Batch Loss: 1.2112 | Learning Rate: 0.000511 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5856/12542 | Batch Loss: 2.4529 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5857/12542 | Batch Loss: 0.8774 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5858/12542 | Batch Loss: 2.0825 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5859/12542 | Batch Loss: 3.5587 | Learning Rate: 0.000511 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5860/12542 | Batch Loss: 0.6780 | Learning Rate: 0.000511 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5861/12542 | Batch Loss: 2.6036 | Learning Rate: 0.000511 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5862/12542 | Batch Loss: 1.8290 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5863/12542 | Batch Loss: 2.8348 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5864/12542 | Batch Loss: 0.8507 | Learning Rate: 0.000511 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5865/12542 | Batch Loss: 2.1843 | Learning Rate: 0.000511 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5866/12542 | Batch Loss: 1.5732 | Learning Rate: 0.000511 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5867/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000511 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5868/12542 | Batch Loss: 1.8657 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5869/12542 | Batch Loss: 2.3121 | Learning Rate: 0.000511 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5870/12542 | Batch Loss: 0.6904 | Learning Rate: 0.000511 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5871/12542 | Batch Loss: 0.6300 | Learning Rate: 0.000511 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5872/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5873/12542 | Batch Loss: 0.9631 | Learning Rate: 0.000511 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5874/12542 | Batch Loss: 1.0153 | Learning Rate: 0.000511 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5875/12542 | Batch Loss: 1.1292 | Learning Rate: 0.000511 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5876/12542 | Batch Loss: 1.4516 | Learning Rate: 0.000510 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5877/12542 | Batch Loss: 0.9365 | Learning Rate: 0.000510 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5878/12542 | Batch Loss: 2.2998 | Learning Rate: 0.000510 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5879/12542 | Batch Loss: 1.3593 | Learning Rate: 0.000510 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5880/12542 | Batch Loss: 0.8606 | Learning Rate: 0.000510 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5881/12542 | Batch Loss: 1.0443 | Learning Rate: 0.000510 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5882/12542 | Batch Loss: 1.1735 | Learning Rate: 0.000510 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5883/12542 | Batch Loss: 1.4715 | Learning Rate: 0.000510 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5884/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000510 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5885/12542 | Batch Loss: 0.8513 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5886/12542 | Batch Loss: 1.2475 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5887/12542 | Batch Loss: 0.9752 | Learning Rate: 0.000510 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5888/12542 | Batch Loss: 1.2654 | Learning Rate: 0.000510 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5889/12542 | Batch Loss: 0.8111 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5890/12542 | Batch Loss: 1.8447 | Learning Rate: 0.000510 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5891/12542 | Batch Loss: 1.7954 | Learning Rate: 0.000510 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5892/12542 | Batch Loss: 3.0292 | Learning Rate: 0.000510 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5893/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000510 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5894/12542 | Batch Loss: 0.8511 | Learning Rate: 0.000510 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5895/12542 | Batch Loss: 1.3851 | Learning Rate: 0.000510 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5896/12542 | Batch Loss: 0.5754 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5897/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5898/12542 | Batch Loss: 0.7013 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5899/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5900/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5901/12542 | Batch Loss: 2.1894 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5902/12542 | Batch Loss: 1.3751 | Learning Rate: 0.000510 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5903/12542 | Batch Loss: 3.1201 | Learning Rate: 0.000510 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5904/12542 | Batch Loss: 1.9455 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5905/12542 | Batch Loss: 1.2047 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5906/12542 | Batch Loss: 1.5748 | Learning Rate: 0.000510 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5907/12542 | Batch Loss: 1.1468 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5908/12542 | Batch Loss: 1.6048 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5909/12542 | Batch Loss: 1.0938 | Learning Rate: 0.000510 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5910/12542 | Batch Loss: 0.9387 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5911/12542 | Batch Loss: 1.3113 | Learning Rate: 0.000510 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5912/12542 | Batch Loss: 1.8150 | Learning Rate: 0.000510 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5913/12542 | Batch Loss: 1.1746 | Learning Rate: 0.000510 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5914/12542 | Batch Loss: 1.4068 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5915/12542 | Batch Loss: 0.9702 | Learning Rate: 0.000509 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5916/12542 | Batch Loss: 1.4831 | Learning Rate: 0.000509 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5917/12542 | Batch Loss: 1.2115 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5918/12542 | Batch Loss: 1.4635 | Learning Rate: 0.000509 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5919/12542 | Batch Loss: 0.7312 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5920/12542 | Batch Loss: 1.7213 | Learning Rate: 0.000509 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5921/12542 | Batch Loss: 1.0380 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5922/12542 | Batch Loss: 1.0590 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5923/12542 | Batch Loss: 0.5121 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5924/12542 | Batch Loss: 2.0227 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5925/12542 | Batch Loss: 1.2160 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5926/12542 | Batch Loss: 1.4428 | Learning Rate: 0.000509 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5927/12542 | Batch Loss: 0.5611 | Learning Rate: 0.000509 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5928/12542 | Batch Loss: 2.3712 | Learning Rate: 0.000509 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5929/12542 | Batch Loss: 0.8115 | Learning Rate: 0.000509 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5930/12542 | Batch Loss: 1.3129 | Learning Rate: 0.000509 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5931/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5932/12542 | Batch Loss: 1.8131 | Learning Rate: 0.000509 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5933/12542 | Batch Loss: 0.5339 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5934/12542 | Batch Loss: 2.2822 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5935/12542 | Batch Loss: 1.2526 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5936/12542 | Batch Loss: 1.0364 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5937/12542 | Batch Loss: 0.5354 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5938/12542 | Batch Loss: 1.5280 | Learning Rate: 0.000509 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5939/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5940/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5941/12542 | Batch Loss: 0.7017 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5942/12542 | Batch Loss: 1.4543 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5943/12542 | Batch Loss: 2.5178 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5944/12542 | Batch Loss: 1.9563 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5945/12542 | Batch Loss: 0.7990 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5946/12542 | Batch Loss: 0.6428 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5947/12542 | Batch Loss: 0.9701 | Learning Rate: 0.000509 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5948/12542 | Batch Loss: 1.6556 | Learning Rate: 0.000509 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5949/12542 | Batch Loss: 1.4645 | Learning Rate: 0.000509 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5950/12542 | Batch Loss: 0.8221 | Learning Rate: 0.000509 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5951/12542 | Batch Loss: 1.2928 | Learning Rate: 0.000509 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5952/12542 | Batch Loss: 1.5968 | Learning Rate: 0.000508 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 5953/12542 | Batch Loss: 2.4752 | Learning Rate: 0.000508 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5954/12542 | Batch Loss: 0.8684 | Learning Rate: 0.000508 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5955/12542 | Batch Loss: 1.2221 | Learning Rate: 0.000508 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5956/12542 | Batch Loss: 1.1702 | Learning Rate: 0.000508 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5957/12542 | Batch Loss: 1.3160 | Learning Rate: 0.000508 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5958/12542 | Batch Loss: 0.7454 | Learning Rate: 0.000508 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5959/12542 | Batch Loss: 1.1365 | Learning Rate: 0.000508 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5960/12542 | Batch Loss: 1.7287 | Learning Rate: 0.000508 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5961/12542 | Batch Loss: 1.7514 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5962/12542 | Batch Loss: 0.7843 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5963/12542 | Batch Loss: 0.8370 | Learning Rate: 0.000508 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5964/12542 | Batch Loss: 0.8594 | Learning Rate: 0.000508 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5965/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000508 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5966/12542 | Batch Loss: 0.8450 | Learning Rate: 0.000508 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5967/12542 | Batch Loss: 2.1953 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5968/12542 | Batch Loss: 0.8336 | Learning Rate: 0.000508 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5969/12542 | Batch Loss: 1.2057 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5970/12542 | Batch Loss: 0.6364 | Learning Rate: 0.000508 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5971/12542 | Batch Loss: 1.1569 | Learning Rate: 0.000508 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5972/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000508 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5973/12542 | Batch Loss: 0.5383 | Learning Rate: 0.000508 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 5974/12542 | Batch Loss: 0.6438 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5975/12542 | Batch Loss: 1.5489 | Learning Rate: 0.000508 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5976/12542 | Batch Loss: 0.3969 | Learning Rate: 0.000508 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5977/12542 | Batch Loss: 1.8519 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5978/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000508 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 5979/12542 | Batch Loss: 1.5002 | Learning Rate: 0.000508 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5980/12542 | Batch Loss: 1.8280 | Learning Rate: 0.000508 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5981/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000508 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5982/12542 | Batch Loss: 1.1665 | Learning Rate: 0.000508 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5983/12542 | Batch Loss: 1.7712 | Learning Rate: 0.000508 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5984/12542 | Batch Loss: 0.6313 | Learning Rate: 0.000508 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5985/12542 | Batch Loss: 1.7803 | Learning Rate: 0.000508 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5986/12542 | Batch Loss: 1.1627 | Learning Rate: 0.000508 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5987/12542 | Batch Loss: 0.7682 | Learning Rate: 0.000508 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5988/12542 | Batch Loss: 2.5017 | Learning Rate: 0.000508 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 5989/12542 | Batch Loss: 1.0387 | Learning Rate: 0.000507 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 5990/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 5991/12542 | Batch Loss: 2.1439 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 5992/12542 | Batch Loss: 1.3421 | Learning Rate: 0.000507 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 5993/12542 | Batch Loss: 2.9420 | Learning Rate: 0.000507 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5994/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000507 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 5995/12542 | Batch Loss: 1.6344 | Learning Rate: 0.000507 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 5996/12542 | Batch Loss: 1.5477 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 5997/12542 | Batch Loss: 1.3682 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5998/12542 | Batch Loss: 1.8193 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 5999/12542 | Batch Loss: 1.7605 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6000/12542 | Batch Loss: 1.2049 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6001/12542 | Batch Loss: 1.4110 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6002/12542 | Batch Loss: 0.4165 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6003/12542 | Batch Loss: 1.1900 | Learning Rate: 0.000507 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6004/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6005/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000507 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6006/12542 | Batch Loss: 0.9640 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6007/12542 | Batch Loss: 1.3952 | Learning Rate: 0.000507 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6008/12542 | Batch Loss: 1.6363 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6009/12542 | Batch Loss: 0.9906 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6010/12542 | Batch Loss: 1.5488 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6011/12542 | Batch Loss: 1.0255 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6012/12542 | Batch Loss: 2.0114 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6013/12542 | Batch Loss: 1.1090 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6014/12542 | Batch Loss: 0.6627 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6015/12542 | Batch Loss: 1.8670 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6016/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6017/12542 | Batch Loss: 1.1938 | Learning Rate: 0.000507 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6018/12542 | Batch Loss: 2.1724 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6019/12542 | Batch Loss: 0.8697 | Learning Rate: 0.000507 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6020/12542 | Batch Loss: 0.7411 | Learning Rate: 0.000507 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6021/12542 | Batch Loss: 2.1035 | Learning Rate: 0.000507 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6022/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6023/12542 | Batch Loss: 1.4681 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6024/12542 | Batch Loss: 1.1172 | Learning Rate: 0.000507 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6025/12542 | Batch Loss: 2.1958 | Learning Rate: 0.000507 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6026/12542 | Batch Loss: 1.8073 | Learning Rate: 0.000507 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6027/12542 | Batch Loss: 1.7129 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6028/12542 | Batch Loss: 1.9251 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6029/12542 | Batch Loss: 1.9382 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6030/12542 | Batch Loss: 0.6540 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6031/12542 | Batch Loss: 1.0688 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6032/12542 | Batch Loss: 1.3101 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6033/12542 | Batch Loss: 1.7079 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6034/12542 | Batch Loss: 0.8806 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6035/12542 | Batch Loss: 0.8928 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6036/12542 | Batch Loss: 0.6953 | Learning Rate: 0.000506 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6037/12542 | Batch Loss: 1.6652 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6038/12542 | Batch Loss: 0.5137 | Learning Rate: 0.000506 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6039/12542 | Batch Loss: 0.5526 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6040/12542 | Batch Loss: 1.1642 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6041/12542 | Batch Loss: 2.7846 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6042/12542 | Batch Loss: 1.3961 | Learning Rate: 0.000506 | Batch Time: 0.55s\n",
      "Epoch 2 | Step 6043/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000506 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6044/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6045/12542 | Batch Loss: 1.2424 | Learning Rate: 0.000506 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6046/12542 | Batch Loss: 1.4339 | Learning Rate: 0.000506 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6047/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000506 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6048/12542 | Batch Loss: 0.5439 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6049/12542 | Batch Loss: 0.7485 | Learning Rate: 0.000506 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6050/12542 | Batch Loss: 1.1107 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6051/12542 | Batch Loss: 1.1040 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6052/12542 | Batch Loss: 0.9131 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6053/12542 | Batch Loss: 3.1008 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6054/12542 | Batch Loss: 1.0280 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6055/12542 | Batch Loss: 1.4015 | Learning Rate: 0.000506 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6056/12542 | Batch Loss: 0.7318 | Learning Rate: 0.000506 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6057/12542 | Batch Loss: 0.5494 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6058/12542 | Batch Loss: 0.5413 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6059/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6060/12542 | Batch Loss: 0.9047 | Learning Rate: 0.000506 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6061/12542 | Batch Loss: 3.4838 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6062/12542 | Batch Loss: 1.9662 | Learning Rate: 0.000506 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6063/12542 | Batch Loss: 2.0000 | Learning Rate: 0.000506 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6064/12542 | Batch Loss: 1.5587 | Learning Rate: 0.000506 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6065/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000505 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6066/12542 | Batch Loss: 0.5216 | Learning Rate: 0.000505 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6067/12542 | Batch Loss: 0.7001 | Learning Rate: 0.000505 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6068/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6069/12542 | Batch Loss: 1.0023 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6070/12542 | Batch Loss: 0.7138 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6071/12542 | Batch Loss: 1.3636 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6072/12542 | Batch Loss: 1.5739 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6073/12542 | Batch Loss: 0.8008 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6074/12542 | Batch Loss: 1.1663 | Learning Rate: 0.000505 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6075/12542 | Batch Loss: 2.7010 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6076/12542 | Batch Loss: 1.5807 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6077/12542 | Batch Loss: 2.0877 | Learning Rate: 0.000505 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6078/12542 | Batch Loss: 0.7840 | Learning Rate: 0.000505 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6079/12542 | Batch Loss: 1.2584 | Learning Rate: 0.000505 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6080/12542 | Batch Loss: 2.2561 | Learning Rate: 0.000505 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6081/12542 | Batch Loss: 1.0580 | Learning Rate: 0.000505 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6082/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000505 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6083/12542 | Batch Loss: 0.7877 | Learning Rate: 0.000505 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6084/12542 | Batch Loss: 0.9250 | Learning Rate: 0.000505 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6085/12542 | Batch Loss: 1.0679 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6086/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6087/12542 | Batch Loss: 1.2400 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6088/12542 | Batch Loss: 0.8453 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6089/12542 | Batch Loss: 0.7413 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6090/12542 | Batch Loss: 1.6349 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6091/12542 | Batch Loss: 0.5618 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6092/12542 | Batch Loss: 1.0015 | Learning Rate: 0.000505 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6093/12542 | Batch Loss: 0.5267 | Learning Rate: 0.000505 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6094/12542 | Batch Loss: 0.7329 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6095/12542 | Batch Loss: 2.0506 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6096/12542 | Batch Loss: 1.3505 | Learning Rate: 0.000505 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6097/12542 | Batch Loss: 1.8397 | Learning Rate: 0.000505 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6098/12542 | Batch Loss: 2.6514 | Learning Rate: 0.000505 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6099/12542 | Batch Loss: 0.7562 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6100/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000505 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6101/12542 | Batch Loss: 1.8510 | Learning Rate: 0.000505 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6102/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6103/12542 | Batch Loss: 1.5730 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6104/12542 | Batch Loss: 1.5925 | Learning Rate: 0.000504 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6105/12542 | Batch Loss: 1.3370 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6106/12542 | Batch Loss: 3.5549 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6107/12542 | Batch Loss: 0.7857 | Learning Rate: 0.000504 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6108/12542 | Batch Loss: 1.6741 | Learning Rate: 0.000504 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6109/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6110/12542 | Batch Loss: 1.5192 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6111/12542 | Batch Loss: 1.4976 | Learning Rate: 0.000504 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6112/12542 | Batch Loss: 1.3263 | Learning Rate: 0.000504 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6113/12542 | Batch Loss: 2.2167 | Learning Rate: 0.000504 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6114/12542 | Batch Loss: 1.8046 | Learning Rate: 0.000504 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6115/12542 | Batch Loss: 0.8147 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6116/12542 | Batch Loss: 0.9372 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6117/12542 | Batch Loss: 0.6786 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6118/12542 | Batch Loss: 1.6442 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6119/12542 | Batch Loss: 1.1684 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6120/12542 | Batch Loss: 2.1232 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6121/12542 | Batch Loss: 2.7729 | Learning Rate: 0.000504 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6122/12542 | Batch Loss: 1.4723 | Learning Rate: 0.000504 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6123/12542 | Batch Loss: 0.7034 | Learning Rate: 0.000504 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6124/12542 | Batch Loss: 1.6194 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6125/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6126/12542 | Batch Loss: 1.5394 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6127/12542 | Batch Loss: 1.1882 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6128/12542 | Batch Loss: 0.8749 | Learning Rate: 0.000504 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6129/12542 | Batch Loss: 0.5084 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6130/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000504 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6131/12542 | Batch Loss: 0.6940 | Learning Rate: 0.000504 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6132/12542 | Batch Loss: 1.1459 | Learning Rate: 0.000504 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6133/12542 | Batch Loss: 1.3493 | Learning Rate: 0.000504 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6134/12542 | Batch Loss: 1.8961 | Learning Rate: 0.000504 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6135/12542 | Batch Loss: 0.9460 | Learning Rate: 0.000504 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6136/12542 | Batch Loss: 1.2735 | Learning Rate: 0.000504 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6137/12542 | Batch Loss: 1.2628 | Learning Rate: 0.000504 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6138/12542 | Batch Loss: 1.7499 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6139/12542 | Batch Loss: 1.6680 | Learning Rate: 0.000504 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6140/12542 | Batch Loss: 0.6500 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6141/12542 | Batch Loss: 0.6904 | Learning Rate: 0.000503 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6142/12542 | Batch Loss: 0.6915 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6143/12542 | Batch Loss: 1.5215 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6144/12542 | Batch Loss: 1.6369 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6145/12542 | Batch Loss: 2.7717 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6146/12542 | Batch Loss: 0.5566 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6147/12542 | Batch Loss: 0.5124 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6148/12542 | Batch Loss: 0.8367 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6149/12542 | Batch Loss: 0.9255 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6150/12542 | Batch Loss: 0.7602 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6151/12542 | Batch Loss: 1.9978 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6152/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6153/12542 | Batch Loss: 1.5619 | Learning Rate: 0.000503 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6154/12542 | Batch Loss: 0.8547 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6155/12542 | Batch Loss: 2.3426 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6156/12542 | Batch Loss: 2.9980 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6157/12542 | Batch Loss: 1.9647 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6158/12542 | Batch Loss: 0.8080 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6159/12542 | Batch Loss: 1.2751 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6160/12542 | Batch Loss: 1.8701 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6161/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000503 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6162/12542 | Batch Loss: 1.9479 | Learning Rate: 0.000503 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6163/12542 | Batch Loss: 1.1173 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6164/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000503 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6165/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000503 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6166/12542 | Batch Loss: 2.1129 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6167/12542 | Batch Loss: 0.9866 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6168/12542 | Batch Loss: 1.9295 | Learning Rate: 0.000503 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6169/12542 | Batch Loss: 1.6772 | Learning Rate: 0.000503 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6170/12542 | Batch Loss: 1.0719 | Learning Rate: 0.000503 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6171/12542 | Batch Loss: 1.1461 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6172/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000503 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6173/12542 | Batch Loss: 1.2295 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6174/12542 | Batch Loss: 0.6845 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6175/12542 | Batch Loss: 1.7092 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6176/12542 | Batch Loss: 0.9982 | Learning Rate: 0.000503 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6177/12542 | Batch Loss: 0.6997 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6178/12542 | Batch Loss: 2.2664 | Learning Rate: 0.000502 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6179/12542 | Batch Loss: 1.3344 | Learning Rate: 0.000502 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6180/12542 | Batch Loss: 1.0962 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6181/12542 | Batch Loss: 1.9578 | Learning Rate: 0.000502 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6182/12542 | Batch Loss: 1.3052 | Learning Rate: 0.000502 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6183/12542 | Batch Loss: 1.4865 | Learning Rate: 0.000502 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6184/12542 | Batch Loss: 0.6686 | Learning Rate: 0.000502 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6185/12542 | Batch Loss: 0.5947 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6186/12542 | Batch Loss: 1.8654 | Learning Rate: 0.000502 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6187/12542 | Batch Loss: 1.1968 | Learning Rate: 0.000502 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6188/12542 | Batch Loss: 0.7658 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6189/12542 | Batch Loss: 1.5904 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6190/12542 | Batch Loss: 1.4869 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6191/12542 | Batch Loss: 0.3070 | Learning Rate: 0.000502 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6192/12542 | Batch Loss: 0.8057 | Learning Rate: 0.000502 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6193/12542 | Batch Loss: 1.1528 | Learning Rate: 0.000502 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6194/12542 | Batch Loss: 1.4850 | Learning Rate: 0.000502 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6195/12542 | Batch Loss: 2.3100 | Learning Rate: 0.000502 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6196/12542 | Batch Loss: 1.9598 | Learning Rate: 0.000502 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6197/12542 | Batch Loss: 0.4882 | Learning Rate: 0.000502 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6198/12542 | Batch Loss: 1.7212 | Learning Rate: 0.000502 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6199/12542 | Batch Loss: 0.8591 | Learning Rate: 0.000502 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6200/12542 | Batch Loss: 1.3551 | Learning Rate: 0.000502 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6201/12542 | Batch Loss: 0.6218 | Learning Rate: 0.000502 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6202/12542 | Batch Loss: 1.3971 | Learning Rate: 0.000502 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6203/12542 | Batch Loss: 1.6073 | Learning Rate: 0.000502 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6204/12542 | Batch Loss: 1.2975 | Learning Rate: 0.000502 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6205/12542 | Batch Loss: 0.7766 | Learning Rate: 0.000502 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6206/12542 | Batch Loss: 0.5743 | Learning Rate: 0.000502 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6207/12542 | Batch Loss: 1.3049 | Learning Rate: 0.000502 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6208/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000502 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6209/12542 | Batch Loss: 0.5808 | Learning Rate: 0.000502 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6210/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000502 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6211/12542 | Batch Loss: 1.6270 | Learning Rate: 0.000502 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6212/12542 | Batch Loss: 1.0775 | Learning Rate: 0.000502 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6213/12542 | Batch Loss: 2.7033 | Learning Rate: 0.000502 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6214/12542 | Batch Loss: 1.0085 | Learning Rate: 0.000502 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6215/12542 | Batch Loss: 2.1537 | Learning Rate: 0.000501 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6216/12542 | Batch Loss: 1.1990 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6217/12542 | Batch Loss: 0.8060 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6218/12542 | Batch Loss: 1.4976 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6219/12542 | Batch Loss: 2.1672 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6220/12542 | Batch Loss: 1.2029 | Learning Rate: 0.000501 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6221/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000501 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6222/12542 | Batch Loss: 1.4736 | Learning Rate: 0.000501 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6223/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000501 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6224/12542 | Batch Loss: 2.1451 | Learning Rate: 0.000501 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6225/12542 | Batch Loss: 1.0778 | Learning Rate: 0.000501 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6226/12542 | Batch Loss: 0.8658 | Learning Rate: 0.000501 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6227/12542 | Batch Loss: 2.0553 | Learning Rate: 0.000501 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6228/12542 | Batch Loss: 1.1078 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6229/12542 | Batch Loss: 1.5788 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6230/12542 | Batch Loss: 0.9550 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6231/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000501 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6232/12542 | Batch Loss: 2.2252 | Learning Rate: 0.000501 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6233/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000501 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6234/12542 | Batch Loss: 1.3225 | Learning Rate: 0.000501 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6235/12542 | Batch Loss: 0.5046 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6236/12542 | Batch Loss: 0.9675 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6237/12542 | Batch Loss: 0.6845 | Learning Rate: 0.000501 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6238/12542 | Batch Loss: 0.5164 | Learning Rate: 0.000501 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6239/12542 | Batch Loss: 1.4880 | Learning Rate: 0.000501 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6240/12542 | Batch Loss: 2.7578 | Learning Rate: 0.000501 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6241/12542 | Batch Loss: 0.7839 | Learning Rate: 0.000501 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6242/12542 | Batch Loss: 1.5638 | Learning Rate: 0.000501 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6243/12542 | Batch Loss: 1.5713 | Learning Rate: 0.000501 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6244/12542 | Batch Loss: 2.0161 | Learning Rate: 0.000501 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6245/12542 | Batch Loss: 0.8927 | Learning Rate: 0.000501 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6246/12542 | Batch Loss: 1.3774 | Learning Rate: 0.000501 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6247/12542 | Batch Loss: 1.8348 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6248/12542 | Batch Loss: 1.5934 | Learning Rate: 0.000501 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6249/12542 | Batch Loss: 1.3516 | Learning Rate: 0.000501 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6250/12542 | Batch Loss: 2.1093 | Learning Rate: 0.000501 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6251/12542 | Batch Loss: 1.4579 | Learning Rate: 0.000501 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6252/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000501 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6253/12542 | Batch Loss: 1.3601 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6254/12542 | Batch Loss: 1.3799 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6255/12542 | Batch Loss: 2.5527 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6256/12542 | Batch Loss: 1.3237 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6257/12542 | Batch Loss: 1.9374 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6258/12542 | Batch Loss: 0.8748 | Learning Rate: 0.000500 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6259/12542 | Batch Loss: 1.9538 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6260/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6261/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6262/12542 | Batch Loss: 1.8853 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6263/12542 | Batch Loss: 2.1446 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6264/12542 | Batch Loss: 2.9772 | Learning Rate: 0.000500 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6265/12542 | Batch Loss: 0.7829 | Learning Rate: 0.000500 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6266/12542 | Batch Loss: 1.0407 | Learning Rate: 0.000500 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6267/12542 | Batch Loss: 1.5844 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6268/12542 | Batch Loss: 2.6210 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6269/12542 | Batch Loss: 0.7852 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6270/12542 | Batch Loss: 1.4103 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6271/12542 | Batch Loss: 0.8276 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6272/12542 | Batch Loss: 1.8536 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6273/12542 | Batch Loss: 1.7736 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6274/12542 | Batch Loss: 0.8957 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6275/12542 | Batch Loss: 0.5823 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6276/12542 | Batch Loss: 1.9227 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6277/12542 | Batch Loss: 2.2285 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6278/12542 | Batch Loss: 1.4779 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6279/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6280/12542 | Batch Loss: 1.7739 | Learning Rate: 0.000500 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6281/12542 | Batch Loss: 1.8697 | Learning Rate: 0.000500 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6282/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6283/12542 | Batch Loss: 2.9226 | Learning Rate: 0.000500 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6284/12542 | Batch Loss: 1.7027 | Learning Rate: 0.000500 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6285/12542 | Batch Loss: 0.8511 | Learning Rate: 0.000500 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6286/12542 | Batch Loss: 0.5998 | Learning Rate: 0.000500 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6287/12542 | Batch Loss: 2.5781 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6288/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000500 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6289/12542 | Batch Loss: 0.4555 | Learning Rate: 0.000500 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6290/12542 | Batch Loss: 1.2980 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6291/12542 | Batch Loss: 1.8023 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6292/12542 | Batch Loss: 0.7716 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6293/12542 | Batch Loss: 0.9866 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6294/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6295/12542 | Batch Loss: 1.3190 | Learning Rate: 0.000499 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6296/12542 | Batch Loss: 1.8086 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6297/12542 | Batch Loss: 1.2743 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6298/12542 | Batch Loss: 0.8468 | Learning Rate: 0.000499 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6299/12542 | Batch Loss: 1.3044 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6300/12542 | Batch Loss: 1.0897 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6301/12542 | Batch Loss: 1.4675 | Learning Rate: 0.000499 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6302/12542 | Batch Loss: 1.0261 | Learning Rate: 0.000499 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6303/12542 | Batch Loss: 1.0227 | Learning Rate: 0.000499 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6304/12542 | Batch Loss: 1.1929 | Learning Rate: 0.000499 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6305/12542 | Batch Loss: 1.3891 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6306/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6307/12542 | Batch Loss: 0.9777 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6308/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000499 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6309/12542 | Batch Loss: 1.0283 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6310/12542 | Batch Loss: 1.7111 | Learning Rate: 0.000499 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6311/12542 | Batch Loss: 1.3978 | Learning Rate: 0.000499 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6312/12542 | Batch Loss: 1.7190 | Learning Rate: 0.000499 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6313/12542 | Batch Loss: 2.5641 | Learning Rate: 0.000499 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6314/12542 | Batch Loss: 1.1558 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6315/12542 | Batch Loss: 1.2985 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6316/12542 | Batch Loss: 1.5526 | Learning Rate: 0.000499 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6317/12542 | Batch Loss: 1.0302 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6318/12542 | Batch Loss: 1.2296 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6319/12542 | Batch Loss: 1.4980 | Learning Rate: 0.000499 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6320/12542 | Batch Loss: 1.9631 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6321/12542 | Batch Loss: 2.0329 | Learning Rate: 0.000499 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6322/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000499 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6323/12542 | Batch Loss: 0.8551 | Learning Rate: 0.000499 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6324/12542 | Batch Loss: 1.3210 | Learning Rate: 0.000499 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6325/12542 | Batch Loss: 1.6429 | Learning Rate: 0.000499 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6326/12542 | Batch Loss: 0.7919 | Learning Rate: 0.000499 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6327/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000499 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6328/12542 | Batch Loss: 1.9117 | Learning Rate: 0.000498 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6329/12542 | Batch Loss: 1.1260 | Learning Rate: 0.000498 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6330/12542 | Batch Loss: 1.1123 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6331/12542 | Batch Loss: 2.0601 | Learning Rate: 0.000498 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6332/12542 | Batch Loss: 1.2864 | Learning Rate: 0.000498 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6333/12542 | Batch Loss: 1.0175 | Learning Rate: 0.000498 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6334/12542 | Batch Loss: 1.5186 | Learning Rate: 0.000498 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6335/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6336/12542 | Batch Loss: 1.2416 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6337/12542 | Batch Loss: 1.3855 | Learning Rate: 0.000498 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6338/12542 | Batch Loss: 1.0009 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6339/12542 | Batch Loss: 1.3119 | Learning Rate: 0.000498 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6340/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000498 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6341/12542 | Batch Loss: 0.7388 | Learning Rate: 0.000498 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6342/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6343/12542 | Batch Loss: 0.8776 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6344/12542 | Batch Loss: 0.3969 | Learning Rate: 0.000498 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6345/12542 | Batch Loss: 1.4067 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6346/12542 | Batch Loss: 3.2381 | Learning Rate: 0.000498 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6347/12542 | Batch Loss: 1.3451 | Learning Rate: 0.000498 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6348/12542 | Batch Loss: 1.1367 | Learning Rate: 0.000498 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6349/12542 | Batch Loss: 1.2709 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6350/12542 | Batch Loss: 1.1110 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6351/12542 | Batch Loss: 1.7550 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6352/12542 | Batch Loss: 1.8643 | Learning Rate: 0.000498 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6353/12542 | Batch Loss: 0.5836 | Learning Rate: 0.000498 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6354/12542 | Batch Loss: 1.8790 | Learning Rate: 0.000498 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6355/12542 | Batch Loss: 1.0575 | Learning Rate: 0.000498 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6356/12542 | Batch Loss: 2.0536 | Learning Rate: 0.000498 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6357/12542 | Batch Loss: 1.2963 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6358/12542 | Batch Loss: 1.2085 | Learning Rate: 0.000498 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6359/12542 | Batch Loss: 1.1089 | Learning Rate: 0.000498 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6360/12542 | Batch Loss: 1.0349 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6361/12542 | Batch Loss: 0.7705 | Learning Rate: 0.000498 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6362/12542 | Batch Loss: 1.3811 | Learning Rate: 0.000498 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6363/12542 | Batch Loss: 2.5149 | Learning Rate: 0.000498 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6364/12542 | Batch Loss: 2.1066 | Learning Rate: 0.000498 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6365/12542 | Batch Loss: 0.7412 | Learning Rate: 0.000498 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6366/12542 | Batch Loss: 1.6208 | Learning Rate: 0.000497 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6367/12542 | Batch Loss: 1.0713 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6368/12542 | Batch Loss: 2.1131 | Learning Rate: 0.000497 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6369/12542 | Batch Loss: 1.2933 | Learning Rate: 0.000497 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6370/12542 | Batch Loss: 1.5363 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6371/12542 | Batch Loss: 0.8269 | Learning Rate: 0.000497 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6372/12542 | Batch Loss: 1.1385 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6373/12542 | Batch Loss: 1.9503 | Learning Rate: 0.000497 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6374/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000497 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6375/12542 | Batch Loss: 1.3302 | Learning Rate: 0.000497 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6376/12542 | Batch Loss: 1.1196 | Learning Rate: 0.000497 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6377/12542 | Batch Loss: 1.2627 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6378/12542 | Batch Loss: 1.7312 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6379/12542 | Batch Loss: 1.3762 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6380/12542 | Batch Loss: 1.2620 | Learning Rate: 0.000497 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6381/12542 | Batch Loss: 1.3488 | Learning Rate: 0.000497 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6382/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000497 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6383/12542 | Batch Loss: 1.5275 | Learning Rate: 0.000497 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6384/12542 | Batch Loss: 0.8231 | Learning Rate: 0.000497 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6385/12542 | Batch Loss: 1.3137 | Learning Rate: 0.000497 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6386/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6387/12542 | Batch Loss: 1.1147 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6388/12542 | Batch Loss: 0.9047 | Learning Rate: 0.000497 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6389/12542 | Batch Loss: 1.5037 | Learning Rate: 0.000497 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6390/12542 | Batch Loss: 1.4596 | Learning Rate: 0.000497 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6391/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000497 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6392/12542 | Batch Loss: 0.5504 | Learning Rate: 0.000497 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6393/12542 | Batch Loss: 1.3690 | Learning Rate: 0.000497 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6394/12542 | Batch Loss: 0.7741 | Learning Rate: 0.000497 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6395/12542 | Batch Loss: 1.3917 | Learning Rate: 0.000497 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6396/12542 | Batch Loss: 1.7622 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6397/12542 | Batch Loss: 1.0020 | Learning Rate: 0.000497 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6398/12542 | Batch Loss: 1.4053 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6399/12542 | Batch Loss: 0.8020 | Learning Rate: 0.000497 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6400/12542 | Batch Loss: 0.9940 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6401/12542 | Batch Loss: 0.4949 | Learning Rate: 0.000497 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6402/12542 | Batch Loss: 0.9702 | Learning Rate: 0.000497 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6403/12542 | Batch Loss: 0.9808 | Learning Rate: 0.000496 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6404/12542 | Batch Loss: 1.3405 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6405/12542 | Batch Loss: 0.7133 | Learning Rate: 0.000496 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6406/12542 | Batch Loss: 0.7314 | Learning Rate: 0.000496 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6407/12542 | Batch Loss: 2.1127 | Learning Rate: 0.000496 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6408/12542 | Batch Loss: 1.5914 | Learning Rate: 0.000496 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6409/12542 | Batch Loss: 0.4970 | Learning Rate: 0.000496 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6410/12542 | Batch Loss: 1.8042 | Learning Rate: 0.000496 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6411/12542 | Batch Loss: 0.4113 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6412/12542 | Batch Loss: 1.6574 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6413/12542 | Batch Loss: 2.1463 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6414/12542 | Batch Loss: 0.5861 | Learning Rate: 0.000496 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6415/12542 | Batch Loss: 1.4182 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6416/12542 | Batch Loss: 0.6228 | Learning Rate: 0.000496 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6417/12542 | Batch Loss: 0.9883 | Learning Rate: 0.000496 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6418/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6419/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000496 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6420/12542 | Batch Loss: 1.0893 | Learning Rate: 0.000496 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6421/12542 | Batch Loss: 0.8176 | Learning Rate: 0.000496 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6422/12542 | Batch Loss: 1.2723 | Learning Rate: 0.000496 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6423/12542 | Batch Loss: 1.0739 | Learning Rate: 0.000496 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6424/12542 | Batch Loss: 0.9636 | Learning Rate: 0.000496 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6425/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000496 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6426/12542 | Batch Loss: 1.3298 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6427/12542 | Batch Loss: 1.5207 | Learning Rate: 0.000496 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6428/12542 | Batch Loss: 1.9872 | Learning Rate: 0.000496 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6429/12542 | Batch Loss: 1.5145 | Learning Rate: 0.000496 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6430/12542 | Batch Loss: 1.0594 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6431/12542 | Batch Loss: 0.8384 | Learning Rate: 0.000496 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6432/12542 | Batch Loss: 2.5777 | Learning Rate: 0.000496 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6433/12542 | Batch Loss: 1.7904 | Learning Rate: 0.000496 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6434/12542 | Batch Loss: 1.9258 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6435/12542 | Batch Loss: 1.3102 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6436/12542 | Batch Loss: 2.3728 | Learning Rate: 0.000496 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6437/12542 | Batch Loss: 1.8605 | Learning Rate: 0.000496 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6438/12542 | Batch Loss: 0.9458 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6439/12542 | Batch Loss: 0.8557 | Learning Rate: 0.000496 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 6440/12542 | Batch Loss: 1.4395 | Learning Rate: 0.000496 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6441/12542 | Batch Loss: 1.0475 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6442/12542 | Batch Loss: 0.5694 | Learning Rate: 0.000495 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6443/12542 | Batch Loss: 1.2835 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6444/12542 | Batch Loss: 0.8141 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6445/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6446/12542 | Batch Loss: 0.5747 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6447/12542 | Batch Loss: 2.2996 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6448/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6449/12542 | Batch Loss: 3.6103 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6450/12542 | Batch Loss: 1.2383 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6451/12542 | Batch Loss: 0.6725 | Learning Rate: 0.000495 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6452/12542 | Batch Loss: 1.4171 | Learning Rate: 0.000495 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6453/12542 | Batch Loss: 0.8018 | Learning Rate: 0.000495 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6454/12542 | Batch Loss: 1.3573 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6455/12542 | Batch Loss: 0.9036 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6456/12542 | Batch Loss: 0.9885 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6457/12542 | Batch Loss: 3.0564 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6458/12542 | Batch Loss: 1.3362 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6459/12542 | Batch Loss: 1.2612 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6460/12542 | Batch Loss: 0.8265 | Learning Rate: 0.000495 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6461/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6462/12542 | Batch Loss: 1.9082 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6463/12542 | Batch Loss: 1.0307 | Learning Rate: 0.000495 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6464/12542 | Batch Loss: 1.1568 | Learning Rate: 0.000495 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6465/12542 | Batch Loss: 1.5864 | Learning Rate: 0.000495 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6466/12542 | Batch Loss: 0.8127 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6467/12542 | Batch Loss: 1.8880 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6468/12542 | Batch Loss: 1.5701 | Learning Rate: 0.000495 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 6469/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000495 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6470/12542 | Batch Loss: 1.4004 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6471/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6472/12542 | Batch Loss: 1.7144 | Learning Rate: 0.000495 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6473/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000495 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6474/12542 | Batch Loss: 0.7481 | Learning Rate: 0.000495 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6475/12542 | Batch Loss: 0.6326 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6476/12542 | Batch Loss: 0.5241 | Learning Rate: 0.000495 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6477/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000495 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6478/12542 | Batch Loss: 0.9137 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6479/12542 | Batch Loss: 1.1480 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6480/12542 | Batch Loss: 2.3379 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6481/12542 | Batch Loss: 0.8700 | Learning Rate: 0.000494 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6482/12542 | Batch Loss: 2.9598 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6483/12542 | Batch Loss: 0.9443 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6484/12542 | Batch Loss: 1.2918 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6485/12542 | Batch Loss: 1.6907 | Learning Rate: 0.000494 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 6486/12542 | Batch Loss: 1.3831 | Learning Rate: 0.000494 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6487/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6488/12542 | Batch Loss: 2.4720 | Learning Rate: 0.000494 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6489/12542 | Batch Loss: 1.2391 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6490/12542 | Batch Loss: 0.8479 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6491/12542 | Batch Loss: 0.9747 | Learning Rate: 0.000494 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6492/12542 | Batch Loss: 1.5060 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6493/12542 | Batch Loss: 1.4845 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6494/12542 | Batch Loss: 1.8507 | Learning Rate: 0.000494 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6495/12542 | Batch Loss: 1.0755 | Learning Rate: 0.000494 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6496/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000494 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6497/12542 | Batch Loss: 0.9787 | Learning Rate: 0.000494 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6498/12542 | Batch Loss: 1.3263 | Learning Rate: 0.000494 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6499/12542 | Batch Loss: 1.0689 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6500/12542 | Batch Loss: 0.8462 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6501/12542 | Batch Loss: 1.3641 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6502/12542 | Batch Loss: 1.1942 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6503/12542 | Batch Loss: 0.6341 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6504/12542 | Batch Loss: 1.1206 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6505/12542 | Batch Loss: 1.6944 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6506/12542 | Batch Loss: 0.3462 | Learning Rate: 0.000494 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6507/12542 | Batch Loss: 0.8291 | Learning Rate: 0.000494 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6508/12542 | Batch Loss: 1.4468 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6509/12542 | Batch Loss: 0.8328 | Learning Rate: 0.000494 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6510/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000494 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6511/12542 | Batch Loss: 2.1497 | Learning Rate: 0.000494 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6512/12542 | Batch Loss: 1.9868 | Learning Rate: 0.000494 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6513/12542 | Batch Loss: 1.0344 | Learning Rate: 0.000494 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6514/12542 | Batch Loss: 1.1935 | Learning Rate: 0.000494 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6515/12542 | Batch Loss: 2.5051 | Learning Rate: 0.000494 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6516/12542 | Batch Loss: 1.0627 | Learning Rate: 0.000493 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6517/12542 | Batch Loss: 1.2190 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6518/12542 | Batch Loss: 1.4044 | Learning Rate: 0.000493 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6519/12542 | Batch Loss: 1.0942 | Learning Rate: 0.000493 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6520/12542 | Batch Loss: 0.8144 | Learning Rate: 0.000493 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6521/12542 | Batch Loss: 1.2391 | Learning Rate: 0.000493 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6522/12542 | Batch Loss: 1.5040 | Learning Rate: 0.000493 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6523/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000493 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6524/12542 | Batch Loss: 1.6907 | Learning Rate: 0.000493 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6525/12542 | Batch Loss: 1.0057 | Learning Rate: 0.000493 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6526/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6527/12542 | Batch Loss: 0.8699 | Learning Rate: 0.000493 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6528/12542 | Batch Loss: 1.7233 | Learning Rate: 0.000493 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6529/12542 | Batch Loss: 1.1211 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6530/12542 | Batch Loss: 1.8022 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6531/12542 | Batch Loss: 1.7711 | Learning Rate: 0.000493 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6532/12542 | Batch Loss: 0.8307 | Learning Rate: 0.000493 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6533/12542 | Batch Loss: 0.6588 | Learning Rate: 0.000493 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6534/12542 | Batch Loss: 1.1761 | Learning Rate: 0.000493 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6535/12542 | Batch Loss: 0.5398 | Learning Rate: 0.000493 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6536/12542 | Batch Loss: 1.0646 | Learning Rate: 0.000493 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6537/12542 | Batch Loss: 1.6731 | Learning Rate: 0.000493 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6538/12542 | Batch Loss: 1.8939 | Learning Rate: 0.000493 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6539/12542 | Batch Loss: 1.0069 | Learning Rate: 0.000493 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6540/12542 | Batch Loss: 1.1795 | Learning Rate: 0.000493 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6541/12542 | Batch Loss: 1.5854 | Learning Rate: 0.000493 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6542/12542 | Batch Loss: 2.0961 | Learning Rate: 0.000493 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6543/12542 | Batch Loss: 2.2161 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6544/12542 | Batch Loss: 0.8497 | Learning Rate: 0.000493 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6545/12542 | Batch Loss: 1.2944 | Learning Rate: 0.000493 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6546/12542 | Batch Loss: 1.0489 | Learning Rate: 0.000493 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6547/12542 | Batch Loss: 1.3081 | Learning Rate: 0.000493 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6548/12542 | Batch Loss: 1.3471 | Learning Rate: 0.000493 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6549/12542 | Batch Loss: 1.2132 | Learning Rate: 0.000493 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6550/12542 | Batch Loss: 1.9916 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6551/12542 | Batch Loss: 1.1769 | Learning Rate: 0.000493 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6552/12542 | Batch Loss: 1.1756 | Learning Rate: 0.000493 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6553/12542 | Batch Loss: 0.9751 | Learning Rate: 0.000493 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6554/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000492 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6555/12542 | Batch Loss: 1.0081 | Learning Rate: 0.000492 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6556/12542 | Batch Loss: 1.1296 | Learning Rate: 0.000492 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6557/12542 | Batch Loss: 0.9715 | Learning Rate: 0.000492 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6558/12542 | Batch Loss: 3.0385 | Learning Rate: 0.000492 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6559/12542 | Batch Loss: 1.8141 | Learning Rate: 0.000492 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6560/12542 | Batch Loss: 1.2344 | Learning Rate: 0.000492 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6561/12542 | Batch Loss: 3.2820 | Learning Rate: 0.000492 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6562/12542 | Batch Loss: 1.4403 | Learning Rate: 0.000492 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6563/12542 | Batch Loss: 1.2585 | Learning Rate: 0.000492 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6564/12542 | Batch Loss: 1.2388 | Learning Rate: 0.000492 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6565/12542 | Batch Loss: 0.6056 | Learning Rate: 0.000492 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6566/12542 | Batch Loss: 0.6753 | Learning Rate: 0.000492 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6567/12542 | Batch Loss: 0.7888 | Learning Rate: 0.000492 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6568/12542 | Batch Loss: 1.5009 | Learning Rate: 0.000492 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6569/12542 | Batch Loss: 0.9464 | Learning Rate: 0.000492 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6570/12542 | Batch Loss: 1.0642 | Learning Rate: 0.000492 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6571/12542 | Batch Loss: 1.2100 | Learning Rate: 0.000492 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6572/12542 | Batch Loss: 0.7552 | Learning Rate: 0.000492 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6573/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000492 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6574/12542 | Batch Loss: 1.8435 | Learning Rate: 0.000492 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6575/12542 | Batch Loss: 1.0244 | Learning Rate: 0.000492 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6576/12542 | Batch Loss: 1.7280 | Learning Rate: 0.000492 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6577/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000492 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6578/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000492 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6579/12542 | Batch Loss: 1.1082 | Learning Rate: 0.000492 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6580/12542 | Batch Loss: 0.7824 | Learning Rate: 0.000492 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6581/12542 | Batch Loss: 0.8765 | Learning Rate: 0.000492 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6582/12542 | Batch Loss: 2.5557 | Learning Rate: 0.000492 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6583/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000492 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6584/12542 | Batch Loss: 1.4257 | Learning Rate: 0.000492 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6585/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000492 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6586/12542 | Batch Loss: 1.3425 | Learning Rate: 0.000492 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6587/12542 | Batch Loss: 1.1111 | Learning Rate: 0.000492 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6588/12542 | Batch Loss: 0.6780 | Learning Rate: 0.000492 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6589/12542 | Batch Loss: 1.7737 | Learning Rate: 0.000492 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6590/12542 | Batch Loss: 1.1867 | Learning Rate: 0.000492 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6591/12542 | Batch Loss: 1.8352 | Learning Rate: 0.000491 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6592/12542 | Batch Loss: 0.9807 | Learning Rate: 0.000491 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6593/12542 | Batch Loss: 0.4478 | Learning Rate: 0.000491 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6594/12542 | Batch Loss: 3.2284 | Learning Rate: 0.000491 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6595/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000491 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6596/12542 | Batch Loss: 1.1810 | Learning Rate: 0.000491 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6597/12542 | Batch Loss: 1.4532 | Learning Rate: 0.000491 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6598/12542 | Batch Loss: 0.7814 | Learning Rate: 0.000491 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6599/12542 | Batch Loss: 1.9779 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6600/12542 | Batch Loss: 1.8527 | Learning Rate: 0.000491 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6601/12542 | Batch Loss: 1.7442 | Learning Rate: 0.000491 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6602/12542 | Batch Loss: 0.7275 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6603/12542 | Batch Loss: 0.3898 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6604/12542 | Batch Loss: 1.0947 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6605/12542 | Batch Loss: 0.4912 | Learning Rate: 0.000491 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6606/12542 | Batch Loss: 2.5338 | Learning Rate: 0.000491 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6607/12542 | Batch Loss: 0.7427 | Learning Rate: 0.000491 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6608/12542 | Batch Loss: 1.0631 | Learning Rate: 0.000491 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6609/12542 | Batch Loss: 1.5832 | Learning Rate: 0.000491 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6610/12542 | Batch Loss: 1.7599 | Learning Rate: 0.000491 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6611/12542 | Batch Loss: 2.6109 | Learning Rate: 0.000491 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6612/12542 | Batch Loss: 0.5963 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6613/12542 | Batch Loss: 2.6603 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6614/12542 | Batch Loss: 2.1774 | Learning Rate: 0.000491 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6615/12542 | Batch Loss: 0.5065 | Learning Rate: 0.000491 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6616/12542 | Batch Loss: 0.8575 | Learning Rate: 0.000491 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6617/12542 | Batch Loss: 1.0174 | Learning Rate: 0.000491 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6618/12542 | Batch Loss: 1.3181 | Learning Rate: 0.000491 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6619/12542 | Batch Loss: 2.2254 | Learning Rate: 0.000491 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6620/12542 | Batch Loss: 1.4323 | Learning Rate: 0.000491 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6621/12542 | Batch Loss: 1.2879 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6622/12542 | Batch Loss: 1.1398 | Learning Rate: 0.000491 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6623/12542 | Batch Loss: 1.4548 | Learning Rate: 0.000491 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6624/12542 | Batch Loss: 1.2938 | Learning Rate: 0.000491 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6625/12542 | Batch Loss: 0.8900 | Learning Rate: 0.000491 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6626/12542 | Batch Loss: 0.6409 | Learning Rate: 0.000491 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6627/12542 | Batch Loss: 0.9161 | Learning Rate: 0.000491 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6628/12542 | Batch Loss: 1.0427 | Learning Rate: 0.000491 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6629/12542 | Batch Loss: 1.5239 | Learning Rate: 0.000490 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6630/12542 | Batch Loss: 2.9842 | Learning Rate: 0.000490 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6631/12542 | Batch Loss: 2.0230 | Learning Rate: 0.000490 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6632/12542 | Batch Loss: 0.3540 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6633/12542 | Batch Loss: 3.0174 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6634/12542 | Batch Loss: 1.3957 | Learning Rate: 0.000490 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6635/12542 | Batch Loss: 1.7714 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6636/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6637/12542 | Batch Loss: 1.0995 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6638/12542 | Batch Loss: 0.4520 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6639/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000490 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6640/12542 | Batch Loss: 1.1284 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6641/12542 | Batch Loss: 1.7546 | Learning Rate: 0.000490 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6642/12542 | Batch Loss: 1.9244 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6643/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000490 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6644/12542 | Batch Loss: 0.8811 | Learning Rate: 0.000490 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6645/12542 | Batch Loss: 1.5519 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6646/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6647/12542 | Batch Loss: 2.4245 | Learning Rate: 0.000490 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6648/12542 | Batch Loss: 1.2711 | Learning Rate: 0.000490 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6649/12542 | Batch Loss: 1.6126 | Learning Rate: 0.000490 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6650/12542 | Batch Loss: 1.3763 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6651/12542 | Batch Loss: 1.0451 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6652/12542 | Batch Loss: 1.1883 | Learning Rate: 0.000490 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6653/12542 | Batch Loss: 1.5538 | Learning Rate: 0.000490 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6654/12542 | Batch Loss: 1.1811 | Learning Rate: 0.000490 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6655/12542 | Batch Loss: 0.7036 | Learning Rate: 0.000490 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6656/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6657/12542 | Batch Loss: 1.9145 | Learning Rate: 0.000490 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6658/12542 | Batch Loss: 1.4577 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6659/12542 | Batch Loss: 1.3064 | Learning Rate: 0.000490 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6660/12542 | Batch Loss: 0.4224 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6661/12542 | Batch Loss: 0.9784 | Learning Rate: 0.000490 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6662/12542 | Batch Loss: 0.7346 | Learning Rate: 0.000490 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6663/12542 | Batch Loss: 1.2602 | Learning Rate: 0.000490 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6664/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000490 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6665/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000490 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6666/12542 | Batch Loss: 0.6175 | Learning Rate: 0.000490 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6667/12542 | Batch Loss: 1.1796 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6668/12542 | Batch Loss: 0.7530 | Learning Rate: 0.000489 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6669/12542 | Batch Loss: 0.9290 | Learning Rate: 0.000489 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6670/12542 | Batch Loss: 0.9540 | Learning Rate: 0.000489 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6671/12542 | Batch Loss: 1.4971 | Learning Rate: 0.000489 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6672/12542 | Batch Loss: 3.7369 | Learning Rate: 0.000489 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6673/12542 | Batch Loss: 2.7659 | Learning Rate: 0.000489 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6674/12542 | Batch Loss: 1.1391 | Learning Rate: 0.000489 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6675/12542 | Batch Loss: 1.1700 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6676/12542 | Batch Loss: 1.2621 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6677/12542 | Batch Loss: 1.2746 | Learning Rate: 0.000489 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6678/12542 | Batch Loss: 3.4156 | Learning Rate: 0.000489 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6679/12542 | Batch Loss: 0.6691 | Learning Rate: 0.000489 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6680/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000489 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6681/12542 | Batch Loss: 1.2834 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6682/12542 | Batch Loss: 2.8156 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6683/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000489 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6684/12542 | Batch Loss: 0.8654 | Learning Rate: 0.000489 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6685/12542 | Batch Loss: 1.4364 | Learning Rate: 0.000489 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6686/12542 | Batch Loss: 0.9665 | Learning Rate: 0.000489 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6687/12542 | Batch Loss: 1.9714 | Learning Rate: 0.000489 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6688/12542 | Batch Loss: 1.9966 | Learning Rate: 0.000489 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6689/12542 | Batch Loss: 2.4281 | Learning Rate: 0.000489 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6690/12542 | Batch Loss: 2.1932 | Learning Rate: 0.000489 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6691/12542 | Batch Loss: 1.5583 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6692/12542 | Batch Loss: 0.6412 | Learning Rate: 0.000489 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6693/12542 | Batch Loss: 1.2245 | Learning Rate: 0.000489 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6694/12542 | Batch Loss: 0.4955 | Learning Rate: 0.000489 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6695/12542 | Batch Loss: 1.4506 | Learning Rate: 0.000489 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6696/12542 | Batch Loss: 1.8415 | Learning Rate: 0.000489 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6697/12542 | Batch Loss: 2.1775 | Learning Rate: 0.000489 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6698/12542 | Batch Loss: 2.4193 | Learning Rate: 0.000489 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6699/12542 | Batch Loss: 1.2294 | Learning Rate: 0.000489 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6700/12542 | Batch Loss: 2.6513 | Learning Rate: 0.000489 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6701/12542 | Batch Loss: 1.1290 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6702/12542 | Batch Loss: 1.1145 | Learning Rate: 0.000489 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6703/12542 | Batch Loss: 0.8905 | Learning Rate: 0.000489 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6704/12542 | Batch Loss: 0.7306 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6705/12542 | Batch Loss: 1.6827 | Learning Rate: 0.000488 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6706/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6707/12542 | Batch Loss: 1.2161 | Learning Rate: 0.000488 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6708/12542 | Batch Loss: 0.8981 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6709/12542 | Batch Loss: 1.5626 | Learning Rate: 0.000488 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6710/12542 | Batch Loss: 1.3454 | Learning Rate: 0.000488 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6711/12542 | Batch Loss: 1.3161 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6712/12542 | Batch Loss: 0.4269 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6713/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6714/12542 | Batch Loss: 2.5631 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6715/12542 | Batch Loss: 3.1248 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6716/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6717/12542 | Batch Loss: 1.0598 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6718/12542 | Batch Loss: 1.4555 | Learning Rate: 0.000488 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6719/12542 | Batch Loss: 0.9964 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6720/12542 | Batch Loss: 1.5997 | Learning Rate: 0.000488 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6721/12542 | Batch Loss: 1.2497 | Learning Rate: 0.000488 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6722/12542 | Batch Loss: 0.6304 | Learning Rate: 0.000488 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6723/12542 | Batch Loss: 0.9137 | Learning Rate: 0.000488 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6724/12542 | Batch Loss: 1.8298 | Learning Rate: 0.000488 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6725/12542 | Batch Loss: 1.7253 | Learning Rate: 0.000488 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6726/12542 | Batch Loss: 1.5443 | Learning Rate: 0.000488 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6727/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000488 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6728/12542 | Batch Loss: 0.5995 | Learning Rate: 0.000488 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6729/12542 | Batch Loss: 0.5945 | Learning Rate: 0.000488 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6730/12542 | Batch Loss: 1.2887 | Learning Rate: 0.000488 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6731/12542 | Batch Loss: 1.0238 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6732/12542 | Batch Loss: 0.5814 | Learning Rate: 0.000488 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6733/12542 | Batch Loss: 1.5908 | Learning Rate: 0.000488 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6734/12542 | Batch Loss: 1.6100 | Learning Rate: 0.000488 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6735/12542 | Batch Loss: 1.4329 | Learning Rate: 0.000488 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6736/12542 | Batch Loss: 1.2772 | Learning Rate: 0.000488 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6737/12542 | Batch Loss: 2.1617 | Learning Rate: 0.000488 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6738/12542 | Batch Loss: 0.9813 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6739/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6740/12542 | Batch Loss: 1.3585 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6741/12542 | Batch Loss: 1.9295 | Learning Rate: 0.000488 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6742/12542 | Batch Loss: 1.5644 | Learning Rate: 0.000487 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6743/12542 | Batch Loss: 1.0068 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6744/12542 | Batch Loss: 2.3558 | Learning Rate: 0.000487 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6745/12542 | Batch Loss: 2.4988 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6746/12542 | Batch Loss: 1.9665 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6747/12542 | Batch Loss: 1.3846 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6748/12542 | Batch Loss: 1.3028 | Learning Rate: 0.000487 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6749/12542 | Batch Loss: 2.1133 | Learning Rate: 0.000487 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6750/12542 | Batch Loss: 0.9877 | Learning Rate: 0.000487 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6751/12542 | Batch Loss: 3.2191 | Learning Rate: 0.000487 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6752/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6753/12542 | Batch Loss: 1.6334 | Learning Rate: 0.000487 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6754/12542 | Batch Loss: 0.6891 | Learning Rate: 0.000487 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6755/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6756/12542 | Batch Loss: 0.5784 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6757/12542 | Batch Loss: 3.0494 | Learning Rate: 0.000487 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6758/12542 | Batch Loss: 0.9378 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6759/12542 | Batch Loss: 1.5680 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6760/12542 | Batch Loss: 1.9869 | Learning Rate: 0.000487 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6761/12542 | Batch Loss: 1.8748 | Learning Rate: 0.000487 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6762/12542 | Batch Loss: 1.1275 | Learning Rate: 0.000487 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6763/12542 | Batch Loss: 1.2503 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6764/12542 | Batch Loss: 1.0570 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6765/12542 | Batch Loss: 3.0434 | Learning Rate: 0.000487 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6766/12542 | Batch Loss: 1.2393 | Learning Rate: 0.000487 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6767/12542 | Batch Loss: 0.9124 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6768/12542 | Batch Loss: 2.1560 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6769/12542 | Batch Loss: 1.5056 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6770/12542 | Batch Loss: 1.3072 | Learning Rate: 0.000487 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6771/12542 | Batch Loss: 1.0694 | Learning Rate: 0.000487 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6772/12542 | Batch Loss: 1.2549 | Learning Rate: 0.000487 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6773/12542 | Batch Loss: 0.8653 | Learning Rate: 0.000487 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6774/12542 | Batch Loss: 1.1067 | Learning Rate: 0.000487 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6775/12542 | Batch Loss: 0.7177 | Learning Rate: 0.000487 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6776/12542 | Batch Loss: 1.5988 | Learning Rate: 0.000487 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6777/12542 | Batch Loss: 2.9039 | Learning Rate: 0.000487 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6778/12542 | Batch Loss: 1.4047 | Learning Rate: 0.000487 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6779/12542 | Batch Loss: 1.9365 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6780/12542 | Batch Loss: 0.6187 | Learning Rate: 0.000486 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6781/12542 | Batch Loss: 0.6298 | Learning Rate: 0.000486 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6782/12542 | Batch Loss: 1.8481 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6783/12542 | Batch Loss: 1.2244 | Learning Rate: 0.000486 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6784/12542 | Batch Loss: 1.7345 | Learning Rate: 0.000486 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6785/12542 | Batch Loss: 1.6491 | Learning Rate: 0.000486 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6786/12542 | Batch Loss: 1.8951 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6787/12542 | Batch Loss: 1.1142 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6788/12542 | Batch Loss: 1.5350 | Learning Rate: 0.000486 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6789/12542 | Batch Loss: 2.0355 | Learning Rate: 0.000486 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6790/12542 | Batch Loss: 2.3744 | Learning Rate: 0.000486 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6791/12542 | Batch Loss: 1.0504 | Learning Rate: 0.000486 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6792/12542 | Batch Loss: 2.6634 | Learning Rate: 0.000486 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6793/12542 | Batch Loss: 1.2462 | Learning Rate: 0.000486 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6794/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6795/12542 | Batch Loss: 1.5639 | Learning Rate: 0.000486 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6796/12542 | Batch Loss: 1.2033 | Learning Rate: 0.000486 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6797/12542 | Batch Loss: 1.1397 | Learning Rate: 0.000486 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6798/12542 | Batch Loss: 0.8613 | Learning Rate: 0.000486 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6799/12542 | Batch Loss: 2.6573 | Learning Rate: 0.000486 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6800/12542 | Batch Loss: 0.7160 | Learning Rate: 0.000486 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6801/12542 | Batch Loss: 0.9354 | Learning Rate: 0.000486 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6802/12542 | Batch Loss: 0.7487 | Learning Rate: 0.000486 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6803/12542 | Batch Loss: 1.6121 | Learning Rate: 0.000486 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 6804/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000486 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6805/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000486 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6806/12542 | Batch Loss: 0.5939 | Learning Rate: 0.000486 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6807/12542 | Batch Loss: 0.5731 | Learning Rate: 0.000486 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6808/12542 | Batch Loss: 1.3081 | Learning Rate: 0.000486 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6809/12542 | Batch Loss: 1.7845 | Learning Rate: 0.000486 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6810/12542 | Batch Loss: 1.0726 | Learning Rate: 0.000486 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6811/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000486 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6812/12542 | Batch Loss: 1.3469 | Learning Rate: 0.000486 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6813/12542 | Batch Loss: 0.7555 | Learning Rate: 0.000486 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6814/12542 | Batch Loss: 0.8784 | Learning Rate: 0.000486 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6815/12542 | Batch Loss: 1.0901 | Learning Rate: 0.000486 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6816/12542 | Batch Loss: 1.9429 | Learning Rate: 0.000486 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6817/12542 | Batch Loss: 0.4552 | Learning Rate: 0.000485 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6818/12542 | Batch Loss: 0.9573 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6819/12542 | Batch Loss: 1.2249 | Learning Rate: 0.000485 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6820/12542 | Batch Loss: 1.4995 | Learning Rate: 0.000485 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6821/12542 | Batch Loss: 0.9698 | Learning Rate: 0.000485 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6822/12542 | Batch Loss: 1.4741 | Learning Rate: 0.000485 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6823/12542 | Batch Loss: 1.7010 | Learning Rate: 0.000485 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6824/12542 | Batch Loss: 1.5674 | Learning Rate: 0.000485 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6825/12542 | Batch Loss: 1.4935 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6826/12542 | Batch Loss: 0.7514 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6827/12542 | Batch Loss: 0.8320 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6828/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000485 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6829/12542 | Batch Loss: 1.0257 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6830/12542 | Batch Loss: 2.1053 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6831/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000485 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6832/12542 | Batch Loss: 1.5956 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6833/12542 | Batch Loss: 3.0349 | Learning Rate: 0.000485 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6834/12542 | Batch Loss: 1.1563 | Learning Rate: 0.000485 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6835/12542 | Batch Loss: 0.8769 | Learning Rate: 0.000485 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6836/12542 | Batch Loss: 0.8393 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6837/12542 | Batch Loss: 1.8652 | Learning Rate: 0.000485 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6838/12542 | Batch Loss: 1.2298 | Learning Rate: 0.000485 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6839/12542 | Batch Loss: 1.0543 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6840/12542 | Batch Loss: 1.3518 | Learning Rate: 0.000485 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6841/12542 | Batch Loss: 1.1998 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6842/12542 | Batch Loss: 1.2456 | Learning Rate: 0.000485 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6843/12542 | Batch Loss: 1.3210 | Learning Rate: 0.000485 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6844/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000485 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6845/12542 | Batch Loss: 0.7368 | Learning Rate: 0.000485 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6846/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6847/12542 | Batch Loss: 1.4190 | Learning Rate: 0.000485 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6848/12542 | Batch Loss: 0.9418 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6849/12542 | Batch Loss: 1.2001 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6850/12542 | Batch Loss: 1.5684 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6851/12542 | Batch Loss: 0.7712 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6852/12542 | Batch Loss: 0.9019 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6853/12542 | Batch Loss: 0.9417 | Learning Rate: 0.000485 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6854/12542 | Batch Loss: 1.1734 | Learning Rate: 0.000485 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6855/12542 | Batch Loss: 0.7188 | Learning Rate: 0.000484 | Batch Time: 0.56s\n",
      "Epoch 2 | Step 6856/12542 | Batch Loss: 1.9854 | Learning Rate: 0.000484 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6857/12542 | Batch Loss: 1.3929 | Learning Rate: 0.000484 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6858/12542 | Batch Loss: 1.9495 | Learning Rate: 0.000484 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6859/12542 | Batch Loss: 0.7275 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6860/12542 | Batch Loss: 1.8358 | Learning Rate: 0.000484 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6861/12542 | Batch Loss: 1.0438 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6862/12542 | Batch Loss: 1.9733 | Learning Rate: 0.000484 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6863/12542 | Batch Loss: 0.5154 | Learning Rate: 0.000484 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6864/12542 | Batch Loss: 2.3416 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6865/12542 | Batch Loss: 1.7701 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6866/12542 | Batch Loss: 0.6916 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6867/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6868/12542 | Batch Loss: 0.9346 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6869/12542 | Batch Loss: 1.8269 | Learning Rate: 0.000484 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6870/12542 | Batch Loss: 1.9473 | Learning Rate: 0.000484 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6871/12542 | Batch Loss: 0.6366 | Learning Rate: 0.000484 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6872/12542 | Batch Loss: 0.8316 | Learning Rate: 0.000484 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6873/12542 | Batch Loss: 0.5178 | Learning Rate: 0.000484 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6874/12542 | Batch Loss: 1.2648 | Learning Rate: 0.000484 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6875/12542 | Batch Loss: 0.8685 | Learning Rate: 0.000484 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6876/12542 | Batch Loss: 0.9176 | Learning Rate: 0.000484 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6877/12542 | Batch Loss: 0.3504 | Learning Rate: 0.000484 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6878/12542 | Batch Loss: 1.4338 | Learning Rate: 0.000484 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6879/12542 | Batch Loss: 1.6370 | Learning Rate: 0.000484 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6880/12542 | Batch Loss: 0.6116 | Learning Rate: 0.000484 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6881/12542 | Batch Loss: 0.8490 | Learning Rate: 0.000484 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6882/12542 | Batch Loss: 1.1788 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6883/12542 | Batch Loss: 2.5750 | Learning Rate: 0.000484 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6884/12542 | Batch Loss: 1.8662 | Learning Rate: 0.000484 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6885/12542 | Batch Loss: 0.5375 | Learning Rate: 0.000484 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6886/12542 | Batch Loss: 1.9594 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6887/12542 | Batch Loss: 2.2413 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6888/12542 | Batch Loss: 1.4000 | Learning Rate: 0.000484 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6889/12542 | Batch Loss: 0.5795 | Learning Rate: 0.000484 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6890/12542 | Batch Loss: 1.3493 | Learning Rate: 0.000484 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6891/12542 | Batch Loss: 1.4831 | Learning Rate: 0.000484 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6892/12542 | Batch Loss: 2.0364 | Learning Rate: 0.000483 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6893/12542 | Batch Loss: 2.2964 | Learning Rate: 0.000483 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6894/12542 | Batch Loss: 1.5161 | Learning Rate: 0.000483 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6895/12542 | Batch Loss: 0.5243 | Learning Rate: 0.000483 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6896/12542 | Batch Loss: 1.8961 | Learning Rate: 0.000483 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6897/12542 | Batch Loss: 0.9744 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6898/12542 | Batch Loss: 0.8758 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6899/12542 | Batch Loss: 0.6674 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6900/12542 | Batch Loss: 1.8377 | Learning Rate: 0.000483 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6901/12542 | Batch Loss: 0.7891 | Learning Rate: 0.000483 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6902/12542 | Batch Loss: 1.3610 | Learning Rate: 0.000483 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6903/12542 | Batch Loss: 1.7557 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6904/12542 | Batch Loss: 1.7888 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6905/12542 | Batch Loss: 1.5508 | Learning Rate: 0.000483 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6906/12542 | Batch Loss: 1.9316 | Learning Rate: 0.000483 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6907/12542 | Batch Loss: 1.1542 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6908/12542 | Batch Loss: 0.8438 | Learning Rate: 0.000483 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6909/12542 | Batch Loss: 1.6020 | Learning Rate: 0.000483 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6910/12542 | Batch Loss: 1.9681 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6911/12542 | Batch Loss: 0.8077 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6912/12542 | Batch Loss: 0.8605 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6913/12542 | Batch Loss: 1.1744 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6914/12542 | Batch Loss: 0.7902 | Learning Rate: 0.000483 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 6915/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000483 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6916/12542 | Batch Loss: 1.2312 | Learning Rate: 0.000483 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6917/12542 | Batch Loss: 1.5256 | Learning Rate: 0.000483 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6918/12542 | Batch Loss: 3.2713 | Learning Rate: 0.000483 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6919/12542 | Batch Loss: 1.8027 | Learning Rate: 0.000483 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6920/12542 | Batch Loss: 1.6972 | Learning Rate: 0.000483 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6921/12542 | Batch Loss: 0.4799 | Learning Rate: 0.000483 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6922/12542 | Batch Loss: 2.0432 | Learning Rate: 0.000483 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6923/12542 | Batch Loss: 1.3042 | Learning Rate: 0.000483 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6924/12542 | Batch Loss: 1.1128 | Learning Rate: 0.000483 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6925/12542 | Batch Loss: 0.7952 | Learning Rate: 0.000483 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6926/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000483 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6927/12542 | Batch Loss: 1.7790 | Learning Rate: 0.000483 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6928/12542 | Batch Loss: 1.1699 | Learning Rate: 0.000483 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6929/12542 | Batch Loss: 1.4951 | Learning Rate: 0.000483 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 6930/12542 | Batch Loss: 1.8452 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6931/12542 | Batch Loss: 1.7128 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6932/12542 | Batch Loss: 1.4304 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6933/12542 | Batch Loss: 0.4619 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6934/12542 | Batch Loss: 1.3914 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6935/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000482 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6936/12542 | Batch Loss: 1.3599 | Learning Rate: 0.000482 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6937/12542 | Batch Loss: 1.1232 | Learning Rate: 0.000482 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6938/12542 | Batch Loss: 0.5494 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6939/12542 | Batch Loss: 1.7247 | Learning Rate: 0.000482 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6940/12542 | Batch Loss: 0.9878 | Learning Rate: 0.000482 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6941/12542 | Batch Loss: 1.2198 | Learning Rate: 0.000482 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6942/12542 | Batch Loss: 1.5904 | Learning Rate: 0.000482 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6943/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000482 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6944/12542 | Batch Loss: 0.9404 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6945/12542 | Batch Loss: 1.6142 | Learning Rate: 0.000482 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6946/12542 | Batch Loss: 1.3230 | Learning Rate: 0.000482 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6947/12542 | Batch Loss: 0.8210 | Learning Rate: 0.000482 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6948/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6949/12542 | Batch Loss: 0.6614 | Learning Rate: 0.000482 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6950/12542 | Batch Loss: 0.9040 | Learning Rate: 0.000482 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6951/12542 | Batch Loss: 2.4986 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6952/12542 | Batch Loss: 0.7194 | Learning Rate: 0.000482 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6953/12542 | Batch Loss: 0.9031 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6954/12542 | Batch Loss: 0.7640 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6955/12542 | Batch Loss: 1.3291 | Learning Rate: 0.000482 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6956/12542 | Batch Loss: 2.5567 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6957/12542 | Batch Loss: 0.4676 | Learning Rate: 0.000482 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6958/12542 | Batch Loss: 0.6464 | Learning Rate: 0.000482 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 6959/12542 | Batch Loss: 0.9892 | Learning Rate: 0.000482 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6960/12542 | Batch Loss: 1.2310 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6961/12542 | Batch Loss: 2.3616 | Learning Rate: 0.000482 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 6962/12542 | Batch Loss: 3.0460 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6963/12542 | Batch Loss: 2.4535 | Learning Rate: 0.000482 | Batch Time: 0.73s\n",
      "Epoch 2 | Step 6964/12542 | Batch Loss: 2.3725 | Learning Rate: 0.000482 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6965/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000482 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6966/12542 | Batch Loss: 1.1127 | Learning Rate: 0.000482 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6967/12542 | Batch Loss: 0.6666 | Learning Rate: 0.000482 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6968/12542 | Batch Loss: 0.8845 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6969/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6970/12542 | Batch Loss: 1.7732 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6971/12542 | Batch Loss: 0.8007 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6972/12542 | Batch Loss: 1.0863 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6973/12542 | Batch Loss: 1.6382 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6974/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000481 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 6975/12542 | Batch Loss: 1.5666 | Learning Rate: 0.000481 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 6976/12542 | Batch Loss: 0.8598 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6977/12542 | Batch Loss: 1.0541 | Learning Rate: 0.000481 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 6978/12542 | Batch Loss: 0.5666 | Learning Rate: 0.000481 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6979/12542 | Batch Loss: 0.9844 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6980/12542 | Batch Loss: 0.5547 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6981/12542 | Batch Loss: 0.8034 | Learning Rate: 0.000481 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 6982/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000481 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6983/12542 | Batch Loss: 0.8185 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6984/12542 | Batch Loss: 0.6184 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6985/12542 | Batch Loss: 0.8467 | Learning Rate: 0.000481 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 6986/12542 | Batch Loss: 0.9808 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6987/12542 | Batch Loss: 0.8549 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6988/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000481 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6989/12542 | Batch Loss: 2.0487 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6990/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6991/12542 | Batch Loss: 1.9830 | Learning Rate: 0.000481 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6992/12542 | Batch Loss: 3.0274 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6993/12542 | Batch Loss: 0.6152 | Learning Rate: 0.000481 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 6994/12542 | Batch Loss: 0.1966 | Learning Rate: 0.000481 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 6995/12542 | Batch Loss: 0.9665 | Learning Rate: 0.000481 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 6996/12542 | Batch Loss: 0.8566 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6997/12542 | Batch Loss: 0.8888 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 6998/12542 | Batch Loss: 2.0703 | Learning Rate: 0.000481 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 6999/12542 | Batch Loss: 0.8406 | Learning Rate: 0.000481 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7000/12542 | Batch Loss: 1.6470 | Learning Rate: 0.000481 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7001/12542 | Batch Loss: 1.4230 | Learning Rate: 0.000481 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7002/12542 | Batch Loss: 1.2407 | Learning Rate: 0.000481 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7003/12542 | Batch Loss: 1.2938 | Learning Rate: 0.000481 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7004/12542 | Batch Loss: 0.7228 | Learning Rate: 0.000481 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7005/12542 | Batch Loss: 2.8402 | Learning Rate: 0.000480 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 7006/12542 | Batch Loss: 0.7546 | Learning Rate: 0.000480 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7007/12542 | Batch Loss: 1.7306 | Learning Rate: 0.000480 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7008/12542 | Batch Loss: 0.7325 | Learning Rate: 0.000480 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7009/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000480 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7010/12542 | Batch Loss: 0.5640 | Learning Rate: 0.000480 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7011/12542 | Batch Loss: 1.9200 | Learning Rate: 0.000480 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7012/12542 | Batch Loss: 1.2819 | Learning Rate: 0.000480 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7013/12542 | Batch Loss: 1.4542 | Learning Rate: 0.000480 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7014/12542 | Batch Loss: 2.4155 | Learning Rate: 0.000480 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7015/12542 | Batch Loss: 0.5127 | Learning Rate: 0.000480 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7016/12542 | Batch Loss: 0.7236 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7017/12542 | Batch Loss: 0.8285 | Learning Rate: 0.000480 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7018/12542 | Batch Loss: 1.3726 | Learning Rate: 0.000480 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7019/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000480 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7020/12542 | Batch Loss: 3.1575 | Learning Rate: 0.000480 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7021/12542 | Batch Loss: 1.0065 | Learning Rate: 0.000480 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7022/12542 | Batch Loss: 1.3586 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7023/12542 | Batch Loss: 2.2250 | Learning Rate: 0.000480 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7024/12542 | Batch Loss: 1.1348 | Learning Rate: 0.000480 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7025/12542 | Batch Loss: 0.6796 | Learning Rate: 0.000480 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7026/12542 | Batch Loss: 0.9717 | Learning Rate: 0.000480 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7027/12542 | Batch Loss: 0.5108 | Learning Rate: 0.000480 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7028/12542 | Batch Loss: 1.3533 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7029/12542 | Batch Loss: 2.0857 | Learning Rate: 0.000480 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7030/12542 | Batch Loss: 2.2466 | Learning Rate: 0.000480 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7031/12542 | Batch Loss: 1.4164 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7032/12542 | Batch Loss: 1.6848 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7033/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7034/12542 | Batch Loss: 1.7086 | Learning Rate: 0.000480 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7035/12542 | Batch Loss: 1.6505 | Learning Rate: 0.000480 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7036/12542 | Batch Loss: 0.6650 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7037/12542 | Batch Loss: 0.7103 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7038/12542 | Batch Loss: 1.1607 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7039/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000480 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7040/12542 | Batch Loss: 2.6598 | Learning Rate: 0.000480 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7041/12542 | Batch Loss: 2.1945 | Learning Rate: 0.000480 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7042/12542 | Batch Loss: 1.6740 | Learning Rate: 0.000480 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7043/12542 | Batch Loss: 0.5871 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7044/12542 | Batch Loss: 0.8407 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7045/12542 | Batch Loss: 2.8759 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7046/12542 | Batch Loss: 1.1330 | Learning Rate: 0.000479 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7047/12542 | Batch Loss: 1.9920 | Learning Rate: 0.000479 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7048/12542 | Batch Loss: 1.2186 | Learning Rate: 0.000479 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7049/12542 | Batch Loss: 1.7855 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7050/12542 | Batch Loss: 2.3905 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7051/12542 | Batch Loss: 1.8481 | Learning Rate: 0.000479 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7052/12542 | Batch Loss: 1.8012 | Learning Rate: 0.000479 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7053/12542 | Batch Loss: 1.8360 | Learning Rate: 0.000479 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7054/12542 | Batch Loss: 0.5049 | Learning Rate: 0.000479 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7055/12542 | Batch Loss: 0.6977 | Learning Rate: 0.000479 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7056/12542 | Batch Loss: 1.2819 | Learning Rate: 0.000479 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7057/12542 | Batch Loss: 1.3201 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7058/12542 | Batch Loss: 1.9854 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7059/12542 | Batch Loss: 2.2293 | Learning Rate: 0.000479 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7060/12542 | Batch Loss: 0.4888 | Learning Rate: 0.000479 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7061/12542 | Batch Loss: 1.3642 | Learning Rate: 0.000479 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7062/12542 | Batch Loss: 1.5693 | Learning Rate: 0.000479 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7063/12542 | Batch Loss: 1.7127 | Learning Rate: 0.000479 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7064/12542 | Batch Loss: 2.0597 | Learning Rate: 0.000479 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7065/12542 | Batch Loss: 0.9534 | Learning Rate: 0.000479 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7066/12542 | Batch Loss: 3.2683 | Learning Rate: 0.000479 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7067/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000479 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7068/12542 | Batch Loss: 0.9226 | Learning Rate: 0.000479 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7069/12542 | Batch Loss: 0.6806 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7070/12542 | Batch Loss: 2.6610 | Learning Rate: 0.000479 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7071/12542 | Batch Loss: 1.2398 | Learning Rate: 0.000479 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7072/12542 | Batch Loss: 0.9580 | Learning Rate: 0.000479 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7073/12542 | Batch Loss: 1.6230 | Learning Rate: 0.000479 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7074/12542 | Batch Loss: 0.8712 | Learning Rate: 0.000479 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7075/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000479 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7076/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000479 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7077/12542 | Batch Loss: 1.9053 | Learning Rate: 0.000479 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7078/12542 | Batch Loss: 1.5300 | Learning Rate: 0.000479 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7079/12542 | Batch Loss: 1.0354 | Learning Rate: 0.000479 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7080/12542 | Batch Loss: 2.5633 | Learning Rate: 0.000478 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7081/12542 | Batch Loss: 1.2339 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7082/12542 | Batch Loss: 2.3860 | Learning Rate: 0.000478 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7083/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7084/12542 | Batch Loss: 0.7323 | Learning Rate: 0.000478 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7085/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7086/12542 | Batch Loss: 0.8153 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7087/12542 | Batch Loss: 1.3484 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7088/12542 | Batch Loss: 0.8074 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7089/12542 | Batch Loss: 1.6346 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7090/12542 | Batch Loss: 1.0927 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7091/12542 | Batch Loss: 2.1726 | Learning Rate: 0.000478 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7092/12542 | Batch Loss: 0.8256 | Learning Rate: 0.000478 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7093/12542 | Batch Loss: 1.1837 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7094/12542 | Batch Loss: 1.4342 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7095/12542 | Batch Loss: 1.8475 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7096/12542 | Batch Loss: 1.9196 | Learning Rate: 0.000478 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7097/12542 | Batch Loss: 1.6370 | Learning Rate: 0.000478 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7098/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000478 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7099/12542 | Batch Loss: 0.7645 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7100/12542 | Batch Loss: 0.9050 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7101/12542 | Batch Loss: 1.8134 | Learning Rate: 0.000478 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7102/12542 | Batch Loss: 0.6436 | Learning Rate: 0.000478 | Batch Time: 0.72s\n",
      "Epoch 2 | Step 7103/12542 | Batch Loss: 1.2852 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7104/12542 | Batch Loss: 1.5468 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7105/12542 | Batch Loss: 0.5437 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7106/12542 | Batch Loss: 1.8276 | Learning Rate: 0.000478 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7107/12542 | Batch Loss: 0.9402 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7108/12542 | Batch Loss: 0.7179 | Learning Rate: 0.000478 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7109/12542 | Batch Loss: 1.3916 | Learning Rate: 0.000478 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7110/12542 | Batch Loss: 1.3431 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7111/12542 | Batch Loss: 1.5533 | Learning Rate: 0.000478 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7112/12542 | Batch Loss: 0.6828 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7113/12542 | Batch Loss: 0.5985 | Learning Rate: 0.000478 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7114/12542 | Batch Loss: 0.4230 | Learning Rate: 0.000478 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7115/12542 | Batch Loss: 1.6025 | Learning Rate: 0.000478 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7116/12542 | Batch Loss: 2.0324 | Learning Rate: 0.000478 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7117/12542 | Batch Loss: 0.6191 | Learning Rate: 0.000478 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7118/12542 | Batch Loss: 1.2120 | Learning Rate: 0.000477 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7119/12542 | Batch Loss: 1.5402 | Learning Rate: 0.000477 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7120/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7121/12542 | Batch Loss: 2.0490 | Learning Rate: 0.000477 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7122/12542 | Batch Loss: 0.9549 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7123/12542 | Batch Loss: 0.6233 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7124/12542 | Batch Loss: 0.6122 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7125/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000477 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7126/12542 | Batch Loss: 1.5103 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7127/12542 | Batch Loss: 3.3966 | Learning Rate: 0.000477 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7128/12542 | Batch Loss: 2.3272 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7129/12542 | Batch Loss: 2.0953 | Learning Rate: 0.000477 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7130/12542 | Batch Loss: 1.8278 | Learning Rate: 0.000477 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7131/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7132/12542 | Batch Loss: 1.0058 | Learning Rate: 0.000477 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7133/12542 | Batch Loss: 2.3317 | Learning Rate: 0.000477 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7134/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000477 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7135/12542 | Batch Loss: 2.5153 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7136/12542 | Batch Loss: 0.8879 | Learning Rate: 0.000477 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7137/12542 | Batch Loss: 0.9877 | Learning Rate: 0.000477 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7138/12542 | Batch Loss: 1.3270 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7139/12542 | Batch Loss: 1.4007 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7140/12542 | Batch Loss: 0.8608 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7141/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000477 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7142/12542 | Batch Loss: 1.9864 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7143/12542 | Batch Loss: 0.7392 | Learning Rate: 0.000477 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7144/12542 | Batch Loss: 2.2077 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7145/12542 | Batch Loss: 0.9629 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7146/12542 | Batch Loss: 1.2334 | Learning Rate: 0.000477 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7147/12542 | Batch Loss: 1.6326 | Learning Rate: 0.000477 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7148/12542 | Batch Loss: 1.4266 | Learning Rate: 0.000477 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7149/12542 | Batch Loss: 1.6123 | Learning Rate: 0.000477 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7150/12542 | Batch Loss: 1.4674 | Learning Rate: 0.000477 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7151/12542 | Batch Loss: 1.5601 | Learning Rate: 0.000477 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7152/12542 | Batch Loss: 1.2914 | Learning Rate: 0.000477 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7153/12542 | Batch Loss: 2.6322 | Learning Rate: 0.000477 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7154/12542 | Batch Loss: 2.7242 | Learning Rate: 0.000477 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7155/12542 | Batch Loss: 1.5267 | Learning Rate: 0.000477 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7156/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000476 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7157/12542 | Batch Loss: 1.7381 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7158/12542 | Batch Loss: 1.0613 | Learning Rate: 0.000476 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7159/12542 | Batch Loss: 1.6381 | Learning Rate: 0.000476 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7160/12542 | Batch Loss: 1.0390 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7161/12542 | Batch Loss: 1.0880 | Learning Rate: 0.000476 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7162/12542 | Batch Loss: 0.9049 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7163/12542 | Batch Loss: 0.9421 | Learning Rate: 0.000476 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7164/12542 | Batch Loss: 1.0595 | Learning Rate: 0.000476 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7165/12542 | Batch Loss: 0.6772 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7166/12542 | Batch Loss: 1.1652 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7167/12542 | Batch Loss: 0.5344 | Learning Rate: 0.000476 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7168/12542 | Batch Loss: 3.4330 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7169/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7170/12542 | Batch Loss: 0.5048 | Learning Rate: 0.000476 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7171/12542 | Batch Loss: 1.2744 | Learning Rate: 0.000476 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7172/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000476 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7173/12542 | Batch Loss: 1.6822 | Learning Rate: 0.000476 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7174/12542 | Batch Loss: 0.4351 | Learning Rate: 0.000476 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7175/12542 | Batch Loss: 1.4648 | Learning Rate: 0.000476 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7176/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000476 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7177/12542 | Batch Loss: 1.2770 | Learning Rate: 0.000476 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7178/12542 | Batch Loss: 0.7614 | Learning Rate: 0.000476 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7179/12542 | Batch Loss: 0.8182 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7180/12542 | Batch Loss: 1.1441 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7181/12542 | Batch Loss: 1.3112 | Learning Rate: 0.000476 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7182/12542 | Batch Loss: 0.9278 | Learning Rate: 0.000476 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7183/12542 | Batch Loss: 1.0206 | Learning Rate: 0.000476 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7184/12542 | Batch Loss: 2.1870 | Learning Rate: 0.000476 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7185/12542 | Batch Loss: 2.0182 | Learning Rate: 0.000476 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7186/12542 | Batch Loss: 0.6370 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7187/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7188/12542 | Batch Loss: 0.7369 | Learning Rate: 0.000476 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7189/12542 | Batch Loss: 0.6291 | Learning Rate: 0.000476 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7190/12542 | Batch Loss: 1.5852 | Learning Rate: 0.000476 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7191/12542 | Batch Loss: 1.8325 | Learning Rate: 0.000476 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7192/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000476 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7193/12542 | Batch Loss: 1.2836 | Learning Rate: 0.000475 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7194/12542 | Batch Loss: 2.0919 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7195/12542 | Batch Loss: 2.0372 | Learning Rate: 0.000475 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7196/12542 | Batch Loss: 0.5455 | Learning Rate: 0.000475 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7197/12542 | Batch Loss: 1.8880 | Learning Rate: 0.000475 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7198/12542 | Batch Loss: 2.2255 | Learning Rate: 0.000475 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7199/12542 | Batch Loss: 1.3010 | Learning Rate: 0.000475 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7200/12542 | Batch Loss: 0.6055 | Learning Rate: 0.000475 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7201/12542 | Batch Loss: 0.4693 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7202/12542 | Batch Loss: 1.1418 | Learning Rate: 0.000475 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7203/12542 | Batch Loss: 2.7236 | Learning Rate: 0.000475 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7204/12542 | Batch Loss: 2.1308 | Learning Rate: 0.000475 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7205/12542 | Batch Loss: 0.7835 | Learning Rate: 0.000475 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7206/12542 | Batch Loss: 0.5256 | Learning Rate: 0.000475 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7207/12542 | Batch Loss: 0.4582 | Learning Rate: 0.000475 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7208/12542 | Batch Loss: 0.4054 | Learning Rate: 0.000475 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7209/12542 | Batch Loss: 1.6959 | Learning Rate: 0.000475 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7210/12542 | Batch Loss: 1.7804 | Learning Rate: 0.000475 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7211/12542 | Batch Loss: 2.1236 | Learning Rate: 0.000475 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7212/12542 | Batch Loss: 1.8495 | Learning Rate: 0.000475 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7213/12542 | Batch Loss: 0.7727 | Learning Rate: 0.000475 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7214/12542 | Batch Loss: 2.2644 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7215/12542 | Batch Loss: 1.6195 | Learning Rate: 0.000475 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7216/12542 | Batch Loss: 0.9922 | Learning Rate: 0.000475 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7217/12542 | Batch Loss: 1.6832 | Learning Rate: 0.000475 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7218/12542 | Batch Loss: 0.6055 | Learning Rate: 0.000475 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7219/12542 | Batch Loss: 2.5489 | Learning Rate: 0.000475 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7220/12542 | Batch Loss: 1.9392 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7221/12542 | Batch Loss: 1.1264 | Learning Rate: 0.000475 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7222/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000475 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7223/12542 | Batch Loss: 0.5397 | Learning Rate: 0.000475 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7224/12542 | Batch Loss: 0.4307 | Learning Rate: 0.000475 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7225/12542 | Batch Loss: 2.1113 | Learning Rate: 0.000475 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7226/12542 | Batch Loss: 2.3142 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7227/12542 | Batch Loss: 1.6365 | Learning Rate: 0.000475 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7228/12542 | Batch Loss: 2.0618 | Learning Rate: 0.000475 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7229/12542 | Batch Loss: 1.3770 | Learning Rate: 0.000475 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7230/12542 | Batch Loss: 0.6089 | Learning Rate: 0.000475 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7231/12542 | Batch Loss: 1.6873 | Learning Rate: 0.000474 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7232/12542 | Batch Loss: 0.6970 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7233/12542 | Batch Loss: 1.9250 | Learning Rate: 0.000474 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7234/12542 | Batch Loss: 1.3681 | Learning Rate: 0.000474 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7235/12542 | Batch Loss: 0.9904 | Learning Rate: 0.000474 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7236/12542 | Batch Loss: 0.9077 | Learning Rate: 0.000474 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7237/12542 | Batch Loss: 0.8094 | Learning Rate: 0.000474 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7238/12542 | Batch Loss: 1.4098 | Learning Rate: 0.000474 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7239/12542 | Batch Loss: 1.2860 | Learning Rate: 0.000474 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7240/12542 | Batch Loss: 0.9706 | Learning Rate: 0.000474 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7241/12542 | Batch Loss: 1.4991 | Learning Rate: 0.000474 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7242/12542 | Batch Loss: 0.7773 | Learning Rate: 0.000474 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7243/12542 | Batch Loss: 0.5780 | Learning Rate: 0.000474 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7244/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000474 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7245/12542 | Batch Loss: 1.8848 | Learning Rate: 0.000474 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7246/12542 | Batch Loss: 1.4306 | Learning Rate: 0.000474 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7247/12542 | Batch Loss: 1.2374 | Learning Rate: 0.000474 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7248/12542 | Batch Loss: 2.4094 | Learning Rate: 0.000474 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7249/12542 | Batch Loss: 1.2674 | Learning Rate: 0.000474 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7250/12542 | Batch Loss: 1.6760 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7251/12542 | Batch Loss: 0.8907 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7252/12542 | Batch Loss: 3.2214 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7253/12542 | Batch Loss: 1.0062 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7254/12542 | Batch Loss: 0.9712 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7255/12542 | Batch Loss: 1.1356 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7256/12542 | Batch Loss: 1.1334 | Learning Rate: 0.000474 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7257/12542 | Batch Loss: 0.9720 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7258/12542 | Batch Loss: 1.1968 | Learning Rate: 0.000474 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7259/12542 | Batch Loss: 1.2131 | Learning Rate: 0.000474 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7260/12542 | Batch Loss: 0.7317 | Learning Rate: 0.000474 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7261/12542 | Batch Loss: 0.9348 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7262/12542 | Batch Loss: 0.9121 | Learning Rate: 0.000474 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7263/12542 | Batch Loss: 2.6901 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7264/12542 | Batch Loss: 1.5698 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7265/12542 | Batch Loss: 1.2458 | Learning Rate: 0.000474 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7266/12542 | Batch Loss: 1.7377 | Learning Rate: 0.000474 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7267/12542 | Batch Loss: 1.8854 | Learning Rate: 0.000474 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7268/12542 | Batch Loss: 0.5787 | Learning Rate: 0.000474 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7269/12542 | Batch Loss: 1.0356 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7270/12542 | Batch Loss: 1.5191 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7271/12542 | Batch Loss: 1.0861 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7272/12542 | Batch Loss: 0.6494 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7273/12542 | Batch Loss: 1.0888 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7274/12542 | Batch Loss: 0.5919 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7275/12542 | Batch Loss: 1.3057 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7276/12542 | Batch Loss: 1.8165 | Learning Rate: 0.000473 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7277/12542 | Batch Loss: 1.3589 | Learning Rate: 0.000473 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7278/12542 | Batch Loss: 0.6130 | Learning Rate: 0.000473 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7279/12542 | Batch Loss: 2.3776 | Learning Rate: 0.000473 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7280/12542 | Batch Loss: 0.7645 | Learning Rate: 0.000473 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7281/12542 | Batch Loss: 2.1898 | Learning Rate: 0.000473 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7282/12542 | Batch Loss: 0.7296 | Learning Rate: 0.000473 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7283/12542 | Batch Loss: 1.2921 | Learning Rate: 0.000473 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7284/12542 | Batch Loss: 0.8705 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7285/12542 | Batch Loss: 1.5811 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7286/12542 | Batch Loss: 1.0235 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7287/12542 | Batch Loss: 1.1923 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7288/12542 | Batch Loss: 0.9691 | Learning Rate: 0.000473 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7289/12542 | Batch Loss: 0.9476 | Learning Rate: 0.000473 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7290/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000473 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7291/12542 | Batch Loss: 1.1685 | Learning Rate: 0.000473 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7292/12542 | Batch Loss: 1.6326 | Learning Rate: 0.000473 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7293/12542 | Batch Loss: 0.9868 | Learning Rate: 0.000473 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7294/12542 | Batch Loss: 0.8559 | Learning Rate: 0.000473 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7295/12542 | Batch Loss: 3.4951 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7296/12542 | Batch Loss: 1.3600 | Learning Rate: 0.000473 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7297/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000473 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7298/12542 | Batch Loss: 1.0884 | Learning Rate: 0.000473 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7299/12542 | Batch Loss: 1.5073 | Learning Rate: 0.000473 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7300/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000473 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7301/12542 | Batch Loss: 1.3980 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7302/12542 | Batch Loss: 1.1677 | Learning Rate: 0.000473 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7303/12542 | Batch Loss: 1.7236 | Learning Rate: 0.000473 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7304/12542 | Batch Loss: 2.0174 | Learning Rate: 0.000473 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7305/12542 | Batch Loss: 1.9269 | Learning Rate: 0.000473 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7306/12542 | Batch Loss: 1.9825 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7307/12542 | Batch Loss: 0.7103 | Learning Rate: 0.000472 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7308/12542 | Batch Loss: 1.1251 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7309/12542 | Batch Loss: 1.4235 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7310/12542 | Batch Loss: 2.5476 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7311/12542 | Batch Loss: 0.9435 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7312/12542 | Batch Loss: 1.0363 | Learning Rate: 0.000472 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7313/12542 | Batch Loss: 0.9471 | Learning Rate: 0.000472 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7314/12542 | Batch Loss: 1.0072 | Learning Rate: 0.000472 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7315/12542 | Batch Loss: 1.7508 | Learning Rate: 0.000472 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7316/12542 | Batch Loss: 0.8877 | Learning Rate: 0.000472 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7317/12542 | Batch Loss: 1.1120 | Learning Rate: 0.000472 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7318/12542 | Batch Loss: 0.8454 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7319/12542 | Batch Loss: 1.0689 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7320/12542 | Batch Loss: 1.3247 | Learning Rate: 0.000472 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7321/12542 | Batch Loss: 0.5223 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7322/12542 | Batch Loss: 1.5508 | Learning Rate: 0.000472 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7323/12542 | Batch Loss: 1.9645 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7324/12542 | Batch Loss: 1.5287 | Learning Rate: 0.000472 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7325/12542 | Batch Loss: 3.0235 | Learning Rate: 0.000472 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7326/12542 | Batch Loss: 2.1556 | Learning Rate: 0.000472 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7327/12542 | Batch Loss: 2.9780 | Learning Rate: 0.000472 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7328/12542 | Batch Loss: 1.5932 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7329/12542 | Batch Loss: 0.8000 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7330/12542 | Batch Loss: 1.5468 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7331/12542 | Batch Loss: 1.6222 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7332/12542 | Batch Loss: 1.3202 | Learning Rate: 0.000472 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7333/12542 | Batch Loss: 1.2608 | Learning Rate: 0.000472 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7334/12542 | Batch Loss: 1.9596 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7335/12542 | Batch Loss: 0.7740 | Learning Rate: 0.000472 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7336/12542 | Batch Loss: 2.2459 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7337/12542 | Batch Loss: 0.6918 | Learning Rate: 0.000472 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7338/12542 | Batch Loss: 0.6400 | Learning Rate: 0.000472 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7339/12542 | Batch Loss: 1.3407 | Learning Rate: 0.000472 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7340/12542 | Batch Loss: 0.8357 | Learning Rate: 0.000472 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7341/12542 | Batch Loss: 1.2314 | Learning Rate: 0.000472 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7342/12542 | Batch Loss: 1.5469 | Learning Rate: 0.000472 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7343/12542 | Batch Loss: 1.6413 | Learning Rate: 0.000472 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7344/12542 | Batch Loss: 1.4654 | Learning Rate: 0.000471 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7345/12542 | Batch Loss: 0.7747 | Learning Rate: 0.000471 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7346/12542 | Batch Loss: 1.9787 | Learning Rate: 0.000471 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7347/12542 | Batch Loss: 2.0491 | Learning Rate: 0.000471 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7348/12542 | Batch Loss: 2.1601 | Learning Rate: 0.000471 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7349/12542 | Batch Loss: 1.9486 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7350/12542 | Batch Loss: 1.1185 | Learning Rate: 0.000471 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7351/12542 | Batch Loss: 2.1733 | Learning Rate: 0.000471 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7352/12542 | Batch Loss: 1.2849 | Learning Rate: 0.000471 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7353/12542 | Batch Loss: 0.8528 | Learning Rate: 0.000471 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7354/12542 | Batch Loss: 1.5360 | Learning Rate: 0.000471 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7355/12542 | Batch Loss: 0.7245 | Learning Rate: 0.000471 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7356/12542 | Batch Loss: 1.3494 | Learning Rate: 0.000471 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7357/12542 | Batch Loss: 1.5803 | Learning Rate: 0.000471 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7358/12542 | Batch Loss: 1.2685 | Learning Rate: 0.000471 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7359/12542 | Batch Loss: 1.3420 | Learning Rate: 0.000471 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7360/12542 | Batch Loss: 1.1493 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7361/12542 | Batch Loss: 2.5002 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7362/12542 | Batch Loss: 0.5366 | Learning Rate: 0.000471 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7363/12542 | Batch Loss: 1.1144 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7364/12542 | Batch Loss: 1.2100 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7365/12542 | Batch Loss: 1.1704 | Learning Rate: 0.000471 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7366/12542 | Batch Loss: 0.7840 | Learning Rate: 0.000471 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7367/12542 | Batch Loss: 1.1891 | Learning Rate: 0.000471 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7368/12542 | Batch Loss: 0.8322 | Learning Rate: 0.000471 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7369/12542 | Batch Loss: 0.7525 | Learning Rate: 0.000471 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7370/12542 | Batch Loss: 2.2966 | Learning Rate: 0.000471 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7371/12542 | Batch Loss: 1.0539 | Learning Rate: 0.000471 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7372/12542 | Batch Loss: 0.4630 | Learning Rate: 0.000471 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7373/12542 | Batch Loss: 0.6901 | Learning Rate: 0.000471 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7374/12542 | Batch Loss: 0.8714 | Learning Rate: 0.000471 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7375/12542 | Batch Loss: 1.3293 | Learning Rate: 0.000471 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7376/12542 | Batch Loss: 1.6678 | Learning Rate: 0.000471 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7377/12542 | Batch Loss: 1.2945 | Learning Rate: 0.000471 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7378/12542 | Batch Loss: 0.8682 | Learning Rate: 0.000471 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7379/12542 | Batch Loss: 1.3750 | Learning Rate: 0.000471 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7380/12542 | Batch Loss: 1.4785 | Learning Rate: 0.000471 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7381/12542 | Batch Loss: 1.2096 | Learning Rate: 0.000470 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7382/12542 | Batch Loss: 1.0865 | Learning Rate: 0.000470 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7383/12542 | Batch Loss: 0.7054 | Learning Rate: 0.000470 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7384/12542 | Batch Loss: 1.3537 | Learning Rate: 0.000470 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7385/12542 | Batch Loss: 0.8234 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7386/12542 | Batch Loss: 0.6692 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7387/12542 | Batch Loss: 1.3152 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7388/12542 | Batch Loss: 0.7271 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7389/12542 | Batch Loss: 2.6016 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7390/12542 | Batch Loss: 1.8010 | Learning Rate: 0.000470 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7391/12542 | Batch Loss: 1.0633 | Learning Rate: 0.000470 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7392/12542 | Batch Loss: 0.7560 | Learning Rate: 0.000470 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7393/12542 | Batch Loss: 1.4667 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7394/12542 | Batch Loss: 1.0721 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7395/12542 | Batch Loss: 1.6811 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7396/12542 | Batch Loss: 0.8540 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7397/12542 | Batch Loss: 1.1262 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7398/12542 | Batch Loss: 1.2609 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7399/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7400/12542 | Batch Loss: 0.6371 | Learning Rate: 0.000470 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7401/12542 | Batch Loss: 1.2936 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7402/12542 | Batch Loss: 0.8240 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7403/12542 | Batch Loss: 1.9615 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7404/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7405/12542 | Batch Loss: 1.4335 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7406/12542 | Batch Loss: 1.5620 | Learning Rate: 0.000470 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7407/12542 | Batch Loss: 1.1024 | Learning Rate: 0.000470 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7408/12542 | Batch Loss: 1.7715 | Learning Rate: 0.000470 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7409/12542 | Batch Loss: 0.8939 | Learning Rate: 0.000470 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7410/12542 | Batch Loss: 0.7836 | Learning Rate: 0.000470 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7411/12542 | Batch Loss: 0.8284 | Learning Rate: 0.000470 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7412/12542 | Batch Loss: 0.8990 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7413/12542 | Batch Loss: 0.8726 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7414/12542 | Batch Loss: 1.2859 | Learning Rate: 0.000470 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7415/12542 | Batch Loss: 1.6895 | Learning Rate: 0.000470 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7416/12542 | Batch Loss: 0.7141 | Learning Rate: 0.000470 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7417/12542 | Batch Loss: 3.3701 | Learning Rate: 0.000470 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7418/12542 | Batch Loss: 0.6102 | Learning Rate: 0.000470 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7419/12542 | Batch Loss: 1.2449 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7420/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000469 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7421/12542 | Batch Loss: 1.8321 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7422/12542 | Batch Loss: 1.9246 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7423/12542 | Batch Loss: 1.0029 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7424/12542 | Batch Loss: 1.9828 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7425/12542 | Batch Loss: 2.5516 | Learning Rate: 0.000469 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7426/12542 | Batch Loss: 0.9651 | Learning Rate: 0.000469 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7427/12542 | Batch Loss: 1.0334 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7428/12542 | Batch Loss: 1.2235 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7429/12542 | Batch Loss: 1.1343 | Learning Rate: 0.000469 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7430/12542 | Batch Loss: 0.7732 | Learning Rate: 0.000469 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7431/12542 | Batch Loss: 1.0224 | Learning Rate: 0.000469 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7432/12542 | Batch Loss: 0.6646 | Learning Rate: 0.000469 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7433/12542 | Batch Loss: 1.2459 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7434/12542 | Batch Loss: 1.7487 | Learning Rate: 0.000469 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7435/12542 | Batch Loss: 1.1091 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7436/12542 | Batch Loss: 1.1287 | Learning Rate: 0.000469 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7437/12542 | Batch Loss: 1.1742 | Learning Rate: 0.000469 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7438/12542 | Batch Loss: 0.7822 | Learning Rate: 0.000469 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7439/12542 | Batch Loss: 0.7709 | Learning Rate: 0.000469 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7440/12542 | Batch Loss: 2.5544 | Learning Rate: 0.000469 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7441/12542 | Batch Loss: 2.7615 | Learning Rate: 0.000469 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7442/12542 | Batch Loss: 0.6618 | Learning Rate: 0.000469 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 7443/12542 | Batch Loss: 2.9357 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7444/12542 | Batch Loss: 3.0514 | Learning Rate: 0.000469 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7445/12542 | Batch Loss: 1.7835 | Learning Rate: 0.000469 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7446/12542 | Batch Loss: 0.7219 | Learning Rate: 0.000469 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7447/12542 | Batch Loss: 0.6260 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7448/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7449/12542 | Batch Loss: 1.1044 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7450/12542 | Batch Loss: 0.9263 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7451/12542 | Batch Loss: 0.5201 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7452/12542 | Batch Loss: 1.6859 | Learning Rate: 0.000469 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7453/12542 | Batch Loss: 1.5241 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7454/12542 | Batch Loss: 2.6229 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7455/12542 | Batch Loss: 0.6298 | Learning Rate: 0.000469 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7456/12542 | Batch Loss: 1.5700 | Learning Rate: 0.000469 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7457/12542 | Batch Loss: 0.6906 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7458/12542 | Batch Loss: 1.6421 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7459/12542 | Batch Loss: 1.7754 | Learning Rate: 0.000468 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7460/12542 | Batch Loss: 1.8673 | Learning Rate: 0.000468 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7461/12542 | Batch Loss: 1.0784 | Learning Rate: 0.000468 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7462/12542 | Batch Loss: 2.4696 | Learning Rate: 0.000468 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7463/12542 | Batch Loss: 0.5846 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7464/12542 | Batch Loss: 1.4258 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7465/12542 | Batch Loss: 1.0182 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7466/12542 | Batch Loss: 1.5974 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7467/12542 | Batch Loss: 1.8199 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7468/12542 | Batch Loss: 1.4835 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7469/12542 | Batch Loss: 1.7699 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7470/12542 | Batch Loss: 1.4812 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7471/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7472/12542 | Batch Loss: 1.0571 | Learning Rate: 0.000468 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 7473/12542 | Batch Loss: 1.7916 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7474/12542 | Batch Loss: 1.6840 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7475/12542 | Batch Loss: 1.4741 | Learning Rate: 0.000468 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 7476/12542 | Batch Loss: 0.9631 | Learning Rate: 0.000468 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7477/12542 | Batch Loss: 1.1711 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7478/12542 | Batch Loss: 3.8091 | Learning Rate: 0.000468 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7479/12542 | Batch Loss: 2.1404 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7480/12542 | Batch Loss: 1.0370 | Learning Rate: 0.000468 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7481/12542 | Batch Loss: 1.1506 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7482/12542 | Batch Loss: 2.4835 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7483/12542 | Batch Loss: 1.5007 | Learning Rate: 0.000468 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7484/12542 | Batch Loss: 0.7134 | Learning Rate: 0.000468 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7485/12542 | Batch Loss: 1.4514 | Learning Rate: 0.000468 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7486/12542 | Batch Loss: 1.0487 | Learning Rate: 0.000468 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7487/12542 | Batch Loss: 0.5814 | Learning Rate: 0.000468 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7488/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000468 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7489/12542 | Batch Loss: 2.4273 | Learning Rate: 0.000468 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7490/12542 | Batch Loss: 1.3719 | Learning Rate: 0.000468 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7491/12542 | Batch Loss: 0.9755 | Learning Rate: 0.000468 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7492/12542 | Batch Loss: 1.7453 | Learning Rate: 0.000468 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7493/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000468 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7494/12542 | Batch Loss: 1.3644 | Learning Rate: 0.000467 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7495/12542 | Batch Loss: 1.7618 | Learning Rate: 0.000467 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7496/12542 | Batch Loss: 1.3596 | Learning Rate: 0.000467 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7497/12542 | Batch Loss: 2.1743 | Learning Rate: 0.000467 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7498/12542 | Batch Loss: 0.7344 | Learning Rate: 0.000467 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7499/12542 | Batch Loss: 1.7020 | Learning Rate: 0.000467 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7500/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000467 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7501/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000467 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7502/12542 | Batch Loss: 1.5988 | Learning Rate: 0.000467 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7503/12542 | Batch Loss: 1.3645 | Learning Rate: 0.000467 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7504/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000467 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7505/12542 | Batch Loss: 1.3823 | Learning Rate: 0.000467 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7506/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000467 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7507/12542 | Batch Loss: 1.3447 | Learning Rate: 0.000467 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7508/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000467 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7509/12542 | Batch Loss: 1.2574 | Learning Rate: 0.000467 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7510/12542 | Batch Loss: 0.6313 | Learning Rate: 0.000467 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7511/12542 | Batch Loss: 0.8989 | Learning Rate: 0.000467 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7512/12542 | Batch Loss: 1.2205 | Learning Rate: 0.000467 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7513/12542 | Batch Loss: 2.5010 | Learning Rate: 0.000467 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7514/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000467 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7515/12542 | Batch Loss: 0.8464 | Learning Rate: 0.000467 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7516/12542 | Batch Loss: 1.7925 | Learning Rate: 0.000467 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 7517/12542 | Batch Loss: 0.8640 | Learning Rate: 0.000467 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7518/12542 | Batch Loss: 1.4678 | Learning Rate: 0.000467 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7519/12542 | Batch Loss: 1.6924 | Learning Rate: 0.000467 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7520/12542 | Batch Loss: 1.7926 | Learning Rate: 0.000467 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7521/12542 | Batch Loss: 1.1129 | Learning Rate: 0.000467 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7522/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000467 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7523/12542 | Batch Loss: 1.7063 | Learning Rate: 0.000467 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7524/12542 | Batch Loss: 1.0251 | Learning Rate: 0.000467 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7525/12542 | Batch Loss: 0.7131 | Learning Rate: 0.000467 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7526/12542 | Batch Loss: 0.9250 | Learning Rate: 0.000467 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7527/12542 | Batch Loss: 1.2038 | Learning Rate: 0.000467 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7528/12542 | Batch Loss: 1.7336 | Learning Rate: 0.000467 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7529/12542 | Batch Loss: 2.9976 | Learning Rate: 0.000467 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7530/12542 | Batch Loss: 1.1982 | Learning Rate: 0.000467 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7531/12542 | Batch Loss: 2.1128 | Learning Rate: 0.000467 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7532/12542 | Batch Loss: 2.1702 | Learning Rate: 0.000466 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7533/12542 | Batch Loss: 1.4158 | Learning Rate: 0.000466 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7534/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7535/12542 | Batch Loss: 0.9429 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7536/12542 | Batch Loss: 0.7742 | Learning Rate: 0.000466 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7537/12542 | Batch Loss: 1.2981 | Learning Rate: 0.000466 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7538/12542 | Batch Loss: 1.2009 | Learning Rate: 0.000466 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7539/12542 | Batch Loss: 0.9776 | Learning Rate: 0.000466 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7540/12542 | Batch Loss: 0.5986 | Learning Rate: 0.000466 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7541/12542 | Batch Loss: 0.9088 | Learning Rate: 0.000466 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7542/12542 | Batch Loss: 1.2315 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7543/12542 | Batch Loss: 1.6043 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7544/12542 | Batch Loss: 1.6139 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7545/12542 | Batch Loss: 0.7728 | Learning Rate: 0.000466 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7546/12542 | Batch Loss: 2.9950 | Learning Rate: 0.000466 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7547/12542 | Batch Loss: 1.2700 | Learning Rate: 0.000466 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7548/12542 | Batch Loss: 1.0793 | Learning Rate: 0.000466 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7549/12542 | Batch Loss: 0.5396 | Learning Rate: 0.000466 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7550/12542 | Batch Loss: 1.7790 | Learning Rate: 0.000466 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7551/12542 | Batch Loss: 1.3479 | Learning Rate: 0.000466 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7552/12542 | Batch Loss: 1.3899 | Learning Rate: 0.000466 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7553/12542 | Batch Loss: 4.4030 | Learning Rate: 0.000466 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7554/12542 | Batch Loss: 1.2209 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7555/12542 | Batch Loss: 1.5568 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7556/12542 | Batch Loss: 1.8493 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7557/12542 | Batch Loss: 1.6645 | Learning Rate: 0.000466 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7558/12542 | Batch Loss: 2.1950 | Learning Rate: 0.000466 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7559/12542 | Batch Loss: 1.4639 | Learning Rate: 0.000466 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7560/12542 | Batch Loss: 1.2292 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7561/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000466 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7562/12542 | Batch Loss: 1.9742 | Learning Rate: 0.000466 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7563/12542 | Batch Loss: 1.5646 | Learning Rate: 0.000466 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7564/12542 | Batch Loss: 1.2409 | Learning Rate: 0.000466 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7565/12542 | Batch Loss: 1.1072 | Learning Rate: 0.000466 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7566/12542 | Batch Loss: 0.8298 | Learning Rate: 0.000466 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7567/12542 | Batch Loss: 1.2416 | Learning Rate: 0.000466 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7568/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000466 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7569/12542 | Batch Loss: 2.2758 | Learning Rate: 0.000466 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7570/12542 | Batch Loss: 0.6529 | Learning Rate: 0.000465 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7571/12542 | Batch Loss: 0.6897 | Learning Rate: 0.000465 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7572/12542 | Batch Loss: 1.3367 | Learning Rate: 0.000465 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7573/12542 | Batch Loss: 1.4473 | Learning Rate: 0.000465 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7574/12542 | Batch Loss: 1.4085 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7575/12542 | Batch Loss: 0.7512 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7576/12542 | Batch Loss: 2.2055 | Learning Rate: 0.000465 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7577/12542 | Batch Loss: 0.7017 | Learning Rate: 0.000465 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7578/12542 | Batch Loss: 2.4086 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7579/12542 | Batch Loss: 1.2070 | Learning Rate: 0.000465 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7580/12542 | Batch Loss: 0.7773 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7581/12542 | Batch Loss: 0.5422 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7582/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000465 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7583/12542 | Batch Loss: 3.0007 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7584/12542 | Batch Loss: 2.1564 | Learning Rate: 0.000465 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7585/12542 | Batch Loss: 1.3583 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7586/12542 | Batch Loss: 1.1924 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7587/12542 | Batch Loss: 1.6222 | Learning Rate: 0.000465 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7588/12542 | Batch Loss: 1.9284 | Learning Rate: 0.000465 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7589/12542 | Batch Loss: 1.6828 | Learning Rate: 0.000465 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7590/12542 | Batch Loss: 1.8832 | Learning Rate: 0.000465 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7591/12542 | Batch Loss: 1.6043 | Learning Rate: 0.000465 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7592/12542 | Batch Loss: 0.9092 | Learning Rate: 0.000465 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7593/12542 | Batch Loss: 1.2837 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7594/12542 | Batch Loss: 1.4379 | Learning Rate: 0.000465 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7595/12542 | Batch Loss: 1.3259 | Learning Rate: 0.000465 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7596/12542 | Batch Loss: 1.5369 | Learning Rate: 0.000465 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7597/12542 | Batch Loss: 0.5413 | Learning Rate: 0.000465 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7598/12542 | Batch Loss: 1.1913 | Learning Rate: 0.000465 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7599/12542 | Batch Loss: 1.9792 | Learning Rate: 0.000465 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7600/12542 | Batch Loss: 1.2514 | Learning Rate: 0.000465 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7601/12542 | Batch Loss: 1.6996 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7602/12542 | Batch Loss: 2.1903 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7603/12542 | Batch Loss: 1.3635 | Learning Rate: 0.000465 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7604/12542 | Batch Loss: 1.6114 | Learning Rate: 0.000465 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7605/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000465 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7606/12542 | Batch Loss: 0.8551 | Learning Rate: 0.000465 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7607/12542 | Batch Loss: 0.6399 | Learning Rate: 0.000464 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7608/12542 | Batch Loss: 0.5622 | Learning Rate: 0.000464 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7609/12542 | Batch Loss: 1.7684 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7610/12542 | Batch Loss: 2.4049 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7611/12542 | Batch Loss: 1.1966 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7612/12542 | Batch Loss: 1.0000 | Learning Rate: 0.000464 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7613/12542 | Batch Loss: 2.1162 | Learning Rate: 0.000464 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7614/12542 | Batch Loss: 0.9474 | Learning Rate: 0.000464 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7615/12542 | Batch Loss: 0.6933 | Learning Rate: 0.000464 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7616/12542 | Batch Loss: 3.1878 | Learning Rate: 0.000464 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7617/12542 | Batch Loss: 0.3515 | Learning Rate: 0.000464 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7618/12542 | Batch Loss: 1.3423 | Learning Rate: 0.000464 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7619/12542 | Batch Loss: 1.8753 | Learning Rate: 0.000464 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7620/12542 | Batch Loss: 0.7429 | Learning Rate: 0.000464 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7621/12542 | Batch Loss: 0.7485 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7622/12542 | Batch Loss: 1.4183 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7623/12542 | Batch Loss: 2.0040 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7624/12542 | Batch Loss: 1.7909 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7625/12542 | Batch Loss: 0.5900 | Learning Rate: 0.000464 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7626/12542 | Batch Loss: 1.2882 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7627/12542 | Batch Loss: 2.0400 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7628/12542 | Batch Loss: 0.9359 | Learning Rate: 0.000464 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7629/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000464 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7630/12542 | Batch Loss: 0.9264 | Learning Rate: 0.000464 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7631/12542 | Batch Loss: 1.5713 | Learning Rate: 0.000464 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7632/12542 | Batch Loss: 1.3526 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7633/12542 | Batch Loss: 1.3952 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7634/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7635/12542 | Batch Loss: 1.8769 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7636/12542 | Batch Loss: 0.9671 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7637/12542 | Batch Loss: 0.7425 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7638/12542 | Batch Loss: 0.4761 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7639/12542 | Batch Loss: 0.6698 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7640/12542 | Batch Loss: 1.4645 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7641/12542 | Batch Loss: 0.7684 | Learning Rate: 0.000464 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7642/12542 | Batch Loss: 0.6463 | Learning Rate: 0.000464 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7643/12542 | Batch Loss: 1.6670 | Learning Rate: 0.000464 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7644/12542 | Batch Loss: 0.8415 | Learning Rate: 0.000464 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7645/12542 | Batch Loss: 1.2929 | Learning Rate: 0.000463 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7646/12542 | Batch Loss: 0.8657 | Learning Rate: 0.000463 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7647/12542 | Batch Loss: 1.1086 | Learning Rate: 0.000463 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7648/12542 | Batch Loss: 0.8525 | Learning Rate: 0.000463 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7649/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000463 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7650/12542 | Batch Loss: 0.8399 | Learning Rate: 0.000463 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7651/12542 | Batch Loss: 0.9675 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7652/12542 | Batch Loss: 1.5119 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7653/12542 | Batch Loss: 0.9924 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7654/12542 | Batch Loss: 0.6742 | Learning Rate: 0.000463 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7655/12542 | Batch Loss: 2.1816 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7656/12542 | Batch Loss: 1.4808 | Learning Rate: 0.000463 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7657/12542 | Batch Loss: 1.9010 | Learning Rate: 0.000463 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7658/12542 | Batch Loss: 0.4941 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7659/12542 | Batch Loss: 1.1201 | Learning Rate: 0.000463 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7660/12542 | Batch Loss: 3.4849 | Learning Rate: 0.000463 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7661/12542 | Batch Loss: 1.7166 | Learning Rate: 0.000463 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7662/12542 | Batch Loss: 1.6216 | Learning Rate: 0.000463 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7663/12542 | Batch Loss: 1.2629 | Learning Rate: 0.000463 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7664/12542 | Batch Loss: 1.2019 | Learning Rate: 0.000463 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7665/12542 | Batch Loss: 1.2502 | Learning Rate: 0.000463 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7666/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000463 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7667/12542 | Batch Loss: 1.2262 | Learning Rate: 0.000463 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7668/12542 | Batch Loss: 1.4045 | Learning Rate: 0.000463 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7669/12542 | Batch Loss: 0.9041 | Learning Rate: 0.000463 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7670/12542 | Batch Loss: 0.7288 | Learning Rate: 0.000463 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7671/12542 | Batch Loss: 0.6895 | Learning Rate: 0.000463 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7672/12542 | Batch Loss: 1.0916 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7673/12542 | Batch Loss: 2.2640 | Learning Rate: 0.000463 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7674/12542 | Batch Loss: 0.6525 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7675/12542 | Batch Loss: 0.9082 | Learning Rate: 0.000463 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7676/12542 | Batch Loss: 0.7685 | Learning Rate: 0.000463 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7677/12542 | Batch Loss: 0.9900 | Learning Rate: 0.000463 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7678/12542 | Batch Loss: 0.9802 | Learning Rate: 0.000463 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7679/12542 | Batch Loss: 2.2304 | Learning Rate: 0.000463 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7680/12542 | Batch Loss: 1.8030 | Learning Rate: 0.000463 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7681/12542 | Batch Loss: 1.6460 | Learning Rate: 0.000463 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7682/12542 | Batch Loss: 0.8959 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7683/12542 | Batch Loss: 0.4969 | Learning Rate: 0.000462 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7684/12542 | Batch Loss: 1.7352 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7685/12542 | Batch Loss: 1.6870 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7686/12542 | Batch Loss: 1.5790 | Learning Rate: 0.000462 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7687/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000462 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7688/12542 | Batch Loss: 0.9756 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7689/12542 | Batch Loss: 1.6030 | Learning Rate: 0.000462 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7690/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7691/12542 | Batch Loss: 1.3078 | Learning Rate: 0.000462 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7692/12542 | Batch Loss: 0.9861 | Learning Rate: 0.000462 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7693/12542 | Batch Loss: 1.5625 | Learning Rate: 0.000462 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7694/12542 | Batch Loss: 0.3132 | Learning Rate: 0.000462 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7695/12542 | Batch Loss: 1.1593 | Learning Rate: 0.000462 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7696/12542 | Batch Loss: 0.7169 | Learning Rate: 0.000462 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7697/12542 | Batch Loss: 1.4064 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7698/12542 | Batch Loss: 2.0067 | Learning Rate: 0.000462 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7699/12542 | Batch Loss: 1.5447 | Learning Rate: 0.000462 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7700/12542 | Batch Loss: 0.7521 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7701/12542 | Batch Loss: 0.8091 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7702/12542 | Batch Loss: 1.5329 | Learning Rate: 0.000462 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7703/12542 | Batch Loss: 0.9237 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7704/12542 | Batch Loss: 3.4328 | Learning Rate: 0.000462 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7705/12542 | Batch Loss: 1.8154 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7706/12542 | Batch Loss: 1.5089 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7707/12542 | Batch Loss: 0.6873 | Learning Rate: 0.000462 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7708/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000462 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7709/12542 | Batch Loss: 1.2126 | Learning Rate: 0.000462 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7710/12542 | Batch Loss: 0.9214 | Learning Rate: 0.000462 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7711/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000462 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7712/12542 | Batch Loss: 1.0120 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7713/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7714/12542 | Batch Loss: 1.0209 | Learning Rate: 0.000462 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7715/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7716/12542 | Batch Loss: 0.6784 | Learning Rate: 0.000462 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7717/12542 | Batch Loss: 0.8314 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7718/12542 | Batch Loss: 0.9322 | Learning Rate: 0.000462 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7719/12542 | Batch Loss: 1.2245 | Learning Rate: 0.000462 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7720/12542 | Batch Loss: 1.1193 | Learning Rate: 0.000461 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7721/12542 | Batch Loss: 0.9805 | Learning Rate: 0.000461 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7722/12542 | Batch Loss: 1.6015 | Learning Rate: 0.000461 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7723/12542 | Batch Loss: 0.9132 | Learning Rate: 0.000461 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7724/12542 | Batch Loss: 1.3022 | Learning Rate: 0.000461 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7725/12542 | Batch Loss: 0.7773 | Learning Rate: 0.000461 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7726/12542 | Batch Loss: 0.9926 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7727/12542 | Batch Loss: 1.2314 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7728/12542 | Batch Loss: 1.8450 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7729/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7730/12542 | Batch Loss: 1.0171 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7731/12542 | Batch Loss: 0.8789 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7732/12542 | Batch Loss: 1.8993 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7733/12542 | Batch Loss: 0.8352 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7734/12542 | Batch Loss: 1.5608 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7735/12542 | Batch Loss: 2.0590 | Learning Rate: 0.000461 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7736/12542 | Batch Loss: 0.8222 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7737/12542 | Batch Loss: 0.5469 | Learning Rate: 0.000461 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7738/12542 | Batch Loss: 1.1200 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7739/12542 | Batch Loss: 1.7063 | Learning Rate: 0.000461 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7740/12542 | Batch Loss: 1.5924 | Learning Rate: 0.000461 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7741/12542 | Batch Loss: 0.4407 | Learning Rate: 0.000461 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7742/12542 | Batch Loss: 0.6404 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7743/12542 | Batch Loss: 1.9315 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7744/12542 | Batch Loss: 2.0160 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7745/12542 | Batch Loss: 1.0947 | Learning Rate: 0.000461 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7746/12542 | Batch Loss: 2.3692 | Learning Rate: 0.000461 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7747/12542 | Batch Loss: 0.8377 | Learning Rate: 0.000461 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7748/12542 | Batch Loss: 1.2116 | Learning Rate: 0.000461 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7749/12542 | Batch Loss: 0.9480 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7750/12542 | Batch Loss: 0.7023 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7751/12542 | Batch Loss: 0.7981 | Learning Rate: 0.000461 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7752/12542 | Batch Loss: 1.5843 | Learning Rate: 0.000461 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7753/12542 | Batch Loss: 1.8428 | Learning Rate: 0.000461 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7754/12542 | Batch Loss: 1.3503 | Learning Rate: 0.000461 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7755/12542 | Batch Loss: 1.0380 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7756/12542 | Batch Loss: 1.9968 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7757/12542 | Batch Loss: 1.1387 | Learning Rate: 0.000461 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7758/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7759/12542 | Batch Loss: 1.3095 | Learning Rate: 0.000460 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7760/12542 | Batch Loss: 0.5403 | Learning Rate: 0.000460 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7761/12542 | Batch Loss: 2.9929 | Learning Rate: 0.000460 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7762/12542 | Batch Loss: 1.0217 | Learning Rate: 0.000460 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7763/12542 | Batch Loss: 0.7705 | Learning Rate: 0.000460 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7764/12542 | Batch Loss: 1.4546 | Learning Rate: 0.000460 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7765/12542 | Batch Loss: 2.0603 | Learning Rate: 0.000460 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7766/12542 | Batch Loss: 0.8403 | Learning Rate: 0.000460 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7767/12542 | Batch Loss: 2.6077 | Learning Rate: 0.000460 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7768/12542 | Batch Loss: 0.6957 | Learning Rate: 0.000460 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7769/12542 | Batch Loss: 1.9013 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7770/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000460 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7771/12542 | Batch Loss: 1.0035 | Learning Rate: 0.000460 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7772/12542 | Batch Loss: 1.6301 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7773/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7774/12542 | Batch Loss: 1.0544 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7775/12542 | Batch Loss: 3.2591 | Learning Rate: 0.000460 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7776/12542 | Batch Loss: 2.0424 | Learning Rate: 0.000460 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7777/12542 | Batch Loss: 1.2670 | Learning Rate: 0.000460 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7778/12542 | Batch Loss: 1.1666 | Learning Rate: 0.000460 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7779/12542 | Batch Loss: 1.0204 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7780/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000460 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7781/12542 | Batch Loss: 0.9786 | Learning Rate: 0.000460 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7782/12542 | Batch Loss: 0.4667 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7783/12542 | Batch Loss: 0.8003 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7784/12542 | Batch Loss: 0.6976 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7785/12542 | Batch Loss: 2.2137 | Learning Rate: 0.000460 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7786/12542 | Batch Loss: 2.6708 | Learning Rate: 0.000460 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7787/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000460 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7788/12542 | Batch Loss: 1.0883 | Learning Rate: 0.000460 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7789/12542 | Batch Loss: 1.0897 | Learning Rate: 0.000460 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7790/12542 | Batch Loss: 2.0563 | Learning Rate: 0.000460 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7791/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7792/12542 | Batch Loss: 1.5950 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7793/12542 | Batch Loss: 1.6546 | Learning Rate: 0.000460 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7794/12542 | Batch Loss: 1.3660 | Learning Rate: 0.000460 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7795/12542 | Batch Loss: 0.7683 | Learning Rate: 0.000459 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7796/12542 | Batch Loss: 1.6311 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7797/12542 | Batch Loss: 0.7292 | Learning Rate: 0.000459 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7798/12542 | Batch Loss: 1.1128 | Learning Rate: 0.000459 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7799/12542 | Batch Loss: 1.5671 | Learning Rate: 0.000459 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7800/12542 | Batch Loss: 0.8296 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7801/12542 | Batch Loss: 1.1315 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7802/12542 | Batch Loss: 2.0522 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7803/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7804/12542 | Batch Loss: 0.9591 | Learning Rate: 0.000459 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7805/12542 | Batch Loss: 1.1555 | Learning Rate: 0.000459 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7806/12542 | Batch Loss: 0.8369 | Learning Rate: 0.000459 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7807/12542 | Batch Loss: 1.5819 | Learning Rate: 0.000459 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7808/12542 | Batch Loss: 1.5170 | Learning Rate: 0.000459 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7809/12542 | Batch Loss: 0.8176 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7810/12542 | Batch Loss: 1.9066 | Learning Rate: 0.000459 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7811/12542 | Batch Loss: 0.7572 | Learning Rate: 0.000459 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7812/12542 | Batch Loss: 1.3595 | Learning Rate: 0.000459 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7813/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000459 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7814/12542 | Batch Loss: 2.1927 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7815/12542 | Batch Loss: 1.1364 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7816/12542 | Batch Loss: 0.8014 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7817/12542 | Batch Loss: 0.9870 | Learning Rate: 0.000459 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7818/12542 | Batch Loss: 2.9791 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7819/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7820/12542 | Batch Loss: 1.0125 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7821/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000459 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7822/12542 | Batch Loss: 1.1236 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7823/12542 | Batch Loss: 1.3205 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7824/12542 | Batch Loss: 2.1498 | Learning Rate: 0.000459 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7825/12542 | Batch Loss: 1.3206 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7826/12542 | Batch Loss: 1.7247 | Learning Rate: 0.000459 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7827/12542 | Batch Loss: 2.7865 | Learning Rate: 0.000459 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7828/12542 | Batch Loss: 1.5613 | Learning Rate: 0.000459 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7829/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000459 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7830/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000459 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7831/12542 | Batch Loss: 2.3276 | Learning Rate: 0.000459 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7832/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000459 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7833/12542 | Batch Loss: 1.2031 | Learning Rate: 0.000458 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7834/12542 | Batch Loss: 1.1962 | Learning Rate: 0.000458 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7835/12542 | Batch Loss: 1.6128 | Learning Rate: 0.000458 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7836/12542 | Batch Loss: 2.2098 | Learning Rate: 0.000458 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7837/12542 | Batch Loss: 1.1947 | Learning Rate: 0.000458 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7838/12542 | Batch Loss: 1.8042 | Learning Rate: 0.000458 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7839/12542 | Batch Loss: 1.6215 | Learning Rate: 0.000458 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7840/12542 | Batch Loss: 1.1223 | Learning Rate: 0.000458 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7841/12542 | Batch Loss: 0.9248 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7842/12542 | Batch Loss: 1.5123 | Learning Rate: 0.000458 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7843/12542 | Batch Loss: 1.8245 | Learning Rate: 0.000458 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7844/12542 | Batch Loss: 2.1886 | Learning Rate: 0.000458 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7845/12542 | Batch Loss: 0.7807 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7846/12542 | Batch Loss: 2.2487 | Learning Rate: 0.000458 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7847/12542 | Batch Loss: 1.5019 | Learning Rate: 0.000458 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7848/12542 | Batch Loss: 0.3891 | Learning Rate: 0.000458 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7849/12542 | Batch Loss: 0.7909 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7850/12542 | Batch Loss: 0.5735 | Learning Rate: 0.000458 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7851/12542 | Batch Loss: 0.8643 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7852/12542 | Batch Loss: 0.7111 | Learning Rate: 0.000458 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7853/12542 | Batch Loss: 1.3857 | Learning Rate: 0.000458 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7854/12542 | Batch Loss: 1.2217 | Learning Rate: 0.000458 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7855/12542 | Batch Loss: 1.0831 | Learning Rate: 0.000458 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7856/12542 | Batch Loss: 1.0366 | Learning Rate: 0.000458 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7857/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000458 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7858/12542 | Batch Loss: 0.7471 | Learning Rate: 0.000458 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7859/12542 | Batch Loss: 0.4719 | Learning Rate: 0.000458 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7860/12542 | Batch Loss: 1.6982 | Learning Rate: 0.000458 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7861/12542 | Batch Loss: 1.6369 | Learning Rate: 0.000458 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7862/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000458 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7863/12542 | Batch Loss: 2.0347 | Learning Rate: 0.000458 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7864/12542 | Batch Loss: 1.3608 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7865/12542 | Batch Loss: 0.5801 | Learning Rate: 0.000458 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7866/12542 | Batch Loss: 1.0300 | Learning Rate: 0.000458 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7867/12542 | Batch Loss: 0.5839 | Learning Rate: 0.000458 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7868/12542 | Batch Loss: 1.0572 | Learning Rate: 0.000458 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7869/12542 | Batch Loss: 0.7514 | Learning Rate: 0.000458 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7870/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000458 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7871/12542 | Batch Loss: 1.1120 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7872/12542 | Batch Loss: 1.3570 | Learning Rate: 0.000457 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7873/12542 | Batch Loss: 1.1253 | Learning Rate: 0.000457 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7874/12542 | Batch Loss: 1.0416 | Learning Rate: 0.000457 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7875/12542 | Batch Loss: 0.6996 | Learning Rate: 0.000457 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7876/12542 | Batch Loss: 2.1290 | Learning Rate: 0.000457 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7877/12542 | Batch Loss: 1.7250 | Learning Rate: 0.000457 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7878/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000457 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7879/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000457 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7880/12542 | Batch Loss: 1.0547 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7881/12542 | Batch Loss: 0.7875 | Learning Rate: 0.000457 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7882/12542 | Batch Loss: 1.3570 | Learning Rate: 0.000457 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 7883/12542 | Batch Loss: 1.6171 | Learning Rate: 0.000457 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7884/12542 | Batch Loss: 1.5158 | Learning Rate: 0.000457 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7885/12542 | Batch Loss: 2.6358 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7886/12542 | Batch Loss: 2.2969 | Learning Rate: 0.000457 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7887/12542 | Batch Loss: 1.5109 | Learning Rate: 0.000457 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7888/12542 | Batch Loss: 2.2251 | Learning Rate: 0.000457 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7889/12542 | Batch Loss: 1.6529 | Learning Rate: 0.000457 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7890/12542 | Batch Loss: 1.5754 | Learning Rate: 0.000457 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7891/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7892/12542 | Batch Loss: 0.7893 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7893/12542 | Batch Loss: 1.0213 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7894/12542 | Batch Loss: 1.1224 | Learning Rate: 0.000457 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7895/12542 | Batch Loss: 1.2709 | Learning Rate: 0.000457 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7896/12542 | Batch Loss: 1.5054 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7897/12542 | Batch Loss: 1.6898 | Learning Rate: 0.000457 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7898/12542 | Batch Loss: 3.2414 | Learning Rate: 0.000457 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7899/12542 | Batch Loss: 2.1552 | Learning Rate: 0.000457 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7900/12542 | Batch Loss: 1.2703 | Learning Rate: 0.000457 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7901/12542 | Batch Loss: 0.7514 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7902/12542 | Batch Loss: 1.8977 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7903/12542 | Batch Loss: 2.0614 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7904/12542 | Batch Loss: 1.0059 | Learning Rate: 0.000457 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7905/12542 | Batch Loss: 1.6410 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7906/12542 | Batch Loss: 0.7767 | Learning Rate: 0.000457 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7907/12542 | Batch Loss: 2.4599 | Learning Rate: 0.000457 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7908/12542 | Batch Loss: 1.2391 | Learning Rate: 0.000456 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7909/12542 | Batch Loss: 1.1047 | Learning Rate: 0.000456 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7910/12542 | Batch Loss: 1.6207 | Learning Rate: 0.000456 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7911/12542 | Batch Loss: 1.4316 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7912/12542 | Batch Loss: 1.3138 | Learning Rate: 0.000456 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7913/12542 | Batch Loss: 1.2889 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7914/12542 | Batch Loss: 1.6960 | Learning Rate: 0.000456 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7915/12542 | Batch Loss: 0.9640 | Learning Rate: 0.000456 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7916/12542 | Batch Loss: 0.6600 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7917/12542 | Batch Loss: 2.2166 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7918/12542 | Batch Loss: 1.8142 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7919/12542 | Batch Loss: 0.6287 | Learning Rate: 0.000456 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7920/12542 | Batch Loss: 0.6620 | Learning Rate: 0.000456 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7921/12542 | Batch Loss: 0.8567 | Learning Rate: 0.000456 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7922/12542 | Batch Loss: 0.9021 | Learning Rate: 0.000456 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7923/12542 | Batch Loss: 0.7699 | Learning Rate: 0.000456 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7924/12542 | Batch Loss: 0.8771 | Learning Rate: 0.000456 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7925/12542 | Batch Loss: 0.8452 | Learning Rate: 0.000456 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 7926/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000456 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7927/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000456 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7928/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000456 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7929/12542 | Batch Loss: 0.6084 | Learning Rate: 0.000456 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7930/12542 | Batch Loss: 1.1940 | Learning Rate: 0.000456 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7931/12542 | Batch Loss: 1.2756 | Learning Rate: 0.000456 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7932/12542 | Batch Loss: 0.7859 | Learning Rate: 0.000456 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7933/12542 | Batch Loss: 0.8373 | Learning Rate: 0.000456 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7934/12542 | Batch Loss: 1.0918 | Learning Rate: 0.000456 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7935/12542 | Batch Loss: 1.2645 | Learning Rate: 0.000456 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7936/12542 | Batch Loss: 3.6410 | Learning Rate: 0.000456 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7937/12542 | Batch Loss: 1.4160 | Learning Rate: 0.000456 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7938/12542 | Batch Loss: 1.0885 | Learning Rate: 0.000456 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7939/12542 | Batch Loss: 3.0830 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7940/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000456 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7941/12542 | Batch Loss: 1.0099 | Learning Rate: 0.000456 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7942/12542 | Batch Loss: 1.1970 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7943/12542 | Batch Loss: 1.0762 | Learning Rate: 0.000456 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7944/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000456 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7945/12542 | Batch Loss: 1.6190 | Learning Rate: 0.000456 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7946/12542 | Batch Loss: 0.4185 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7947/12542 | Batch Loss: 2.6196 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7948/12542 | Batch Loss: 1.0626 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7949/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000455 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7950/12542 | Batch Loss: 0.9753 | Learning Rate: 0.000455 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7951/12542 | Batch Loss: 0.3766 | Learning Rate: 0.000455 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7952/12542 | Batch Loss: 1.8469 | Learning Rate: 0.000455 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7953/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000455 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7954/12542 | Batch Loss: 1.7039 | Learning Rate: 0.000455 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7955/12542 | Batch Loss: 1.6822 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7956/12542 | Batch Loss: 1.3273 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7957/12542 | Batch Loss: 1.1680 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7958/12542 | Batch Loss: 1.9091 | Learning Rate: 0.000455 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 7959/12542 | Batch Loss: 1.1115 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7960/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000455 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7961/12542 | Batch Loss: 1.7829 | Learning Rate: 0.000455 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7962/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000455 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7963/12542 | Batch Loss: 0.5917 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7964/12542 | Batch Loss: 1.0335 | Learning Rate: 0.000455 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 7965/12542 | Batch Loss: 1.5441 | Learning Rate: 0.000455 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7966/12542 | Batch Loss: 2.9645 | Learning Rate: 0.000455 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7967/12542 | Batch Loss: 0.7534 | Learning Rate: 0.000455 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7968/12542 | Batch Loss: 0.7595 | Learning Rate: 0.000455 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7969/12542 | Batch Loss: 1.0524 | Learning Rate: 0.000455 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7970/12542 | Batch Loss: 1.0113 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7971/12542 | Batch Loss: 0.8662 | Learning Rate: 0.000455 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7972/12542 | Batch Loss: 0.9306 | Learning Rate: 0.000455 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 7973/12542 | Batch Loss: 0.7175 | Learning Rate: 0.000455 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7974/12542 | Batch Loss: 1.5401 | Learning Rate: 0.000455 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7975/12542 | Batch Loss: 0.7305 | Learning Rate: 0.000455 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7976/12542 | Batch Loss: 0.8712 | Learning Rate: 0.000455 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7977/12542 | Batch Loss: 1.1641 | Learning Rate: 0.000455 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 7978/12542 | Batch Loss: 1.9929 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7979/12542 | Batch Loss: 2.0010 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7980/12542 | Batch Loss: 0.7489 | Learning Rate: 0.000455 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7981/12542 | Batch Loss: 1.0491 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7982/12542 | Batch Loss: 2.4880 | Learning Rate: 0.000455 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7983/12542 | Batch Loss: 1.0544 | Learning Rate: 0.000454 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 7984/12542 | Batch Loss: 0.8142 | Learning Rate: 0.000454 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7985/12542 | Batch Loss: 1.3917 | Learning Rate: 0.000454 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7986/12542 | Batch Loss: 1.5347 | Learning Rate: 0.000454 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7987/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000454 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 7988/12542 | Batch Loss: 2.1331 | Learning Rate: 0.000454 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 7989/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000454 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7990/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7991/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000454 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7992/12542 | Batch Loss: 0.9825 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 7993/12542 | Batch Loss: 0.7197 | Learning Rate: 0.000454 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7994/12542 | Batch Loss: 0.4234 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7995/12542 | Batch Loss: 1.7259 | Learning Rate: 0.000454 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 7996/12542 | Batch Loss: 1.7227 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 7997/12542 | Batch Loss: 2.0600 | Learning Rate: 0.000454 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 7998/12542 | Batch Loss: 1.3326 | Learning Rate: 0.000454 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 7999/12542 | Batch Loss: 2.4355 | Learning Rate: 0.000454 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8000/12542 | Batch Loss: 1.5811 | Learning Rate: 0.000454 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8001/12542 | Batch Loss: 0.8901 | Learning Rate: 0.000454 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8002/12542 | Batch Loss: 0.6862 | Learning Rate: 0.000454 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8003/12542 | Batch Loss: 1.0071 | Learning Rate: 0.000454 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8004/12542 | Batch Loss: 1.5239 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8005/12542 | Batch Loss: 0.5334 | Learning Rate: 0.000454 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8006/12542 | Batch Loss: 1.1166 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8007/12542 | Batch Loss: 0.4982 | Learning Rate: 0.000454 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8008/12542 | Batch Loss: 1.5340 | Learning Rate: 0.000454 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8009/12542 | Batch Loss: 2.3089 | Learning Rate: 0.000454 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8010/12542 | Batch Loss: 0.9155 | Learning Rate: 0.000454 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8011/12542 | Batch Loss: 1.0657 | Learning Rate: 0.000454 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8012/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000454 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8013/12542 | Batch Loss: 1.4373 | Learning Rate: 0.000454 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8014/12542 | Batch Loss: 1.2267 | Learning Rate: 0.000454 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8015/12542 | Batch Loss: 1.3528 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8016/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8017/12542 | Batch Loss: 1.4084 | Learning Rate: 0.000454 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8018/12542 | Batch Loss: 1.6419 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8019/12542 | Batch Loss: 0.9525 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8020/12542 | Batch Loss: 1.4113 | Learning Rate: 0.000454 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8021/12542 | Batch Loss: 1.0033 | Learning Rate: 0.000453 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8022/12542 | Batch Loss: 2.4175 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8023/12542 | Batch Loss: 1.4487 | Learning Rate: 0.000453 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8024/12542 | Batch Loss: 1.5456 | Learning Rate: 0.000453 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8025/12542 | Batch Loss: 0.5692 | Learning Rate: 0.000453 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 8026/12542 | Batch Loss: 2.6656 | Learning Rate: 0.000453 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8027/12542 | Batch Loss: 2.2439 | Learning Rate: 0.000453 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8028/12542 | Batch Loss: 1.1613 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8029/12542 | Batch Loss: 1.5703 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8030/12542 | Batch Loss: 0.8200 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8031/12542 | Batch Loss: 0.8974 | Learning Rate: 0.000453 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8032/12542 | Batch Loss: 0.7631 | Learning Rate: 0.000453 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8033/12542 | Batch Loss: 2.3512 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8034/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8035/12542 | Batch Loss: 2.0415 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8036/12542 | Batch Loss: 1.7783 | Learning Rate: 0.000453 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8037/12542 | Batch Loss: 0.8713 | Learning Rate: 0.000453 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8038/12542 | Batch Loss: 1.6770 | Learning Rate: 0.000453 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8039/12542 | Batch Loss: 0.7315 | Learning Rate: 0.000453 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8040/12542 | Batch Loss: 0.7096 | Learning Rate: 0.000453 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8041/12542 | Batch Loss: 1.6870 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8042/12542 | Batch Loss: 0.2778 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8043/12542 | Batch Loss: 1.3005 | Learning Rate: 0.000453 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8044/12542 | Batch Loss: 0.5376 | Learning Rate: 0.000453 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8045/12542 | Batch Loss: 1.1249 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8046/12542 | Batch Loss: 2.7056 | Learning Rate: 0.000453 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8047/12542 | Batch Loss: 1.7478 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8048/12542 | Batch Loss: 1.8163 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8049/12542 | Batch Loss: 1.3281 | Learning Rate: 0.000453 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8050/12542 | Batch Loss: 1.3791 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8051/12542 | Batch Loss: 1.7308 | Learning Rate: 0.000453 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8052/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000453 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 8053/12542 | Batch Loss: 1.1173 | Learning Rate: 0.000453 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8054/12542 | Batch Loss: 0.6106 | Learning Rate: 0.000453 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8055/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000453 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8056/12542 | Batch Loss: 1.4138 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8057/12542 | Batch Loss: 0.7656 | Learning Rate: 0.000453 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8058/12542 | Batch Loss: 0.7330 | Learning Rate: 0.000453 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8059/12542 | Batch Loss: 1.0713 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8060/12542 | Batch Loss: 1.9137 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8061/12542 | Batch Loss: 1.3762 | Learning Rate: 0.000452 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8062/12542 | Batch Loss: 0.6239 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8063/12542 | Batch Loss: 0.9558 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8064/12542 | Batch Loss: 0.9276 | Learning Rate: 0.000452 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8065/12542 | Batch Loss: 0.8801 | Learning Rate: 0.000452 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8066/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000452 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8067/12542 | Batch Loss: 0.5806 | Learning Rate: 0.000452 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8068/12542 | Batch Loss: 0.8768 | Learning Rate: 0.000452 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8069/12542 | Batch Loss: 1.2864 | Learning Rate: 0.000452 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8070/12542 | Batch Loss: 1.3990 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8071/12542 | Batch Loss: 0.6941 | Learning Rate: 0.000452 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8072/12542 | Batch Loss: 1.0213 | Learning Rate: 0.000452 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8073/12542 | Batch Loss: 0.9896 | Learning Rate: 0.000452 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8074/12542 | Batch Loss: 1.9100 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8075/12542 | Batch Loss: 1.0259 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8076/12542 | Batch Loss: 1.1583 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8077/12542 | Batch Loss: 1.0010 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8078/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8079/12542 | Batch Loss: 0.7091 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8080/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000452 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8081/12542 | Batch Loss: 0.7265 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8082/12542 | Batch Loss: 1.1383 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8083/12542 | Batch Loss: 1.9942 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8084/12542 | Batch Loss: 1.4479 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8085/12542 | Batch Loss: 1.8468 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8086/12542 | Batch Loss: 1.2764 | Learning Rate: 0.000452 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8087/12542 | Batch Loss: 1.8040 | Learning Rate: 0.000452 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8088/12542 | Batch Loss: 1.8083 | Learning Rate: 0.000452 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8089/12542 | Batch Loss: 1.6830 | Learning Rate: 0.000452 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8090/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000452 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8091/12542 | Batch Loss: 1.1610 | Learning Rate: 0.000452 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8092/12542 | Batch Loss: 2.1729 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8093/12542 | Batch Loss: 1.8765 | Learning Rate: 0.000452 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8094/12542 | Batch Loss: 0.7599 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8095/12542 | Batch Loss: 2.2018 | Learning Rate: 0.000452 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8096/12542 | Batch Loss: 2.3228 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8097/12542 | Batch Loss: 1.0416 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8098/12542 | Batch Loss: 0.9906 | Learning Rate: 0.000451 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8099/12542 | Batch Loss: 1.3331 | Learning Rate: 0.000451 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8100/12542 | Batch Loss: 1.6785 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8101/12542 | Batch Loss: 1.1460 | Learning Rate: 0.000451 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8102/12542 | Batch Loss: 0.9672 | Learning Rate: 0.000451 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8103/12542 | Batch Loss: 2.7870 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8104/12542 | Batch Loss: 2.0156 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8105/12542 | Batch Loss: 1.5667 | Learning Rate: 0.000451 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8106/12542 | Batch Loss: 0.5366 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8107/12542 | Batch Loss: 0.9358 | Learning Rate: 0.000451 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8108/12542 | Batch Loss: 2.4706 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8109/12542 | Batch Loss: 0.5906 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8110/12542 | Batch Loss: 1.0606 | Learning Rate: 0.000451 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8111/12542 | Batch Loss: 1.1460 | Learning Rate: 0.000451 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8112/12542 | Batch Loss: 0.8260 | Learning Rate: 0.000451 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8113/12542 | Batch Loss: 1.2510 | Learning Rate: 0.000451 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8114/12542 | Batch Loss: 1.6006 | Learning Rate: 0.000451 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8115/12542 | Batch Loss: 1.1241 | Learning Rate: 0.000451 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8116/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8117/12542 | Batch Loss: 1.8277 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8118/12542 | Batch Loss: 1.5466 | Learning Rate: 0.000451 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8119/12542 | Batch Loss: 1.6822 | Learning Rate: 0.000451 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8120/12542 | Batch Loss: 1.3459 | Learning Rate: 0.000451 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8121/12542 | Batch Loss: 0.9785 | Learning Rate: 0.000451 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8122/12542 | Batch Loss: 1.4943 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8123/12542 | Batch Loss: 1.1163 | Learning Rate: 0.000451 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8124/12542 | Batch Loss: 0.6654 | Learning Rate: 0.000451 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 8125/12542 | Batch Loss: 2.5060 | Learning Rate: 0.000451 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8126/12542 | Batch Loss: 1.1182 | Learning Rate: 0.000451 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8127/12542 | Batch Loss: 1.2362 | Learning Rate: 0.000451 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8128/12542 | Batch Loss: 1.4589 | Learning Rate: 0.000451 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8129/12542 | Batch Loss: 0.7227 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8130/12542 | Batch Loss: 1.0603 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8131/12542 | Batch Loss: 0.9895 | Learning Rate: 0.000451 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8132/12542 | Batch Loss: 1.4743 | Learning Rate: 0.000451 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8133/12542 | Batch Loss: 0.8341 | Learning Rate: 0.000451 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8134/12542 | Batch Loss: 1.5600 | Learning Rate: 0.000450 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8135/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000450 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8136/12542 | Batch Loss: 1.2786 | Learning Rate: 0.000450 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8137/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000450 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8138/12542 | Batch Loss: 2.4926 | Learning Rate: 0.000450 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 8139/12542 | Batch Loss: 1.1651 | Learning Rate: 0.000450 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8140/12542 | Batch Loss: 1.7633 | Learning Rate: 0.000450 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8141/12542 | Batch Loss: 2.7341 | Learning Rate: 0.000450 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8142/12542 | Batch Loss: 1.5433 | Learning Rate: 0.000450 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8143/12542 | Batch Loss: 1.4632 | Learning Rate: 0.000450 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8144/12542 | Batch Loss: 0.6471 | Learning Rate: 0.000450 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8145/12542 | Batch Loss: 1.2657 | Learning Rate: 0.000450 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8146/12542 | Batch Loss: 2.2295 | Learning Rate: 0.000450 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8147/12542 | Batch Loss: 0.9182 | Learning Rate: 0.000450 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8148/12542 | Batch Loss: 0.9547 | Learning Rate: 0.000450 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8149/12542 | Batch Loss: 1.0558 | Learning Rate: 0.000450 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8150/12542 | Batch Loss: 2.5523 | Learning Rate: 0.000450 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8151/12542 | Batch Loss: 2.1717 | Learning Rate: 0.000450 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8152/12542 | Batch Loss: 0.9694 | Learning Rate: 0.000450 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8153/12542 | Batch Loss: 1.4251 | Learning Rate: 0.000450 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8154/12542 | Batch Loss: 2.4444 | Learning Rate: 0.000450 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8155/12542 | Batch Loss: 2.8663 | Learning Rate: 0.000450 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8156/12542 | Batch Loss: 1.4576 | Learning Rate: 0.000450 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8157/12542 | Batch Loss: 0.8331 | Learning Rate: 0.000450 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8158/12542 | Batch Loss: 1.1230 | Learning Rate: 0.000450 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8159/12542 | Batch Loss: 0.6535 | Learning Rate: 0.000450 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8160/12542 | Batch Loss: 1.5476 | Learning Rate: 0.000450 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8161/12542 | Batch Loss: 1.2722 | Learning Rate: 0.000450 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8162/12542 | Batch Loss: 0.7745 | Learning Rate: 0.000450 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8163/12542 | Batch Loss: 1.1970 | Learning Rate: 0.000450 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8164/12542 | Batch Loss: 2.5860 | Learning Rate: 0.000450 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8165/12542 | Batch Loss: 1.5106 | Learning Rate: 0.000450 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8166/12542 | Batch Loss: 1.1524 | Learning Rate: 0.000450 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8167/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000450 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8168/12542 | Batch Loss: 0.5565 | Learning Rate: 0.000450 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8169/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000450 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8170/12542 | Batch Loss: 0.9353 | Learning Rate: 0.000450 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8171/12542 | Batch Loss: 1.2168 | Learning Rate: 0.000450 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8172/12542 | Batch Loss: 1.4371 | Learning Rate: 0.000449 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8173/12542 | Batch Loss: 1.8780 | Learning Rate: 0.000449 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8174/12542 | Batch Loss: 0.7774 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8175/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8176/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8177/12542 | Batch Loss: 1.0445 | Learning Rate: 0.000449 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8178/12542 | Batch Loss: 1.5382 | Learning Rate: 0.000449 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8179/12542 | Batch Loss: 1.6184 | Learning Rate: 0.000449 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8180/12542 | Batch Loss: 1.1316 | Learning Rate: 0.000449 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8181/12542 | Batch Loss: 1.0343 | Learning Rate: 0.000449 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8182/12542 | Batch Loss: 0.6873 | Learning Rate: 0.000449 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8183/12542 | Batch Loss: 0.7111 | Learning Rate: 0.000449 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8184/12542 | Batch Loss: 1.3534 | Learning Rate: 0.000449 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8185/12542 | Batch Loss: 1.2684 | Learning Rate: 0.000449 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8186/12542 | Batch Loss: 1.2915 | Learning Rate: 0.000449 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8187/12542 | Batch Loss: 1.0746 | Learning Rate: 0.000449 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8188/12542 | Batch Loss: 0.6270 | Learning Rate: 0.000449 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8189/12542 | Batch Loss: 0.8312 | Learning Rate: 0.000449 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8190/12542 | Batch Loss: 1.2439 | Learning Rate: 0.000449 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8191/12542 | Batch Loss: 1.6468 | Learning Rate: 0.000449 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8192/12542 | Batch Loss: 1.3191 | Learning Rate: 0.000449 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8193/12542 | Batch Loss: 1.4842 | Learning Rate: 0.000449 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8194/12542 | Batch Loss: 0.7939 | Learning Rate: 0.000449 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8195/12542 | Batch Loss: 1.6279 | Learning Rate: 0.000449 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8196/12542 | Batch Loss: 1.4779 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8197/12542 | Batch Loss: 1.9781 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8198/12542 | Batch Loss: 1.6983 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8199/12542 | Batch Loss: 1.2068 | Learning Rate: 0.000449 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8200/12542 | Batch Loss: 0.8160 | Learning Rate: 0.000449 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8201/12542 | Batch Loss: 1.4876 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8202/12542 | Batch Loss: 0.9463 | Learning Rate: 0.000449 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8203/12542 | Batch Loss: 1.6598 | Learning Rate: 0.000449 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8204/12542 | Batch Loss: 1.8322 | Learning Rate: 0.000449 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8205/12542 | Batch Loss: 1.5297 | Learning Rate: 0.000449 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8206/12542 | Batch Loss: 1.6132 | Learning Rate: 0.000449 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8207/12542 | Batch Loss: 1.6220 | Learning Rate: 0.000449 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8208/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000449 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8209/12542 | Batch Loss: 1.0792 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8210/12542 | Batch Loss: 1.9390 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8211/12542 | Batch Loss: 0.6112 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8212/12542 | Batch Loss: 1.5591 | Learning Rate: 0.000448 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8213/12542 | Batch Loss: 1.5164 | Learning Rate: 0.000448 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8214/12542 | Batch Loss: 2.8030 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8215/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8216/12542 | Batch Loss: 1.0538 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8217/12542 | Batch Loss: 1.3841 | Learning Rate: 0.000448 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8218/12542 | Batch Loss: 0.8221 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8219/12542 | Batch Loss: 0.7743 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8220/12542 | Batch Loss: 1.4881 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8221/12542 | Batch Loss: 2.0971 | Learning Rate: 0.000448 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8222/12542 | Batch Loss: 1.6622 | Learning Rate: 0.000448 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8223/12542 | Batch Loss: 4.1630 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8224/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8225/12542 | Batch Loss: 2.1213 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8226/12542 | Batch Loss: 1.9312 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8227/12542 | Batch Loss: 0.8308 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8228/12542 | Batch Loss: 1.1751 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8229/12542 | Batch Loss: 1.8034 | Learning Rate: 0.000448 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8230/12542 | Batch Loss: 0.8993 | Learning Rate: 0.000448 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8231/12542 | Batch Loss: 1.0852 | Learning Rate: 0.000448 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8232/12542 | Batch Loss: 1.7321 | Learning Rate: 0.000448 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8233/12542 | Batch Loss: 1.8254 | Learning Rate: 0.000448 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8234/12542 | Batch Loss: 1.0816 | Learning Rate: 0.000448 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8235/12542 | Batch Loss: 1.4569 | Learning Rate: 0.000448 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8236/12542 | Batch Loss: 0.5395 | Learning Rate: 0.000448 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8237/12542 | Batch Loss: 1.8876 | Learning Rate: 0.000448 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8238/12542 | Batch Loss: 2.9034 | Learning Rate: 0.000448 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8239/12542 | Batch Loss: 1.7312 | Learning Rate: 0.000448 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8240/12542 | Batch Loss: 1.5316 | Learning Rate: 0.000448 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8241/12542 | Batch Loss: 0.8022 | Learning Rate: 0.000448 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8242/12542 | Batch Loss: 1.4162 | Learning Rate: 0.000448 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8243/12542 | Batch Loss: 1.6027 | Learning Rate: 0.000448 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8244/12542 | Batch Loss: 0.7005 | Learning Rate: 0.000448 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8245/12542 | Batch Loss: 0.9024 | Learning Rate: 0.000448 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8246/12542 | Batch Loss: 1.2728 | Learning Rate: 0.000448 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8247/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000447 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8248/12542 | Batch Loss: 1.2313 | Learning Rate: 0.000447 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8249/12542 | Batch Loss: 2.6196 | Learning Rate: 0.000447 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8250/12542 | Batch Loss: 0.8901 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8251/12542 | Batch Loss: 1.1452 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8252/12542 | Batch Loss: 3.5822 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8253/12542 | Batch Loss: 0.3710 | Learning Rate: 0.000447 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8254/12542 | Batch Loss: 0.6494 | Learning Rate: 0.000447 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8255/12542 | Batch Loss: 1.1579 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8256/12542 | Batch Loss: 1.6095 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8257/12542 | Batch Loss: 2.1652 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8258/12542 | Batch Loss: 2.0582 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8259/12542 | Batch Loss: 1.7825 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8260/12542 | Batch Loss: 0.8266 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8261/12542 | Batch Loss: 0.9108 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8262/12542 | Batch Loss: 1.7259 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8263/12542 | Batch Loss: 1.4475 | Learning Rate: 0.000447 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8264/12542 | Batch Loss: 1.3794 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8265/12542 | Batch Loss: 1.1707 | Learning Rate: 0.000447 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8266/12542 | Batch Loss: 1.3314 | Learning Rate: 0.000447 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8267/12542 | Batch Loss: 3.1370 | Learning Rate: 0.000447 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8268/12542 | Batch Loss: 1.7714 | Learning Rate: 0.000447 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8269/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8270/12542 | Batch Loss: 1.1496 | Learning Rate: 0.000447 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8271/12542 | Batch Loss: 0.9682 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8272/12542 | Batch Loss: 0.7020 | Learning Rate: 0.000447 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8273/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8274/12542 | Batch Loss: 1.5853 | Learning Rate: 0.000447 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8275/12542 | Batch Loss: 0.9098 | Learning Rate: 0.000447 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8276/12542 | Batch Loss: 0.7624 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8277/12542 | Batch Loss: 1.9440 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8278/12542 | Batch Loss: 1.8216 | Learning Rate: 0.000447 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8279/12542 | Batch Loss: 1.4440 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8280/12542 | Batch Loss: 1.3365 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8281/12542 | Batch Loss: 0.5723 | Learning Rate: 0.000447 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8282/12542 | Batch Loss: 1.8609 | Learning Rate: 0.000447 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8283/12542 | Batch Loss: 0.8793 | Learning Rate: 0.000447 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8284/12542 | Batch Loss: 0.8210 | Learning Rate: 0.000446 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8285/12542 | Batch Loss: 1.4873 | Learning Rate: 0.000446 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8286/12542 | Batch Loss: 1.4425 | Learning Rate: 0.000446 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8287/12542 | Batch Loss: 1.3241 | Learning Rate: 0.000446 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8288/12542 | Batch Loss: 0.9990 | Learning Rate: 0.000446 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8289/12542 | Batch Loss: 2.0067 | Learning Rate: 0.000446 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8290/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8291/12542 | Batch Loss: 2.4698 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8292/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000446 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8293/12542 | Batch Loss: 2.4432 | Learning Rate: 0.000446 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8294/12542 | Batch Loss: 1.6338 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8295/12542 | Batch Loss: 1.2584 | Learning Rate: 0.000446 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8296/12542 | Batch Loss: 1.1609 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8297/12542 | Batch Loss: 1.2737 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8298/12542 | Batch Loss: 0.7462 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8299/12542 | Batch Loss: 0.5767 | Learning Rate: 0.000446 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8300/12542 | Batch Loss: 0.9181 | Learning Rate: 0.000446 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8301/12542 | Batch Loss: 1.1110 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8302/12542 | Batch Loss: 1.8529 | Learning Rate: 0.000446 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8303/12542 | Batch Loss: 0.9098 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8304/12542 | Batch Loss: 1.8840 | Learning Rate: 0.000446 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8305/12542 | Batch Loss: 0.6400 | Learning Rate: 0.000446 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8306/12542 | Batch Loss: 0.7838 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8307/12542 | Batch Loss: 1.6724 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8308/12542 | Batch Loss: 0.6484 | Learning Rate: 0.000446 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8309/12542 | Batch Loss: 0.7635 | Learning Rate: 0.000446 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8310/12542 | Batch Loss: 0.9426 | Learning Rate: 0.000446 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8311/12542 | Batch Loss: 0.6593 | Learning Rate: 0.000446 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8312/12542 | Batch Loss: 1.0578 | Learning Rate: 0.000446 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8313/12542 | Batch Loss: 2.1050 | Learning Rate: 0.000446 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8314/12542 | Batch Loss: 1.0937 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8315/12542 | Batch Loss: 0.8500 | Learning Rate: 0.000446 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8316/12542 | Batch Loss: 0.7029 | Learning Rate: 0.000446 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8317/12542 | Batch Loss: 2.2384 | Learning Rate: 0.000446 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8318/12542 | Batch Loss: 0.9993 | Learning Rate: 0.000446 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8319/12542 | Batch Loss: 0.9727 | Learning Rate: 0.000446 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8320/12542 | Batch Loss: 0.7873 | Learning Rate: 0.000446 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8321/12542 | Batch Loss: 1.4336 | Learning Rate: 0.000446 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8322/12542 | Batch Loss: 1.5697 | Learning Rate: 0.000445 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8323/12542 | Batch Loss: 0.9167 | Learning Rate: 0.000445 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8324/12542 | Batch Loss: 0.8563 | Learning Rate: 0.000445 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8325/12542 | Batch Loss: 1.2292 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8326/12542 | Batch Loss: 0.4978 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8327/12542 | Batch Loss: 0.7655 | Learning Rate: 0.000445 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8328/12542 | Batch Loss: 0.8021 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8329/12542 | Batch Loss: 1.0844 | Learning Rate: 0.000445 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8330/12542 | Batch Loss: 0.8040 | Learning Rate: 0.000445 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8331/12542 | Batch Loss: 0.5130 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8332/12542 | Batch Loss: 1.4643 | Learning Rate: 0.000445 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8333/12542 | Batch Loss: 1.1304 | Learning Rate: 0.000445 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8334/12542 | Batch Loss: 1.0225 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8335/12542 | Batch Loss: 1.0486 | Learning Rate: 0.000445 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8336/12542 | Batch Loss: 1.1573 | Learning Rate: 0.000445 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8337/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000445 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8338/12542 | Batch Loss: 2.3705 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8339/12542 | Batch Loss: 0.9248 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8340/12542 | Batch Loss: 2.1733 | Learning Rate: 0.000445 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8341/12542 | Batch Loss: 0.6484 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8342/12542 | Batch Loss: 0.6694 | Learning Rate: 0.000445 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8343/12542 | Batch Loss: 0.6312 | Learning Rate: 0.000445 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8344/12542 | Batch Loss: 0.8350 | Learning Rate: 0.000445 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8345/12542 | Batch Loss: 1.3048 | Learning Rate: 0.000445 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8346/12542 | Batch Loss: 0.8024 | Learning Rate: 0.000445 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8347/12542 | Batch Loss: 1.6379 | Learning Rate: 0.000445 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8348/12542 | Batch Loss: 0.4103 | Learning Rate: 0.000445 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8349/12542 | Batch Loss: 1.4242 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8350/12542 | Batch Loss: 0.8560 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8351/12542 | Batch Loss: 1.7612 | Learning Rate: 0.000445 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8352/12542 | Batch Loss: 0.6863 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8353/12542 | Batch Loss: 0.5659 | Learning Rate: 0.000445 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8354/12542 | Batch Loss: 1.5225 | Learning Rate: 0.000445 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8355/12542 | Batch Loss: 0.7719 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8356/12542 | Batch Loss: 1.7055 | Learning Rate: 0.000445 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8357/12542 | Batch Loss: 1.9780 | Learning Rate: 0.000445 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8358/12542 | Batch Loss: 1.0085 | Learning Rate: 0.000445 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8359/12542 | Batch Loss: 1.0918 | Learning Rate: 0.000445 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8360/12542 | Batch Loss: 1.0877 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8361/12542 | Batch Loss: 0.7621 | Learning Rate: 0.000444 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8362/12542 | Batch Loss: 1.3862 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8363/12542 | Batch Loss: 1.1224 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8364/12542 | Batch Loss: 1.4712 | Learning Rate: 0.000444 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8365/12542 | Batch Loss: 1.4923 | Learning Rate: 0.000444 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8366/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000444 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8367/12542 | Batch Loss: 1.0783 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8368/12542 | Batch Loss: 2.6177 | Learning Rate: 0.000444 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8369/12542 | Batch Loss: 1.3975 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8370/12542 | Batch Loss: 2.2963 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8371/12542 | Batch Loss: 1.1004 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8372/12542 | Batch Loss: 1.1234 | Learning Rate: 0.000444 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8373/12542 | Batch Loss: 1.8378 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8374/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8375/12542 | Batch Loss: 1.5628 | Learning Rate: 0.000444 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8376/12542 | Batch Loss: 1.6109 | Learning Rate: 0.000444 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8377/12542 | Batch Loss: 1.3307 | Learning Rate: 0.000444 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8378/12542 | Batch Loss: 0.7397 | Learning Rate: 0.000444 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8379/12542 | Batch Loss: 1.7500 | Learning Rate: 0.000444 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8380/12542 | Batch Loss: 1.5802 | Learning Rate: 0.000444 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8381/12542 | Batch Loss: 1.6323 | Learning Rate: 0.000444 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8382/12542 | Batch Loss: 1.3269 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8383/12542 | Batch Loss: 1.9278 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8384/12542 | Batch Loss: 3.0707 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8385/12542 | Batch Loss: 2.7014 | Learning Rate: 0.000444 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8386/12542 | Batch Loss: 3.7216 | Learning Rate: 0.000444 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8387/12542 | Batch Loss: 1.6685 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8388/12542 | Batch Loss: 1.9146 | Learning Rate: 0.000444 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8389/12542 | Batch Loss: 1.0760 | Learning Rate: 0.000444 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8390/12542 | Batch Loss: 2.1872 | Learning Rate: 0.000444 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8391/12542 | Batch Loss: 0.9041 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8392/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000444 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8393/12542 | Batch Loss: 0.9875 | Learning Rate: 0.000444 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8394/12542 | Batch Loss: 1.2575 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8395/12542 | Batch Loss: 0.9055 | Learning Rate: 0.000444 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 8396/12542 | Batch Loss: 1.3040 | Learning Rate: 0.000444 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8397/12542 | Batch Loss: 1.1306 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8398/12542 | Batch Loss: 0.9213 | Learning Rate: 0.000443 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8399/12542 | Batch Loss: 1.2687 | Learning Rate: 0.000443 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8400/12542 | Batch Loss: 1.2651 | Learning Rate: 0.000443 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8401/12542 | Batch Loss: 0.2878 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8402/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8403/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000443 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8404/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000443 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8405/12542 | Batch Loss: 1.0980 | Learning Rate: 0.000443 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8406/12542 | Batch Loss: 1.0203 | Learning Rate: 0.000443 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8407/12542 | Batch Loss: 2.4282 | Learning Rate: 0.000443 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8408/12542 | Batch Loss: 1.0049 | Learning Rate: 0.000443 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8409/12542 | Batch Loss: 1.0035 | Learning Rate: 0.000443 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8410/12542 | Batch Loss: 1.5492 | Learning Rate: 0.000443 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8411/12542 | Batch Loss: 1.2434 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8412/12542 | Batch Loss: 1.6077 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8413/12542 | Batch Loss: 1.3361 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8414/12542 | Batch Loss: 1.0010 | Learning Rate: 0.000443 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8415/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000443 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8416/12542 | Batch Loss: 0.8078 | Learning Rate: 0.000443 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8417/12542 | Batch Loss: 0.8036 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8418/12542 | Batch Loss: 1.0240 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8419/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000443 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8420/12542 | Batch Loss: 0.7348 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8421/12542 | Batch Loss: 0.6768 | Learning Rate: 0.000443 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8422/12542 | Batch Loss: 0.7775 | Learning Rate: 0.000443 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8423/12542 | Batch Loss: 2.5970 | Learning Rate: 0.000443 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8424/12542 | Batch Loss: 1.2482 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8425/12542 | Batch Loss: 1.1863 | Learning Rate: 0.000443 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8426/12542 | Batch Loss: 0.9563 | Learning Rate: 0.000443 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8427/12542 | Batch Loss: 1.0203 | Learning Rate: 0.000443 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8428/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8429/12542 | Batch Loss: 2.8483 | Learning Rate: 0.000443 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8430/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000443 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8431/12542 | Batch Loss: 2.2676 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8432/12542 | Batch Loss: 0.5396 | Learning Rate: 0.000443 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8433/12542 | Batch Loss: 0.9290 | Learning Rate: 0.000443 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8434/12542 | Batch Loss: 1.9808 | Learning Rate: 0.000443 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8435/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8436/12542 | Batch Loss: 0.6458 | Learning Rate: 0.000442 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8437/12542 | Batch Loss: 0.3322 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8438/12542 | Batch Loss: 1.8887 | Learning Rate: 0.000442 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8439/12542 | Batch Loss: 1.1119 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8440/12542 | Batch Loss: 0.7619 | Learning Rate: 0.000442 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8441/12542 | Batch Loss: 2.1941 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8442/12542 | Batch Loss: 0.8125 | Learning Rate: 0.000442 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8443/12542 | Batch Loss: 1.7823 | Learning Rate: 0.000442 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8444/12542 | Batch Loss: 1.2346 | Learning Rate: 0.000442 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8445/12542 | Batch Loss: 1.6252 | Learning Rate: 0.000442 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8446/12542 | Batch Loss: 1.6647 | Learning Rate: 0.000442 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8447/12542 | Batch Loss: 1.5300 | Learning Rate: 0.000442 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8448/12542 | Batch Loss: 1.4668 | Learning Rate: 0.000442 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8449/12542 | Batch Loss: 1.6353 | Learning Rate: 0.000442 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8450/12542 | Batch Loss: 2.0507 | Learning Rate: 0.000442 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8451/12542 | Batch Loss: 1.7889 | Learning Rate: 0.000442 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8452/12542 | Batch Loss: 1.5526 | Learning Rate: 0.000442 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8453/12542 | Batch Loss: 1.0963 | Learning Rate: 0.000442 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8454/12542 | Batch Loss: 1.3867 | Learning Rate: 0.000442 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8455/12542 | Batch Loss: 1.1980 | Learning Rate: 0.000442 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8456/12542 | Batch Loss: 1.8531 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8457/12542 | Batch Loss: 1.5492 | Learning Rate: 0.000442 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8458/12542 | Batch Loss: 0.9596 | Learning Rate: 0.000442 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8459/12542 | Batch Loss: 1.1306 | Learning Rate: 0.000442 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8460/12542 | Batch Loss: 2.2872 | Learning Rate: 0.000442 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8461/12542 | Batch Loss: 1.6067 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8462/12542 | Batch Loss: 0.8649 | Learning Rate: 0.000442 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8463/12542 | Batch Loss: 1.2689 | Learning Rate: 0.000442 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8464/12542 | Batch Loss: 1.6138 | Learning Rate: 0.000442 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8465/12542 | Batch Loss: 1.3588 | Learning Rate: 0.000442 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8466/12542 | Batch Loss: 2.0719 | Learning Rate: 0.000442 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8467/12542 | Batch Loss: 2.2524 | Learning Rate: 0.000442 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8468/12542 | Batch Loss: 1.5391 | Learning Rate: 0.000442 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8469/12542 | Batch Loss: 1.1941 | Learning Rate: 0.000442 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8470/12542 | Batch Loss: 0.7738 | Learning Rate: 0.000442 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8471/12542 | Batch Loss: 0.8566 | Learning Rate: 0.000442 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8472/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000442 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8473/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8474/12542 | Batch Loss: 2.5715 | Learning Rate: 0.000441 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8475/12542 | Batch Loss: 1.2166 | Learning Rate: 0.000441 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8476/12542 | Batch Loss: 1.8188 | Learning Rate: 0.000441 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8477/12542 | Batch Loss: 0.9254 | Learning Rate: 0.000441 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8478/12542 | Batch Loss: 0.9860 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8479/12542 | Batch Loss: 0.8562 | Learning Rate: 0.000441 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8480/12542 | Batch Loss: 1.6287 | Learning Rate: 0.000441 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8481/12542 | Batch Loss: 2.1298 | Learning Rate: 0.000441 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8482/12542 | Batch Loss: 1.1768 | Learning Rate: 0.000441 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8483/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8484/12542 | Batch Loss: 1.5581 | Learning Rate: 0.000441 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8485/12542 | Batch Loss: 0.8651 | Learning Rate: 0.000441 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8486/12542 | Batch Loss: 1.0601 | Learning Rate: 0.000441 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8487/12542 | Batch Loss: 1.3911 | Learning Rate: 0.000441 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8488/12542 | Batch Loss: 1.3926 | Learning Rate: 0.000441 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8489/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000441 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8490/12542 | Batch Loss: 0.7767 | Learning Rate: 0.000441 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8491/12542 | Batch Loss: 1.2628 | Learning Rate: 0.000441 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8492/12542 | Batch Loss: 1.4706 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8493/12542 | Batch Loss: 0.9785 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8494/12542 | Batch Loss: 1.3926 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8495/12542 | Batch Loss: 1.9082 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8496/12542 | Batch Loss: 0.7709 | Learning Rate: 0.000441 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8497/12542 | Batch Loss: 1.3621 | Learning Rate: 0.000441 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8498/12542 | Batch Loss: 2.6721 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8499/12542 | Batch Loss: 0.5132 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8500/12542 | Batch Loss: 2.7174 | Learning Rate: 0.000441 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8501/12542 | Batch Loss: 2.0329 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8502/12542 | Batch Loss: 1.2977 | Learning Rate: 0.000441 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8503/12542 | Batch Loss: 2.1820 | Learning Rate: 0.000441 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8504/12542 | Batch Loss: 1.2546 | Learning Rate: 0.000441 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8505/12542 | Batch Loss: 0.4435 | Learning Rate: 0.000441 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8506/12542 | Batch Loss: 0.9016 | Learning Rate: 0.000441 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8507/12542 | Batch Loss: 0.8649 | Learning Rate: 0.000441 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8508/12542 | Batch Loss: 1.3191 | Learning Rate: 0.000441 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8509/12542 | Batch Loss: 2.0022 | Learning Rate: 0.000441 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8510/12542 | Batch Loss: 1.8959 | Learning Rate: 0.000440 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8511/12542 | Batch Loss: 2.0396 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8512/12542 | Batch Loss: 0.6847 | Learning Rate: 0.000440 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8513/12542 | Batch Loss: 1.8611 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8514/12542 | Batch Loss: 2.6625 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8515/12542 | Batch Loss: 1.4501 | Learning Rate: 0.000440 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8516/12542 | Batch Loss: 2.7766 | Learning Rate: 0.000440 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8517/12542 | Batch Loss: 1.9899 | Learning Rate: 0.000440 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8518/12542 | Batch Loss: 1.4376 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8519/12542 | Batch Loss: 0.8897 | Learning Rate: 0.000440 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8520/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8521/12542 | Batch Loss: 0.5128 | Learning Rate: 0.000440 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8522/12542 | Batch Loss: 2.0883 | Learning Rate: 0.000440 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8523/12542 | Batch Loss: 0.6465 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8524/12542 | Batch Loss: 1.6660 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8525/12542 | Batch Loss: 1.0857 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8526/12542 | Batch Loss: 0.7915 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8527/12542 | Batch Loss: 1.4999 | Learning Rate: 0.000440 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8528/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000440 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8529/12542 | Batch Loss: 3.5346 | Learning Rate: 0.000440 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8530/12542 | Batch Loss: 0.9811 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8531/12542 | Batch Loss: 2.4143 | Learning Rate: 0.000440 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8532/12542 | Batch Loss: 1.1589 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8533/12542 | Batch Loss: 1.0816 | Learning Rate: 0.000440 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8534/12542 | Batch Loss: 1.7887 | Learning Rate: 0.000440 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8535/12542 | Batch Loss: 0.7422 | Learning Rate: 0.000440 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8536/12542 | Batch Loss: 1.7953 | Learning Rate: 0.000440 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8537/12542 | Batch Loss: 2.0445 | Learning Rate: 0.000440 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8538/12542 | Batch Loss: 0.8895 | Learning Rate: 0.000440 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8539/12542 | Batch Loss: 1.2633 | Learning Rate: 0.000440 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8540/12542 | Batch Loss: 1.1725 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8541/12542 | Batch Loss: 0.8316 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8542/12542 | Batch Loss: 0.8208 | Learning Rate: 0.000440 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8543/12542 | Batch Loss: 0.6828 | Learning Rate: 0.000440 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8544/12542 | Batch Loss: 1.0064 | Learning Rate: 0.000440 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8545/12542 | Batch Loss: 2.4262 | Learning Rate: 0.000440 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8546/12542 | Batch Loss: 1.3713 | Learning Rate: 0.000440 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8547/12542 | Batch Loss: 0.8273 | Learning Rate: 0.000440 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8548/12542 | Batch Loss: 1.2581 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8549/12542 | Batch Loss: 0.6480 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8550/12542 | Batch Loss: 0.7568 | Learning Rate: 0.000439 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8551/12542 | Batch Loss: 1.7985 | Learning Rate: 0.000439 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8552/12542 | Batch Loss: 0.7894 | Learning Rate: 0.000439 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8553/12542 | Batch Loss: 2.3944 | Learning Rate: 0.000439 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8554/12542 | Batch Loss: 1.3194 | Learning Rate: 0.000439 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8555/12542 | Batch Loss: 0.7045 | Learning Rate: 0.000439 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8556/12542 | Batch Loss: 1.2278 | Learning Rate: 0.000439 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8557/12542 | Batch Loss: 1.2090 | Learning Rate: 0.000439 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8558/12542 | Batch Loss: 1.9685 | Learning Rate: 0.000439 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8559/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000439 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8560/12542 | Batch Loss: 0.6200 | Learning Rate: 0.000439 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8561/12542 | Batch Loss: 1.7693 | Learning Rate: 0.000439 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8562/12542 | Batch Loss: 0.8460 | Learning Rate: 0.000439 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8563/12542 | Batch Loss: 2.0080 | Learning Rate: 0.000439 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8564/12542 | Batch Loss: 1.8538 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8565/12542 | Batch Loss: 0.6333 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8566/12542 | Batch Loss: 1.3592 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8567/12542 | Batch Loss: 1.0939 | Learning Rate: 0.000439 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8568/12542 | Batch Loss: 2.5724 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8569/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000439 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8570/12542 | Batch Loss: 1.2101 | Learning Rate: 0.000439 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8571/12542 | Batch Loss: 1.3435 | Learning Rate: 0.000439 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8572/12542 | Batch Loss: 2.0286 | Learning Rate: 0.000439 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8573/12542 | Batch Loss: 2.8170 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8574/12542 | Batch Loss: 0.8497 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8575/12542 | Batch Loss: 1.3443 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8576/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8577/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000439 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8578/12542 | Batch Loss: 1.1234 | Learning Rate: 0.000439 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8579/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8580/12542 | Batch Loss: 2.4239 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8581/12542 | Batch Loss: 0.8383 | Learning Rate: 0.000439 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8582/12542 | Batch Loss: 0.5959 | Learning Rate: 0.000439 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8583/12542 | Batch Loss: 2.9704 | Learning Rate: 0.000439 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8584/12542 | Batch Loss: 1.7886 | Learning Rate: 0.000439 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8585/12542 | Batch Loss: 0.9016 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8586/12542 | Batch Loss: 1.6618 | Learning Rate: 0.000438 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8587/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000438 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8588/12542 | Batch Loss: 1.5862 | Learning Rate: 0.000438 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8589/12542 | Batch Loss: 0.6288 | Learning Rate: 0.000438 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8590/12542 | Batch Loss: 1.1564 | Learning Rate: 0.000438 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8591/12542 | Batch Loss: 1.7288 | Learning Rate: 0.000438 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8592/12542 | Batch Loss: 0.4130 | Learning Rate: 0.000438 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8593/12542 | Batch Loss: 0.9698 | Learning Rate: 0.000438 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8594/12542 | Batch Loss: 1.2394 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8595/12542 | Batch Loss: 1.4474 | Learning Rate: 0.000438 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8596/12542 | Batch Loss: 1.3047 | Learning Rate: 0.000438 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8597/12542 | Batch Loss: 0.6686 | Learning Rate: 0.000438 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8598/12542 | Batch Loss: 0.6982 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8599/12542 | Batch Loss: 0.4814 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8600/12542 | Batch Loss: 1.5826 | Learning Rate: 0.000438 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8601/12542 | Batch Loss: 2.3254 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8602/12542 | Batch Loss: 0.7697 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8603/12542 | Batch Loss: 0.6268 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8604/12542 | Batch Loss: 2.3362 | Learning Rate: 0.000438 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8605/12542 | Batch Loss: 1.0147 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8606/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000438 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8607/12542 | Batch Loss: 1.0404 | Learning Rate: 0.000438 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8608/12542 | Batch Loss: 1.6459 | Learning Rate: 0.000438 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8609/12542 | Batch Loss: 1.0031 | Learning Rate: 0.000438 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8610/12542 | Batch Loss: 1.2010 | Learning Rate: 0.000438 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8611/12542 | Batch Loss: 1.6262 | Learning Rate: 0.000438 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8612/12542 | Batch Loss: 0.5401 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8613/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8614/12542 | Batch Loss: 1.3906 | Learning Rate: 0.000438 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8615/12542 | Batch Loss: 1.4459 | Learning Rate: 0.000438 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8616/12542 | Batch Loss: 1.7695 | Learning Rate: 0.000438 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8617/12542 | Batch Loss: 1.9571 | Learning Rate: 0.000438 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8618/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000438 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8619/12542 | Batch Loss: 1.2608 | Learning Rate: 0.000438 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8620/12542 | Batch Loss: 1.6171 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8621/12542 | Batch Loss: 1.3904 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8622/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000438 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8623/12542 | Batch Loss: 0.5598 | Learning Rate: 0.000437 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8624/12542 | Batch Loss: 1.1156 | Learning Rate: 0.000437 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8625/12542 | Batch Loss: 2.1981 | Learning Rate: 0.000437 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8626/12542 | Batch Loss: 1.0598 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8627/12542 | Batch Loss: 1.0082 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8628/12542 | Batch Loss: 1.7270 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8629/12542 | Batch Loss: 1.3958 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8630/12542 | Batch Loss: 1.1612 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8631/12542 | Batch Loss: 0.8703 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8632/12542 | Batch Loss: 1.3967 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8633/12542 | Batch Loss: 1.1842 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8634/12542 | Batch Loss: 2.1756 | Learning Rate: 0.000437 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8635/12542 | Batch Loss: 1.7597 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8636/12542 | Batch Loss: 1.9357 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8637/12542 | Batch Loss: 0.7483 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8638/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8639/12542 | Batch Loss: 1.3959 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8640/12542 | Batch Loss: 0.6194 | Learning Rate: 0.000437 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8641/12542 | Batch Loss: 0.6344 | Learning Rate: 0.000437 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8642/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000437 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8643/12542 | Batch Loss: 0.7107 | Learning Rate: 0.000437 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8644/12542 | Batch Loss: 0.7329 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8645/12542 | Batch Loss: 1.4806 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8646/12542 | Batch Loss: 1.0773 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8647/12542 | Batch Loss: 0.7061 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8648/12542 | Batch Loss: 0.9492 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8649/12542 | Batch Loss: 1.5751 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8650/12542 | Batch Loss: 1.1396 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8651/12542 | Batch Loss: 1.7596 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8652/12542 | Batch Loss: 2.3871 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8653/12542 | Batch Loss: 1.3498 | Learning Rate: 0.000437 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8654/12542 | Batch Loss: 0.7546 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8655/12542 | Batch Loss: 1.5610 | Learning Rate: 0.000437 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8656/12542 | Batch Loss: 0.8924 | Learning Rate: 0.000437 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8657/12542 | Batch Loss: 2.1050 | Learning Rate: 0.000437 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8658/12542 | Batch Loss: 1.5599 | Learning Rate: 0.000437 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8659/12542 | Batch Loss: 0.7552 | Learning Rate: 0.000437 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8660/12542 | Batch Loss: 1.7389 | Learning Rate: 0.000437 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8661/12542 | Batch Loss: 0.6068 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8662/12542 | Batch Loss: 0.8601 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8663/12542 | Batch Loss: 1.8296 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8664/12542 | Batch Loss: 1.1726 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8665/12542 | Batch Loss: 1.2824 | Learning Rate: 0.000436 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8666/12542 | Batch Loss: 0.7153 | Learning Rate: 0.000436 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8667/12542 | Batch Loss: 1.1031 | Learning Rate: 0.000436 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8668/12542 | Batch Loss: 0.8477 | Learning Rate: 0.000436 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8669/12542 | Batch Loss: 1.3311 | Learning Rate: 0.000436 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8670/12542 | Batch Loss: 1.3945 | Learning Rate: 0.000436 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8671/12542 | Batch Loss: 0.7282 | Learning Rate: 0.000436 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8672/12542 | Batch Loss: 1.5841 | Learning Rate: 0.000436 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8673/12542 | Batch Loss: 1.6638 | Learning Rate: 0.000436 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8674/12542 | Batch Loss: 1.1097 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8675/12542 | Batch Loss: 1.0870 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8676/12542 | Batch Loss: 0.7884 | Learning Rate: 0.000436 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8677/12542 | Batch Loss: 0.8288 | Learning Rate: 0.000436 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8678/12542 | Batch Loss: 1.8318 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8679/12542 | Batch Loss: 1.3265 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8680/12542 | Batch Loss: 0.8398 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8681/12542 | Batch Loss: 0.9662 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8682/12542 | Batch Loss: 1.2984 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8683/12542 | Batch Loss: 1.5359 | Learning Rate: 0.000436 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 8684/12542 | Batch Loss: 1.6177 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8685/12542 | Batch Loss: 1.8359 | Learning Rate: 0.000436 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 8686/12542 | Batch Loss: 1.4917 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8687/12542 | Batch Loss: 1.5580 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8688/12542 | Batch Loss: 1.5543 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8689/12542 | Batch Loss: 1.3193 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8690/12542 | Batch Loss: 1.1023 | Learning Rate: 0.000436 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8691/12542 | Batch Loss: 0.7496 | Learning Rate: 0.000436 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8692/12542 | Batch Loss: 0.4604 | Learning Rate: 0.000436 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8693/12542 | Batch Loss: 1.4444 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8694/12542 | Batch Loss: 0.7816 | Learning Rate: 0.000436 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8695/12542 | Batch Loss: 0.7934 | Learning Rate: 0.000436 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8696/12542 | Batch Loss: 0.8347 | Learning Rate: 0.000436 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8697/12542 | Batch Loss: 0.6336 | Learning Rate: 0.000436 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8698/12542 | Batch Loss: 2.3602 | Learning Rate: 0.000435 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8699/12542 | Batch Loss: 0.6146 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8700/12542 | Batch Loss: 1.5274 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8701/12542 | Batch Loss: 1.6753 | Learning Rate: 0.000435 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8702/12542 | Batch Loss: 0.6818 | Learning Rate: 0.000435 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8703/12542 | Batch Loss: 0.5958 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8704/12542 | Batch Loss: 0.5191 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8705/12542 | Batch Loss: 1.2461 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8706/12542 | Batch Loss: 2.5225 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8707/12542 | Batch Loss: 1.5158 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8708/12542 | Batch Loss: 1.1164 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8709/12542 | Batch Loss: 1.4522 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8710/12542 | Batch Loss: 1.8149 | Learning Rate: 0.000435 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8711/12542 | Batch Loss: 1.5705 | Learning Rate: 0.000435 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8712/12542 | Batch Loss: 1.3690 | Learning Rate: 0.000435 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8713/12542 | Batch Loss: 0.9021 | Learning Rate: 0.000435 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8714/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000435 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8715/12542 | Batch Loss: 0.7969 | Learning Rate: 0.000435 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8716/12542 | Batch Loss: 1.5821 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8717/12542 | Batch Loss: 1.1526 | Learning Rate: 0.000435 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8718/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8719/12542 | Batch Loss: 1.6851 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8720/12542 | Batch Loss: 1.7550 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8721/12542 | Batch Loss: 0.6888 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8722/12542 | Batch Loss: 1.8277 | Learning Rate: 0.000435 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8723/12542 | Batch Loss: 3.9450 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8724/12542 | Batch Loss: 0.8171 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8725/12542 | Batch Loss: 0.4204 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8726/12542 | Batch Loss: 1.5112 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8727/12542 | Batch Loss: 1.8495 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8728/12542 | Batch Loss: 1.5110 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8729/12542 | Batch Loss: 0.6867 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8730/12542 | Batch Loss: 0.3915 | Learning Rate: 0.000435 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8731/12542 | Batch Loss: 2.8659 | Learning Rate: 0.000435 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8732/12542 | Batch Loss: 0.6937 | Learning Rate: 0.000435 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8733/12542 | Batch Loss: 1.6422 | Learning Rate: 0.000435 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8734/12542 | Batch Loss: 1.8339 | Learning Rate: 0.000435 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8735/12542 | Batch Loss: 0.9442 | Learning Rate: 0.000435 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8736/12542 | Batch Loss: 0.8234 | Learning Rate: 0.000434 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8737/12542 | Batch Loss: 0.7345 | Learning Rate: 0.000434 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8738/12542 | Batch Loss: 0.9800 | Learning Rate: 0.000434 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8739/12542 | Batch Loss: 0.7076 | Learning Rate: 0.000434 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8740/12542 | Batch Loss: 0.5589 | Learning Rate: 0.000434 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8741/12542 | Batch Loss: 1.1088 | Learning Rate: 0.000434 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8742/12542 | Batch Loss: 2.1909 | Learning Rate: 0.000434 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8743/12542 | Batch Loss: 1.4721 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8744/12542 | Batch Loss: 1.5974 | Learning Rate: 0.000434 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8745/12542 | Batch Loss: 0.5130 | Learning Rate: 0.000434 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8746/12542 | Batch Loss: 1.2453 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8747/12542 | Batch Loss: 1.2974 | Learning Rate: 0.000434 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8748/12542 | Batch Loss: 1.1801 | Learning Rate: 0.000434 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8749/12542 | Batch Loss: 1.3824 | Learning Rate: 0.000434 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8750/12542 | Batch Loss: 0.7960 | Learning Rate: 0.000434 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8751/12542 | Batch Loss: 0.9146 | Learning Rate: 0.000434 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8752/12542 | Batch Loss: 1.2192 | Learning Rate: 0.000434 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8753/12542 | Batch Loss: 0.4865 | Learning Rate: 0.000434 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8754/12542 | Batch Loss: 1.5939 | Learning Rate: 0.000434 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8755/12542 | Batch Loss: 1.8873 | Learning Rate: 0.000434 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8756/12542 | Batch Loss: 0.9550 | Learning Rate: 0.000434 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8757/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8758/12542 | Batch Loss: 1.3086 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8759/12542 | Batch Loss: 1.5161 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8760/12542 | Batch Loss: 1.6847 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8761/12542 | Batch Loss: 2.2547 | Learning Rate: 0.000434 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8762/12542 | Batch Loss: 1.3431 | Learning Rate: 0.000434 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8763/12542 | Batch Loss: 0.8316 | Learning Rate: 0.000434 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8764/12542 | Batch Loss: 0.6216 | Learning Rate: 0.000434 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8765/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000434 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8766/12542 | Batch Loss: 0.7880 | Learning Rate: 0.000434 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8767/12542 | Batch Loss: 1.0201 | Learning Rate: 0.000434 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8768/12542 | Batch Loss: 1.2597 | Learning Rate: 0.000434 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8769/12542 | Batch Loss: 0.5505 | Learning Rate: 0.000434 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8770/12542 | Batch Loss: 1.2530 | Learning Rate: 0.000434 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8771/12542 | Batch Loss: 1.4683 | Learning Rate: 0.000434 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8772/12542 | Batch Loss: 0.5248 | Learning Rate: 0.000434 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8773/12542 | Batch Loss: 1.2970 | Learning Rate: 0.000434 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8774/12542 | Batch Loss: 1.1893 | Learning Rate: 0.000433 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8775/12542 | Batch Loss: 1.0430 | Learning Rate: 0.000433 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8776/12542 | Batch Loss: 1.2043 | Learning Rate: 0.000433 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8777/12542 | Batch Loss: 1.5713 | Learning Rate: 0.000433 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8778/12542 | Batch Loss: 0.5834 | Learning Rate: 0.000433 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8779/12542 | Batch Loss: 0.6625 | Learning Rate: 0.000433 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8780/12542 | Batch Loss: 1.4437 | Learning Rate: 0.000433 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8781/12542 | Batch Loss: 2.9099 | Learning Rate: 0.000433 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8782/12542 | Batch Loss: 2.0956 | Learning Rate: 0.000433 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8783/12542 | Batch Loss: 0.8870 | Learning Rate: 0.000433 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8784/12542 | Batch Loss: 1.1438 | Learning Rate: 0.000433 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8785/12542 | Batch Loss: 0.9633 | Learning Rate: 0.000433 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8786/12542 | Batch Loss: 0.8636 | Learning Rate: 0.000433 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8787/12542 | Batch Loss: 0.6852 | Learning Rate: 0.000433 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8788/12542 | Batch Loss: 1.6637 | Learning Rate: 0.000433 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8789/12542 | Batch Loss: 0.5189 | Learning Rate: 0.000433 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8790/12542 | Batch Loss: 0.4824 | Learning Rate: 0.000433 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8791/12542 | Batch Loss: 1.0173 | Learning Rate: 0.000433 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8792/12542 | Batch Loss: 1.0444 | Learning Rate: 0.000433 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8793/12542 | Batch Loss: 0.5596 | Learning Rate: 0.000433 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8794/12542 | Batch Loss: 1.5111 | Learning Rate: 0.000433 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8795/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000433 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8796/12542 | Batch Loss: 0.5258 | Learning Rate: 0.000433 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8797/12542 | Batch Loss: 1.4464 | Learning Rate: 0.000433 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8798/12542 | Batch Loss: 1.8192 | Learning Rate: 0.000433 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8799/12542 | Batch Loss: 0.7900 | Learning Rate: 0.000433 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8800/12542 | Batch Loss: 1.9289 | Learning Rate: 0.000433 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8801/12542 | Batch Loss: 1.3215 | Learning Rate: 0.000433 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8802/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000433 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8803/12542 | Batch Loss: 0.9703 | Learning Rate: 0.000433 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8804/12542 | Batch Loss: 1.6691 | Learning Rate: 0.000433 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8805/12542 | Batch Loss: 1.0247 | Learning Rate: 0.000433 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8806/12542 | Batch Loss: 4.1342 | Learning Rate: 0.000433 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8807/12542 | Batch Loss: 1.2356 | Learning Rate: 0.000433 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8808/12542 | Batch Loss: 1.5064 | Learning Rate: 0.000433 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8809/12542 | Batch Loss: 2.0223 | Learning Rate: 0.000433 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8810/12542 | Batch Loss: 1.0617 | Learning Rate: 0.000433 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8811/12542 | Batch Loss: 1.2275 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8812/12542 | Batch Loss: 1.3735 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8813/12542 | Batch Loss: 1.4374 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8814/12542 | Batch Loss: 0.8952 | Learning Rate: 0.000432 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8815/12542 | Batch Loss: 0.7942 | Learning Rate: 0.000432 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8816/12542 | Batch Loss: 1.1143 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8817/12542 | Batch Loss: 1.9472 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8818/12542 | Batch Loss: 0.9643 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8819/12542 | Batch Loss: 1.2468 | Learning Rate: 0.000432 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8820/12542 | Batch Loss: 1.3334 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8821/12542 | Batch Loss: 1.1465 | Learning Rate: 0.000432 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8822/12542 | Batch Loss: 1.7432 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8823/12542 | Batch Loss: 1.4559 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8824/12542 | Batch Loss: 0.5149 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8825/12542 | Batch Loss: 0.7391 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8826/12542 | Batch Loss: 1.9321 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8827/12542 | Batch Loss: 2.1269 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8828/12542 | Batch Loss: 0.6717 | Learning Rate: 0.000432 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8829/12542 | Batch Loss: 1.8820 | Learning Rate: 0.000432 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8830/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000432 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8831/12542 | Batch Loss: 1.4780 | Learning Rate: 0.000432 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8832/12542 | Batch Loss: 0.4383 | Learning Rate: 0.000432 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8833/12542 | Batch Loss: 1.6049 | Learning Rate: 0.000432 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8834/12542 | Batch Loss: 1.0481 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8835/12542 | Batch Loss: 1.3301 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8836/12542 | Batch Loss: 1.9737 | Learning Rate: 0.000432 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8837/12542 | Batch Loss: 1.0301 | Learning Rate: 0.000432 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8838/12542 | Batch Loss: 1.0061 | Learning Rate: 0.000432 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8839/12542 | Batch Loss: 3.3182 | Learning Rate: 0.000432 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8840/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000432 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8841/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000432 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8842/12542 | Batch Loss: 0.9769 | Learning Rate: 0.000432 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8843/12542 | Batch Loss: 1.5747 | Learning Rate: 0.000432 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8844/12542 | Batch Loss: 1.6603 | Learning Rate: 0.000432 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8845/12542 | Batch Loss: 0.8901 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8846/12542 | Batch Loss: 1.0844 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8847/12542 | Batch Loss: 2.0629 | Learning Rate: 0.000432 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8848/12542 | Batch Loss: 1.4400 | Learning Rate: 0.000432 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8849/12542 | Batch Loss: 1.0809 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8850/12542 | Batch Loss: 2.2470 | Learning Rate: 0.000431 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8851/12542 | Batch Loss: 1.5589 | Learning Rate: 0.000431 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8852/12542 | Batch Loss: 0.5031 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8853/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8854/12542 | Batch Loss: 0.7386 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8855/12542 | Batch Loss: 1.0558 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8856/12542 | Batch Loss: 0.8542 | Learning Rate: 0.000431 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 8857/12542 | Batch Loss: 2.7769 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8858/12542 | Batch Loss: 1.8398 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8859/12542 | Batch Loss: 0.4258 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8860/12542 | Batch Loss: 0.6488 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8861/12542 | Batch Loss: 1.3499 | Learning Rate: 0.000431 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8862/12542 | Batch Loss: 0.7570 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8863/12542 | Batch Loss: 0.6852 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8864/12542 | Batch Loss: 0.8905 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8865/12542 | Batch Loss: 0.9784 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8866/12542 | Batch Loss: 1.5267 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8867/12542 | Batch Loss: 1.9993 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8868/12542 | Batch Loss: 0.7498 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8869/12542 | Batch Loss: 2.2483 | Learning Rate: 0.000431 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8870/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8871/12542 | Batch Loss: 0.6193 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8872/12542 | Batch Loss: 2.6339 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8873/12542 | Batch Loss: 0.7382 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8874/12542 | Batch Loss: 0.8594 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8875/12542 | Batch Loss: 1.1404 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8876/12542 | Batch Loss: 0.5765 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8877/12542 | Batch Loss: 1.2494 | Learning Rate: 0.000431 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8878/12542 | Batch Loss: 1.4782 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8879/12542 | Batch Loss: 1.0188 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8880/12542 | Batch Loss: 0.6351 | Learning Rate: 0.000431 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8881/12542 | Batch Loss: 0.9792 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8882/12542 | Batch Loss: 1.6832 | Learning Rate: 0.000431 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8883/12542 | Batch Loss: 2.0675 | Learning Rate: 0.000431 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8884/12542 | Batch Loss: 0.5486 | Learning Rate: 0.000431 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8885/12542 | Batch Loss: 2.0723 | Learning Rate: 0.000431 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8886/12542 | Batch Loss: 1.5309 | Learning Rate: 0.000431 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8887/12542 | Batch Loss: 1.0112 | Learning Rate: 0.000430 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8888/12542 | Batch Loss: 2.0067 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8889/12542 | Batch Loss: 0.9531 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8890/12542 | Batch Loss: 0.5505 | Learning Rate: 0.000430 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8891/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000430 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8892/12542 | Batch Loss: 1.6422 | Learning Rate: 0.000430 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8893/12542 | Batch Loss: 1.2808 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8894/12542 | Batch Loss: 1.2957 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8895/12542 | Batch Loss: 1.8282 | Learning Rate: 0.000430 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8896/12542 | Batch Loss: 1.2842 | Learning Rate: 0.000430 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8897/12542 | Batch Loss: 0.5328 | Learning Rate: 0.000430 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8898/12542 | Batch Loss: 2.2873 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8899/12542 | Batch Loss: 1.2810 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8900/12542 | Batch Loss: 0.8121 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8901/12542 | Batch Loss: 2.8094 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8902/12542 | Batch Loss: 2.1344 | Learning Rate: 0.000430 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8903/12542 | Batch Loss: 1.2588 | Learning Rate: 0.000430 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8904/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8905/12542 | Batch Loss: 0.7753 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8906/12542 | Batch Loss: 1.4907 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8907/12542 | Batch Loss: 1.6658 | Learning Rate: 0.000430 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8908/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000430 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8909/12542 | Batch Loss: 1.0695 | Learning Rate: 0.000430 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8910/12542 | Batch Loss: 0.8058 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8911/12542 | Batch Loss: 1.2928 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8912/12542 | Batch Loss: 1.5588 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8913/12542 | Batch Loss: 1.4860 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8914/12542 | Batch Loss: 0.3724 | Learning Rate: 0.000430 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8915/12542 | Batch Loss: 1.3359 | Learning Rate: 0.000430 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8916/12542 | Batch Loss: 0.8376 | Learning Rate: 0.000430 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8917/12542 | Batch Loss: 0.8135 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8918/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000430 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8919/12542 | Batch Loss: 1.1995 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8920/12542 | Batch Loss: 1.3090 | Learning Rate: 0.000430 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8921/12542 | Batch Loss: 1.0354 | Learning Rate: 0.000430 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8922/12542 | Batch Loss: 0.6114 | Learning Rate: 0.000430 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8923/12542 | Batch Loss: 1.1263 | Learning Rate: 0.000430 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8924/12542 | Batch Loss: 0.8694 | Learning Rate: 0.000429 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8925/12542 | Batch Loss: 2.1597 | Learning Rate: 0.000429 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8926/12542 | Batch Loss: 0.9035 | Learning Rate: 0.000429 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8927/12542 | Batch Loss: 1.0144 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8928/12542 | Batch Loss: 1.5464 | Learning Rate: 0.000429 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8929/12542 | Batch Loss: 1.1469 | Learning Rate: 0.000429 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8930/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000429 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 8931/12542 | Batch Loss: 0.9918 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8932/12542 | Batch Loss: 3.1015 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8933/12542 | Batch Loss: 0.7812 | Learning Rate: 0.000429 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8934/12542 | Batch Loss: 1.0239 | Learning Rate: 0.000429 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8935/12542 | Batch Loss: 1.4373 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8936/12542 | Batch Loss: 0.5242 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8937/12542 | Batch Loss: 1.7638 | Learning Rate: 0.000429 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8938/12542 | Batch Loss: 1.1148 | Learning Rate: 0.000429 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8939/12542 | Batch Loss: 0.7765 | Learning Rate: 0.000429 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8940/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000429 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8941/12542 | Batch Loss: 0.7682 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8942/12542 | Batch Loss: 1.9157 | Learning Rate: 0.000429 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8943/12542 | Batch Loss: 1.8742 | Learning Rate: 0.000429 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8944/12542 | Batch Loss: 1.5005 | Learning Rate: 0.000429 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8945/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000429 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8946/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000429 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8947/12542 | Batch Loss: 0.9200 | Learning Rate: 0.000429 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8948/12542 | Batch Loss: 1.3831 | Learning Rate: 0.000429 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8949/12542 | Batch Loss: 1.0916 | Learning Rate: 0.000429 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8950/12542 | Batch Loss: 0.5744 | Learning Rate: 0.000429 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8951/12542 | Batch Loss: 2.4094 | Learning Rate: 0.000429 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8952/12542 | Batch Loss: 0.6664 | Learning Rate: 0.000429 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8953/12542 | Batch Loss: 2.1749 | Learning Rate: 0.000429 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8954/12542 | Batch Loss: 0.9467 | Learning Rate: 0.000429 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8955/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000429 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8956/12542 | Batch Loss: 2.5031 | Learning Rate: 0.000429 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8957/12542 | Batch Loss: 0.5988 | Learning Rate: 0.000429 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8958/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000429 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8959/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000429 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8960/12542 | Batch Loss: 0.6914 | Learning Rate: 0.000429 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8961/12542 | Batch Loss: 1.3800 | Learning Rate: 0.000429 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8962/12542 | Batch Loss: 1.1077 | Learning Rate: 0.000428 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8963/12542 | Batch Loss: 1.6890 | Learning Rate: 0.000428 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8964/12542 | Batch Loss: 1.6514 | Learning Rate: 0.000428 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8965/12542 | Batch Loss: 1.2330 | Learning Rate: 0.000428 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8966/12542 | Batch Loss: 1.2422 | Learning Rate: 0.000428 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8967/12542 | Batch Loss: 0.6551 | Learning Rate: 0.000428 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8968/12542 | Batch Loss: 0.9718 | Learning Rate: 0.000428 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 8969/12542 | Batch Loss: 1.3341 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8970/12542 | Batch Loss: 1.1846 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8971/12542 | Batch Loss: 1.7714 | Learning Rate: 0.000428 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8972/12542 | Batch Loss: 1.4517 | Learning Rate: 0.000428 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8973/12542 | Batch Loss: 1.9063 | Learning Rate: 0.000428 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8974/12542 | Batch Loss: 1.8176 | Learning Rate: 0.000428 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8975/12542 | Batch Loss: 1.3684 | Learning Rate: 0.000428 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 8976/12542 | Batch Loss: 1.3657 | Learning Rate: 0.000428 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 8977/12542 | Batch Loss: 0.9188 | Learning Rate: 0.000428 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8978/12542 | Batch Loss: 1.1920 | Learning Rate: 0.000428 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8979/12542 | Batch Loss: 1.4036 | Learning Rate: 0.000428 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8980/12542 | Batch Loss: 0.8834 | Learning Rate: 0.000428 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8981/12542 | Batch Loss: 1.7577 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8982/12542 | Batch Loss: 3.4396 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8983/12542 | Batch Loss: 1.8984 | Learning Rate: 0.000428 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8984/12542 | Batch Loss: 0.9232 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8985/12542 | Batch Loss: 0.7423 | Learning Rate: 0.000428 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 8986/12542 | Batch Loss: 2.4388 | Learning Rate: 0.000428 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 8987/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000428 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8988/12542 | Batch Loss: 2.1022 | Learning Rate: 0.000428 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8989/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000428 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8990/12542 | Batch Loss: 1.1901 | Learning Rate: 0.000428 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 8991/12542 | Batch Loss: 2.8395 | Learning Rate: 0.000428 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8992/12542 | Batch Loss: 2.1947 | Learning Rate: 0.000428 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8993/12542 | Batch Loss: 1.9317 | Learning Rate: 0.000428 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8994/12542 | Batch Loss: 1.0533 | Learning Rate: 0.000428 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 8995/12542 | Batch Loss: 1.4986 | Learning Rate: 0.000428 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 8996/12542 | Batch Loss: 1.5669 | Learning Rate: 0.000428 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 8997/12542 | Batch Loss: 1.5286 | Learning Rate: 0.000428 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 8998/12542 | Batch Loss: 1.4291 | Learning Rate: 0.000428 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 8999/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000427 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9000/12542 | Batch Loss: 0.7903 | Learning Rate: 0.000427 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9001/12542 | Batch Loss: 1.0556 | Learning Rate: 0.000427 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9002/12542 | Batch Loss: 1.1006 | Learning Rate: 0.000427 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9003/12542 | Batch Loss: 1.0531 | Learning Rate: 0.000427 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9004/12542 | Batch Loss: 1.7628 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9005/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000427 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9006/12542 | Batch Loss: 1.3282 | Learning Rate: 0.000427 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9007/12542 | Batch Loss: 1.9879 | Learning Rate: 0.000427 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9008/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000427 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9009/12542 | Batch Loss: 2.0503 | Learning Rate: 0.000427 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9010/12542 | Batch Loss: 1.6009 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9011/12542 | Batch Loss: 0.5935 | Learning Rate: 0.000427 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9012/12542 | Batch Loss: 3.2663 | Learning Rate: 0.000427 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9013/12542 | Batch Loss: 1.1630 | Learning Rate: 0.000427 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9014/12542 | Batch Loss: 1.3875 | Learning Rate: 0.000427 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9015/12542 | Batch Loss: 3.0209 | Learning Rate: 0.000427 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9016/12542 | Batch Loss: 1.0455 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9017/12542 | Batch Loss: 1.0416 | Learning Rate: 0.000427 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9018/12542 | Batch Loss: 0.8109 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9019/12542 | Batch Loss: 0.8089 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9020/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000427 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9021/12542 | Batch Loss: 0.9873 | Learning Rate: 0.000427 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9022/12542 | Batch Loss: 1.6703 | Learning Rate: 0.000427 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9023/12542 | Batch Loss: 2.7402 | Learning Rate: 0.000427 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9024/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000427 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9025/12542 | Batch Loss: 2.0088 | Learning Rate: 0.000427 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9026/12542 | Batch Loss: 1.4159 | Learning Rate: 0.000427 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9027/12542 | Batch Loss: 1.8682 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9028/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000427 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9029/12542 | Batch Loss: 1.0805 | Learning Rate: 0.000427 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9030/12542 | Batch Loss: 1.0018 | Learning Rate: 0.000427 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9031/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000427 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9032/12542 | Batch Loss: 1.9324 | Learning Rate: 0.000427 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9033/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000427 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9034/12542 | Batch Loss: 2.7876 | Learning Rate: 0.000427 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9035/12542 | Batch Loss: 0.7421 | Learning Rate: 0.000427 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9036/12542 | Batch Loss: 0.6590 | Learning Rate: 0.000427 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9037/12542 | Batch Loss: 2.3043 | Learning Rate: 0.000426 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9038/12542 | Batch Loss: 0.9022 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9039/12542 | Batch Loss: 1.0028 | Learning Rate: 0.000426 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9040/12542 | Batch Loss: 1.0995 | Learning Rate: 0.000426 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9041/12542 | Batch Loss: 1.3994 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9042/12542 | Batch Loss: 0.7940 | Learning Rate: 0.000426 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9043/12542 | Batch Loss: 1.1183 | Learning Rate: 0.000426 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9044/12542 | Batch Loss: 0.7448 | Learning Rate: 0.000426 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9045/12542 | Batch Loss: 1.2016 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9046/12542 | Batch Loss: 1.8445 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9047/12542 | Batch Loss: 3.0587 | Learning Rate: 0.000426 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9048/12542 | Batch Loss: 1.1851 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9049/12542 | Batch Loss: 1.2228 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9050/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9051/12542 | Batch Loss: 1.6781 | Learning Rate: 0.000426 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9052/12542 | Batch Loss: 1.5450 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9053/12542 | Batch Loss: 1.6149 | Learning Rate: 0.000426 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9054/12542 | Batch Loss: 1.5557 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9055/12542 | Batch Loss: 1.4862 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9056/12542 | Batch Loss: 1.5132 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9057/12542 | Batch Loss: 1.0735 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9058/12542 | Batch Loss: 0.3869 | Learning Rate: 0.000426 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9059/12542 | Batch Loss: 1.1438 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9060/12542 | Batch Loss: 2.1327 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9061/12542 | Batch Loss: 0.7116 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9062/12542 | Batch Loss: 1.3101 | Learning Rate: 0.000426 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9063/12542 | Batch Loss: 1.7242 | Learning Rate: 0.000426 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9064/12542 | Batch Loss: 1.2838 | Learning Rate: 0.000426 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9065/12542 | Batch Loss: 1.7299 | Learning Rate: 0.000426 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9066/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000426 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9067/12542 | Batch Loss: 0.8628 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9068/12542 | Batch Loss: 0.8482 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9069/12542 | Batch Loss: 1.1165 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9070/12542 | Batch Loss: 1.1355 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9071/12542 | Batch Loss: 1.2235 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9072/12542 | Batch Loss: 1.6286 | Learning Rate: 0.000426 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9073/12542 | Batch Loss: 2.9141 | Learning Rate: 0.000426 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9074/12542 | Batch Loss: 0.9592 | Learning Rate: 0.000426 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9075/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000425 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9076/12542 | Batch Loss: 1.0636 | Learning Rate: 0.000425 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9077/12542 | Batch Loss: 1.6934 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9078/12542 | Batch Loss: 1.2566 | Learning Rate: 0.000425 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9079/12542 | Batch Loss: 1.4403 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9080/12542 | Batch Loss: 0.8909 | Learning Rate: 0.000425 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9081/12542 | Batch Loss: 0.7593 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9082/12542 | Batch Loss: 0.9525 | Learning Rate: 0.000425 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9083/12542 | Batch Loss: 2.5366 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9084/12542 | Batch Loss: 3.8975 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9085/12542 | Batch Loss: 1.4530 | Learning Rate: 0.000425 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9086/12542 | Batch Loss: 1.2359 | Learning Rate: 0.000425 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9087/12542 | Batch Loss: 1.3835 | Learning Rate: 0.000425 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9088/12542 | Batch Loss: 0.6229 | Learning Rate: 0.000425 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9089/12542 | Batch Loss: 1.0219 | Learning Rate: 0.000425 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9090/12542 | Batch Loss: 0.8533 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9091/12542 | Batch Loss: 0.6963 | Learning Rate: 0.000425 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9092/12542 | Batch Loss: 0.9844 | Learning Rate: 0.000425 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9093/12542 | Batch Loss: 1.5213 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9094/12542 | Batch Loss: 1.2394 | Learning Rate: 0.000425 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9095/12542 | Batch Loss: 1.5951 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9096/12542 | Batch Loss: 0.9413 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9097/12542 | Batch Loss: 0.6933 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9098/12542 | Batch Loss: 4.9282 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9099/12542 | Batch Loss: 0.7039 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9100/12542 | Batch Loss: 1.5958 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9101/12542 | Batch Loss: 1.3895 | Learning Rate: 0.000425 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9102/12542 | Batch Loss: 0.8975 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9103/12542 | Batch Loss: 1.8599 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9104/12542 | Batch Loss: 1.3104 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9105/12542 | Batch Loss: 1.1767 | Learning Rate: 0.000425 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9106/12542 | Batch Loss: 1.7096 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9107/12542 | Batch Loss: 0.9665 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9108/12542 | Batch Loss: 0.9602 | Learning Rate: 0.000425 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9109/12542 | Batch Loss: 1.9869 | Learning Rate: 0.000425 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9110/12542 | Batch Loss: 2.6997 | Learning Rate: 0.000425 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9111/12542 | Batch Loss: 0.8610 | Learning Rate: 0.000425 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9112/12542 | Batch Loss: 1.2487 | Learning Rate: 0.000424 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9113/12542 | Batch Loss: 0.8908 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9114/12542 | Batch Loss: 1.4592 | Learning Rate: 0.000424 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9115/12542 | Batch Loss: 1.1926 | Learning Rate: 0.000424 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9116/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000424 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9117/12542 | Batch Loss: 1.3377 | Learning Rate: 0.000424 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9118/12542 | Batch Loss: 0.8702 | Learning Rate: 0.000424 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9119/12542 | Batch Loss: 2.6743 | Learning Rate: 0.000424 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9120/12542 | Batch Loss: 1.3358 | Learning Rate: 0.000424 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9121/12542 | Batch Loss: 1.3658 | Learning Rate: 0.000424 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9122/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000424 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9123/12542 | Batch Loss: 1.3620 | Learning Rate: 0.000424 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9124/12542 | Batch Loss: 0.8776 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9125/12542 | Batch Loss: 0.9747 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9126/12542 | Batch Loss: 2.1692 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9127/12542 | Batch Loss: 0.7648 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9128/12542 | Batch Loss: 1.7786 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9129/12542 | Batch Loss: 1.5798 | Learning Rate: 0.000424 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9130/12542 | Batch Loss: 1.0150 | Learning Rate: 0.000424 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9131/12542 | Batch Loss: 1.1220 | Learning Rate: 0.000424 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9132/12542 | Batch Loss: 0.4569 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9133/12542 | Batch Loss: 2.9683 | Learning Rate: 0.000424 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9134/12542 | Batch Loss: 2.2736 | Learning Rate: 0.000424 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9135/12542 | Batch Loss: 1.5295 | Learning Rate: 0.000424 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9136/12542 | Batch Loss: 1.8423 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9137/12542 | Batch Loss: 1.7567 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9138/12542 | Batch Loss: 1.8698 | Learning Rate: 0.000424 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 9139/12542 | Batch Loss: 1.0018 | Learning Rate: 0.000424 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9140/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000424 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9141/12542 | Batch Loss: 0.9061 | Learning Rate: 0.000424 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9142/12542 | Batch Loss: 0.8942 | Learning Rate: 0.000424 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9143/12542 | Batch Loss: 1.3770 | Learning Rate: 0.000424 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9144/12542 | Batch Loss: 0.8350 | Learning Rate: 0.000424 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9145/12542 | Batch Loss: 0.7229 | Learning Rate: 0.000424 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9146/12542 | Batch Loss: 0.9985 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9147/12542 | Batch Loss: 0.8973 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9148/12542 | Batch Loss: 1.5955 | Learning Rate: 0.000424 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9149/12542 | Batch Loss: 0.5545 | Learning Rate: 0.000424 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9150/12542 | Batch Loss: 0.9235 | Learning Rate: 0.000423 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9151/12542 | Batch Loss: 1.1684 | Learning Rate: 0.000423 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9152/12542 | Batch Loss: 2.1272 | Learning Rate: 0.000423 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9153/12542 | Batch Loss: 2.2704 | Learning Rate: 0.000423 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9154/12542 | Batch Loss: 2.2624 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9155/12542 | Batch Loss: 1.0499 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9156/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9157/12542 | Batch Loss: 0.8282 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9158/12542 | Batch Loss: 0.8999 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9159/12542 | Batch Loss: 0.6646 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9160/12542 | Batch Loss: 1.0088 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9161/12542 | Batch Loss: 0.8305 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9162/12542 | Batch Loss: 1.9420 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9163/12542 | Batch Loss: 0.7987 | Learning Rate: 0.000423 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9164/12542 | Batch Loss: 1.6666 | Learning Rate: 0.000423 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9165/12542 | Batch Loss: 1.4401 | Learning Rate: 0.000423 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9166/12542 | Batch Loss: 0.4585 | Learning Rate: 0.000423 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9167/12542 | Batch Loss: 1.4212 | Learning Rate: 0.000423 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9168/12542 | Batch Loss: 1.9370 | Learning Rate: 0.000423 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9169/12542 | Batch Loss: 0.9118 | Learning Rate: 0.000423 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9170/12542 | Batch Loss: 2.2501 | Learning Rate: 0.000423 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9171/12542 | Batch Loss: 1.2562 | Learning Rate: 0.000423 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9172/12542 | Batch Loss: 4.1940 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9173/12542 | Batch Loss: 0.7728 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9174/12542 | Batch Loss: 1.6664 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9175/12542 | Batch Loss: 0.9989 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9176/12542 | Batch Loss: 1.4085 | Learning Rate: 0.000423 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9177/12542 | Batch Loss: 1.1934 | Learning Rate: 0.000423 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9178/12542 | Batch Loss: 1.1265 | Learning Rate: 0.000423 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9179/12542 | Batch Loss: 1.0675 | Learning Rate: 0.000423 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9180/12542 | Batch Loss: 1.0399 | Learning Rate: 0.000423 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9181/12542 | Batch Loss: 2.1573 | Learning Rate: 0.000423 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9182/12542 | Batch Loss: 1.3335 | Learning Rate: 0.000423 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9183/12542 | Batch Loss: 1.4378 | Learning Rate: 0.000423 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9184/12542 | Batch Loss: 1.0726 | Learning Rate: 0.000423 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9185/12542 | Batch Loss: 1.3148 | Learning Rate: 0.000423 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9186/12542 | Batch Loss: 1.3260 | Learning Rate: 0.000423 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9187/12542 | Batch Loss: 0.5778 | Learning Rate: 0.000423 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9188/12542 | Batch Loss: 2.1918 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9189/12542 | Batch Loss: 0.6837 | Learning Rate: 0.000422 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9190/12542 | Batch Loss: 1.5750 | Learning Rate: 0.000422 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9191/12542 | Batch Loss: 2.6266 | Learning Rate: 0.000422 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9192/12542 | Batch Loss: 1.7385 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9193/12542 | Batch Loss: 1.3910 | Learning Rate: 0.000422 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9194/12542 | Batch Loss: 2.5609 | Learning Rate: 0.000422 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9195/12542 | Batch Loss: 0.9584 | Learning Rate: 0.000422 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9196/12542 | Batch Loss: 0.9793 | Learning Rate: 0.000422 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9197/12542 | Batch Loss: 1.0185 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9198/12542 | Batch Loss: 0.5074 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9199/12542 | Batch Loss: 1.3099 | Learning Rate: 0.000422 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9200/12542 | Batch Loss: 1.5278 | Learning Rate: 0.000422 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9201/12542 | Batch Loss: 1.0937 | Learning Rate: 0.000422 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9202/12542 | Batch Loss: 1.1309 | Learning Rate: 0.000422 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9203/12542 | Batch Loss: 1.1991 | Learning Rate: 0.000422 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9204/12542 | Batch Loss: 2.1710 | Learning Rate: 0.000422 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9205/12542 | Batch Loss: 1.8458 | Learning Rate: 0.000422 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9206/12542 | Batch Loss: 1.2237 | Learning Rate: 0.000422 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9207/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000422 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9208/12542 | Batch Loss: 1.8590 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9209/12542 | Batch Loss: 0.7198 | Learning Rate: 0.000422 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9210/12542 | Batch Loss: 0.9149 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9211/12542 | Batch Loss: 0.7020 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9212/12542 | Batch Loss: 1.3062 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9213/12542 | Batch Loss: 1.3249 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9214/12542 | Batch Loss: 0.9430 | Learning Rate: 0.000422 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9215/12542 | Batch Loss: 0.9147 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9216/12542 | Batch Loss: 1.9740 | Learning Rate: 0.000422 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9217/12542 | Batch Loss: 0.8366 | Learning Rate: 0.000422 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9218/12542 | Batch Loss: 1.2594 | Learning Rate: 0.000422 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9219/12542 | Batch Loss: 1.8088 | Learning Rate: 0.000422 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9220/12542 | Batch Loss: 1.2023 | Learning Rate: 0.000422 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9221/12542 | Batch Loss: 1.9816 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9222/12542 | Batch Loss: 1.9237 | Learning Rate: 0.000422 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9223/12542 | Batch Loss: 0.8608 | Learning Rate: 0.000422 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9224/12542 | Batch Loss: 0.9693 | Learning Rate: 0.000422 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9225/12542 | Batch Loss: 0.8399 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9226/12542 | Batch Loss: 1.5236 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9227/12542 | Batch Loss: 0.9735 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9228/12542 | Batch Loss: 0.9551 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9229/12542 | Batch Loss: 2.1453 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9230/12542 | Batch Loss: 0.8983 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9231/12542 | Batch Loss: 1.9574 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9232/12542 | Batch Loss: 0.8341 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9233/12542 | Batch Loss: 0.5952 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9234/12542 | Batch Loss: 1.4194 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9235/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9236/12542 | Batch Loss: 2.1519 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9237/12542 | Batch Loss: 1.0650 | Learning Rate: 0.000421 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9238/12542 | Batch Loss: 0.5812 | Learning Rate: 0.000421 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9239/12542 | Batch Loss: 2.8709 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9240/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9241/12542 | Batch Loss: 1.2128 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9242/12542 | Batch Loss: 1.3657 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9243/12542 | Batch Loss: 1.8925 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9244/12542 | Batch Loss: 0.5922 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9245/12542 | Batch Loss: 3.1989 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9246/12542 | Batch Loss: 0.7844 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9247/12542 | Batch Loss: 0.5102 | Learning Rate: 0.000421 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9248/12542 | Batch Loss: 2.1849 | Learning Rate: 0.000421 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9249/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9250/12542 | Batch Loss: 1.8125 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9251/12542 | Batch Loss: 1.2297 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9252/12542 | Batch Loss: 2.7426 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9253/12542 | Batch Loss: 1.0842 | Learning Rate: 0.000421 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9254/12542 | Batch Loss: 0.9739 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9255/12542 | Batch Loss: 1.8794 | Learning Rate: 0.000421 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9256/12542 | Batch Loss: 0.9215 | Learning Rate: 0.000421 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9257/12542 | Batch Loss: 1.4417 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9258/12542 | Batch Loss: 0.8688 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9259/12542 | Batch Loss: 2.0250 | Learning Rate: 0.000421 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9260/12542 | Batch Loss: 2.6689 | Learning Rate: 0.000421 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9261/12542 | Batch Loss: 0.5122 | Learning Rate: 0.000421 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9262/12542 | Batch Loss: 1.3642 | Learning Rate: 0.000421 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9263/12542 | Batch Loss: 1.9240 | Learning Rate: 0.000420 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9264/12542 | Batch Loss: 1.5180 | Learning Rate: 0.000420 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9265/12542 | Batch Loss: 1.4350 | Learning Rate: 0.000420 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9266/12542 | Batch Loss: 1.1928 | Learning Rate: 0.000420 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9267/12542 | Batch Loss: 0.5885 | Learning Rate: 0.000420 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9268/12542 | Batch Loss: 1.0047 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9269/12542 | Batch Loss: 1.2433 | Learning Rate: 0.000420 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9270/12542 | Batch Loss: 1.2568 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9271/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000420 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9272/12542 | Batch Loss: 1.7151 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9273/12542 | Batch Loss: 2.1433 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9274/12542 | Batch Loss: 1.7699 | Learning Rate: 0.000420 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9275/12542 | Batch Loss: 0.7003 | Learning Rate: 0.000420 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9276/12542 | Batch Loss: 0.5351 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9277/12542 | Batch Loss: 3.7350 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9278/12542 | Batch Loss: 1.3397 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9279/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9280/12542 | Batch Loss: 0.7360 | Learning Rate: 0.000420 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9281/12542 | Batch Loss: 1.0411 | Learning Rate: 0.000420 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9282/12542 | Batch Loss: 0.8114 | Learning Rate: 0.000420 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9283/12542 | Batch Loss: 0.9255 | Learning Rate: 0.000420 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9284/12542 | Batch Loss: 0.8917 | Learning Rate: 0.000420 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9285/12542 | Batch Loss: 1.2732 | Learning Rate: 0.000420 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9286/12542 | Batch Loss: 1.6300 | Learning Rate: 0.000420 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9287/12542 | Batch Loss: 0.8235 | Learning Rate: 0.000420 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9288/12542 | Batch Loss: 0.6400 | Learning Rate: 0.000420 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9289/12542 | Batch Loss: 1.2944 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9290/12542 | Batch Loss: 0.8496 | Learning Rate: 0.000420 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9291/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000420 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9292/12542 | Batch Loss: 0.8526 | Learning Rate: 0.000420 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9293/12542 | Batch Loss: 1.3433 | Learning Rate: 0.000420 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9294/12542 | Batch Loss: 1.0979 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9295/12542 | Batch Loss: 0.6533 | Learning Rate: 0.000420 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9296/12542 | Batch Loss: 1.1011 | Learning Rate: 0.000420 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9297/12542 | Batch Loss: 1.9111 | Learning Rate: 0.000420 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9298/12542 | Batch Loss: 1.4276 | Learning Rate: 0.000420 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9299/12542 | Batch Loss: 1.3015 | Learning Rate: 0.000420 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9300/12542 | Batch Loss: 0.8553 | Learning Rate: 0.000419 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9301/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000419 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9302/12542 | Batch Loss: 1.1294 | Learning Rate: 0.000419 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9303/12542 | Batch Loss: 3.0235 | Learning Rate: 0.000419 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9304/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000419 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9305/12542 | Batch Loss: 0.8032 | Learning Rate: 0.000419 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9306/12542 | Batch Loss: 1.6939 | Learning Rate: 0.000419 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9307/12542 | Batch Loss: 1.3871 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9308/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9309/12542 | Batch Loss: 1.7901 | Learning Rate: 0.000419 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9310/12542 | Batch Loss: 0.9384 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9311/12542 | Batch Loss: 1.0738 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9312/12542 | Batch Loss: 0.7278 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9313/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000419 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9314/12542 | Batch Loss: 4.1814 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9315/12542 | Batch Loss: 0.7518 | Learning Rate: 0.000419 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9316/12542 | Batch Loss: 1.4998 | Learning Rate: 0.000419 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9317/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9318/12542 | Batch Loss: 0.7385 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9319/12542 | Batch Loss: 2.4465 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9320/12542 | Batch Loss: 1.4574 | Learning Rate: 0.000419 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9321/12542 | Batch Loss: 1.8842 | Learning Rate: 0.000419 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9322/12542 | Batch Loss: 1.6481 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9323/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9324/12542 | Batch Loss: 1.1552 | Learning Rate: 0.000419 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9325/12542 | Batch Loss: 1.2340 | Learning Rate: 0.000419 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9326/12542 | Batch Loss: 0.6286 | Learning Rate: 0.000419 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9327/12542 | Batch Loss: 1.3981 | Learning Rate: 0.000419 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9328/12542 | Batch Loss: 1.1478 | Learning Rate: 0.000419 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9329/12542 | Batch Loss: 0.9619 | Learning Rate: 0.000419 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9330/12542 | Batch Loss: 0.7228 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9331/12542 | Batch Loss: 0.9541 | Learning Rate: 0.000419 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9332/12542 | Batch Loss: 2.0226 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9333/12542 | Batch Loss: 1.7459 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9334/12542 | Batch Loss: 1.8461 | Learning Rate: 0.000419 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9335/12542 | Batch Loss: 1.4749 | Learning Rate: 0.000419 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9336/12542 | Batch Loss: 1.0177 | Learning Rate: 0.000419 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9337/12542 | Batch Loss: 1.0870 | Learning Rate: 0.000419 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9338/12542 | Batch Loss: 2.6513 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9339/12542 | Batch Loss: 0.6452 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9340/12542 | Batch Loss: 0.7326 | Learning Rate: 0.000418 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9341/12542 | Batch Loss: 1.4423 | Learning Rate: 0.000418 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9342/12542 | Batch Loss: 0.9034 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9343/12542 | Batch Loss: 1.2230 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9344/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9345/12542 | Batch Loss: 0.8408 | Learning Rate: 0.000418 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9346/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9347/12542 | Batch Loss: 1.8192 | Learning Rate: 0.000418 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9348/12542 | Batch Loss: 1.5724 | Learning Rate: 0.000418 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9349/12542 | Batch Loss: 1.4701 | Learning Rate: 0.000418 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9350/12542 | Batch Loss: 0.9842 | Learning Rate: 0.000418 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9351/12542 | Batch Loss: 1.9474 | Learning Rate: 0.000418 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9352/12542 | Batch Loss: 2.2794 | Learning Rate: 0.000418 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9353/12542 | Batch Loss: 1.1703 | Learning Rate: 0.000418 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9354/12542 | Batch Loss: 1.2701 | Learning Rate: 0.000418 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9355/12542 | Batch Loss: 1.1960 | Learning Rate: 0.000418 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9356/12542 | Batch Loss: 1.6096 | Learning Rate: 0.000418 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9357/12542 | Batch Loss: 1.7109 | Learning Rate: 0.000418 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9358/12542 | Batch Loss: 0.9373 | Learning Rate: 0.000418 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9359/12542 | Batch Loss: 2.1926 | Learning Rate: 0.000418 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9360/12542 | Batch Loss: 0.7016 | Learning Rate: 0.000418 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9361/12542 | Batch Loss: 0.5501 | Learning Rate: 0.000418 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9362/12542 | Batch Loss: 0.9568 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9363/12542 | Batch Loss: 1.4992 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9364/12542 | Batch Loss: 1.3793 | Learning Rate: 0.000418 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9365/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000418 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9366/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000418 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9367/12542 | Batch Loss: 0.8689 | Learning Rate: 0.000418 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9368/12542 | Batch Loss: 2.3232 | Learning Rate: 0.000418 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9369/12542 | Batch Loss: 0.6481 | Learning Rate: 0.000418 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9370/12542 | Batch Loss: 0.8063 | Learning Rate: 0.000418 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9371/12542 | Batch Loss: 1.2806 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9372/12542 | Batch Loss: 1.6837 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9373/12542 | Batch Loss: 1.7154 | Learning Rate: 0.000418 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9374/12542 | Batch Loss: 1.4786 | Learning Rate: 0.000418 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9375/12542 | Batch Loss: 0.6312 | Learning Rate: 0.000418 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9376/12542 | Batch Loss: 1.1801 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9377/12542 | Batch Loss: 0.7697 | Learning Rate: 0.000417 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9378/12542 | Batch Loss: 2.1029 | Learning Rate: 0.000417 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9379/12542 | Batch Loss: 2.2115 | Learning Rate: 0.000417 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9380/12542 | Batch Loss: 1.4714 | Learning Rate: 0.000417 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9381/12542 | Batch Loss: 1.5490 | Learning Rate: 0.000417 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9382/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000417 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9383/12542 | Batch Loss: 1.5184 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9384/12542 | Batch Loss: 0.7036 | Learning Rate: 0.000417 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9385/12542 | Batch Loss: 0.3671 | Learning Rate: 0.000417 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9386/12542 | Batch Loss: 1.3849 | Learning Rate: 0.000417 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9387/12542 | Batch Loss: 0.8597 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9388/12542 | Batch Loss: 0.7506 | Learning Rate: 0.000417 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9389/12542 | Batch Loss: 3.0621 | Learning Rate: 0.000417 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9390/12542 | Batch Loss: 0.8201 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9391/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9392/12542 | Batch Loss: 0.5103 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9393/12542 | Batch Loss: 0.4787 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9394/12542 | Batch Loss: 1.4484 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9395/12542 | Batch Loss: 0.6992 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9396/12542 | Batch Loss: 1.4520 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9397/12542 | Batch Loss: 1.1650 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9398/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000417 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9399/12542 | Batch Loss: 1.3688 | Learning Rate: 0.000417 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9400/12542 | Batch Loss: 0.7235 | Learning Rate: 0.000417 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9401/12542 | Batch Loss: 0.4577 | Learning Rate: 0.000417 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9402/12542 | Batch Loss: 1.1278 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9403/12542 | Batch Loss: 0.6737 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9404/12542 | Batch Loss: 1.1503 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9405/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9406/12542 | Batch Loss: 1.7241 | Learning Rate: 0.000417 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9407/12542 | Batch Loss: 0.7971 | Learning Rate: 0.000417 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9408/12542 | Batch Loss: 0.6325 | Learning Rate: 0.000417 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9409/12542 | Batch Loss: 1.4056 | Learning Rate: 0.000417 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9410/12542 | Batch Loss: 2.9215 | Learning Rate: 0.000417 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9411/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000417 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9412/12542 | Batch Loss: 1.7491 | Learning Rate: 0.000417 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9413/12542 | Batch Loss: 0.7802 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9414/12542 | Batch Loss: 1.4709 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9415/12542 | Batch Loss: 1.3706 | Learning Rate: 0.000416 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9416/12542 | Batch Loss: 1.0910 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9417/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9418/12542 | Batch Loss: 0.7407 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9419/12542 | Batch Loss: 1.8685 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9420/12542 | Batch Loss: 1.7959 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9421/12542 | Batch Loss: 1.1116 | Learning Rate: 0.000416 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9422/12542 | Batch Loss: 0.9010 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9423/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9424/12542 | Batch Loss: 0.6433 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9425/12542 | Batch Loss: 1.3858 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9426/12542 | Batch Loss: 0.8671 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9427/12542 | Batch Loss: 0.7041 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9428/12542 | Batch Loss: 1.4676 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9429/12542 | Batch Loss: 2.2415 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9430/12542 | Batch Loss: 0.9020 | Learning Rate: 0.000416 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9431/12542 | Batch Loss: 2.8372 | Learning Rate: 0.000416 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9432/12542 | Batch Loss: 0.3991 | Learning Rate: 0.000416 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9433/12542 | Batch Loss: 0.9318 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9434/12542 | Batch Loss: 0.8534 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9435/12542 | Batch Loss: 1.4520 | Learning Rate: 0.000416 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9436/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9437/12542 | Batch Loss: 1.3282 | Learning Rate: 0.000416 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9438/12542 | Batch Loss: 1.7269 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9439/12542 | Batch Loss: 1.1298 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9440/12542 | Batch Loss: 1.1389 | Learning Rate: 0.000416 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9441/12542 | Batch Loss: 1.4482 | Learning Rate: 0.000416 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9442/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000416 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9443/12542 | Batch Loss: 1.2100 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9444/12542 | Batch Loss: 1.1038 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9445/12542 | Batch Loss: 0.9440 | Learning Rate: 0.000416 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9446/12542 | Batch Loss: 1.3988 | Learning Rate: 0.000416 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9447/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9448/12542 | Batch Loss: 0.9196 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9449/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000416 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9450/12542 | Batch Loss: 1.0510 | Learning Rate: 0.000416 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9451/12542 | Batch Loss: 2.9112 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9452/12542 | Batch Loss: 0.8773 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9453/12542 | Batch Loss: 0.7111 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9454/12542 | Batch Loss: 2.3102 | Learning Rate: 0.000415 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9455/12542 | Batch Loss: 0.7878 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9456/12542 | Batch Loss: 1.2083 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9457/12542 | Batch Loss: 1.1186 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9458/12542 | Batch Loss: 1.0105 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9459/12542 | Batch Loss: 0.5538 | Learning Rate: 0.000415 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9460/12542 | Batch Loss: 1.1635 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9461/12542 | Batch Loss: 1.4496 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9462/12542 | Batch Loss: 0.6937 | Learning Rate: 0.000415 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9463/12542 | Batch Loss: 1.1842 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9464/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9465/12542 | Batch Loss: 1.4809 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9466/12542 | Batch Loss: 2.4417 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9467/12542 | Batch Loss: 1.1805 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9468/12542 | Batch Loss: 2.6029 | Learning Rate: 0.000415 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9469/12542 | Batch Loss: 0.5075 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9470/12542 | Batch Loss: 0.5448 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9471/12542 | Batch Loss: 0.8340 | Learning Rate: 0.000415 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9472/12542 | Batch Loss: 0.9577 | Learning Rate: 0.000415 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9473/12542 | Batch Loss: 0.8229 | Learning Rate: 0.000415 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9474/12542 | Batch Loss: 1.1821 | Learning Rate: 0.000415 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9475/12542 | Batch Loss: 1.3816 | Learning Rate: 0.000415 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9476/12542 | Batch Loss: 1.7346 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9477/12542 | Batch Loss: 0.6513 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9478/12542 | Batch Loss: 2.0796 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9479/12542 | Batch Loss: 0.8923 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9480/12542 | Batch Loss: 0.7146 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9481/12542 | Batch Loss: 0.6041 | Learning Rate: 0.000415 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9482/12542 | Batch Loss: 2.1761 | Learning Rate: 0.000415 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9483/12542 | Batch Loss: 0.7318 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9484/12542 | Batch Loss: 2.1314 | Learning Rate: 0.000415 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9485/12542 | Batch Loss: 0.9064 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9486/12542 | Batch Loss: 0.3666 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9487/12542 | Batch Loss: 1.1539 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9488/12542 | Batch Loss: 0.7660 | Learning Rate: 0.000415 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9489/12542 | Batch Loss: 1.6724 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9490/12542 | Batch Loss: 1.1193 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9491/12542 | Batch Loss: 1.2297 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9492/12542 | Batch Loss: 1.5077 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9493/12542 | Batch Loss: 1.1762 | Learning Rate: 0.000414 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9494/12542 | Batch Loss: 1.0263 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9495/12542 | Batch Loss: 1.7169 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9496/12542 | Batch Loss: 0.7762 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9497/12542 | Batch Loss: 1.8896 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9498/12542 | Batch Loss: 0.6943 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9499/12542 | Batch Loss: 0.4467 | Learning Rate: 0.000414 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9500/12542 | Batch Loss: 0.7304 | Learning Rate: 0.000414 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9501/12542 | Batch Loss: 0.8584 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9502/12542 | Batch Loss: 0.8799 | Learning Rate: 0.000414 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9503/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000414 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9504/12542 | Batch Loss: 0.8785 | Learning Rate: 0.000414 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9505/12542 | Batch Loss: 2.2782 | Learning Rate: 0.000414 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9506/12542 | Batch Loss: 1.4299 | Learning Rate: 0.000414 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9507/12542 | Batch Loss: 1.7044 | Learning Rate: 0.000414 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9508/12542 | Batch Loss: 0.9738 | Learning Rate: 0.000414 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9509/12542 | Batch Loss: 1.7628 | Learning Rate: 0.000414 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9510/12542 | Batch Loss: 1.4998 | Learning Rate: 0.000414 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9511/12542 | Batch Loss: 1.3347 | Learning Rate: 0.000414 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9512/12542 | Batch Loss: 1.8123 | Learning Rate: 0.000414 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9513/12542 | Batch Loss: 3.5474 | Learning Rate: 0.000414 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9514/12542 | Batch Loss: 1.2740 | Learning Rate: 0.000414 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9515/12542 | Batch Loss: 3.0697 | Learning Rate: 0.000414 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9516/12542 | Batch Loss: 1.2108 | Learning Rate: 0.000414 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9517/12542 | Batch Loss: 0.5895 | Learning Rate: 0.000414 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9518/12542 | Batch Loss: 2.1903 | Learning Rate: 0.000414 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9519/12542 | Batch Loss: 1.9411 | Learning Rate: 0.000414 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9520/12542 | Batch Loss: 0.7922 | Learning Rate: 0.000414 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9521/12542 | Batch Loss: 0.9522 | Learning Rate: 0.000414 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9522/12542 | Batch Loss: 0.9049 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9523/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000414 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9524/12542 | Batch Loss: 1.4584 | Learning Rate: 0.000414 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9525/12542 | Batch Loss: 1.0324 | Learning Rate: 0.000414 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9526/12542 | Batch Loss: 1.4934 | Learning Rate: 0.000413 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9527/12542 | Batch Loss: 2.4936 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9528/12542 | Batch Loss: 1.2180 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9529/12542 | Batch Loss: 1.3380 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9530/12542 | Batch Loss: 1.8353 | Learning Rate: 0.000413 | Batch Time: 0.56s\n",
      "Epoch 2 | Step 9531/12542 | Batch Loss: 1.4344 | Learning Rate: 0.000413 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9532/12542 | Batch Loss: 1.2667 | Learning Rate: 0.000413 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9533/12542 | Batch Loss: 1.0372 | Learning Rate: 0.000413 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9534/12542 | Batch Loss: 0.5776 | Learning Rate: 0.000413 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9535/12542 | Batch Loss: 2.2611 | Learning Rate: 0.000413 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9536/12542 | Batch Loss: 1.0404 | Learning Rate: 0.000413 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9537/12542 | Batch Loss: 1.2714 | Learning Rate: 0.000413 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9538/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000413 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9539/12542 | Batch Loss: 0.7028 | Learning Rate: 0.000413 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9540/12542 | Batch Loss: 1.1544 | Learning Rate: 0.000413 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9541/12542 | Batch Loss: 1.2705 | Learning Rate: 0.000413 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9542/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000413 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9543/12542 | Batch Loss: 1.3522 | Learning Rate: 0.000413 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9544/12542 | Batch Loss: 1.1185 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9545/12542 | Batch Loss: 2.2510 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9546/12542 | Batch Loss: 1.3460 | Learning Rate: 0.000413 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9547/12542 | Batch Loss: 0.7377 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9548/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000413 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9549/12542 | Batch Loss: 1.3122 | Learning Rate: 0.000413 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9550/12542 | Batch Loss: 0.7294 | Learning Rate: 0.000413 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9551/12542 | Batch Loss: 0.4961 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9552/12542 | Batch Loss: 0.8651 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9553/12542 | Batch Loss: 0.3300 | Learning Rate: 0.000413 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9554/12542 | Batch Loss: 1.3324 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9555/12542 | Batch Loss: 1.4514 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9556/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000413 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9557/12542 | Batch Loss: 2.8750 | Learning Rate: 0.000413 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9558/12542 | Batch Loss: 1.4136 | Learning Rate: 0.000413 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9559/12542 | Batch Loss: 1.7674 | Learning Rate: 0.000413 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9560/12542 | Batch Loss: 0.6872 | Learning Rate: 0.000413 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9561/12542 | Batch Loss: 1.4755 | Learning Rate: 0.000413 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9562/12542 | Batch Loss: 1.2920 | Learning Rate: 0.000413 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9563/12542 | Batch Loss: 0.7968 | Learning Rate: 0.000413 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9564/12542 | Batch Loss: 0.8250 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9565/12542 | Batch Loss: 1.0882 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9566/12542 | Batch Loss: 1.2541 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9567/12542 | Batch Loss: 0.7254 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9568/12542 | Batch Loss: 1.2638 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9569/12542 | Batch Loss: 1.0746 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9570/12542 | Batch Loss: 1.3959 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9571/12542 | Batch Loss: 0.7191 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9572/12542 | Batch Loss: 3.3530 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9573/12542 | Batch Loss: 1.4084 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9574/12542 | Batch Loss: 1.0278 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9575/12542 | Batch Loss: 1.2132 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9576/12542 | Batch Loss: 0.8094 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9577/12542 | Batch Loss: 1.6074 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9578/12542 | Batch Loss: 0.7782 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9579/12542 | Batch Loss: 0.8070 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9580/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9581/12542 | Batch Loss: 1.5613 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9582/12542 | Batch Loss: 0.9573 | Learning Rate: 0.000412 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9583/12542 | Batch Loss: 0.7276 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9584/12542 | Batch Loss: 1.5420 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9585/12542 | Batch Loss: 3.2605 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9586/12542 | Batch Loss: 2.5543 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9587/12542 | Batch Loss: 1.5989 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9588/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9589/12542 | Batch Loss: 1.0098 | Learning Rate: 0.000412 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9590/12542 | Batch Loss: 0.3514 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9591/12542 | Batch Loss: 0.6792 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9592/12542 | Batch Loss: 0.8069 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9593/12542 | Batch Loss: 1.0801 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9594/12542 | Batch Loss: 1.7255 | Learning Rate: 0.000412 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9595/12542 | Batch Loss: 0.9954 | Learning Rate: 0.000412 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9596/12542 | Batch Loss: 1.5885 | Learning Rate: 0.000412 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9597/12542 | Batch Loss: 2.0956 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9598/12542 | Batch Loss: 2.0291 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9599/12542 | Batch Loss: 0.5588 | Learning Rate: 0.000412 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9600/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000412 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9601/12542 | Batch Loss: 1.5904 | Learning Rate: 0.000411 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9602/12542 | Batch Loss: 3.8782 | Learning Rate: 0.000411 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9603/12542 | Batch Loss: 2.3361 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9604/12542 | Batch Loss: 0.7148 | Learning Rate: 0.000411 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9605/12542 | Batch Loss: 2.1915 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9606/12542 | Batch Loss: 1.1794 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9607/12542 | Batch Loss: 2.1062 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9608/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9609/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9610/12542 | Batch Loss: 1.8775 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9611/12542 | Batch Loss: 1.0518 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9612/12542 | Batch Loss: 1.4520 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9613/12542 | Batch Loss: 1.7786 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9614/12542 | Batch Loss: 0.8157 | Learning Rate: 0.000411 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9615/12542 | Batch Loss: 1.8102 | Learning Rate: 0.000411 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9616/12542 | Batch Loss: 0.9021 | Learning Rate: 0.000411 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9617/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000411 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9618/12542 | Batch Loss: 0.7401 | Learning Rate: 0.000411 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9619/12542 | Batch Loss: 0.9318 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9620/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000411 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9621/12542 | Batch Loss: 1.8439 | Learning Rate: 0.000411 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9622/12542 | Batch Loss: 1.5107 | Learning Rate: 0.000411 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9623/12542 | Batch Loss: 0.6103 | Learning Rate: 0.000411 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9624/12542 | Batch Loss: 1.0131 | Learning Rate: 0.000411 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9625/12542 | Batch Loss: 1.1550 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9626/12542 | Batch Loss: 2.0529 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9627/12542 | Batch Loss: 1.0361 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9628/12542 | Batch Loss: 0.8490 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9629/12542 | Batch Loss: 0.8552 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9630/12542 | Batch Loss: 1.3590 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9631/12542 | Batch Loss: 1.1403 | Learning Rate: 0.000411 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9632/12542 | Batch Loss: 0.5882 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9633/12542 | Batch Loss: 0.6942 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9634/12542 | Batch Loss: 1.7869 | Learning Rate: 0.000411 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9635/12542 | Batch Loss: 1.6974 | Learning Rate: 0.000411 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9636/12542 | Batch Loss: 1.4591 | Learning Rate: 0.000411 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9637/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000411 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9638/12542 | Batch Loss: 2.0148 | Learning Rate: 0.000411 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9639/12542 | Batch Loss: 1.3164 | Learning Rate: 0.000410 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9640/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9641/12542 | Batch Loss: 1.8110 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9642/12542 | Batch Loss: 2.7900 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9643/12542 | Batch Loss: 2.2542 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9644/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9645/12542 | Batch Loss: 0.9495 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9646/12542 | Batch Loss: 2.9825 | Learning Rate: 0.000410 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9647/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9648/12542 | Batch Loss: 0.9877 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9649/12542 | Batch Loss: 2.0617 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9650/12542 | Batch Loss: 0.7685 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9651/12542 | Batch Loss: 1.3810 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9652/12542 | Batch Loss: 1.6862 | Learning Rate: 0.000410 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9653/12542 | Batch Loss: 1.8735 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9654/12542 | Batch Loss: 1.2993 | Learning Rate: 0.000410 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9655/12542 | Batch Loss: 2.1347 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9656/12542 | Batch Loss: 1.2869 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9657/12542 | Batch Loss: 1.4603 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9658/12542 | Batch Loss: 1.8244 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9659/12542 | Batch Loss: 1.8300 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9660/12542 | Batch Loss: 1.3467 | Learning Rate: 0.000410 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9661/12542 | Batch Loss: 1.9493 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9662/12542 | Batch Loss: 1.2535 | Learning Rate: 0.000410 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9663/12542 | Batch Loss: 1.8802 | Learning Rate: 0.000410 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9664/12542 | Batch Loss: 1.2459 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9665/12542 | Batch Loss: 2.0304 | Learning Rate: 0.000410 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9666/12542 | Batch Loss: 1.1569 | Learning Rate: 0.000410 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9667/12542 | Batch Loss: 1.5957 | Learning Rate: 0.000410 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9668/12542 | Batch Loss: 1.2119 | Learning Rate: 0.000410 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9669/12542 | Batch Loss: 1.0031 | Learning Rate: 0.000410 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9670/12542 | Batch Loss: 1.4610 | Learning Rate: 0.000410 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9671/12542 | Batch Loss: 2.2348 | Learning Rate: 0.000410 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9672/12542 | Batch Loss: 2.0714 | Learning Rate: 0.000410 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9673/12542 | Batch Loss: 1.1583 | Learning Rate: 0.000410 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9674/12542 | Batch Loss: 1.5160 | Learning Rate: 0.000410 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9675/12542 | Batch Loss: 2.3819 | Learning Rate: 0.000410 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9676/12542 | Batch Loss: 1.3953 | Learning Rate: 0.000410 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9677/12542 | Batch Loss: 0.6310 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9678/12542 | Batch Loss: 2.5012 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9679/12542 | Batch Loss: 2.7357 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9680/12542 | Batch Loss: 3.6936 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9681/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9682/12542 | Batch Loss: 1.2030 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9683/12542 | Batch Loss: 0.6311 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9684/12542 | Batch Loss: 1.1879 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9685/12542 | Batch Loss: 1.1641 | Learning Rate: 0.000409 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9686/12542 | Batch Loss: 1.3557 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9687/12542 | Batch Loss: 1.0820 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9688/12542 | Batch Loss: 0.7497 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9689/12542 | Batch Loss: 1.1481 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9690/12542 | Batch Loss: 1.5631 | Learning Rate: 0.000409 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9691/12542 | Batch Loss: 1.6508 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9692/12542 | Batch Loss: 0.9297 | Learning Rate: 0.000409 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9693/12542 | Batch Loss: 1.4977 | Learning Rate: 0.000409 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9694/12542 | Batch Loss: 0.3359 | Learning Rate: 0.000409 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9695/12542 | Batch Loss: 1.6585 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9696/12542 | Batch Loss: 1.2948 | Learning Rate: 0.000409 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9697/12542 | Batch Loss: 1.2947 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9698/12542 | Batch Loss: 0.7778 | Learning Rate: 0.000409 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9699/12542 | Batch Loss: 1.4050 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9700/12542 | Batch Loss: 1.0333 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9701/12542 | Batch Loss: 1.6778 | Learning Rate: 0.000409 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9702/12542 | Batch Loss: 2.1588 | Learning Rate: 0.000409 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9703/12542 | Batch Loss: 1.6283 | Learning Rate: 0.000409 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9704/12542 | Batch Loss: 3.0740 | Learning Rate: 0.000409 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9705/12542 | Batch Loss: 0.4851 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9706/12542 | Batch Loss: 2.1125 | Learning Rate: 0.000409 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9707/12542 | Batch Loss: 1.1042 | Learning Rate: 0.000409 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9708/12542 | Batch Loss: 0.8359 | Learning Rate: 0.000409 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9709/12542 | Batch Loss: 1.4428 | Learning Rate: 0.000409 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9710/12542 | Batch Loss: 1.8865 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9711/12542 | Batch Loss: 1.7302 | Learning Rate: 0.000409 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9712/12542 | Batch Loss: 1.2498 | Learning Rate: 0.000409 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9713/12542 | Batch Loss: 1.4713 | Learning Rate: 0.000409 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9714/12542 | Batch Loss: 1.3211 | Learning Rate: 0.000408 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9715/12542 | Batch Loss: 2.3496 | Learning Rate: 0.000408 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9716/12542 | Batch Loss: 1.5215 | Learning Rate: 0.000408 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9717/12542 | Batch Loss: 0.9319 | Learning Rate: 0.000408 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9718/12542 | Batch Loss: 1.5152 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9719/12542 | Batch Loss: 0.7896 | Learning Rate: 0.000408 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9720/12542 | Batch Loss: 0.9472 | Learning Rate: 0.000408 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9721/12542 | Batch Loss: 0.7498 | Learning Rate: 0.000408 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9722/12542 | Batch Loss: 0.6988 | Learning Rate: 0.000408 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9723/12542 | Batch Loss: 0.6307 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9724/12542 | Batch Loss: 1.0292 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9725/12542 | Batch Loss: 1.5527 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9726/12542 | Batch Loss: 0.7959 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9727/12542 | Batch Loss: 1.7876 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9728/12542 | Batch Loss: 2.2055 | Learning Rate: 0.000408 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9729/12542 | Batch Loss: 0.8910 | Learning Rate: 0.000408 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9730/12542 | Batch Loss: 0.7886 | Learning Rate: 0.000408 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9731/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000408 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9732/12542 | Batch Loss: 2.4834 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9733/12542 | Batch Loss: 1.5234 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9734/12542 | Batch Loss: 1.0324 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9735/12542 | Batch Loss: 0.8279 | Learning Rate: 0.000408 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9736/12542 | Batch Loss: 1.2379 | Learning Rate: 0.000408 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9737/12542 | Batch Loss: 0.9458 | Learning Rate: 0.000408 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9738/12542 | Batch Loss: 3.0276 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9739/12542 | Batch Loss: 2.3011 | Learning Rate: 0.000408 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9740/12542 | Batch Loss: 1.7088 | Learning Rate: 0.000408 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9741/12542 | Batch Loss: 0.8900 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9742/12542 | Batch Loss: 1.8646 | Learning Rate: 0.000408 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9743/12542 | Batch Loss: 2.2660 | Learning Rate: 0.000408 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9744/12542 | Batch Loss: 2.4149 | Learning Rate: 0.000408 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9745/12542 | Batch Loss: 2.8206 | Learning Rate: 0.000408 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9746/12542 | Batch Loss: 1.1159 | Learning Rate: 0.000408 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9747/12542 | Batch Loss: 0.9792 | Learning Rate: 0.000408 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9748/12542 | Batch Loss: 0.9359 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9749/12542 | Batch Loss: 2.2758 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9750/12542 | Batch Loss: 0.8044 | Learning Rate: 0.000408 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9751/12542 | Batch Loss: 0.7529 | Learning Rate: 0.000408 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9752/12542 | Batch Loss: 2.7784 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9753/12542 | Batch Loss: 1.5425 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9754/12542 | Batch Loss: 1.5026 | Learning Rate: 0.000407 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9755/12542 | Batch Loss: 1.8142 | Learning Rate: 0.000407 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9756/12542 | Batch Loss: 1.5746 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9757/12542 | Batch Loss: 0.7291 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9758/12542 | Batch Loss: 1.3932 | Learning Rate: 0.000407 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9759/12542 | Batch Loss: 1.8731 | Learning Rate: 0.000407 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9760/12542 | Batch Loss: 3.1294 | Learning Rate: 0.000407 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9761/12542 | Batch Loss: 0.9870 | Learning Rate: 0.000407 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9762/12542 | Batch Loss: 0.8710 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9763/12542 | Batch Loss: 2.6578 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9764/12542 | Batch Loss: 1.1680 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9765/12542 | Batch Loss: 0.9410 | Learning Rate: 0.000407 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9766/12542 | Batch Loss: 1.0362 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9767/12542 | Batch Loss: 0.8436 | Learning Rate: 0.000407 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9768/12542 | Batch Loss: 0.8527 | Learning Rate: 0.000407 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9769/12542 | Batch Loss: 1.0321 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9770/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9771/12542 | Batch Loss: 1.3485 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9772/12542 | Batch Loss: 0.8403 | Learning Rate: 0.000407 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9773/12542 | Batch Loss: 1.4381 | Learning Rate: 0.000407 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9774/12542 | Batch Loss: 0.9186 | Learning Rate: 0.000407 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9775/12542 | Batch Loss: 0.6381 | Learning Rate: 0.000407 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9776/12542 | Batch Loss: 0.5580 | Learning Rate: 0.000407 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9777/12542 | Batch Loss: 1.3463 | Learning Rate: 0.000407 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9778/12542 | Batch Loss: 0.5296 | Learning Rate: 0.000407 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9779/12542 | Batch Loss: 0.3295 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9780/12542 | Batch Loss: 1.3682 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9781/12542 | Batch Loss: 3.8357 | Learning Rate: 0.000407 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9782/12542 | Batch Loss: 0.9138 | Learning Rate: 0.000407 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9783/12542 | Batch Loss: 0.9438 | Learning Rate: 0.000407 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9784/12542 | Batch Loss: 1.6127 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9785/12542 | Batch Loss: 0.5898 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9786/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9787/12542 | Batch Loss: 2.0069 | Learning Rate: 0.000407 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9788/12542 | Batch Loss: 1.1625 | Learning Rate: 0.000407 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9789/12542 | Batch Loss: 0.4833 | Learning Rate: 0.000407 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9790/12542 | Batch Loss: 1.1135 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9791/12542 | Batch Loss: 1.7148 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9792/12542 | Batch Loss: 1.2267 | Learning Rate: 0.000406 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9793/12542 | Batch Loss: 1.8937 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9794/12542 | Batch Loss: 2.8939 | Learning Rate: 0.000406 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9795/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000406 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9796/12542 | Batch Loss: 0.9558 | Learning Rate: 0.000406 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9797/12542 | Batch Loss: 0.9904 | Learning Rate: 0.000406 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9798/12542 | Batch Loss: 1.1004 | Learning Rate: 0.000406 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9799/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000406 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9800/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000406 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9801/12542 | Batch Loss: 1.6914 | Learning Rate: 0.000406 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9802/12542 | Batch Loss: 2.0351 | Learning Rate: 0.000406 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9803/12542 | Batch Loss: 0.3796 | Learning Rate: 0.000406 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9804/12542 | Batch Loss: 0.6561 | Learning Rate: 0.000406 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9805/12542 | Batch Loss: 0.8352 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9806/12542 | Batch Loss: 0.9943 | Learning Rate: 0.000406 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9807/12542 | Batch Loss: 1.2521 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9808/12542 | Batch Loss: 1.0673 | Learning Rate: 0.000406 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9809/12542 | Batch Loss: 1.1615 | Learning Rate: 0.000406 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9810/12542 | Batch Loss: 2.4002 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9811/12542 | Batch Loss: 1.9152 | Learning Rate: 0.000406 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9812/12542 | Batch Loss: 2.8106 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9813/12542 | Batch Loss: 1.1025 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9814/12542 | Batch Loss: 1.8632 | Learning Rate: 0.000406 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9815/12542 | Batch Loss: 2.7705 | Learning Rate: 0.000406 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9816/12542 | Batch Loss: 0.7055 | Learning Rate: 0.000406 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9817/12542 | Batch Loss: 1.0802 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9818/12542 | Batch Loss: 0.9011 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9819/12542 | Batch Loss: 1.9644 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9820/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9821/12542 | Batch Loss: 1.7999 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9822/12542 | Batch Loss: 1.7365 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9823/12542 | Batch Loss: 0.7523 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9824/12542 | Batch Loss: 3.2051 | Learning Rate: 0.000406 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9825/12542 | Batch Loss: 2.3746 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9826/12542 | Batch Loss: 1.1103 | Learning Rate: 0.000406 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9827/12542 | Batch Loss: 1.0222 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9828/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000405 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9829/12542 | Batch Loss: 1.4723 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9830/12542 | Batch Loss: 1.2961 | Learning Rate: 0.000405 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9831/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9832/12542 | Batch Loss: 1.1629 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9833/12542 | Batch Loss: 1.5390 | Learning Rate: 0.000405 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9834/12542 | Batch Loss: 1.6241 | Learning Rate: 0.000405 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9835/12542 | Batch Loss: 1.5132 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9836/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000405 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9837/12542 | Batch Loss: 0.3833 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9838/12542 | Batch Loss: 1.2553 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9839/12542 | Batch Loss: 0.7371 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9840/12542 | Batch Loss: 1.0115 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9841/12542 | Batch Loss: 1.1139 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9842/12542 | Batch Loss: 1.9082 | Learning Rate: 0.000405 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9843/12542 | Batch Loss: 0.9165 | Learning Rate: 0.000405 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9844/12542 | Batch Loss: 0.9928 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9845/12542 | Batch Loss: 3.0199 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9846/12542 | Batch Loss: 2.5550 | Learning Rate: 0.000405 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9847/12542 | Batch Loss: 1.0780 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9848/12542 | Batch Loss: 1.9921 | Learning Rate: 0.000405 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9849/12542 | Batch Loss: 2.1397 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9850/12542 | Batch Loss: 0.6855 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9851/12542 | Batch Loss: 1.4112 | Learning Rate: 0.000405 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9852/12542 | Batch Loss: 1.0873 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9853/12542 | Batch Loss: 1.3995 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9854/12542 | Batch Loss: 0.9457 | Learning Rate: 0.000405 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9855/12542 | Batch Loss: 1.2448 | Learning Rate: 0.000405 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9856/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9857/12542 | Batch Loss: 0.6609 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9858/12542 | Batch Loss: 1.7777 | Learning Rate: 0.000405 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9859/12542 | Batch Loss: 1.0126 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9860/12542 | Batch Loss: 1.2581 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9861/12542 | Batch Loss: 0.7580 | Learning Rate: 0.000405 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9862/12542 | Batch Loss: 0.6221 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9863/12542 | Batch Loss: 1.4808 | Learning Rate: 0.000405 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9864/12542 | Batch Loss: 0.7953 | Learning Rate: 0.000405 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9865/12542 | Batch Loss: 1.6241 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9866/12542 | Batch Loss: 0.7128 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9867/12542 | Batch Loss: 0.9093 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9868/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9869/12542 | Batch Loss: 1.1813 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9870/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9871/12542 | Batch Loss: 1.5115 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9872/12542 | Batch Loss: 2.8101 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9873/12542 | Batch Loss: 1.4904 | Learning Rate: 0.000404 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9874/12542 | Batch Loss: 1.0520 | Learning Rate: 0.000404 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9875/12542 | Batch Loss: 2.0400 | Learning Rate: 0.000404 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9876/12542 | Batch Loss: 3.4693 | Learning Rate: 0.000404 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9877/12542 | Batch Loss: 2.7590 | Learning Rate: 0.000404 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9878/12542 | Batch Loss: 0.4244 | Learning Rate: 0.000404 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9879/12542 | Batch Loss: 0.9219 | Learning Rate: 0.000404 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9880/12542 | Batch Loss: 1.5034 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9881/12542 | Batch Loss: 0.8644 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9882/12542 | Batch Loss: 0.9855 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9883/12542 | Batch Loss: 0.4210 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9884/12542 | Batch Loss: 1.3822 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9885/12542 | Batch Loss: 1.9855 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9886/12542 | Batch Loss: 1.1142 | Learning Rate: 0.000404 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9887/12542 | Batch Loss: 0.7522 | Learning Rate: 0.000404 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9888/12542 | Batch Loss: 1.8120 | Learning Rate: 0.000404 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9889/12542 | Batch Loss: 1.1507 | Learning Rate: 0.000404 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9890/12542 | Batch Loss: 0.9336 | Learning Rate: 0.000404 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9891/12542 | Batch Loss: 0.6926 | Learning Rate: 0.000404 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 9892/12542 | Batch Loss: 1.1676 | Learning Rate: 0.000404 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9893/12542 | Batch Loss: 0.5900 | Learning Rate: 0.000404 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9894/12542 | Batch Loss: 0.9624 | Learning Rate: 0.000404 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9895/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000404 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9896/12542 | Batch Loss: 1.5974 | Learning Rate: 0.000404 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9897/12542 | Batch Loss: 3.2354 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9898/12542 | Batch Loss: 1.4975 | Learning Rate: 0.000404 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9899/12542 | Batch Loss: 1.2848 | Learning Rate: 0.000404 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9900/12542 | Batch Loss: 0.5538 | Learning Rate: 0.000404 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9901/12542 | Batch Loss: 0.5671 | Learning Rate: 0.000404 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9902/12542 | Batch Loss: 1.9143 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9903/12542 | Batch Loss: 1.5944 | Learning Rate: 0.000403 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 9904/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9905/12542 | Batch Loss: 0.9382 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9906/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000403 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9907/12542 | Batch Loss: 0.6970 | Learning Rate: 0.000403 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9908/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9909/12542 | Batch Loss: 0.6629 | Learning Rate: 0.000403 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9910/12542 | Batch Loss: 0.5006 | Learning Rate: 0.000403 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9911/12542 | Batch Loss: 1.4358 | Learning Rate: 0.000403 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9912/12542 | Batch Loss: 1.0827 | Learning Rate: 0.000403 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9913/12542 | Batch Loss: 1.5887 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9914/12542 | Batch Loss: 0.5609 | Learning Rate: 0.000403 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9915/12542 | Batch Loss: 1.2783 | Learning Rate: 0.000403 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9916/12542 | Batch Loss: 0.8398 | Learning Rate: 0.000403 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9917/12542 | Batch Loss: 1.6710 | Learning Rate: 0.000403 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9918/12542 | Batch Loss: 1.8140 | Learning Rate: 0.000403 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9919/12542 | Batch Loss: 1.5386 | Learning Rate: 0.000403 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9920/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000403 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9921/12542 | Batch Loss: 0.7638 | Learning Rate: 0.000403 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9922/12542 | Batch Loss: 3.7087 | Learning Rate: 0.000403 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9923/12542 | Batch Loss: 2.3104 | Learning Rate: 0.000403 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 9924/12542 | Batch Loss: 1.1957 | Learning Rate: 0.000403 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9925/12542 | Batch Loss: 1.4228 | Learning Rate: 0.000403 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9926/12542 | Batch Loss: 1.8236 | Learning Rate: 0.000403 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9927/12542 | Batch Loss: 1.6726 | Learning Rate: 0.000403 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9928/12542 | Batch Loss: 1.5996 | Learning Rate: 0.000403 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9929/12542 | Batch Loss: 1.7255 | Learning Rate: 0.000403 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9930/12542 | Batch Loss: 0.6900 | Learning Rate: 0.000403 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9931/12542 | Batch Loss: 1.0545 | Learning Rate: 0.000403 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9932/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000403 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9933/12542 | Batch Loss: 1.0269 | Learning Rate: 0.000403 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9934/12542 | Batch Loss: 0.7693 | Learning Rate: 0.000403 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9935/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000403 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9936/12542 | Batch Loss: 1.4328 | Learning Rate: 0.000403 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9937/12542 | Batch Loss: 2.0414 | Learning Rate: 0.000403 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9938/12542 | Batch Loss: 1.6739 | Learning Rate: 0.000403 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9939/12542 | Batch Loss: 1.8647 | Learning Rate: 0.000403 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9940/12542 | Batch Loss: 1.5345 | Learning Rate: 0.000402 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9941/12542 | Batch Loss: 1.6656 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9942/12542 | Batch Loss: 0.5881 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9943/12542 | Batch Loss: 1.4604 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9944/12542 | Batch Loss: 1.9265 | Learning Rate: 0.000402 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9945/12542 | Batch Loss: 1.9473 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9946/12542 | Batch Loss: 1.7790 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9947/12542 | Batch Loss: 0.9647 | Learning Rate: 0.000402 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9948/12542 | Batch Loss: 0.7189 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9949/12542 | Batch Loss: 1.1983 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9950/12542 | Batch Loss: 1.4931 | Learning Rate: 0.000402 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9951/12542 | Batch Loss: 1.1752 | Learning Rate: 0.000402 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9952/12542 | Batch Loss: 2.8581 | Learning Rate: 0.000402 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 9953/12542 | Batch Loss: 2.3318 | Learning Rate: 0.000402 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9954/12542 | Batch Loss: 2.1010 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9955/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000402 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9956/12542 | Batch Loss: 1.1371 | Learning Rate: 0.000402 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 9957/12542 | Batch Loss: 0.6960 | Learning Rate: 0.000402 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 9958/12542 | Batch Loss: 0.8544 | Learning Rate: 0.000402 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 9959/12542 | Batch Loss: 0.6800 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9960/12542 | Batch Loss: 2.2753 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9961/12542 | Batch Loss: 1.1473 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9962/12542 | Batch Loss: 0.8653 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9963/12542 | Batch Loss: 1.2612 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9964/12542 | Batch Loss: 0.8446 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9965/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000402 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9966/12542 | Batch Loss: 1.6778 | Learning Rate: 0.000402 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9967/12542 | Batch Loss: 2.3335 | Learning Rate: 0.000402 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9968/12542 | Batch Loss: 1.6290 | Learning Rate: 0.000402 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9969/12542 | Batch Loss: 0.7721 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9970/12542 | Batch Loss: 0.5128 | Learning Rate: 0.000402 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9971/12542 | Batch Loss: 1.0228 | Learning Rate: 0.000402 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9972/12542 | Batch Loss: 0.9723 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9973/12542 | Batch Loss: 2.8272 | Learning Rate: 0.000402 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9974/12542 | Batch Loss: 0.6624 | Learning Rate: 0.000402 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9975/12542 | Batch Loss: 0.9919 | Learning Rate: 0.000402 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9976/12542 | Batch Loss: 0.7152 | Learning Rate: 0.000402 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 9977/12542 | Batch Loss: 0.7953 | Learning Rate: 0.000402 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9978/12542 | Batch Loss: 3.5670 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9979/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9980/12542 | Batch Loss: 1.0884 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9981/12542 | Batch Loss: 1.8182 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9982/12542 | Batch Loss: 1.4827 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9983/12542 | Batch Loss: 0.7014 | Learning Rate: 0.000401 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 9984/12542 | Batch Loss: 0.7154 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9985/12542 | Batch Loss: 1.2372 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9986/12542 | Batch Loss: 0.4532 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9987/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000401 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9988/12542 | Batch Loss: 1.5787 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 9989/12542 | Batch Loss: 1.9476 | Learning Rate: 0.000401 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 9990/12542 | Batch Loss: 1.1445 | Learning Rate: 0.000401 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 9991/12542 | Batch Loss: 3.3809 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9992/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9993/12542 | Batch Loss: 0.9856 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 9994/12542 | Batch Loss: 2.3229 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9995/12542 | Batch Loss: 1.1691 | Learning Rate: 0.000401 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 9996/12542 | Batch Loss: 1.5975 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9997/12542 | Batch Loss: 0.4953 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 9998/12542 | Batch Loss: 1.8237 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 9999/12542 | Batch Loss: 1.0526 | Learning Rate: 0.000401 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10000/12542 | Batch Loss: 0.7052 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10001/12542 | Batch Loss: 2.5068 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10002/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10003/12542 | Batch Loss: 1.0984 | Learning Rate: 0.000401 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10004/12542 | Batch Loss: 3.1565 | Learning Rate: 0.000401 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10005/12542 | Batch Loss: 0.8310 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10006/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10007/12542 | Batch Loss: 0.5807 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10008/12542 | Batch Loss: 1.8597 | Learning Rate: 0.000401 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 10009/12542 | Batch Loss: 1.0043 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10010/12542 | Batch Loss: 1.0723 | Learning Rate: 0.000401 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10011/12542 | Batch Loss: 1.1218 | Learning Rate: 0.000401 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10012/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000401 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10013/12542 | Batch Loss: 0.7970 | Learning Rate: 0.000401 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10014/12542 | Batch Loss: 0.8715 | Learning Rate: 0.000401 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10015/12542 | Batch Loss: 1.5849 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10016/12542 | Batch Loss: 3.0923 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10017/12542 | Batch Loss: 0.9211 | Learning Rate: 0.000400 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10018/12542 | Batch Loss: 1.8271 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10019/12542 | Batch Loss: 0.6384 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10020/12542 | Batch Loss: 1.5821 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10021/12542 | Batch Loss: 2.0330 | Learning Rate: 0.000400 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10022/12542 | Batch Loss: 1.0304 | Learning Rate: 0.000400 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10023/12542 | Batch Loss: 1.8934 | Learning Rate: 0.000400 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10024/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000400 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10025/12542 | Batch Loss: 1.0421 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10026/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10027/12542 | Batch Loss: 1.8488 | Learning Rate: 0.000400 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10028/12542 | Batch Loss: 1.0243 | Learning Rate: 0.000400 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10029/12542 | Batch Loss: 1.6709 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10030/12542 | Batch Loss: 1.7557 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10031/12542 | Batch Loss: 1.0539 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10032/12542 | Batch Loss: 0.9855 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10033/12542 | Batch Loss: 1.7845 | Learning Rate: 0.000400 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10034/12542 | Batch Loss: 0.8569 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10035/12542 | Batch Loss: 1.3807 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10036/12542 | Batch Loss: 0.6603 | Learning Rate: 0.000400 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10037/12542 | Batch Loss: 1.8095 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10038/12542 | Batch Loss: 1.4849 | Learning Rate: 0.000400 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10039/12542 | Batch Loss: 1.5979 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10040/12542 | Batch Loss: 1.1448 | Learning Rate: 0.000400 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10041/12542 | Batch Loss: 0.8125 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10042/12542 | Batch Loss: 0.7980 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10043/12542 | Batch Loss: 2.2183 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10044/12542 | Batch Loss: 0.9773 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10045/12542 | Batch Loss: 1.0777 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10046/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000400 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10047/12542 | Batch Loss: 2.6889 | Learning Rate: 0.000400 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10048/12542 | Batch Loss: 1.7579 | Learning Rate: 0.000400 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10049/12542 | Batch Loss: 0.6757 | Learning Rate: 0.000400 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10050/12542 | Batch Loss: 1.0701 | Learning Rate: 0.000400 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10051/12542 | Batch Loss: 1.7907 | Learning Rate: 0.000400 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10052/12542 | Batch Loss: 1.8798 | Learning Rate: 0.000400 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10053/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000399 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10054/12542 | Batch Loss: 1.5498 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10055/12542 | Batch Loss: 1.1366 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10056/12542 | Batch Loss: 0.8714 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10057/12542 | Batch Loss: 1.8879 | Learning Rate: 0.000399 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10058/12542 | Batch Loss: 1.6670 | Learning Rate: 0.000399 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10059/12542 | Batch Loss: 1.2698 | Learning Rate: 0.000399 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10060/12542 | Batch Loss: 2.0024 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10061/12542 | Batch Loss: 1.2024 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10062/12542 | Batch Loss: 1.6132 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10063/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10064/12542 | Batch Loss: 1.1940 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10065/12542 | Batch Loss: 0.7981 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10066/12542 | Batch Loss: 1.2361 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10067/12542 | Batch Loss: 1.4536 | Learning Rate: 0.000399 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10068/12542 | Batch Loss: 0.5991 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10069/12542 | Batch Loss: 2.6055 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10070/12542 | Batch Loss: 0.5520 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10071/12542 | Batch Loss: 1.3758 | Learning Rate: 0.000399 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10072/12542 | Batch Loss: 2.2246 | Learning Rate: 0.000399 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10073/12542 | Batch Loss: 1.4058 | Learning Rate: 0.000399 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10074/12542 | Batch Loss: 1.2323 | Learning Rate: 0.000399 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10075/12542 | Batch Loss: 0.4498 | Learning Rate: 0.000399 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10076/12542 | Batch Loss: 1.2680 | Learning Rate: 0.000399 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10077/12542 | Batch Loss: 2.3634 | Learning Rate: 0.000399 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10078/12542 | Batch Loss: 1.3572 | Learning Rate: 0.000399 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10079/12542 | Batch Loss: 2.6203 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10080/12542 | Batch Loss: 1.2258 | Learning Rate: 0.000399 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10081/12542 | Batch Loss: 0.4735 | Learning Rate: 0.000399 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10082/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000399 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10083/12542 | Batch Loss: 2.1785 | Learning Rate: 0.000399 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 10084/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000399 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10085/12542 | Batch Loss: 0.7315 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10086/12542 | Batch Loss: 1.4315 | Learning Rate: 0.000399 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10087/12542 | Batch Loss: 2.1774 | Learning Rate: 0.000399 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10088/12542 | Batch Loss: 1.5272 | Learning Rate: 0.000399 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10089/12542 | Batch Loss: 0.6876 | Learning Rate: 0.000399 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10090/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000399 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10091/12542 | Batch Loss: 1.1877 | Learning Rate: 0.000398 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10092/12542 | Batch Loss: 1.3364 | Learning Rate: 0.000398 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10093/12542 | Batch Loss: 1.0984 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10094/12542 | Batch Loss: 1.4237 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10095/12542 | Batch Loss: 0.6268 | Learning Rate: 0.000398 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10096/12542 | Batch Loss: 3.0690 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10097/12542 | Batch Loss: 1.9719 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10098/12542 | Batch Loss: 1.4756 | Learning Rate: 0.000398 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10099/12542 | Batch Loss: 0.8142 | Learning Rate: 0.000398 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10100/12542 | Batch Loss: 0.9965 | Learning Rate: 0.000398 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10101/12542 | Batch Loss: 1.3786 | Learning Rate: 0.000398 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10102/12542 | Batch Loss: 1.7506 | Learning Rate: 0.000398 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10103/12542 | Batch Loss: 1.2268 | Learning Rate: 0.000398 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10104/12542 | Batch Loss: 1.3967 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10105/12542 | Batch Loss: 1.4631 | Learning Rate: 0.000398 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10106/12542 | Batch Loss: 1.5968 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10107/12542 | Batch Loss: 2.2318 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10108/12542 | Batch Loss: 1.3658 | Learning Rate: 0.000398 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 10109/12542 | Batch Loss: 1.2171 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10110/12542 | Batch Loss: 1.9698 | Learning Rate: 0.000398 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10111/12542 | Batch Loss: 1.8481 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10112/12542 | Batch Loss: 0.6629 | Learning Rate: 0.000398 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10113/12542 | Batch Loss: 0.7050 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10114/12542 | Batch Loss: 1.5102 | Learning Rate: 0.000398 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10115/12542 | Batch Loss: 1.8743 | Learning Rate: 0.000398 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10116/12542 | Batch Loss: 0.9008 | Learning Rate: 0.000398 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10117/12542 | Batch Loss: 0.5635 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10118/12542 | Batch Loss: 1.9819 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10119/12542 | Batch Loss: 1.7908 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10120/12542 | Batch Loss: 0.8837 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10121/12542 | Batch Loss: 2.4343 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10122/12542 | Batch Loss: 0.8407 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10123/12542 | Batch Loss: 0.9895 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10124/12542 | Batch Loss: 1.0412 | Learning Rate: 0.000398 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10125/12542 | Batch Loss: 1.4547 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10126/12542 | Batch Loss: 1.4525 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10127/12542 | Batch Loss: 1.2097 | Learning Rate: 0.000398 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10128/12542 | Batch Loss: 1.2989 | Learning Rate: 0.000397 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10129/12542 | Batch Loss: 2.0358 | Learning Rate: 0.000397 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10130/12542 | Batch Loss: 1.0498 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10131/12542 | Batch Loss: 1.5663 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10132/12542 | Batch Loss: 0.8770 | Learning Rate: 0.000397 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10133/12542 | Batch Loss: 1.3142 | Learning Rate: 0.000397 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10134/12542 | Batch Loss: 1.3545 | Learning Rate: 0.000397 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10135/12542 | Batch Loss: 1.8184 | Learning Rate: 0.000397 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10136/12542 | Batch Loss: 0.7954 | Learning Rate: 0.000397 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10137/12542 | Batch Loss: 1.2988 | Learning Rate: 0.000397 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10138/12542 | Batch Loss: 0.8305 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10139/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10140/12542 | Batch Loss: 1.1221 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10141/12542 | Batch Loss: 0.2918 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10142/12542 | Batch Loss: 0.6968 | Learning Rate: 0.000397 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10143/12542 | Batch Loss: 1.0279 | Learning Rate: 0.000397 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10144/12542 | Batch Loss: 1.4821 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10145/12542 | Batch Loss: 1.4334 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10146/12542 | Batch Loss: 1.0972 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10147/12542 | Batch Loss: 0.7835 | Learning Rate: 0.000397 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10148/12542 | Batch Loss: 0.7508 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10149/12542 | Batch Loss: 2.5934 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10150/12542 | Batch Loss: 1.9540 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10151/12542 | Batch Loss: 2.4404 | Learning Rate: 0.000397 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10152/12542 | Batch Loss: 0.8606 | Learning Rate: 0.000397 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10153/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000397 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10154/12542 | Batch Loss: 0.9316 | Learning Rate: 0.000397 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10155/12542 | Batch Loss: 2.5233 | Learning Rate: 0.000397 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10156/12542 | Batch Loss: 2.3035 | Learning Rate: 0.000397 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10157/12542 | Batch Loss: 1.0570 | Learning Rate: 0.000397 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10158/12542 | Batch Loss: 1.8813 | Learning Rate: 0.000397 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10159/12542 | Batch Loss: 1.0832 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10160/12542 | Batch Loss: 2.3615 | Learning Rate: 0.000397 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10161/12542 | Batch Loss: 0.8690 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10162/12542 | Batch Loss: 0.8206 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10163/12542 | Batch Loss: 0.5495 | Learning Rate: 0.000397 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10164/12542 | Batch Loss: 1.9350 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10165/12542 | Batch Loss: 0.6891 | Learning Rate: 0.000397 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10166/12542 | Batch Loss: 1.6332 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10167/12542 | Batch Loss: 1.3785 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10168/12542 | Batch Loss: 1.2307 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10169/12542 | Batch Loss: 1.5364 | Learning Rate: 0.000396 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10170/12542 | Batch Loss: 0.8563 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10171/12542 | Batch Loss: 2.3028 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10172/12542 | Batch Loss: 1.6096 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10173/12542 | Batch Loss: 1.6103 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10174/12542 | Batch Loss: 0.7710 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10175/12542 | Batch Loss: 0.5454 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10176/12542 | Batch Loss: 0.7433 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10177/12542 | Batch Loss: 0.5742 | Learning Rate: 0.000396 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10178/12542 | Batch Loss: 1.0120 | Learning Rate: 0.000396 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10179/12542 | Batch Loss: 2.5216 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10180/12542 | Batch Loss: 0.7280 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10181/12542 | Batch Loss: 2.0501 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10182/12542 | Batch Loss: 1.3132 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10183/12542 | Batch Loss: 0.9720 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10184/12542 | Batch Loss: 2.2165 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10185/12542 | Batch Loss: 1.9007 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10186/12542 | Batch Loss: 0.5978 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10187/12542 | Batch Loss: 0.6371 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10188/12542 | Batch Loss: 3.3157 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10189/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10190/12542 | Batch Loss: 2.3632 | Learning Rate: 0.000396 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10191/12542 | Batch Loss: 1.7429 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10192/12542 | Batch Loss: 0.8657 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10193/12542 | Batch Loss: 1.7686 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10194/12542 | Batch Loss: 2.2112 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10195/12542 | Batch Loss: 0.7105 | Learning Rate: 0.000396 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 10196/12542 | Batch Loss: 1.4669 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10197/12542 | Batch Loss: 1.5698 | Learning Rate: 0.000396 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10198/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10199/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000396 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10200/12542 | Batch Loss: 0.6594 | Learning Rate: 0.000396 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10201/12542 | Batch Loss: 1.6166 | Learning Rate: 0.000396 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10202/12542 | Batch Loss: 0.9466 | Learning Rate: 0.000396 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10203/12542 | Batch Loss: 1.4919 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10204/12542 | Batch Loss: 1.2305 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10205/12542 | Batch Loss: 1.3750 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10206/12542 | Batch Loss: 1.1445 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10207/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10208/12542 | Batch Loss: 2.0517 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10209/12542 | Batch Loss: 1.3937 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10210/12542 | Batch Loss: 1.0565 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10211/12542 | Batch Loss: 1.0904 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10212/12542 | Batch Loss: 0.7929 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10213/12542 | Batch Loss: 0.8766 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10214/12542 | Batch Loss: 1.1850 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10215/12542 | Batch Loss: 1.7469 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10216/12542 | Batch Loss: 0.4895 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10217/12542 | Batch Loss: 1.2370 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10218/12542 | Batch Loss: 1.2824 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10219/12542 | Batch Loss: 0.6339 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10220/12542 | Batch Loss: 1.7991 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10221/12542 | Batch Loss: 1.0200 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10222/12542 | Batch Loss: 1.1455 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10223/12542 | Batch Loss: 1.2231 | Learning Rate: 0.000395 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10224/12542 | Batch Loss: 3.9503 | Learning Rate: 0.000395 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10225/12542 | Batch Loss: 0.5664 | Learning Rate: 0.000395 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10226/12542 | Batch Loss: 0.6257 | Learning Rate: 0.000395 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10227/12542 | Batch Loss: 1.3440 | Learning Rate: 0.000395 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10228/12542 | Batch Loss: 0.8220 | Learning Rate: 0.000395 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10229/12542 | Batch Loss: 1.8777 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10230/12542 | Batch Loss: 1.9530 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10231/12542 | Batch Loss: 1.1023 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10232/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000395 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10233/12542 | Batch Loss: 1.1209 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10234/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000395 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10235/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10236/12542 | Batch Loss: 1.7339 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10237/12542 | Batch Loss: 0.8632 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10238/12542 | Batch Loss: 1.9538 | Learning Rate: 0.000395 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10239/12542 | Batch Loss: 1.7060 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10240/12542 | Batch Loss: 1.4427 | Learning Rate: 0.000395 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10241/12542 | Batch Loss: 0.6211 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10242/12542 | Batch Loss: 1.5974 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10243/12542 | Batch Loss: 1.9204 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10244/12542 | Batch Loss: 0.8970 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10245/12542 | Batch Loss: 1.8419 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10246/12542 | Batch Loss: 0.5489 | Learning Rate: 0.000394 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10247/12542 | Batch Loss: 0.8662 | Learning Rate: 0.000394 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10248/12542 | Batch Loss: 0.9851 | Learning Rate: 0.000394 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10249/12542 | Batch Loss: 1.2876 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10250/12542 | Batch Loss: 1.6101 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10251/12542 | Batch Loss: 1.8497 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10252/12542 | Batch Loss: 0.5737 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10253/12542 | Batch Loss: 1.4866 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10254/12542 | Batch Loss: 1.2680 | Learning Rate: 0.000394 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10255/12542 | Batch Loss: 0.4908 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10256/12542 | Batch Loss: 1.0044 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10257/12542 | Batch Loss: 2.5178 | Learning Rate: 0.000394 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10258/12542 | Batch Loss: 0.7418 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10259/12542 | Batch Loss: 2.1113 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10260/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000394 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10261/12542 | Batch Loss: 1.3753 | Learning Rate: 0.000394 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10262/12542 | Batch Loss: 0.7561 | Learning Rate: 0.000394 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10263/12542 | Batch Loss: 0.4571 | Learning Rate: 0.000394 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10264/12542 | Batch Loss: 1.4887 | Learning Rate: 0.000394 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10265/12542 | Batch Loss: 0.7799 | Learning Rate: 0.000394 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10266/12542 | Batch Loss: 0.6972 | Learning Rate: 0.000394 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10267/12542 | Batch Loss: 1.9263 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10268/12542 | Batch Loss: 2.1860 | Learning Rate: 0.000394 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10269/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000394 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10270/12542 | Batch Loss: 0.5642 | Learning Rate: 0.000394 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10271/12542 | Batch Loss: 1.4968 | Learning Rate: 0.000394 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10272/12542 | Batch Loss: 1.9594 | Learning Rate: 0.000394 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10273/12542 | Batch Loss: 2.6297 | Learning Rate: 0.000394 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10274/12542 | Batch Loss: 1.3731 | Learning Rate: 0.000394 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10275/12542 | Batch Loss: 1.0281 | Learning Rate: 0.000394 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10276/12542 | Batch Loss: 0.8640 | Learning Rate: 0.000394 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10277/12542 | Batch Loss: 2.2528 | Learning Rate: 0.000394 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10278/12542 | Batch Loss: 0.9952 | Learning Rate: 0.000394 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10279/12542 | Batch Loss: 1.2398 | Learning Rate: 0.000393 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10280/12542 | Batch Loss: 1.4176 | Learning Rate: 0.000393 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10281/12542 | Batch Loss: 1.0108 | Learning Rate: 0.000393 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10282/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000393 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10283/12542 | Batch Loss: 0.7248 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10284/12542 | Batch Loss: 0.9002 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10285/12542 | Batch Loss: 0.9182 | Learning Rate: 0.000393 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10286/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000393 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10287/12542 | Batch Loss: 0.5822 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10288/12542 | Batch Loss: 0.5803 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10289/12542 | Batch Loss: 1.0862 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10290/12542 | Batch Loss: 1.6338 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10291/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000393 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10292/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10293/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000393 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10294/12542 | Batch Loss: 2.7288 | Learning Rate: 0.000393 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10295/12542 | Batch Loss: 2.6793 | Learning Rate: 0.000393 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10296/12542 | Batch Loss: 1.8825 | Learning Rate: 0.000393 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10297/12542 | Batch Loss: 0.8082 | Learning Rate: 0.000393 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10298/12542 | Batch Loss: 1.7552 | Learning Rate: 0.000393 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10299/12542 | Batch Loss: 1.4823 | Learning Rate: 0.000393 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10300/12542 | Batch Loss: 0.7718 | Learning Rate: 0.000393 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10301/12542 | Batch Loss: 0.6283 | Learning Rate: 0.000393 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10302/12542 | Batch Loss: 0.8847 | Learning Rate: 0.000393 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10303/12542 | Batch Loss: 0.9672 | Learning Rate: 0.000393 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10304/12542 | Batch Loss: 0.6173 | Learning Rate: 0.000393 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10305/12542 | Batch Loss: 0.8928 | Learning Rate: 0.000393 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10306/12542 | Batch Loss: 1.2004 | Learning Rate: 0.000393 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10307/12542 | Batch Loss: 0.9898 | Learning Rate: 0.000393 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10308/12542 | Batch Loss: 1.0661 | Learning Rate: 0.000393 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10309/12542 | Batch Loss: 1.3123 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10310/12542 | Batch Loss: 1.4449 | Learning Rate: 0.000393 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10311/12542 | Batch Loss: 1.3002 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10312/12542 | Batch Loss: 1.4499 | Learning Rate: 0.000393 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10313/12542 | Batch Loss: 1.5205 | Learning Rate: 0.000393 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10314/12542 | Batch Loss: 1.3399 | Learning Rate: 0.000393 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10315/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000393 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10316/12542 | Batch Loss: 0.6949 | Learning Rate: 0.000392 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10317/12542 | Batch Loss: 0.7138 | Learning Rate: 0.000392 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10318/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000392 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10319/12542 | Batch Loss: 0.7661 | Learning Rate: 0.000392 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10320/12542 | Batch Loss: 0.5266 | Learning Rate: 0.000392 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10321/12542 | Batch Loss: 1.1448 | Learning Rate: 0.000392 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10322/12542 | Batch Loss: 1.1610 | Learning Rate: 0.000392 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10323/12542 | Batch Loss: 0.9619 | Learning Rate: 0.000392 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10324/12542 | Batch Loss: 0.7950 | Learning Rate: 0.000392 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10325/12542 | Batch Loss: 1.9831 | Learning Rate: 0.000392 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10326/12542 | Batch Loss: 1.9874 | Learning Rate: 0.000392 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10327/12542 | Batch Loss: 1.2326 | Learning Rate: 0.000392 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10328/12542 | Batch Loss: 1.3901 | Learning Rate: 0.000392 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10329/12542 | Batch Loss: 0.7491 | Learning Rate: 0.000392 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10330/12542 | Batch Loss: 1.2650 | Learning Rate: 0.000392 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10331/12542 | Batch Loss: 1.7532 | Learning Rate: 0.000392 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10332/12542 | Batch Loss: 0.7495 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10333/12542 | Batch Loss: 1.4088 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10334/12542 | Batch Loss: 1.3963 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10335/12542 | Batch Loss: 0.5341 | Learning Rate: 0.000392 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10336/12542 | Batch Loss: 1.1594 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10337/12542 | Batch Loss: 2.0776 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10338/12542 | Batch Loss: 1.1364 | Learning Rate: 0.000392 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10339/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000392 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10340/12542 | Batch Loss: 2.4940 | Learning Rate: 0.000392 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10341/12542 | Batch Loss: 0.9256 | Learning Rate: 0.000392 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10342/12542 | Batch Loss: 2.7379 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10343/12542 | Batch Loss: 0.9175 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10344/12542 | Batch Loss: 1.4643 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10345/12542 | Batch Loss: 2.1715 | Learning Rate: 0.000392 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10346/12542 | Batch Loss: 1.6999 | Learning Rate: 0.000392 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10347/12542 | Batch Loss: 1.6334 | Learning Rate: 0.000392 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10348/12542 | Batch Loss: 0.7239 | Learning Rate: 0.000392 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10349/12542 | Batch Loss: 1.7625 | Learning Rate: 0.000392 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10350/12542 | Batch Loss: 2.0395 | Learning Rate: 0.000392 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10351/12542 | Batch Loss: 1.3036 | Learning Rate: 0.000392 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10352/12542 | Batch Loss: 1.0292 | Learning Rate: 0.000392 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10353/12542 | Batch Loss: 2.3345 | Learning Rate: 0.000392 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10354/12542 | Batch Loss: 2.0583 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10355/12542 | Batch Loss: 1.7263 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10356/12542 | Batch Loss: 1.5428 | Learning Rate: 0.000391 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10357/12542 | Batch Loss: 0.6402 | Learning Rate: 0.000391 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10358/12542 | Batch Loss: 1.2625 | Learning Rate: 0.000391 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10359/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000391 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10360/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10361/12542 | Batch Loss: 2.2781 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10362/12542 | Batch Loss: 2.5000 | Learning Rate: 0.000391 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10363/12542 | Batch Loss: 2.5419 | Learning Rate: 0.000391 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10364/12542 | Batch Loss: 1.0089 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10365/12542 | Batch Loss: 1.2205 | Learning Rate: 0.000391 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10366/12542 | Batch Loss: 1.6203 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10367/12542 | Batch Loss: 0.9013 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10368/12542 | Batch Loss: 0.9848 | Learning Rate: 0.000391 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10369/12542 | Batch Loss: 1.1533 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10370/12542 | Batch Loss: 2.2640 | Learning Rate: 0.000391 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10371/12542 | Batch Loss: 1.4543 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10372/12542 | Batch Loss: 1.0408 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10373/12542 | Batch Loss: 1.0950 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10374/12542 | Batch Loss: 2.3159 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10375/12542 | Batch Loss: 3.3766 | Learning Rate: 0.000391 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10376/12542 | Batch Loss: 1.1349 | Learning Rate: 0.000391 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10377/12542 | Batch Loss: 1.3646 | Learning Rate: 0.000391 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10378/12542 | Batch Loss: 1.2863 | Learning Rate: 0.000391 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10379/12542 | Batch Loss: 0.8628 | Learning Rate: 0.000391 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10380/12542 | Batch Loss: 1.3612 | Learning Rate: 0.000391 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10381/12542 | Batch Loss: 1.3917 | Learning Rate: 0.000391 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10382/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000391 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10383/12542 | Batch Loss: 1.3220 | Learning Rate: 0.000391 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10384/12542 | Batch Loss: 1.0660 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10385/12542 | Batch Loss: 1.3251 | Learning Rate: 0.000391 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10386/12542 | Batch Loss: 1.3788 | Learning Rate: 0.000391 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10387/12542 | Batch Loss: 0.9499 | Learning Rate: 0.000391 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10388/12542 | Batch Loss: 0.5223 | Learning Rate: 0.000391 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10389/12542 | Batch Loss: 0.9085 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10390/12542 | Batch Loss: 0.7369 | Learning Rate: 0.000391 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10391/12542 | Batch Loss: 1.6630 | Learning Rate: 0.000391 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10392/12542 | Batch Loss: 0.5914 | Learning Rate: 0.000390 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10393/12542 | Batch Loss: 0.7783 | Learning Rate: 0.000390 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10394/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10395/12542 | Batch Loss: 0.5229 | Learning Rate: 0.000390 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10396/12542 | Batch Loss: 0.6227 | Learning Rate: 0.000390 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10397/12542 | Batch Loss: 1.0060 | Learning Rate: 0.000390 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10398/12542 | Batch Loss: 1.3217 | Learning Rate: 0.000390 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10399/12542 | Batch Loss: 1.8938 | Learning Rate: 0.000390 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10400/12542 | Batch Loss: 1.3048 | Learning Rate: 0.000390 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10401/12542 | Batch Loss: 1.1847 | Learning Rate: 0.000390 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10402/12542 | Batch Loss: 0.7802 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10403/12542 | Batch Loss: 0.5970 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10404/12542 | Batch Loss: 1.1020 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10405/12542 | Batch Loss: 0.5455 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10406/12542 | Batch Loss: 1.8758 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10407/12542 | Batch Loss: 2.1557 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10408/12542 | Batch Loss: 1.2072 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10409/12542 | Batch Loss: 1.8353 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10410/12542 | Batch Loss: 0.6350 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10411/12542 | Batch Loss: 0.5515 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10412/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10413/12542 | Batch Loss: 2.9392 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10414/12542 | Batch Loss: 1.9553 | Learning Rate: 0.000390 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10415/12542 | Batch Loss: 0.7056 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10416/12542 | Batch Loss: 1.1696 | Learning Rate: 0.000390 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10417/12542 | Batch Loss: 0.7904 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10418/12542 | Batch Loss: 1.1791 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10419/12542 | Batch Loss: 1.1779 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10420/12542 | Batch Loss: 3.1788 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10421/12542 | Batch Loss: 0.9965 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10422/12542 | Batch Loss: 2.4294 | Learning Rate: 0.000390 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 10423/12542 | Batch Loss: 2.1616 | Learning Rate: 0.000390 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10424/12542 | Batch Loss: 1.6407 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10425/12542 | Batch Loss: 1.5989 | Learning Rate: 0.000390 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10426/12542 | Batch Loss: 1.1003 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10427/12542 | Batch Loss: 0.8660 | Learning Rate: 0.000390 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10428/12542 | Batch Loss: 1.0118 | Learning Rate: 0.000390 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10429/12542 | Batch Loss: 0.9709 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10430/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000389 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10431/12542 | Batch Loss: 0.7539 | Learning Rate: 0.000389 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10432/12542 | Batch Loss: 1.4743 | Learning Rate: 0.000389 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10433/12542 | Batch Loss: 0.8544 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10434/12542 | Batch Loss: 2.2131 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10435/12542 | Batch Loss: 1.1168 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10436/12542 | Batch Loss: 1.0118 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10437/12542 | Batch Loss: 1.0460 | Learning Rate: 0.000389 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10438/12542 | Batch Loss: 1.1036 | Learning Rate: 0.000389 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10439/12542 | Batch Loss: 1.5993 | Learning Rate: 0.000389 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10440/12542 | Batch Loss: 2.0534 | Learning Rate: 0.000389 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10441/12542 | Batch Loss: 4.0771 | Learning Rate: 0.000389 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10442/12542 | Batch Loss: 2.0059 | Learning Rate: 0.000389 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10443/12542 | Batch Loss: 1.5889 | Learning Rate: 0.000389 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10444/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000389 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10445/12542 | Batch Loss: 1.4036 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10446/12542 | Batch Loss: 0.4841 | Learning Rate: 0.000389 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10447/12542 | Batch Loss: 1.8656 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10448/12542 | Batch Loss: 3.1731 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10449/12542 | Batch Loss: 1.3874 | Learning Rate: 0.000389 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10450/12542 | Batch Loss: 0.6064 | Learning Rate: 0.000389 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10451/12542 | Batch Loss: 1.0180 | Learning Rate: 0.000389 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10452/12542 | Batch Loss: 3.5506 | Learning Rate: 0.000389 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10453/12542 | Batch Loss: 1.8466 | Learning Rate: 0.000389 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10454/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10455/12542 | Batch Loss: 2.6037 | Learning Rate: 0.000389 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10456/12542 | Batch Loss: 1.0705 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10457/12542 | Batch Loss: 0.7618 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10458/12542 | Batch Loss: 1.4866 | Learning Rate: 0.000389 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10459/12542 | Batch Loss: 2.4381 | Learning Rate: 0.000389 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10460/12542 | Batch Loss: 1.3479 | Learning Rate: 0.000389 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10461/12542 | Batch Loss: 0.8337 | Learning Rate: 0.000389 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10462/12542 | Batch Loss: 0.8629 | Learning Rate: 0.000389 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10463/12542 | Batch Loss: 2.7955 | Learning Rate: 0.000389 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10464/12542 | Batch Loss: 4.1282 | Learning Rate: 0.000389 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10465/12542 | Batch Loss: 1.5635 | Learning Rate: 0.000389 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10466/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000389 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10467/12542 | Batch Loss: 0.9442 | Learning Rate: 0.000388 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10468/12542 | Batch Loss: 1.0111 | Learning Rate: 0.000388 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10469/12542 | Batch Loss: 0.9714 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10470/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10471/12542 | Batch Loss: 0.4365 | Learning Rate: 0.000388 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10472/12542 | Batch Loss: 1.5131 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10473/12542 | Batch Loss: 1.4731 | Learning Rate: 0.000388 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10474/12542 | Batch Loss: 2.2455 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10475/12542 | Batch Loss: 2.1243 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10476/12542 | Batch Loss: 1.1941 | Learning Rate: 0.000388 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10477/12542 | Batch Loss: 1.2174 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10478/12542 | Batch Loss: 1.8728 | Learning Rate: 0.000388 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10479/12542 | Batch Loss: 1.1473 | Learning Rate: 0.000388 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10480/12542 | Batch Loss: 1.3775 | Learning Rate: 0.000388 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10481/12542 | Batch Loss: 0.9848 | Learning Rate: 0.000388 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10482/12542 | Batch Loss: 1.3579 | Learning Rate: 0.000388 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10483/12542 | Batch Loss: 1.1046 | Learning Rate: 0.000388 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10484/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000388 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10485/12542 | Batch Loss: 0.9052 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10486/12542 | Batch Loss: 1.4734 | Learning Rate: 0.000388 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10487/12542 | Batch Loss: 0.7517 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10488/12542 | Batch Loss: 1.1238 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10489/12542 | Batch Loss: 1.3094 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10490/12542 | Batch Loss: 0.2976 | Learning Rate: 0.000388 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10491/12542 | Batch Loss: 0.6754 | Learning Rate: 0.000388 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10492/12542 | Batch Loss: 1.4200 | Learning Rate: 0.000388 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10493/12542 | Batch Loss: 0.8051 | Learning Rate: 0.000388 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10494/12542 | Batch Loss: 0.8868 | Learning Rate: 0.000388 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10495/12542 | Batch Loss: 0.6631 | Learning Rate: 0.000388 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10496/12542 | Batch Loss: 3.5009 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10497/12542 | Batch Loss: 1.9218 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10498/12542 | Batch Loss: 2.8581 | Learning Rate: 0.000388 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10499/12542 | Batch Loss: 1.4314 | Learning Rate: 0.000388 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10500/12542 | Batch Loss: 0.8579 | Learning Rate: 0.000388 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10501/12542 | Batch Loss: 1.2437 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10502/12542 | Batch Loss: 0.7939 | Learning Rate: 0.000388 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10503/12542 | Batch Loss: 1.8248 | Learning Rate: 0.000388 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10504/12542 | Batch Loss: 1.5971 | Learning Rate: 0.000387 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10505/12542 | Batch Loss: 0.8357 | Learning Rate: 0.000387 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10506/12542 | Batch Loss: 1.0272 | Learning Rate: 0.000387 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10507/12542 | Batch Loss: 1.0577 | Learning Rate: 0.000387 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10508/12542 | Batch Loss: 0.9883 | Learning Rate: 0.000387 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10509/12542 | Batch Loss: 0.9646 | Learning Rate: 0.000387 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10510/12542 | Batch Loss: 2.4266 | Learning Rate: 0.000387 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10511/12542 | Batch Loss: 1.2776 | Learning Rate: 0.000387 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10512/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000387 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10513/12542 | Batch Loss: 1.0457 | Learning Rate: 0.000387 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10514/12542 | Batch Loss: 3.1213 | Learning Rate: 0.000387 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10515/12542 | Batch Loss: 0.9126 | Learning Rate: 0.000387 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10516/12542 | Batch Loss: 1.3915 | Learning Rate: 0.000387 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10517/12542 | Batch Loss: 0.8447 | Learning Rate: 0.000387 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10518/12542 | Batch Loss: 0.5798 | Learning Rate: 0.000387 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10519/12542 | Batch Loss: 1.2856 | Learning Rate: 0.000387 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10520/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000387 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10521/12542 | Batch Loss: 1.0708 | Learning Rate: 0.000387 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10522/12542 | Batch Loss: 2.3816 | Learning Rate: 0.000387 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10523/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000387 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10524/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000387 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10525/12542 | Batch Loss: 1.8876 | Learning Rate: 0.000387 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10526/12542 | Batch Loss: 1.0982 | Learning Rate: 0.000387 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10527/12542 | Batch Loss: 2.0500 | Learning Rate: 0.000387 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10528/12542 | Batch Loss: 1.2022 | Learning Rate: 0.000387 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10529/12542 | Batch Loss: 1.0343 | Learning Rate: 0.000387 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10530/12542 | Batch Loss: 0.9882 | Learning Rate: 0.000387 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10531/12542 | Batch Loss: 0.5956 | Learning Rate: 0.000387 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10532/12542 | Batch Loss: 1.3885 | Learning Rate: 0.000387 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10533/12542 | Batch Loss: 0.4417 | Learning Rate: 0.000387 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10534/12542 | Batch Loss: 1.7709 | Learning Rate: 0.000387 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10535/12542 | Batch Loss: 0.9777 | Learning Rate: 0.000387 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10536/12542 | Batch Loss: 1.9037 | Learning Rate: 0.000387 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10537/12542 | Batch Loss: 1.0036 | Learning Rate: 0.000387 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10538/12542 | Batch Loss: 1.4351 | Learning Rate: 0.000387 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10539/12542 | Batch Loss: 2.5918 | Learning Rate: 0.000387 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10540/12542 | Batch Loss: 1.4680 | Learning Rate: 0.000387 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10541/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000387 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10542/12542 | Batch Loss: 1.4833 | Learning Rate: 0.000386 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10543/12542 | Batch Loss: 1.7123 | Learning Rate: 0.000386 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10544/12542 | Batch Loss: 1.8640 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10545/12542 | Batch Loss: 0.9475 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10546/12542 | Batch Loss: 0.8914 | Learning Rate: 0.000386 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10547/12542 | Batch Loss: 1.8298 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10548/12542 | Batch Loss: 0.7986 | Learning Rate: 0.000386 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10549/12542 | Batch Loss: 1.7269 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10550/12542 | Batch Loss: 0.8297 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10551/12542 | Batch Loss: 1.3506 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10552/12542 | Batch Loss: 2.6099 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10553/12542 | Batch Loss: 0.5428 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10554/12542 | Batch Loss: 1.7548 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10555/12542 | Batch Loss: 1.7820 | Learning Rate: 0.000386 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10556/12542 | Batch Loss: 1.9257 | Learning Rate: 0.000386 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10557/12542 | Batch Loss: 0.5960 | Learning Rate: 0.000386 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10558/12542 | Batch Loss: 3.7017 | Learning Rate: 0.000386 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10559/12542 | Batch Loss: 0.6986 | Learning Rate: 0.000386 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10560/12542 | Batch Loss: 1.5336 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10561/12542 | Batch Loss: 2.0316 | Learning Rate: 0.000386 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10562/12542 | Batch Loss: 1.1002 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10563/12542 | Batch Loss: 0.5070 | Learning Rate: 0.000386 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10564/12542 | Batch Loss: 0.6709 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10565/12542 | Batch Loss: 0.7250 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10566/12542 | Batch Loss: 0.9817 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10567/12542 | Batch Loss: 0.7439 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10568/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10569/12542 | Batch Loss: 1.3127 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10570/12542 | Batch Loss: 2.3190 | Learning Rate: 0.000386 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10571/12542 | Batch Loss: 1.3406 | Learning Rate: 0.000386 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10572/12542 | Batch Loss: 0.8952 | Learning Rate: 0.000386 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10573/12542 | Batch Loss: 1.9714 | Learning Rate: 0.000386 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10574/12542 | Batch Loss: 0.8404 | Learning Rate: 0.000386 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10575/12542 | Batch Loss: 0.9785 | Learning Rate: 0.000386 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10576/12542 | Batch Loss: 1.8336 | Learning Rate: 0.000386 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10577/12542 | Batch Loss: 0.8821 | Learning Rate: 0.000386 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10578/12542 | Batch Loss: 1.5537 | Learning Rate: 0.000386 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10579/12542 | Batch Loss: 1.7214 | Learning Rate: 0.000386 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10580/12542 | Batch Loss: 1.2315 | Learning Rate: 0.000385 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10581/12542 | Batch Loss: 2.9201 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10582/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10583/12542 | Batch Loss: 1.3371 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10584/12542 | Batch Loss: 1.1077 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10585/12542 | Batch Loss: 1.1458 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10586/12542 | Batch Loss: 1.3482 | Learning Rate: 0.000385 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10587/12542 | Batch Loss: 0.7787 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10588/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000385 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10589/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000385 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10590/12542 | Batch Loss: 2.1065 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10591/12542 | Batch Loss: 1.1427 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10592/12542 | Batch Loss: 1.2337 | Learning Rate: 0.000385 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10593/12542 | Batch Loss: 1.3435 | Learning Rate: 0.000385 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10594/12542 | Batch Loss: 2.1169 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10595/12542 | Batch Loss: 2.6660 | Learning Rate: 0.000385 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10596/12542 | Batch Loss: 0.8619 | Learning Rate: 0.000385 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10597/12542 | Batch Loss: 0.8806 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10598/12542 | Batch Loss: 1.3602 | Learning Rate: 0.000385 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10599/12542 | Batch Loss: 0.7421 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10600/12542 | Batch Loss: 1.4758 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10601/12542 | Batch Loss: 2.3241 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10602/12542 | Batch Loss: 1.6879 | Learning Rate: 0.000385 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10603/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000385 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10604/12542 | Batch Loss: 1.5234 | Learning Rate: 0.000385 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10605/12542 | Batch Loss: 1.3379 | Learning Rate: 0.000385 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10606/12542 | Batch Loss: 0.7288 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10607/12542 | Batch Loss: 2.6171 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10608/12542 | Batch Loss: 3.2493 | Learning Rate: 0.000385 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10609/12542 | Batch Loss: 0.8774 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10610/12542 | Batch Loss: 0.8707 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10611/12542 | Batch Loss: 1.1668 | Learning Rate: 0.000385 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10612/12542 | Batch Loss: 1.0088 | Learning Rate: 0.000385 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10613/12542 | Batch Loss: 0.6918 | Learning Rate: 0.000385 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10614/12542 | Batch Loss: 1.6541 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10615/12542 | Batch Loss: 0.9988 | Learning Rate: 0.000385 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10616/12542 | Batch Loss: 0.5539 | Learning Rate: 0.000385 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10617/12542 | Batch Loss: 1.1427 | Learning Rate: 0.000384 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10618/12542 | Batch Loss: 1.6869 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10619/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10620/12542 | Batch Loss: 0.5466 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10621/12542 | Batch Loss: 0.8755 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10622/12542 | Batch Loss: 2.3793 | Learning Rate: 0.000384 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10623/12542 | Batch Loss: 0.7378 | Learning Rate: 0.000384 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10624/12542 | Batch Loss: 3.3733 | Learning Rate: 0.000384 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10625/12542 | Batch Loss: 0.8024 | Learning Rate: 0.000384 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10626/12542 | Batch Loss: 0.9639 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10627/12542 | Batch Loss: 1.7911 | Learning Rate: 0.000384 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10628/12542 | Batch Loss: 1.7537 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10629/12542 | Batch Loss: 3.3136 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10630/12542 | Batch Loss: 1.0485 | Learning Rate: 0.000384 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10631/12542 | Batch Loss: 0.7284 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10632/12542 | Batch Loss: 1.4504 | Learning Rate: 0.000384 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10633/12542 | Batch Loss: 1.9069 | Learning Rate: 0.000384 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10634/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000384 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10635/12542 | Batch Loss: 0.6291 | Learning Rate: 0.000384 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10636/12542 | Batch Loss: 1.5302 | Learning Rate: 0.000384 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10637/12542 | Batch Loss: 0.6827 | Learning Rate: 0.000384 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10638/12542 | Batch Loss: 2.0307 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10639/12542 | Batch Loss: 0.8863 | Learning Rate: 0.000384 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10640/12542 | Batch Loss: 0.9836 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10641/12542 | Batch Loss: 0.8346 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10642/12542 | Batch Loss: 1.1315 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10643/12542 | Batch Loss: 1.0334 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10644/12542 | Batch Loss: 1.5628 | Learning Rate: 0.000384 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10645/12542 | Batch Loss: 1.2511 | Learning Rate: 0.000384 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10646/12542 | Batch Loss: 2.1198 | Learning Rate: 0.000384 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10647/12542 | Batch Loss: 1.0032 | Learning Rate: 0.000384 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10648/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000384 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10649/12542 | Batch Loss: 1.1533 | Learning Rate: 0.000384 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10650/12542 | Batch Loss: 0.7574 | Learning Rate: 0.000384 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10651/12542 | Batch Loss: 2.0657 | Learning Rate: 0.000384 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10652/12542 | Batch Loss: 1.8689 | Learning Rate: 0.000384 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10653/12542 | Batch Loss: 1.1558 | Learning Rate: 0.000384 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10654/12542 | Batch Loss: 1.7378 | Learning Rate: 0.000384 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10655/12542 | Batch Loss: 1.0901 | Learning Rate: 0.000383 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10656/12542 | Batch Loss: 0.5724 | Learning Rate: 0.000383 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10657/12542 | Batch Loss: 1.2941 | Learning Rate: 0.000383 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10658/12542 | Batch Loss: 0.8244 | Learning Rate: 0.000383 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10659/12542 | Batch Loss: 3.3786 | Learning Rate: 0.000383 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10660/12542 | Batch Loss: 0.9965 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10661/12542 | Batch Loss: 1.1860 | Learning Rate: 0.000383 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10662/12542 | Batch Loss: 1.0228 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10663/12542 | Batch Loss: 2.2981 | Learning Rate: 0.000383 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10664/12542 | Batch Loss: 0.5267 | Learning Rate: 0.000383 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10665/12542 | Batch Loss: 0.7544 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10666/12542 | Batch Loss: 0.6715 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10667/12542 | Batch Loss: 1.2664 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10668/12542 | Batch Loss: 0.8830 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10669/12542 | Batch Loss: 1.4235 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10670/12542 | Batch Loss: 0.9772 | Learning Rate: 0.000383 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10671/12542 | Batch Loss: 0.5434 | Learning Rate: 0.000383 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10672/12542 | Batch Loss: 0.8764 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10673/12542 | Batch Loss: 1.8034 | Learning Rate: 0.000383 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10674/12542 | Batch Loss: 2.1737 | Learning Rate: 0.000383 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10675/12542 | Batch Loss: 0.4878 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10676/12542 | Batch Loss: 1.7473 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10677/12542 | Batch Loss: 0.9783 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10678/12542 | Batch Loss: 2.9765 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10679/12542 | Batch Loss: 2.2290 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10680/12542 | Batch Loss: 1.6289 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10681/12542 | Batch Loss: 0.7598 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10682/12542 | Batch Loss: 1.3144 | Learning Rate: 0.000383 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10683/12542 | Batch Loss: 1.3128 | Learning Rate: 0.000383 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10684/12542 | Batch Loss: 2.1352 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10685/12542 | Batch Loss: 1.5169 | Learning Rate: 0.000383 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10686/12542 | Batch Loss: 1.6030 | Learning Rate: 0.000383 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10687/12542 | Batch Loss: 0.6975 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10688/12542 | Batch Loss: 1.9448 | Learning Rate: 0.000383 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10689/12542 | Batch Loss: 1.5105 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10690/12542 | Batch Loss: 1.2946 | Learning Rate: 0.000383 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10691/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000383 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10692/12542 | Batch Loss: 0.8954 | Learning Rate: 0.000383 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10693/12542 | Batch Loss: 1.0405 | Learning Rate: 0.000382 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10694/12542 | Batch Loss: 1.2790 | Learning Rate: 0.000382 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10695/12542 | Batch Loss: 1.4337 | Learning Rate: 0.000382 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10696/12542 | Batch Loss: 1.9222 | Learning Rate: 0.000382 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10697/12542 | Batch Loss: 1.2299 | Learning Rate: 0.000382 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10698/12542 | Batch Loss: 0.8370 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10699/12542 | Batch Loss: 0.5148 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10700/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10701/12542 | Batch Loss: 1.9957 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10702/12542 | Batch Loss: 2.4565 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10703/12542 | Batch Loss: 1.3387 | Learning Rate: 0.000382 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10704/12542 | Batch Loss: 1.7614 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10705/12542 | Batch Loss: 0.9216 | Learning Rate: 0.000382 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10706/12542 | Batch Loss: 1.5046 | Learning Rate: 0.000382 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10707/12542 | Batch Loss: 0.6689 | Learning Rate: 0.000382 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10708/12542 | Batch Loss: 0.6421 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10709/12542 | Batch Loss: 1.6156 | Learning Rate: 0.000382 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10710/12542 | Batch Loss: 0.8432 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10711/12542 | Batch Loss: 2.4948 | Learning Rate: 0.000382 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10712/12542 | Batch Loss: 1.0468 | Learning Rate: 0.000382 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10713/12542 | Batch Loss: 0.7867 | Learning Rate: 0.000382 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10714/12542 | Batch Loss: 0.7059 | Learning Rate: 0.000382 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10715/12542 | Batch Loss: 1.4366 | Learning Rate: 0.000382 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10716/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000382 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10717/12542 | Batch Loss: 0.9623 | Learning Rate: 0.000382 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10718/12542 | Batch Loss: 0.3214 | Learning Rate: 0.000382 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10719/12542 | Batch Loss: 0.5637 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10720/12542 | Batch Loss: 1.7563 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10721/12542 | Batch Loss: 2.1587 | Learning Rate: 0.000382 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10722/12542 | Batch Loss: 2.0939 | Learning Rate: 0.000382 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10723/12542 | Batch Loss: 2.6715 | Learning Rate: 0.000382 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10724/12542 | Batch Loss: 2.1373 | Learning Rate: 0.000382 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10725/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10726/12542 | Batch Loss: 1.5677 | Learning Rate: 0.000382 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10727/12542 | Batch Loss: 1.1573 | Learning Rate: 0.000382 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10728/12542 | Batch Loss: 1.4193 | Learning Rate: 0.000382 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10729/12542 | Batch Loss: 1.2569 | Learning Rate: 0.000382 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10730/12542 | Batch Loss: 1.9043 | Learning Rate: 0.000381 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10731/12542 | Batch Loss: 2.0551 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10732/12542 | Batch Loss: 1.6875 | Learning Rate: 0.000381 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10733/12542 | Batch Loss: 1.5164 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10734/12542 | Batch Loss: 0.6629 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10735/12542 | Batch Loss: 1.1806 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10736/12542 | Batch Loss: 0.9156 | Learning Rate: 0.000381 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10737/12542 | Batch Loss: 2.5428 | Learning Rate: 0.000381 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10738/12542 | Batch Loss: 1.3100 | Learning Rate: 0.000381 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10739/12542 | Batch Loss: 1.2607 | Learning Rate: 0.000381 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10740/12542 | Batch Loss: 1.6145 | Learning Rate: 0.000381 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10741/12542 | Batch Loss: 1.0516 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10742/12542 | Batch Loss: 0.9999 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10743/12542 | Batch Loss: 1.5003 | Learning Rate: 0.000381 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10744/12542 | Batch Loss: 1.8643 | Learning Rate: 0.000381 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10745/12542 | Batch Loss: 0.8246 | Learning Rate: 0.000381 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10746/12542 | Batch Loss: 2.6311 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10747/12542 | Batch Loss: 0.9392 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10748/12542 | Batch Loss: 0.6405 | Learning Rate: 0.000381 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10749/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000381 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10750/12542 | Batch Loss: 1.9138 | Learning Rate: 0.000381 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10751/12542 | Batch Loss: 0.7298 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10752/12542 | Batch Loss: 2.3522 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10753/12542 | Batch Loss: 1.6970 | Learning Rate: 0.000381 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10754/12542 | Batch Loss: 1.1307 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10755/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000381 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10756/12542 | Batch Loss: 0.8479 | Learning Rate: 0.000381 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10757/12542 | Batch Loss: 1.7654 | Learning Rate: 0.000381 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10758/12542 | Batch Loss: 2.6417 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10759/12542 | Batch Loss: 3.1317 | Learning Rate: 0.000381 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10760/12542 | Batch Loss: 1.0355 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10761/12542 | Batch Loss: 1.3353 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10762/12542 | Batch Loss: 1.5624 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10763/12542 | Batch Loss: 1.5306 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10764/12542 | Batch Loss: 0.9484 | Learning Rate: 0.000381 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10765/12542 | Batch Loss: 0.6496 | Learning Rate: 0.000381 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10766/12542 | Batch Loss: 1.9846 | Learning Rate: 0.000381 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10767/12542 | Batch Loss: 0.8645 | Learning Rate: 0.000381 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10768/12542 | Batch Loss: 1.6645 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10769/12542 | Batch Loss: 1.2934 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10770/12542 | Batch Loss: 0.7524 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10771/12542 | Batch Loss: 1.0597 | Learning Rate: 0.000380 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10772/12542 | Batch Loss: 0.6934 | Learning Rate: 0.000380 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10773/12542 | Batch Loss: 1.7666 | Learning Rate: 0.000380 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10774/12542 | Batch Loss: 0.9291 | Learning Rate: 0.000380 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10775/12542 | Batch Loss: 0.8857 | Learning Rate: 0.000380 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10776/12542 | Batch Loss: 1.0556 | Learning Rate: 0.000380 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10777/12542 | Batch Loss: 2.6957 | Learning Rate: 0.000380 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10778/12542 | Batch Loss: 0.8994 | Learning Rate: 0.000380 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10779/12542 | Batch Loss: 2.6858 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10780/12542 | Batch Loss: 1.6370 | Learning Rate: 0.000380 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10781/12542 | Batch Loss: 0.8836 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10782/12542 | Batch Loss: 1.1409 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10783/12542 | Batch Loss: 1.5583 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10784/12542 | Batch Loss: 1.9072 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10785/12542 | Batch Loss: 0.6918 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10786/12542 | Batch Loss: 1.2863 | Learning Rate: 0.000380 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10787/12542 | Batch Loss: 1.1752 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10788/12542 | Batch Loss: 1.0236 | Learning Rate: 0.000380 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10789/12542 | Batch Loss: 0.6747 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10790/12542 | Batch Loss: 1.2787 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10791/12542 | Batch Loss: 2.2830 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10792/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000380 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10793/12542 | Batch Loss: 1.9804 | Learning Rate: 0.000380 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10794/12542 | Batch Loss: 1.7586 | Learning Rate: 0.000380 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10795/12542 | Batch Loss: 1.5867 | Learning Rate: 0.000380 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10796/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000380 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10797/12542 | Batch Loss: 1.4787 | Learning Rate: 0.000380 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10798/12542 | Batch Loss: 1.4201 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10799/12542 | Batch Loss: 0.7463 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10800/12542 | Batch Loss: 2.1787 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10801/12542 | Batch Loss: 1.8553 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10802/12542 | Batch Loss: 1.4525 | Learning Rate: 0.000380 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10803/12542 | Batch Loss: 1.8546 | Learning Rate: 0.000380 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10804/12542 | Batch Loss: 0.9097 | Learning Rate: 0.000380 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10805/12542 | Batch Loss: 1.5567 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10806/12542 | Batch Loss: 1.0183 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10807/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10808/12542 | Batch Loss: 2.1224 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10809/12542 | Batch Loss: 1.0521 | Learning Rate: 0.000379 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10810/12542 | Batch Loss: 0.6263 | Learning Rate: 0.000379 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10811/12542 | Batch Loss: 0.6641 | Learning Rate: 0.000379 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10812/12542 | Batch Loss: 0.7740 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10813/12542 | Batch Loss: 1.5379 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10814/12542 | Batch Loss: 1.2047 | Learning Rate: 0.000379 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10815/12542 | Batch Loss: 1.3623 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10816/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000379 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10817/12542 | Batch Loss: 1.1629 | Learning Rate: 0.000379 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10818/12542 | Batch Loss: 1.3544 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10819/12542 | Batch Loss: 0.6981 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10820/12542 | Batch Loss: 0.4960 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10821/12542 | Batch Loss: 1.5329 | Learning Rate: 0.000379 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10822/12542 | Batch Loss: 0.4430 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10823/12542 | Batch Loss: 0.6384 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10824/12542 | Batch Loss: 0.6886 | Learning Rate: 0.000379 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10825/12542 | Batch Loss: 1.8366 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10826/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10827/12542 | Batch Loss: 1.4134 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10828/12542 | Batch Loss: 1.2725 | Learning Rate: 0.000379 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10829/12542 | Batch Loss: 0.9057 | Learning Rate: 0.000379 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10830/12542 | Batch Loss: 1.0179 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10831/12542 | Batch Loss: 1.2645 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10832/12542 | Batch Loss: 1.2747 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10833/12542 | Batch Loss: 2.1115 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10834/12542 | Batch Loss: 0.3892 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10835/12542 | Batch Loss: 2.2951 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10836/12542 | Batch Loss: 1.8891 | Learning Rate: 0.000379 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10837/12542 | Batch Loss: 0.6923 | Learning Rate: 0.000379 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10838/12542 | Batch Loss: 1.8937 | Learning Rate: 0.000379 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10839/12542 | Batch Loss: 0.7528 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10840/12542 | Batch Loss: 2.6756 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10841/12542 | Batch Loss: 2.1800 | Learning Rate: 0.000379 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10842/12542 | Batch Loss: 0.6562 | Learning Rate: 0.000379 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10843/12542 | Batch Loss: 1.4828 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10844/12542 | Batch Loss: 1.2465 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10845/12542 | Batch Loss: 1.2066 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10846/12542 | Batch Loss: 0.7284 | Learning Rate: 0.000378 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10847/12542 | Batch Loss: 0.6720 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10848/12542 | Batch Loss: 1.9461 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10849/12542 | Batch Loss: 1.0944 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10850/12542 | Batch Loss: 2.1194 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10851/12542 | Batch Loss: 2.0852 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10852/12542 | Batch Loss: 1.0403 | Learning Rate: 0.000378 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10853/12542 | Batch Loss: 1.6019 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10854/12542 | Batch Loss: 0.5377 | Learning Rate: 0.000378 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10855/12542 | Batch Loss: 0.5482 | Learning Rate: 0.000378 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10856/12542 | Batch Loss: 1.5391 | Learning Rate: 0.000378 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10857/12542 | Batch Loss: 2.5036 | Learning Rate: 0.000378 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10858/12542 | Batch Loss: 1.6514 | Learning Rate: 0.000378 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10859/12542 | Batch Loss: 0.6097 | Learning Rate: 0.000378 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10860/12542 | Batch Loss: 1.0438 | Learning Rate: 0.000378 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10861/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000378 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10862/12542 | Batch Loss: 3.0301 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10863/12542 | Batch Loss: 1.2200 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10864/12542 | Batch Loss: 0.5052 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10865/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10866/12542 | Batch Loss: 1.5867 | Learning Rate: 0.000378 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10867/12542 | Batch Loss: 1.5916 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10868/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000378 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10869/12542 | Batch Loss: 1.3830 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10870/12542 | Batch Loss: 1.0660 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10871/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10872/12542 | Batch Loss: 1.1420 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10873/12542 | Batch Loss: 0.8103 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10874/12542 | Batch Loss: 1.3231 | Learning Rate: 0.000378 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10875/12542 | Batch Loss: 0.7530 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10876/12542 | Batch Loss: 1.1738 | Learning Rate: 0.000378 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10877/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000378 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10878/12542 | Batch Loss: 1.6954 | Learning Rate: 0.000378 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10879/12542 | Batch Loss: 2.6967 | Learning Rate: 0.000378 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10880/12542 | Batch Loss: 0.9131 | Learning Rate: 0.000378 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10881/12542 | Batch Loss: 1.4090 | Learning Rate: 0.000377 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10882/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000377 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10883/12542 | Batch Loss: 2.1502 | Learning Rate: 0.000377 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10884/12542 | Batch Loss: 0.9880 | Learning Rate: 0.000377 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10885/12542 | Batch Loss: 1.5416 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10886/12542 | Batch Loss: 1.0337 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10887/12542 | Batch Loss: 1.3953 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10888/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10889/12542 | Batch Loss: 0.7974 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10890/12542 | Batch Loss: 1.2190 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10891/12542 | Batch Loss: 2.5857 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10892/12542 | Batch Loss: 0.7822 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10893/12542 | Batch Loss: 0.8102 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10894/12542 | Batch Loss: 3.0409 | Learning Rate: 0.000377 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10895/12542 | Batch Loss: 0.6352 | Learning Rate: 0.000377 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10896/12542 | Batch Loss: 0.8871 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10897/12542 | Batch Loss: 1.5872 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10898/12542 | Batch Loss: 1.2283 | Learning Rate: 0.000377 | Batch Time: 0.71s\n",
      "Epoch 2 | Step 10899/12542 | Batch Loss: 1.1898 | Learning Rate: 0.000377 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10900/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000377 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10901/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10902/12542 | Batch Loss: 1.2589 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10903/12542 | Batch Loss: 1.7915 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10904/12542 | Batch Loss: 2.4216 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10905/12542 | Batch Loss: 0.5877 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10906/12542 | Batch Loss: 0.7611 | Learning Rate: 0.000377 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10907/12542 | Batch Loss: 1.9009 | Learning Rate: 0.000377 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10908/12542 | Batch Loss: 1.1478 | Learning Rate: 0.000377 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10909/12542 | Batch Loss: 1.9699 | Learning Rate: 0.000377 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10910/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000377 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10911/12542 | Batch Loss: 0.6476 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10912/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10913/12542 | Batch Loss: 1.6824 | Learning Rate: 0.000377 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10914/12542 | Batch Loss: 1.2380 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10915/12542 | Batch Loss: 1.4649 | Learning Rate: 0.000377 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10916/12542 | Batch Loss: 0.4856 | Learning Rate: 0.000377 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10917/12542 | Batch Loss: 0.6053 | Learning Rate: 0.000377 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10918/12542 | Batch Loss: 1.2998 | Learning Rate: 0.000376 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10919/12542 | Batch Loss: 1.3610 | Learning Rate: 0.000376 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10920/12542 | Batch Loss: 1.0224 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10921/12542 | Batch Loss: 1.0428 | Learning Rate: 0.000376 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10922/12542 | Batch Loss: 1.0320 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10923/12542 | Batch Loss: 0.7737 | Learning Rate: 0.000376 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10924/12542 | Batch Loss: 1.2479 | Learning Rate: 0.000376 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10925/12542 | Batch Loss: 0.6531 | Learning Rate: 0.000376 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10926/12542 | Batch Loss: 0.7915 | Learning Rate: 0.000376 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 10927/12542 | Batch Loss: 2.6544 | Learning Rate: 0.000376 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 10928/12542 | Batch Loss: 0.9054 | Learning Rate: 0.000376 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10929/12542 | Batch Loss: 3.0123 | Learning Rate: 0.000376 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10930/12542 | Batch Loss: 1.2690 | Learning Rate: 0.000376 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10931/12542 | Batch Loss: 2.0242 | Learning Rate: 0.000376 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10932/12542 | Batch Loss: 2.0924 | Learning Rate: 0.000376 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10933/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10934/12542 | Batch Loss: 2.1974 | Learning Rate: 0.000376 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10935/12542 | Batch Loss: 1.4818 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10936/12542 | Batch Loss: 0.9216 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10937/12542 | Batch Loss: 0.7597 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10938/12542 | Batch Loss: 1.8290 | Learning Rate: 0.000376 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10939/12542 | Batch Loss: 0.5204 | Learning Rate: 0.000376 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10940/12542 | Batch Loss: 0.8549 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10941/12542 | Batch Loss: 0.6954 | Learning Rate: 0.000376 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10942/12542 | Batch Loss: 1.0346 | Learning Rate: 0.000376 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10943/12542 | Batch Loss: 0.9340 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10944/12542 | Batch Loss: 0.7518 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10945/12542 | Batch Loss: 1.1584 | Learning Rate: 0.000376 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10946/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10947/12542 | Batch Loss: 1.3308 | Learning Rate: 0.000376 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10948/12542 | Batch Loss: 0.8737 | Learning Rate: 0.000376 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10949/12542 | Batch Loss: 3.2307 | Learning Rate: 0.000376 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10950/12542 | Batch Loss: 1.2740 | Learning Rate: 0.000376 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10951/12542 | Batch Loss: 1.0806 | Learning Rate: 0.000376 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10952/12542 | Batch Loss: 1.0333 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10953/12542 | Batch Loss: 1.4817 | Learning Rate: 0.000376 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10954/12542 | Batch Loss: 0.9865 | Learning Rate: 0.000376 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10955/12542 | Batch Loss: 0.5054 | Learning Rate: 0.000376 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10956/12542 | Batch Loss: 0.4401 | Learning Rate: 0.000375 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10957/12542 | Batch Loss: 0.6549 | Learning Rate: 0.000375 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10958/12542 | Batch Loss: 1.7415 | Learning Rate: 0.000375 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10959/12542 | Batch Loss: 1.2780 | Learning Rate: 0.000375 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10960/12542 | Batch Loss: 0.8564 | Learning Rate: 0.000375 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10961/12542 | Batch Loss: 1.9095 | Learning Rate: 0.000375 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10962/12542 | Batch Loss: 2.7593 | Learning Rate: 0.000375 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10963/12542 | Batch Loss: 1.7914 | Learning Rate: 0.000375 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10964/12542 | Batch Loss: 1.0703 | Learning Rate: 0.000375 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10965/12542 | Batch Loss: 1.6594 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10966/12542 | Batch Loss: 1.7557 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10967/12542 | Batch Loss: 2.6180 | Learning Rate: 0.000375 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10968/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000375 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10969/12542 | Batch Loss: 1.3475 | Learning Rate: 0.000375 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 10970/12542 | Batch Loss: 1.3392 | Learning Rate: 0.000375 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10971/12542 | Batch Loss: 2.0624 | Learning Rate: 0.000375 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 10972/12542 | Batch Loss: 1.2440 | Learning Rate: 0.000375 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10973/12542 | Batch Loss: 2.0747 | Learning Rate: 0.000375 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 10974/12542 | Batch Loss: 1.2857 | Learning Rate: 0.000375 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 10975/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000375 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 10976/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10977/12542 | Batch Loss: 1.0368 | Learning Rate: 0.000375 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10978/12542 | Batch Loss: 1.4438 | Learning Rate: 0.000375 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10979/12542 | Batch Loss: 1.8242 | Learning Rate: 0.000375 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10980/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10981/12542 | Batch Loss: 1.1570 | Learning Rate: 0.000375 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10982/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000375 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 10983/12542 | Batch Loss: 1.5186 | Learning Rate: 0.000375 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10984/12542 | Batch Loss: 1.3930 | Learning Rate: 0.000375 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 10985/12542 | Batch Loss: 0.5071 | Learning Rate: 0.000375 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10986/12542 | Batch Loss: 2.8057 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10987/12542 | Batch Loss: 1.0849 | Learning Rate: 0.000375 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 10988/12542 | Batch Loss: 1.0405 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10989/12542 | Batch Loss: 1.0963 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10990/12542 | Batch Loss: 1.5153 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10991/12542 | Batch Loss: 0.7594 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10992/12542 | Batch Loss: 1.2912 | Learning Rate: 0.000375 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10993/12542 | Batch Loss: 2.0105 | Learning Rate: 0.000375 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10994/12542 | Batch Loss: 2.6181 | Learning Rate: 0.000374 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 10995/12542 | Batch Loss: 1.5372 | Learning Rate: 0.000374 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10996/12542 | Batch Loss: 1.6060 | Learning Rate: 0.000374 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 10997/12542 | Batch Loss: 1.9348 | Learning Rate: 0.000374 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10998/12542 | Batch Loss: 0.6636 | Learning Rate: 0.000374 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 10999/12542 | Batch Loss: 1.5970 | Learning Rate: 0.000374 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11000/12542 | Batch Loss: 1.3640 | Learning Rate: 0.000374 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11001/12542 | Batch Loss: 1.0464 | Learning Rate: 0.000374 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11002/12542 | Batch Loss: 1.5959 | Learning Rate: 0.000374 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11003/12542 | Batch Loss: 1.3582 | Learning Rate: 0.000374 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11004/12542 | Batch Loss: 1.1946 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11005/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000374 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11006/12542 | Batch Loss: 1.0712 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11007/12542 | Batch Loss: 2.1245 | Learning Rate: 0.000374 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11008/12542 | Batch Loss: 1.5715 | Learning Rate: 0.000374 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11009/12542 | Batch Loss: 0.7320 | Learning Rate: 0.000374 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11010/12542 | Batch Loss: 0.6461 | Learning Rate: 0.000374 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11011/12542 | Batch Loss: 0.3145 | Learning Rate: 0.000374 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11012/12542 | Batch Loss: 1.8583 | Learning Rate: 0.000374 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11013/12542 | Batch Loss: 2.4004 | Learning Rate: 0.000374 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11014/12542 | Batch Loss: 1.2810 | Learning Rate: 0.000374 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11015/12542 | Batch Loss: 1.3010 | Learning Rate: 0.000374 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11016/12542 | Batch Loss: 1.8494 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11017/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11018/12542 | Batch Loss: 1.4895 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11019/12542 | Batch Loss: 0.7871 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11020/12542 | Batch Loss: 0.5282 | Learning Rate: 0.000374 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11021/12542 | Batch Loss: 0.8837 | Learning Rate: 0.000374 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11022/12542 | Batch Loss: 1.6997 | Learning Rate: 0.000374 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11023/12542 | Batch Loss: 1.0857 | Learning Rate: 0.000374 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11024/12542 | Batch Loss: 0.7815 | Learning Rate: 0.000374 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11025/12542 | Batch Loss: 1.8327 | Learning Rate: 0.000374 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11026/12542 | Batch Loss: 0.6341 | Learning Rate: 0.000374 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11027/12542 | Batch Loss: 1.3464 | Learning Rate: 0.000374 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11028/12542 | Batch Loss: 1.3479 | Learning Rate: 0.000374 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11029/12542 | Batch Loss: 1.2345 | Learning Rate: 0.000374 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11030/12542 | Batch Loss: 2.0122 | Learning Rate: 0.000374 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11031/12542 | Batch Loss: 0.6384 | Learning Rate: 0.000373 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11032/12542 | Batch Loss: 1.5129 | Learning Rate: 0.000373 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11033/12542 | Batch Loss: 1.0874 | Learning Rate: 0.000373 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11034/12542 | Batch Loss: 1.3603 | Learning Rate: 0.000373 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11035/12542 | Batch Loss: 1.2675 | Learning Rate: 0.000373 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11036/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000373 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11037/12542 | Batch Loss: 1.2035 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11038/12542 | Batch Loss: 0.4503 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11039/12542 | Batch Loss: 0.9776 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11040/12542 | Batch Loss: 1.3171 | Learning Rate: 0.000373 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11041/12542 | Batch Loss: 1.2003 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11042/12542 | Batch Loss: 0.8916 | Learning Rate: 0.000373 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11043/12542 | Batch Loss: 1.1066 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11044/12542 | Batch Loss: 1.1407 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11045/12542 | Batch Loss: 1.7013 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11046/12542 | Batch Loss: 1.5119 | Learning Rate: 0.000373 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11047/12542 | Batch Loss: 0.7077 | Learning Rate: 0.000373 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11048/12542 | Batch Loss: 1.4966 | Learning Rate: 0.000373 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11049/12542 | Batch Loss: 1.6925 | Learning Rate: 0.000373 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11050/12542 | Batch Loss: 0.5835 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11051/12542 | Batch Loss: 0.5708 | Learning Rate: 0.000373 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11052/12542 | Batch Loss: 1.1093 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11053/12542 | Batch Loss: 1.8256 | Learning Rate: 0.000373 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11054/12542 | Batch Loss: 0.6357 | Learning Rate: 0.000373 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11055/12542 | Batch Loss: 0.6061 | Learning Rate: 0.000373 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11056/12542 | Batch Loss: 0.8881 | Learning Rate: 0.000373 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11057/12542 | Batch Loss: 0.7249 | Learning Rate: 0.000373 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11058/12542 | Batch Loss: 1.3578 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11059/12542 | Batch Loss: 1.9582 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11060/12542 | Batch Loss: 1.6504 | Learning Rate: 0.000373 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11061/12542 | Batch Loss: 1.2124 | Learning Rate: 0.000373 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11062/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000373 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11063/12542 | Batch Loss: 1.0866 | Learning Rate: 0.000373 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11064/12542 | Batch Loss: 1.1994 | Learning Rate: 0.000373 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11065/12542 | Batch Loss: 1.1638 | Learning Rate: 0.000373 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11066/12542 | Batch Loss: 1.8181 | Learning Rate: 0.000373 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11067/12542 | Batch Loss: 1.2329 | Learning Rate: 0.000373 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11068/12542 | Batch Loss: 1.9006 | Learning Rate: 0.000373 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11069/12542 | Batch Loss: 1.3841 | Learning Rate: 0.000372 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11070/12542 | Batch Loss: 6.4024 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11071/12542 | Batch Loss: 0.5391 | Learning Rate: 0.000372 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11072/12542 | Batch Loss: 1.3185 | Learning Rate: 0.000372 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11073/12542 | Batch Loss: 1.4824 | Learning Rate: 0.000372 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11074/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000372 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11075/12542 | Batch Loss: 1.0813 | Learning Rate: 0.000372 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11076/12542 | Batch Loss: 0.8849 | Learning Rate: 0.000372 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11077/12542 | Batch Loss: 1.6688 | Learning Rate: 0.000372 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11078/12542 | Batch Loss: 0.7430 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11079/12542 | Batch Loss: 2.3657 | Learning Rate: 0.000372 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11080/12542 | Batch Loss: 0.6218 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11081/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11082/12542 | Batch Loss: 2.8324 | Learning Rate: 0.000372 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11083/12542 | Batch Loss: 1.2501 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11084/12542 | Batch Loss: 1.1613 | Learning Rate: 0.000372 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11085/12542 | Batch Loss: 1.3684 | Learning Rate: 0.000372 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11086/12542 | Batch Loss: 1.3051 | Learning Rate: 0.000372 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11087/12542 | Batch Loss: 3.2604 | Learning Rate: 0.000372 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11088/12542 | Batch Loss: 1.2507 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11089/12542 | Batch Loss: 0.6170 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11090/12542 | Batch Loss: 0.9763 | Learning Rate: 0.000372 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11091/12542 | Batch Loss: 1.5291 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11092/12542 | Batch Loss: 1.3396 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11093/12542 | Batch Loss: 1.7860 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11094/12542 | Batch Loss: 1.0914 | Learning Rate: 0.000372 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11095/12542 | Batch Loss: 0.3749 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11096/12542 | Batch Loss: 2.5000 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11097/12542 | Batch Loss: 2.6714 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11098/12542 | Batch Loss: 1.2665 | Learning Rate: 0.000372 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11099/12542 | Batch Loss: 0.8770 | Learning Rate: 0.000372 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11100/12542 | Batch Loss: 1.8047 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11101/12542 | Batch Loss: 1.2910 | Learning Rate: 0.000372 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11102/12542 | Batch Loss: 1.4199 | Learning Rate: 0.000372 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11103/12542 | Batch Loss: 3.5920 | Learning Rate: 0.000372 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11104/12542 | Batch Loss: 0.8299 | Learning Rate: 0.000372 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11105/12542 | Batch Loss: 1.3128 | Learning Rate: 0.000372 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11106/12542 | Batch Loss: 2.0177 | Learning Rate: 0.000371 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11107/12542 | Batch Loss: 0.9916 | Learning Rate: 0.000371 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11108/12542 | Batch Loss: 1.2753 | Learning Rate: 0.000371 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11109/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11110/12542 | Batch Loss: 0.5742 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11111/12542 | Batch Loss: 1.6550 | Learning Rate: 0.000371 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11112/12542 | Batch Loss: 1.7275 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11113/12542 | Batch Loss: 1.2667 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11114/12542 | Batch Loss: 1.3193 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11115/12542 | Batch Loss: 0.9977 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11116/12542 | Batch Loss: 0.5037 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11117/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11118/12542 | Batch Loss: 2.5877 | Learning Rate: 0.000371 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11119/12542 | Batch Loss: 0.7103 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11120/12542 | Batch Loss: 0.5273 | Learning Rate: 0.000371 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11121/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11122/12542 | Batch Loss: 0.9559 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11123/12542 | Batch Loss: 1.6421 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11124/12542 | Batch Loss: 1.1312 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11125/12542 | Batch Loss: 1.9365 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11126/12542 | Batch Loss: 2.2607 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11127/12542 | Batch Loss: 2.0803 | Learning Rate: 0.000371 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11128/12542 | Batch Loss: 0.8829 | Learning Rate: 0.000371 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11129/12542 | Batch Loss: 1.3271 | Learning Rate: 0.000371 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11130/12542 | Batch Loss: 0.3360 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11131/12542 | Batch Loss: 1.1116 | Learning Rate: 0.000371 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11132/12542 | Batch Loss: 0.8024 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11133/12542 | Batch Loss: 1.2369 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11134/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11135/12542 | Batch Loss: 1.9909 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11136/12542 | Batch Loss: 0.6331 | Learning Rate: 0.000371 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11137/12542 | Batch Loss: 0.4845 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11138/12542 | Batch Loss: 1.0337 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11139/12542 | Batch Loss: 1.2800 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11140/12542 | Batch Loss: 2.3183 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11141/12542 | Batch Loss: 1.1597 | Learning Rate: 0.000371 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11142/12542 | Batch Loss: 1.8271 | Learning Rate: 0.000371 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11143/12542 | Batch Loss: 1.6165 | Learning Rate: 0.000371 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11144/12542 | Batch Loss: 1.4963 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11145/12542 | Batch Loss: 1.5895 | Learning Rate: 0.000370 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11146/12542 | Batch Loss: 1.8979 | Learning Rate: 0.000370 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11147/12542 | Batch Loss: 2.0073 | Learning Rate: 0.000370 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11148/12542 | Batch Loss: 1.5467 | Learning Rate: 0.000370 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11149/12542 | Batch Loss: 1.1686 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11150/12542 | Batch Loss: 1.4722 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11151/12542 | Batch Loss: 0.8344 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11152/12542 | Batch Loss: 1.2696 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11153/12542 | Batch Loss: 0.9750 | Learning Rate: 0.000370 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11154/12542 | Batch Loss: 1.7932 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11155/12542 | Batch Loss: 2.7210 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11156/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11157/12542 | Batch Loss: 1.1949 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11158/12542 | Batch Loss: 1.5017 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11159/12542 | Batch Loss: 1.5355 | Learning Rate: 0.000370 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11160/12542 | Batch Loss: 1.0013 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11161/12542 | Batch Loss: 0.8213 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11162/12542 | Batch Loss: 0.9201 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11163/12542 | Batch Loss: 0.6235 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11164/12542 | Batch Loss: 0.6057 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11165/12542 | Batch Loss: 0.9164 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11166/12542 | Batch Loss: 1.0050 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11167/12542 | Batch Loss: 0.8128 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11168/12542 | Batch Loss: 1.4724 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11169/12542 | Batch Loss: 2.3158 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11170/12542 | Batch Loss: 2.0806 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11171/12542 | Batch Loss: 3.3636 | Learning Rate: 0.000370 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11172/12542 | Batch Loss: 0.6296 | Learning Rate: 0.000370 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11173/12542 | Batch Loss: 0.9181 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11174/12542 | Batch Loss: 1.2522 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11175/12542 | Batch Loss: 1.0868 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11176/12542 | Batch Loss: 1.3584 | Learning Rate: 0.000370 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11177/12542 | Batch Loss: 0.7402 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11178/12542 | Batch Loss: 1.0475 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11179/12542 | Batch Loss: 0.9254 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11180/12542 | Batch Loss: 1.4065 | Learning Rate: 0.000370 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11181/12542 | Batch Loss: 0.7953 | Learning Rate: 0.000370 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11182/12542 | Batch Loss: 0.8127 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11183/12542 | Batch Loss: 1.3513 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11184/12542 | Batch Loss: 0.7589 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11185/12542 | Batch Loss: 1.5261 | Learning Rate: 0.000369 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11186/12542 | Batch Loss: 0.8217 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11187/12542 | Batch Loss: 0.9491 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11188/12542 | Batch Loss: 2.1191 | Learning Rate: 0.000369 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11189/12542 | Batch Loss: 0.6911 | Learning Rate: 0.000369 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11190/12542 | Batch Loss: 1.6319 | Learning Rate: 0.000369 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11191/12542 | Batch Loss: 0.7647 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11192/12542 | Batch Loss: 1.2504 | Learning Rate: 0.000369 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11193/12542 | Batch Loss: 0.7532 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11194/12542 | Batch Loss: 0.9309 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11195/12542 | Batch Loss: 0.6124 | Learning Rate: 0.000369 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11196/12542 | Batch Loss: 1.8698 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11197/12542 | Batch Loss: 1.7776 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11198/12542 | Batch Loss: 0.8022 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11199/12542 | Batch Loss: 0.8046 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11200/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11201/12542 | Batch Loss: 0.4779 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11202/12542 | Batch Loss: 1.4499 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11203/12542 | Batch Loss: 2.6234 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11204/12542 | Batch Loss: 2.9840 | Learning Rate: 0.000369 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11205/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11206/12542 | Batch Loss: 1.4331 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11207/12542 | Batch Loss: 1.7022 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11208/12542 | Batch Loss: 1.4789 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11209/12542 | Batch Loss: 0.6542 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11210/12542 | Batch Loss: 0.8098 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11211/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11212/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000369 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11213/12542 | Batch Loss: 0.8701 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11214/12542 | Batch Loss: 2.5042 | Learning Rate: 0.000369 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11215/12542 | Batch Loss: 1.2025 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11216/12542 | Batch Loss: 2.4506 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11217/12542 | Batch Loss: 1.6139 | Learning Rate: 0.000369 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11218/12542 | Batch Loss: 1.2952 | Learning Rate: 0.000369 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11219/12542 | Batch Loss: 1.0125 | Learning Rate: 0.000368 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11220/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000368 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11221/12542 | Batch Loss: 0.8455 | Learning Rate: 0.000368 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11222/12542 | Batch Loss: 1.4943 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11223/12542 | Batch Loss: 1.2767 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11224/12542 | Batch Loss: 0.7246 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11225/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11226/12542 | Batch Loss: 1.1953 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11227/12542 | Batch Loss: 1.5118 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11228/12542 | Batch Loss: 2.0809 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11229/12542 | Batch Loss: 0.6117 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11230/12542 | Batch Loss: 2.8797 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11231/12542 | Batch Loss: 1.6379 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11232/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000368 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11233/12542 | Batch Loss: 0.4724 | Learning Rate: 0.000368 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11234/12542 | Batch Loss: 1.6919 | Learning Rate: 0.000368 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11235/12542 | Batch Loss: 1.2879 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11236/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11237/12542 | Batch Loss: 1.5456 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11238/12542 | Batch Loss: 0.9526 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11239/12542 | Batch Loss: 1.8421 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11240/12542 | Batch Loss: 1.0429 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11241/12542 | Batch Loss: 0.9705 | Learning Rate: 0.000368 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11242/12542 | Batch Loss: 1.5264 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11243/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11244/12542 | Batch Loss: 0.9662 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11245/12542 | Batch Loss: 1.9178 | Learning Rate: 0.000368 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11246/12542 | Batch Loss: 0.7756 | Learning Rate: 0.000368 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11247/12542 | Batch Loss: 1.2412 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11248/12542 | Batch Loss: 1.7176 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11249/12542 | Batch Loss: 0.6271 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11250/12542 | Batch Loss: 0.7439 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11251/12542 | Batch Loss: 2.0735 | Learning Rate: 0.000368 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11252/12542 | Batch Loss: 0.7970 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11253/12542 | Batch Loss: 1.6800 | Learning Rate: 0.000368 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11254/12542 | Batch Loss: 1.6529 | Learning Rate: 0.000368 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11255/12542 | Batch Loss: 1.0968 | Learning Rate: 0.000368 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11256/12542 | Batch Loss: 1.0533 | Learning Rate: 0.000368 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11257/12542 | Batch Loss: 0.9792 | Learning Rate: 0.000367 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11258/12542 | Batch Loss: 1.9173 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11259/12542 | Batch Loss: 1.5685 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11260/12542 | Batch Loss: 0.9927 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11261/12542 | Batch Loss: 0.8215 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11262/12542 | Batch Loss: 2.5670 | Learning Rate: 0.000367 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11263/12542 | Batch Loss: 1.1867 | Learning Rate: 0.000367 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11264/12542 | Batch Loss: 0.9239 | Learning Rate: 0.000367 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11265/12542 | Batch Loss: 0.5090 | Learning Rate: 0.000367 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11266/12542 | Batch Loss: 0.7491 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11267/12542 | Batch Loss: 0.8044 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11268/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11269/12542 | Batch Loss: 0.6230 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11270/12542 | Batch Loss: 0.7617 | Learning Rate: 0.000367 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11271/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11272/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11273/12542 | Batch Loss: 1.7408 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11274/12542 | Batch Loss: 1.6442 | Learning Rate: 0.000367 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11275/12542 | Batch Loss: 1.6053 | Learning Rate: 0.000367 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11276/12542 | Batch Loss: 1.5143 | Learning Rate: 0.000367 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11277/12542 | Batch Loss: 1.4104 | Learning Rate: 0.000367 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11278/12542 | Batch Loss: 1.0161 | Learning Rate: 0.000367 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11279/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000367 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11280/12542 | Batch Loss: 0.8649 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11281/12542 | Batch Loss: 1.0794 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11282/12542 | Batch Loss: 1.1333 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11283/12542 | Batch Loss: 0.9360 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11284/12542 | Batch Loss: 1.4460 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11285/12542 | Batch Loss: 1.2023 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11286/12542 | Batch Loss: 1.3926 | Learning Rate: 0.000367 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11287/12542 | Batch Loss: 0.9721 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11288/12542 | Batch Loss: 0.9376 | Learning Rate: 0.000367 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11289/12542 | Batch Loss: 0.8170 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11290/12542 | Batch Loss: 2.3793 | Learning Rate: 0.000367 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11291/12542 | Batch Loss: 1.4154 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11292/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000367 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11293/12542 | Batch Loss: 0.5101 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11294/12542 | Batch Loss: 2.2850 | Learning Rate: 0.000367 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11295/12542 | Batch Loss: 1.2472 | Learning Rate: 0.000366 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11296/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11297/12542 | Batch Loss: 0.6062 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11298/12542 | Batch Loss: 0.7101 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11299/12542 | Batch Loss: 2.1564 | Learning Rate: 0.000366 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11300/12542 | Batch Loss: 0.9269 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11301/12542 | Batch Loss: 1.7235 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11302/12542 | Batch Loss: 0.8702 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11303/12542 | Batch Loss: 1.0640 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11304/12542 | Batch Loss: 0.9035 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11305/12542 | Batch Loss: 3.1191 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11306/12542 | Batch Loss: 0.7597 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11307/12542 | Batch Loss: 1.3445 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11308/12542 | Batch Loss: 1.7235 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11309/12542 | Batch Loss: 2.6389 | Learning Rate: 0.000366 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11310/12542 | Batch Loss: 1.7300 | Learning Rate: 0.000366 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11311/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000366 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11312/12542 | Batch Loss: 1.8201 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11313/12542 | Batch Loss: 0.9757 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11314/12542 | Batch Loss: 1.3248 | Learning Rate: 0.000366 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11315/12542 | Batch Loss: 1.0566 | Learning Rate: 0.000366 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11316/12542 | Batch Loss: 2.0808 | Learning Rate: 0.000366 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11317/12542 | Batch Loss: 0.9927 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11318/12542 | Batch Loss: 1.2563 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11319/12542 | Batch Loss: 0.9598 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11320/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11321/12542 | Batch Loss: 1.5922 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11322/12542 | Batch Loss: 0.6894 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11323/12542 | Batch Loss: 1.7674 | Learning Rate: 0.000366 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11324/12542 | Batch Loss: 0.7281 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11325/12542 | Batch Loss: 2.1736 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11326/12542 | Batch Loss: 1.4193 | Learning Rate: 0.000366 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11327/12542 | Batch Loss: 0.9175 | Learning Rate: 0.000366 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11328/12542 | Batch Loss: 0.7538 | Learning Rate: 0.000366 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11329/12542 | Batch Loss: 1.5696 | Learning Rate: 0.000366 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11330/12542 | Batch Loss: 1.6978 | Learning Rate: 0.000366 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11331/12542 | Batch Loss: 1.0427 | Learning Rate: 0.000366 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11332/12542 | Batch Loss: 1.9649 | Learning Rate: 0.000365 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11333/12542 | Batch Loss: 1.9247 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11334/12542 | Batch Loss: 1.4422 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11335/12542 | Batch Loss: 1.9602 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11336/12542 | Batch Loss: 1.9708 | Learning Rate: 0.000365 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11337/12542 | Batch Loss: 1.9272 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11338/12542 | Batch Loss: 1.8512 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11339/12542 | Batch Loss: 1.6363 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11340/12542 | Batch Loss: 2.9640 | Learning Rate: 0.000365 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11341/12542 | Batch Loss: 0.5529 | Learning Rate: 0.000365 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11342/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000365 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11343/12542 | Batch Loss: 1.1449 | Learning Rate: 0.000365 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11344/12542 | Batch Loss: 1.1695 | Learning Rate: 0.000365 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11345/12542 | Batch Loss: 1.3723 | Learning Rate: 0.000365 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11346/12542 | Batch Loss: 1.7774 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11347/12542 | Batch Loss: 2.2544 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11348/12542 | Batch Loss: 0.9261 | Learning Rate: 0.000365 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11349/12542 | Batch Loss: 2.4544 | Learning Rate: 0.000365 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11350/12542 | Batch Loss: 0.7607 | Learning Rate: 0.000365 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11351/12542 | Batch Loss: 0.8105 | Learning Rate: 0.000365 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11352/12542 | Batch Loss: 0.7741 | Learning Rate: 0.000365 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11353/12542 | Batch Loss: 1.6834 | Learning Rate: 0.000365 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11354/12542 | Batch Loss: 1.5458 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11355/12542 | Batch Loss: 1.9514 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11356/12542 | Batch Loss: 1.3004 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11357/12542 | Batch Loss: 1.7343 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11358/12542 | Batch Loss: 1.1893 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11359/12542 | Batch Loss: 2.1449 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11360/12542 | Batch Loss: 1.0372 | Learning Rate: 0.000365 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11361/12542 | Batch Loss: 0.7323 | Learning Rate: 0.000365 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11362/12542 | Batch Loss: 1.1559 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11363/12542 | Batch Loss: 1.2185 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11364/12542 | Batch Loss: 2.2422 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11365/12542 | Batch Loss: 1.8525 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11366/12542 | Batch Loss: 1.1656 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11367/12542 | Batch Loss: 1.4127 | Learning Rate: 0.000365 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11368/12542 | Batch Loss: 1.2796 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11369/12542 | Batch Loss: 0.6862 | Learning Rate: 0.000365 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11370/12542 | Batch Loss: 1.2349 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11371/12542 | Batch Loss: 1.8591 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11372/12542 | Batch Loss: 1.1648 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11373/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11374/12542 | Batch Loss: 1.7068 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11375/12542 | Batch Loss: 0.7430 | Learning Rate: 0.000364 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11376/12542 | Batch Loss: 1.4034 | Learning Rate: 0.000364 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11377/12542 | Batch Loss: 1.8531 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11378/12542 | Batch Loss: 0.9053 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11379/12542 | Batch Loss: 1.9003 | Learning Rate: 0.000364 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11380/12542 | Batch Loss: 1.4796 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11381/12542 | Batch Loss: 0.9309 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11382/12542 | Batch Loss: 0.8307 | Learning Rate: 0.000364 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11383/12542 | Batch Loss: 1.4410 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11384/12542 | Batch Loss: 0.9337 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11385/12542 | Batch Loss: 1.3922 | Learning Rate: 0.000364 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11386/12542 | Batch Loss: 0.6132 | Learning Rate: 0.000364 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11387/12542 | Batch Loss: 2.3223 | Learning Rate: 0.000364 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11388/12542 | Batch Loss: 0.9227 | Learning Rate: 0.000364 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11389/12542 | Batch Loss: 0.4522 | Learning Rate: 0.000364 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11390/12542 | Batch Loss: 1.3220 | Learning Rate: 0.000364 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11391/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11392/12542 | Batch Loss: 3.2427 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11393/12542 | Batch Loss: 1.6955 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11394/12542 | Batch Loss: 1.3929 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11395/12542 | Batch Loss: 0.6494 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11396/12542 | Batch Loss: 2.0774 | Learning Rate: 0.000364 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11397/12542 | Batch Loss: 0.9858 | Learning Rate: 0.000364 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11398/12542 | Batch Loss: 1.6659 | Learning Rate: 0.000364 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11399/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000364 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11400/12542 | Batch Loss: 1.6630 | Learning Rate: 0.000364 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11401/12542 | Batch Loss: 1.0225 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11402/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000364 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11403/12542 | Batch Loss: 1.1918 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11404/12542 | Batch Loss: 1.7287 | Learning Rate: 0.000364 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11405/12542 | Batch Loss: 1.3045 | Learning Rate: 0.000364 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11406/12542 | Batch Loss: 0.8622 | Learning Rate: 0.000364 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11407/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11408/12542 | Batch Loss: 0.6683 | Learning Rate: 0.000363 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11409/12542 | Batch Loss: 0.8365 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11410/12542 | Batch Loss: 1.5713 | Learning Rate: 0.000363 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11411/12542 | Batch Loss: 0.6901 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11412/12542 | Batch Loss: 0.8290 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11413/12542 | Batch Loss: 0.8512 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11414/12542 | Batch Loss: 1.6462 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11415/12542 | Batch Loss: 1.8457 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11416/12542 | Batch Loss: 0.9663 | Learning Rate: 0.000363 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11417/12542 | Batch Loss: 1.9698 | Learning Rate: 0.000363 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11418/12542 | Batch Loss: 0.6696 | Learning Rate: 0.000363 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11419/12542 | Batch Loss: 0.8959 | Learning Rate: 0.000363 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11420/12542 | Batch Loss: 1.8135 | Learning Rate: 0.000363 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11421/12542 | Batch Loss: 2.7785 | Learning Rate: 0.000363 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11422/12542 | Batch Loss: 0.6228 | Learning Rate: 0.000363 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11423/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11424/12542 | Batch Loss: 0.6330 | Learning Rate: 0.000363 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11425/12542 | Batch Loss: 1.1557 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11426/12542 | Batch Loss: 1.5235 | Learning Rate: 0.000363 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11427/12542 | Batch Loss: 2.4355 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11428/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11429/12542 | Batch Loss: 1.4134 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11430/12542 | Batch Loss: 1.2338 | Learning Rate: 0.000363 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11431/12542 | Batch Loss: 1.5267 | Learning Rate: 0.000363 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11432/12542 | Batch Loss: 1.1452 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11433/12542 | Batch Loss: 3.1948 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11434/12542 | Batch Loss: 1.1537 | Learning Rate: 0.000363 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11435/12542 | Batch Loss: 0.5103 | Learning Rate: 0.000363 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11436/12542 | Batch Loss: 1.3187 | Learning Rate: 0.000363 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11437/12542 | Batch Loss: 1.2551 | Learning Rate: 0.000363 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11438/12542 | Batch Loss: 0.9856 | Learning Rate: 0.000363 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11439/12542 | Batch Loss: 0.7421 | Learning Rate: 0.000363 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11440/12542 | Batch Loss: 2.0749 | Learning Rate: 0.000363 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11441/12542 | Batch Loss: 0.6844 | Learning Rate: 0.000363 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11442/12542 | Batch Loss: 1.6523 | Learning Rate: 0.000363 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11443/12542 | Batch Loss: 0.7740 | Learning Rate: 0.000363 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11444/12542 | Batch Loss: 2.6663 | Learning Rate: 0.000363 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11445/12542 | Batch Loss: 0.3555 | Learning Rate: 0.000362 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11446/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000362 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11447/12542 | Batch Loss: 0.9624 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11448/12542 | Batch Loss: 1.2078 | Learning Rate: 0.000362 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11449/12542 | Batch Loss: 0.5879 | Learning Rate: 0.000362 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11450/12542 | Batch Loss: 0.8084 | Learning Rate: 0.000362 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11451/12542 | Batch Loss: 0.8793 | Learning Rate: 0.000362 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11452/12542 | Batch Loss: 0.6980 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11453/12542 | Batch Loss: 0.7384 | Learning Rate: 0.000362 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11454/12542 | Batch Loss: 0.9986 | Learning Rate: 0.000362 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11455/12542 | Batch Loss: 1.1273 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11456/12542 | Batch Loss: 0.5286 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11457/12542 | Batch Loss: 1.9022 | Learning Rate: 0.000362 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11458/12542 | Batch Loss: 0.9623 | Learning Rate: 0.000362 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11459/12542 | Batch Loss: 1.6400 | Learning Rate: 0.000362 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11460/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000362 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11461/12542 | Batch Loss: 0.7403 | Learning Rate: 0.000362 | Batch Time: 0.70s\n",
      "Epoch 2 | Step 11462/12542 | Batch Loss: 1.0127 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11463/12542 | Batch Loss: 0.9478 | Learning Rate: 0.000362 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11464/12542 | Batch Loss: 0.6295 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11465/12542 | Batch Loss: 2.1924 | Learning Rate: 0.000362 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11466/12542 | Batch Loss: 3.1678 | Learning Rate: 0.000362 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11467/12542 | Batch Loss: 0.7313 | Learning Rate: 0.000362 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11468/12542 | Batch Loss: 1.5803 | Learning Rate: 0.000362 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11469/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11470/12542 | Batch Loss: 1.0506 | Learning Rate: 0.000362 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11471/12542 | Batch Loss: 1.0861 | Learning Rate: 0.000362 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11472/12542 | Batch Loss: 0.7528 | Learning Rate: 0.000362 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11473/12542 | Batch Loss: 1.2188 | Learning Rate: 0.000362 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11474/12542 | Batch Loss: 1.2695 | Learning Rate: 0.000362 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11475/12542 | Batch Loss: 1.8296 | Learning Rate: 0.000362 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11476/12542 | Batch Loss: 1.8766 | Learning Rate: 0.000362 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11477/12542 | Batch Loss: 1.8119 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11478/12542 | Batch Loss: 1.0570 | Learning Rate: 0.000362 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11479/12542 | Batch Loss: 0.5391 | Learning Rate: 0.000362 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11480/12542 | Batch Loss: 1.6794 | Learning Rate: 0.000362 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11481/12542 | Batch Loss: 1.8231 | Learning Rate: 0.000362 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11482/12542 | Batch Loss: 1.1451 | Learning Rate: 0.000362 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11483/12542 | Batch Loss: 1.4460 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11484/12542 | Batch Loss: 2.4752 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11485/12542 | Batch Loss: 3.7301 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11486/12542 | Batch Loss: 1.8661 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11487/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11488/12542 | Batch Loss: 1.7208 | Learning Rate: 0.000361 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11489/12542 | Batch Loss: 1.2917 | Learning Rate: 0.000361 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11490/12542 | Batch Loss: 0.7054 | Learning Rate: 0.000361 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11491/12542 | Batch Loss: 1.5914 | Learning Rate: 0.000361 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11492/12542 | Batch Loss: 1.9041 | Learning Rate: 0.000361 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11493/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11494/12542 | Batch Loss: 1.8410 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11495/12542 | Batch Loss: 0.3223 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11496/12542 | Batch Loss: 0.5434 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11497/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11498/12542 | Batch Loss: 1.0477 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11499/12542 | Batch Loss: 2.4199 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11500/12542 | Batch Loss: 1.1800 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11501/12542 | Batch Loss: 0.6163 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11502/12542 | Batch Loss: 2.3875 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11503/12542 | Batch Loss: 1.6212 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11504/12542 | Batch Loss: 1.0496 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11505/12542 | Batch Loss: 1.2194 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11506/12542 | Batch Loss: 0.5562 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11507/12542 | Batch Loss: 2.0376 | Learning Rate: 0.000361 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11508/12542 | Batch Loss: 0.8517 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11509/12542 | Batch Loss: 1.2340 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11510/12542 | Batch Loss: 1.3502 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11511/12542 | Batch Loss: 0.9346 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11512/12542 | Batch Loss: 1.7709 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11513/12542 | Batch Loss: 0.9150 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11514/12542 | Batch Loss: 1.3175 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11515/12542 | Batch Loss: 1.0653 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11516/12542 | Batch Loss: 1.8384 | Learning Rate: 0.000361 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11517/12542 | Batch Loss: 0.9080 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11518/12542 | Batch Loss: 1.3508 | Learning Rate: 0.000361 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11519/12542 | Batch Loss: 1.1526 | Learning Rate: 0.000361 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11520/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000360 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11521/12542 | Batch Loss: 0.3637 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11522/12542 | Batch Loss: 1.4814 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11523/12542 | Batch Loss: 1.3188 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11524/12542 | Batch Loss: 1.8687 | Learning Rate: 0.000360 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11525/12542 | Batch Loss: 0.9057 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11526/12542 | Batch Loss: 2.1657 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11527/12542 | Batch Loss: 2.5230 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11528/12542 | Batch Loss: 1.1168 | Learning Rate: 0.000360 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11529/12542 | Batch Loss: 1.1519 | Learning Rate: 0.000360 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11530/12542 | Batch Loss: 0.7655 | Learning Rate: 0.000360 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11531/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000360 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11532/12542 | Batch Loss: 1.3151 | Learning Rate: 0.000360 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11533/12542 | Batch Loss: 2.2424 | Learning Rate: 0.000360 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11534/12542 | Batch Loss: 0.9667 | Learning Rate: 0.000360 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11535/12542 | Batch Loss: 2.4959 | Learning Rate: 0.000360 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11536/12542 | Batch Loss: 1.6008 | Learning Rate: 0.000360 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11537/12542 | Batch Loss: 1.1458 | Learning Rate: 0.000360 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11538/12542 | Batch Loss: 2.1967 | Learning Rate: 0.000360 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11539/12542 | Batch Loss: 0.7460 | Learning Rate: 0.000360 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11540/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000360 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11541/12542 | Batch Loss: 1.1357 | Learning Rate: 0.000360 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11542/12542 | Batch Loss: 1.6534 | Learning Rate: 0.000360 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11543/12542 | Batch Loss: 1.0994 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11544/12542 | Batch Loss: 1.1325 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11545/12542 | Batch Loss: 0.5090 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11546/12542 | Batch Loss: 1.4767 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11547/12542 | Batch Loss: 1.6999 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11548/12542 | Batch Loss: 0.6853 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11549/12542 | Batch Loss: 4.6771 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11550/12542 | Batch Loss: 0.8744 | Learning Rate: 0.000360 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11551/12542 | Batch Loss: 0.4313 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11552/12542 | Batch Loss: 1.3473 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11553/12542 | Batch Loss: 0.8761 | Learning Rate: 0.000360 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11554/12542 | Batch Loss: 0.8654 | Learning Rate: 0.000360 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11555/12542 | Batch Loss: 1.8396 | Learning Rate: 0.000360 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11556/12542 | Batch Loss: 1.2547 | Learning Rate: 0.000360 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11557/12542 | Batch Loss: 0.6680 | Learning Rate: 0.000360 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11558/12542 | Batch Loss: 2.0141 | Learning Rate: 0.000359 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11559/12542 | Batch Loss: 0.9876 | Learning Rate: 0.000359 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11560/12542 | Batch Loss: 0.9074 | Learning Rate: 0.000359 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11561/12542 | Batch Loss: 1.8691 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11562/12542 | Batch Loss: 3.3480 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11563/12542 | Batch Loss: 1.9908 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11564/12542 | Batch Loss: 0.9957 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11565/12542 | Batch Loss: 0.6571 | Learning Rate: 0.000359 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11566/12542 | Batch Loss: 0.4944 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11567/12542 | Batch Loss: 1.4918 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11568/12542 | Batch Loss: 3.4753 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11569/12542 | Batch Loss: 0.7055 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11570/12542 | Batch Loss: 1.7828 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11571/12542 | Batch Loss: 1.8911 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11572/12542 | Batch Loss: 1.3289 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11573/12542 | Batch Loss: 0.9182 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11574/12542 | Batch Loss: 1.5430 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11575/12542 | Batch Loss: 1.5416 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11576/12542 | Batch Loss: 0.7146 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11577/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11578/12542 | Batch Loss: 1.3403 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11579/12542 | Batch Loss: 0.5533 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11580/12542 | Batch Loss: 2.7386 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11581/12542 | Batch Loss: 1.6923 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11582/12542 | Batch Loss: 2.6314 | Learning Rate: 0.000359 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11583/12542 | Batch Loss: 0.9438 | Learning Rate: 0.000359 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11584/12542 | Batch Loss: 0.7241 | Learning Rate: 0.000359 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11585/12542 | Batch Loss: 0.7202 | Learning Rate: 0.000359 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11586/12542 | Batch Loss: 0.6971 | Learning Rate: 0.000359 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11587/12542 | Batch Loss: 1.2090 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11588/12542 | Batch Loss: 1.4720 | Learning Rate: 0.000359 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11589/12542 | Batch Loss: 0.8852 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11590/12542 | Batch Loss: 0.9150 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11591/12542 | Batch Loss: 0.7844 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11592/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11593/12542 | Batch Loss: 0.7839 | Learning Rate: 0.000359 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11594/12542 | Batch Loss: 0.9218 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11595/12542 | Batch Loss: 0.7331 | Learning Rate: 0.000359 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11596/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11597/12542 | Batch Loss: 0.8000 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11598/12542 | Batch Loss: 0.6867 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11599/12542 | Batch Loss: 0.8961 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11600/12542 | Batch Loss: 1.7212 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11601/12542 | Batch Loss: 1.0152 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11602/12542 | Batch Loss: 1.0639 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11603/12542 | Batch Loss: 1.8377 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11604/12542 | Batch Loss: 0.6476 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11605/12542 | Batch Loss: 1.1395 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11606/12542 | Batch Loss: 1.4472 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11607/12542 | Batch Loss: 1.2608 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11608/12542 | Batch Loss: 1.9161 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11609/12542 | Batch Loss: 1.5977 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11610/12542 | Batch Loss: 1.2312 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11611/12542 | Batch Loss: 1.9420 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11612/12542 | Batch Loss: 1.0646 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11613/12542 | Batch Loss: 1.2552 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11614/12542 | Batch Loss: 1.3268 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11615/12542 | Batch Loss: 2.4559 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11616/12542 | Batch Loss: 1.5600 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11617/12542 | Batch Loss: 1.3043 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11618/12542 | Batch Loss: 1.4095 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11619/12542 | Batch Loss: 1.1837 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11620/12542 | Batch Loss: 0.9517 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11621/12542 | Batch Loss: 2.4099 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11622/12542 | Batch Loss: 0.5220 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11623/12542 | Batch Loss: 1.2905 | Learning Rate: 0.000358 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11624/12542 | Batch Loss: 1.3665 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11625/12542 | Batch Loss: 2.0125 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11626/12542 | Batch Loss: 2.4093 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11627/12542 | Batch Loss: 1.5373 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11628/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11629/12542 | Batch Loss: 0.6152 | Learning Rate: 0.000358 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11630/12542 | Batch Loss: 1.4784 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11631/12542 | Batch Loss: 0.6978 | Learning Rate: 0.000358 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11632/12542 | Batch Loss: 1.0855 | Learning Rate: 0.000358 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11633/12542 | Batch Loss: 1.9526 | Learning Rate: 0.000357 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11634/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11635/12542 | Batch Loss: 1.6843 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11636/12542 | Batch Loss: 1.1056 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11637/12542 | Batch Loss: 0.8839 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11638/12542 | Batch Loss: 1.7576 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11639/12542 | Batch Loss: 0.4246 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11640/12542 | Batch Loss: 1.2346 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11641/12542 | Batch Loss: 1.5007 | Learning Rate: 0.000357 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11642/12542 | Batch Loss: 1.3814 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11643/12542 | Batch Loss: 1.5119 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11644/12542 | Batch Loss: 0.5068 | Learning Rate: 0.000357 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11645/12542 | Batch Loss: 1.8930 | Learning Rate: 0.000357 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11646/12542 | Batch Loss: 1.1378 | Learning Rate: 0.000357 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11647/12542 | Batch Loss: 0.8486 | Learning Rate: 0.000357 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11648/12542 | Batch Loss: 0.5741 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11649/12542 | Batch Loss: 1.2396 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11650/12542 | Batch Loss: 1.4034 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11651/12542 | Batch Loss: 0.4552 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11652/12542 | Batch Loss: 1.2343 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11653/12542 | Batch Loss: 0.7381 | Learning Rate: 0.000357 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11654/12542 | Batch Loss: 1.4692 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11655/12542 | Batch Loss: 1.3164 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11656/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11657/12542 | Batch Loss: 1.9910 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11658/12542 | Batch Loss: 0.9189 | Learning Rate: 0.000357 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11659/12542 | Batch Loss: 1.3712 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11660/12542 | Batch Loss: 1.4732 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11661/12542 | Batch Loss: 0.8661 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11662/12542 | Batch Loss: 1.4118 | Learning Rate: 0.000357 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11663/12542 | Batch Loss: 0.8370 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11664/12542 | Batch Loss: 1.6827 | Learning Rate: 0.000357 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11665/12542 | Batch Loss: 1.5443 | Learning Rate: 0.000357 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11666/12542 | Batch Loss: 0.9501 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11667/12542 | Batch Loss: 0.5072 | Learning Rate: 0.000357 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11668/12542 | Batch Loss: 1.2371 | Learning Rate: 0.000357 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11669/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000357 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11670/12542 | Batch Loss: 1.7643 | Learning Rate: 0.000357 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11671/12542 | Batch Loss: 1.8233 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11672/12542 | Batch Loss: 0.9787 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11673/12542 | Batch Loss: 1.5276 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11674/12542 | Batch Loss: 2.6953 | Learning Rate: 0.000356 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11675/12542 | Batch Loss: 1.6297 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11676/12542 | Batch Loss: 1.3987 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11677/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11678/12542 | Batch Loss: 0.7701 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11679/12542 | Batch Loss: 0.9656 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11680/12542 | Batch Loss: 0.3597 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11681/12542 | Batch Loss: 0.9069 | Learning Rate: 0.000356 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11682/12542 | Batch Loss: 1.0948 | Learning Rate: 0.000356 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11683/12542 | Batch Loss: 0.9249 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11684/12542 | Batch Loss: 1.5662 | Learning Rate: 0.000356 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11685/12542 | Batch Loss: 1.2017 | Learning Rate: 0.000356 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11686/12542 | Batch Loss: 1.6282 | Learning Rate: 0.000356 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11687/12542 | Batch Loss: 0.7788 | Learning Rate: 0.000356 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11688/12542 | Batch Loss: 0.8822 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11689/12542 | Batch Loss: 1.9412 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11690/12542 | Batch Loss: 1.9713 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11691/12542 | Batch Loss: 1.9583 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11692/12542 | Batch Loss: 1.9001 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11693/12542 | Batch Loss: 0.9488 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11694/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000356 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11695/12542 | Batch Loss: 1.4491 | Learning Rate: 0.000356 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11696/12542 | Batch Loss: 1.6834 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11697/12542 | Batch Loss: 1.6586 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11698/12542 | Batch Loss: 1.8816 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11699/12542 | Batch Loss: 1.1927 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11700/12542 | Batch Loss: 0.8779 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11701/12542 | Batch Loss: 0.5362 | Learning Rate: 0.000356 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11702/12542 | Batch Loss: 1.4999 | Learning Rate: 0.000356 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11703/12542 | Batch Loss: 1.4485 | Learning Rate: 0.000356 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11704/12542 | Batch Loss: 2.7874 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11705/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000356 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11706/12542 | Batch Loss: 2.7280 | Learning Rate: 0.000356 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11707/12542 | Batch Loss: 2.3772 | Learning Rate: 0.000356 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11708/12542 | Batch Loss: 0.4705 | Learning Rate: 0.000355 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11709/12542 | Batch Loss: 1.7024 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11710/12542 | Batch Loss: 1.1541 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11711/12542 | Batch Loss: 0.7813 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11712/12542 | Batch Loss: 1.1755 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11713/12542 | Batch Loss: 2.6159 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11714/12542 | Batch Loss: 0.5965 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11715/12542 | Batch Loss: 1.5604 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11716/12542 | Batch Loss: 0.9390 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11717/12542 | Batch Loss: 1.6868 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11718/12542 | Batch Loss: 1.1379 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11719/12542 | Batch Loss: 0.8538 | Learning Rate: 0.000355 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11720/12542 | Batch Loss: 0.4719 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11721/12542 | Batch Loss: 0.6030 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11722/12542 | Batch Loss: 0.9782 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11723/12542 | Batch Loss: 0.7373 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11724/12542 | Batch Loss: 1.2411 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11725/12542 | Batch Loss: 2.3354 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11726/12542 | Batch Loss: 2.2122 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11727/12542 | Batch Loss: 1.4142 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11728/12542 | Batch Loss: 1.8022 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11729/12542 | Batch Loss: 0.9344 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11730/12542 | Batch Loss: 2.2067 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11731/12542 | Batch Loss: 1.3891 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11732/12542 | Batch Loss: 1.1641 | Learning Rate: 0.000355 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11733/12542 | Batch Loss: 2.4109 | Learning Rate: 0.000355 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11734/12542 | Batch Loss: 2.6988 | Learning Rate: 0.000355 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11735/12542 | Batch Loss: 1.0498 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11736/12542 | Batch Loss: 0.8154 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11737/12542 | Batch Loss: 2.3615 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11738/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11739/12542 | Batch Loss: 1.1417 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11740/12542 | Batch Loss: 1.0259 | Learning Rate: 0.000355 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11741/12542 | Batch Loss: 0.5915 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11742/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11743/12542 | Batch Loss: 2.0356 | Learning Rate: 0.000355 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11744/12542 | Batch Loss: 3.1616 | Learning Rate: 0.000355 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11745/12542 | Batch Loss: 1.2690 | Learning Rate: 0.000355 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11746/12542 | Batch Loss: 1.9745 | Learning Rate: 0.000354 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11747/12542 | Batch Loss: 1.1024 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11748/12542 | Batch Loss: 1.4980 | Learning Rate: 0.000354 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11749/12542 | Batch Loss: 1.8692 | Learning Rate: 0.000354 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11750/12542 | Batch Loss: 1.6170 | Learning Rate: 0.000354 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11751/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000354 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11752/12542 | Batch Loss: 2.7236 | Learning Rate: 0.000354 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11753/12542 | Batch Loss: 0.9770 | Learning Rate: 0.000354 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11754/12542 | Batch Loss: 1.4482 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11755/12542 | Batch Loss: 2.5308 | Learning Rate: 0.000354 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11756/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11757/12542 | Batch Loss: 1.8447 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11758/12542 | Batch Loss: 1.3549 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11759/12542 | Batch Loss: 1.2952 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11760/12542 | Batch Loss: 0.9065 | Learning Rate: 0.000354 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11761/12542 | Batch Loss: 1.1487 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11762/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11763/12542 | Batch Loss: 1.2388 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11764/12542 | Batch Loss: 2.7087 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11765/12542 | Batch Loss: 0.7758 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11766/12542 | Batch Loss: 1.1738 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11767/12542 | Batch Loss: 2.1010 | Learning Rate: 0.000354 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11768/12542 | Batch Loss: 1.7045 | Learning Rate: 0.000354 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11769/12542 | Batch Loss: 1.1012 | Learning Rate: 0.000354 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11770/12542 | Batch Loss: 1.4024 | Learning Rate: 0.000354 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11771/12542 | Batch Loss: 0.4266 | Learning Rate: 0.000354 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11772/12542 | Batch Loss: 0.6201 | Learning Rate: 0.000354 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11773/12542 | Batch Loss: 1.9581 | Learning Rate: 0.000354 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11774/12542 | Batch Loss: 1.2020 | Learning Rate: 0.000354 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11775/12542 | Batch Loss: 1.0915 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11776/12542 | Batch Loss: 2.1954 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11777/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000354 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11778/12542 | Batch Loss: 1.6280 | Learning Rate: 0.000354 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11779/12542 | Batch Loss: 1.6112 | Learning Rate: 0.000354 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11780/12542 | Batch Loss: 0.9140 | Learning Rate: 0.000354 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11781/12542 | Batch Loss: 1.2945 | Learning Rate: 0.000354 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11782/12542 | Batch Loss: 2.7140 | Learning Rate: 0.000354 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11783/12542 | Batch Loss: 1.6516 | Learning Rate: 0.000354 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11784/12542 | Batch Loss: 1.0386 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11785/12542 | Batch Loss: 1.6051 | Learning Rate: 0.000353 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11786/12542 | Batch Loss: 0.5020 | Learning Rate: 0.000353 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11787/12542 | Batch Loss: 0.7169 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11788/12542 | Batch Loss: 1.4314 | Learning Rate: 0.000353 | Batch Time: 0.54s\n",
      "Epoch 2 | Step 11789/12542 | Batch Loss: 1.3189 | Learning Rate: 0.000353 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11790/12542 | Batch Loss: 1.2588 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11791/12542 | Batch Loss: 1.3942 | Learning Rate: 0.000353 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11792/12542 | Batch Loss: 1.8420 | Learning Rate: 0.000353 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11793/12542 | Batch Loss: 2.3625 | Learning Rate: 0.000353 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11794/12542 | Batch Loss: 2.5863 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11795/12542 | Batch Loss: 0.6591 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11796/12542 | Batch Loss: 0.4416 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11797/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11798/12542 | Batch Loss: 1.5321 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11799/12542 | Batch Loss: 1.2846 | Learning Rate: 0.000353 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11800/12542 | Batch Loss: 2.7503 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11801/12542 | Batch Loss: 1.1348 | Learning Rate: 0.000353 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11802/12542 | Batch Loss: 2.1934 | Learning Rate: 0.000353 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11803/12542 | Batch Loss: 0.4619 | Learning Rate: 0.000353 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11804/12542 | Batch Loss: 1.4242 | Learning Rate: 0.000353 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11805/12542 | Batch Loss: 0.8345 | Learning Rate: 0.000353 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11806/12542 | Batch Loss: 1.4456 | Learning Rate: 0.000353 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11807/12542 | Batch Loss: 0.9469 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11808/12542 | Batch Loss: 1.3849 | Learning Rate: 0.000353 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11809/12542 | Batch Loss: 1.3487 | Learning Rate: 0.000353 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11810/12542 | Batch Loss: 0.9242 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11811/12542 | Batch Loss: 1.0732 | Learning Rate: 0.000353 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11812/12542 | Batch Loss: 0.6994 | Learning Rate: 0.000353 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11813/12542 | Batch Loss: 1.7094 | Learning Rate: 0.000353 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11814/12542 | Batch Loss: 1.5405 | Learning Rate: 0.000353 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11815/12542 | Batch Loss: 0.6623 | Learning Rate: 0.000353 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11816/12542 | Batch Loss: 1.1837 | Learning Rate: 0.000353 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11817/12542 | Batch Loss: 1.7269 | Learning Rate: 0.000353 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11818/12542 | Batch Loss: 1.7537 | Learning Rate: 0.000353 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11819/12542 | Batch Loss: 1.6498 | Learning Rate: 0.000353 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11820/12542 | Batch Loss: 1.2346 | Learning Rate: 0.000353 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11821/12542 | Batch Loss: 1.8829 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11822/12542 | Batch Loss: 1.6496 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11823/12542 | Batch Loss: 2.2703 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11824/12542 | Batch Loss: 0.9561 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11825/12542 | Batch Loss: 0.7506 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11826/12542 | Batch Loss: 0.7632 | Learning Rate: 0.000352 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11827/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11828/12542 | Batch Loss: 1.5120 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11829/12542 | Batch Loss: 2.4712 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11830/12542 | Batch Loss: 2.0772 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11831/12542 | Batch Loss: 1.1099 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11832/12542 | Batch Loss: 2.2707 | Learning Rate: 0.000352 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11833/12542 | Batch Loss: 1.9998 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11834/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000352 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11835/12542 | Batch Loss: 1.9116 | Learning Rate: 0.000352 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11836/12542 | Batch Loss: 0.8956 | Learning Rate: 0.000352 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11837/12542 | Batch Loss: 1.5119 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11838/12542 | Batch Loss: 0.8411 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11839/12542 | Batch Loss: 1.4053 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11840/12542 | Batch Loss: 1.0891 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11841/12542 | Batch Loss: 2.9736 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11842/12542 | Batch Loss: 0.6539 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11843/12542 | Batch Loss: 2.0146 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11844/12542 | Batch Loss: 1.0099 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11845/12542 | Batch Loss: 0.2766 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11846/12542 | Batch Loss: 1.7593 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11847/12542 | Batch Loss: 0.7648 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11848/12542 | Batch Loss: 0.9176 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11849/12542 | Batch Loss: 1.0920 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11850/12542 | Batch Loss: 1.7457 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11851/12542 | Batch Loss: 0.4513 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11852/12542 | Batch Loss: 0.9809 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11853/12542 | Batch Loss: 0.9234 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11854/12542 | Batch Loss: 1.9774 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11855/12542 | Batch Loss: 1.2188 | Learning Rate: 0.000352 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11856/12542 | Batch Loss: 2.1004 | Learning Rate: 0.000352 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11857/12542 | Batch Loss: 1.0357 | Learning Rate: 0.000352 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11858/12542 | Batch Loss: 2.0623 | Learning Rate: 0.000352 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11859/12542 | Batch Loss: 1.2151 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11860/12542 | Batch Loss: 2.0887 | Learning Rate: 0.000351 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11861/12542 | Batch Loss: 1.9736 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11862/12542 | Batch Loss: 2.7478 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11863/12542 | Batch Loss: 1.6374 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11864/12542 | Batch Loss: 1.0085 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11865/12542 | Batch Loss: 2.8317 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11866/12542 | Batch Loss: 2.5613 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11867/12542 | Batch Loss: 0.5083 | Learning Rate: 0.000351 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11868/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11869/12542 | Batch Loss: 1.6370 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11870/12542 | Batch Loss: 0.8215 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11871/12542 | Batch Loss: 2.1451 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11872/12542 | Batch Loss: 2.1222 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11873/12542 | Batch Loss: 1.8021 | Learning Rate: 0.000351 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11874/12542 | Batch Loss: 2.2402 | Learning Rate: 0.000351 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11875/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000351 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11876/12542 | Batch Loss: 2.9303 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11877/12542 | Batch Loss: 1.6526 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11878/12542 | Batch Loss: 1.3483 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11879/12542 | Batch Loss: 1.7606 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11880/12542 | Batch Loss: 3.0126 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11881/12542 | Batch Loss: 0.7876 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11882/12542 | Batch Loss: 1.0634 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11883/12542 | Batch Loss: 1.1888 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11884/12542 | Batch Loss: 0.8478 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11885/12542 | Batch Loss: 1.9360 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11886/12542 | Batch Loss: 1.6639 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11887/12542 | Batch Loss: 1.1000 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11888/12542 | Batch Loss: 0.6626 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11889/12542 | Batch Loss: 1.2185 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11890/12542 | Batch Loss: 1.0732 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11891/12542 | Batch Loss: 1.6736 | Learning Rate: 0.000351 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11892/12542 | Batch Loss: 1.7827 | Learning Rate: 0.000351 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11893/12542 | Batch Loss: 1.7756 | Learning Rate: 0.000351 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11894/12542 | Batch Loss: 1.5519 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11895/12542 | Batch Loss: 1.1559 | Learning Rate: 0.000351 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11896/12542 | Batch Loss: 0.7896 | Learning Rate: 0.000351 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11897/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11898/12542 | Batch Loss: 1.8947 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11899/12542 | Batch Loss: 2.5039 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11900/12542 | Batch Loss: 0.7126 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11901/12542 | Batch Loss: 1.9731 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11902/12542 | Batch Loss: 1.8329 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11903/12542 | Batch Loss: 2.2529 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11904/12542 | Batch Loss: 0.8189 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11905/12542 | Batch Loss: 1.0131 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11906/12542 | Batch Loss: 0.8672 | Learning Rate: 0.000350 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11907/12542 | Batch Loss: 1.7752 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11908/12542 | Batch Loss: 1.9091 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11909/12542 | Batch Loss: 2.3590 | Learning Rate: 0.000350 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11910/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000350 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11911/12542 | Batch Loss: 1.3996 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11912/12542 | Batch Loss: 1.4775 | Learning Rate: 0.000350 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 11913/12542 | Batch Loss: 1.6261 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11914/12542 | Batch Loss: 1.0834 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11915/12542 | Batch Loss: 1.4224 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11916/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000350 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11917/12542 | Batch Loss: 1.3427 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11918/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000350 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11919/12542 | Batch Loss: 1.7949 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11920/12542 | Batch Loss: 0.4667 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11921/12542 | Batch Loss: 1.4692 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11922/12542 | Batch Loss: 0.5968 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11923/12542 | Batch Loss: 1.6182 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11924/12542 | Batch Loss: 3.2066 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11925/12542 | Batch Loss: 0.9589 | Learning Rate: 0.000350 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11926/12542 | Batch Loss: 1.6300 | Learning Rate: 0.000350 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11927/12542 | Batch Loss: 1.3368 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11928/12542 | Batch Loss: 1.0998 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11929/12542 | Batch Loss: 1.7530 | Learning Rate: 0.000350 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11930/12542 | Batch Loss: 1.6915 | Learning Rate: 0.000350 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11931/12542 | Batch Loss: 1.0145 | Learning Rate: 0.000350 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11932/12542 | Batch Loss: 2.2183 | Learning Rate: 0.000350 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11933/12542 | Batch Loss: 1.5748 | Learning Rate: 0.000350 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11934/12542 | Batch Loss: 0.7066 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11935/12542 | Batch Loss: 2.2664 | Learning Rate: 0.000349 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11936/12542 | Batch Loss: 0.7803 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11937/12542 | Batch Loss: 1.6363 | Learning Rate: 0.000349 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11938/12542 | Batch Loss: 0.7754 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11939/12542 | Batch Loss: 1.3868 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11940/12542 | Batch Loss: 1.0676 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11941/12542 | Batch Loss: 1.1639 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11942/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000349 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11943/12542 | Batch Loss: 1.8017 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11944/12542 | Batch Loss: 1.8210 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11945/12542 | Batch Loss: 1.0324 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11946/12542 | Batch Loss: 2.0916 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11947/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11948/12542 | Batch Loss: 1.2754 | Learning Rate: 0.000349 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11949/12542 | Batch Loss: 1.0480 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11950/12542 | Batch Loss: 3.1185 | Learning Rate: 0.000349 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11951/12542 | Batch Loss: 1.6268 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11952/12542 | Batch Loss: 1.1750 | Learning Rate: 0.000349 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11953/12542 | Batch Loss: 1.5048 | Learning Rate: 0.000349 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11954/12542 | Batch Loss: 0.4649 | Learning Rate: 0.000349 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 11955/12542 | Batch Loss: 0.9768 | Learning Rate: 0.000349 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11956/12542 | Batch Loss: 1.0444 | Learning Rate: 0.000349 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11957/12542 | Batch Loss: 0.8987 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11958/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11959/12542 | Batch Loss: 2.3560 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11960/12542 | Batch Loss: 2.3720 | Learning Rate: 0.000349 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11961/12542 | Batch Loss: 1.1136 | Learning Rate: 0.000349 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11962/12542 | Batch Loss: 1.8143 | Learning Rate: 0.000349 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11963/12542 | Batch Loss: 2.5286 | Learning Rate: 0.000349 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11964/12542 | Batch Loss: 1.3672 | Learning Rate: 0.000349 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11965/12542 | Batch Loss: 0.6894 | Learning Rate: 0.000349 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11966/12542 | Batch Loss: 1.4939 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11967/12542 | Batch Loss: 1.8814 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11968/12542 | Batch Loss: 1.5094 | Learning Rate: 0.000349 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11969/12542 | Batch Loss: 0.8883 | Learning Rate: 0.000349 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11970/12542 | Batch Loss: 0.7954 | Learning Rate: 0.000349 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11971/12542 | Batch Loss: 2.0141 | Learning Rate: 0.000349 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11972/12542 | Batch Loss: 0.8599 | Learning Rate: 0.000348 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 11973/12542 | Batch Loss: 2.2590 | Learning Rate: 0.000348 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 11974/12542 | Batch Loss: 1.7196 | Learning Rate: 0.000348 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 11975/12542 | Batch Loss: 3.2286 | Learning Rate: 0.000348 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 11976/12542 | Batch Loss: 0.5601 | Learning Rate: 0.000348 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 11977/12542 | Batch Loss: 1.1358 | Learning Rate: 0.000348 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11978/12542 | Batch Loss: 0.8576 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11979/12542 | Batch Loss: 1.5253 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11980/12542 | Batch Loss: 0.6243 | Learning Rate: 0.000348 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11981/12542 | Batch Loss: 1.5818 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11982/12542 | Batch Loss: 1.6311 | Learning Rate: 0.000348 | Batch Time: 0.55s\n",
      "Epoch 2 | Step 11983/12542 | Batch Loss: 1.9887 | Learning Rate: 0.000348 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11984/12542 | Batch Loss: 0.6656 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11985/12542 | Batch Loss: 0.6202 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11986/12542 | Batch Loss: 1.1072 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11987/12542 | Batch Loss: 0.7042 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11988/12542 | Batch Loss: 1.2966 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11989/12542 | Batch Loss: 0.6551 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11990/12542 | Batch Loss: 1.8598 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 11991/12542 | Batch Loss: 0.9848 | Learning Rate: 0.000348 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 11992/12542 | Batch Loss: 0.4334 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11993/12542 | Batch Loss: 1.2253 | Learning Rate: 0.000348 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 11994/12542 | Batch Loss: 0.4929 | Learning Rate: 0.000348 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11995/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000348 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 11996/12542 | Batch Loss: 0.5500 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 11997/12542 | Batch Loss: 1.6642 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11998/12542 | Batch Loss: 1.5330 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 11999/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000348 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12000/12542 | Batch Loss: 0.4722 | Learning Rate: 0.000348 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12001/12542 | Batch Loss: 1.5951 | Learning Rate: 0.000348 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12002/12542 | Batch Loss: 1.2674 | Learning Rate: 0.000348 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12003/12542 | Batch Loss: 0.8342 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12004/12542 | Batch Loss: 2.5342 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12005/12542 | Batch Loss: 1.1485 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12006/12542 | Batch Loss: 1.1571 | Learning Rate: 0.000348 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12007/12542 | Batch Loss: 2.6440 | Learning Rate: 0.000348 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12008/12542 | Batch Loss: 0.6512 | Learning Rate: 0.000348 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12009/12542 | Batch Loss: 2.1073 | Learning Rate: 0.000347 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12010/12542 | Batch Loss: 0.8381 | Learning Rate: 0.000347 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12011/12542 | Batch Loss: 1.7192 | Learning Rate: 0.000347 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12012/12542 | Batch Loss: 1.7108 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12013/12542 | Batch Loss: 1.4149 | Learning Rate: 0.000347 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12014/12542 | Batch Loss: 2.4234 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12015/12542 | Batch Loss: 0.6219 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12016/12542 | Batch Loss: 1.2616 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12017/12542 | Batch Loss: 1.1371 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12018/12542 | Batch Loss: 2.2064 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12019/12542 | Batch Loss: 1.0673 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12020/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12021/12542 | Batch Loss: 0.8030 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12022/12542 | Batch Loss: 0.9360 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12023/12542 | Batch Loss: 1.0770 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12024/12542 | Batch Loss: 0.6391 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12025/12542 | Batch Loss: 1.1316 | Learning Rate: 0.000347 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12026/12542 | Batch Loss: 1.0523 | Learning Rate: 0.000347 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12027/12542 | Batch Loss: 1.7441 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12028/12542 | Batch Loss: 0.8267 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12029/12542 | Batch Loss: 1.9541 | Learning Rate: 0.000347 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12030/12542 | Batch Loss: 1.0519 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12031/12542 | Batch Loss: 0.9449 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12032/12542 | Batch Loss: 1.1126 | Learning Rate: 0.000347 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12033/12542 | Batch Loss: 1.5770 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12034/12542 | Batch Loss: 1.3401 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12035/12542 | Batch Loss: 0.5356 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12036/12542 | Batch Loss: 1.1779 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12037/12542 | Batch Loss: 1.8444 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12038/12542 | Batch Loss: 1.2266 | Learning Rate: 0.000347 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12039/12542 | Batch Loss: 1.6303 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12040/12542 | Batch Loss: 2.3029 | Learning Rate: 0.000347 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12041/12542 | Batch Loss: 1.2749 | Learning Rate: 0.000347 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12042/12542 | Batch Loss: 1.5495 | Learning Rate: 0.000347 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12043/12542 | Batch Loss: 1.5274 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12044/12542 | Batch Loss: 1.6274 | Learning Rate: 0.000347 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12045/12542 | Batch Loss: 1.5152 | Learning Rate: 0.000347 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12046/12542 | Batch Loss: 1.7421 | Learning Rate: 0.000347 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12047/12542 | Batch Loss: 0.4475 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12048/12542 | Batch Loss: 0.7705 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12049/12542 | Batch Loss: 0.9622 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12050/12542 | Batch Loss: 1.3525 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12051/12542 | Batch Loss: 1.5563 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12052/12542 | Batch Loss: 0.8198 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12053/12542 | Batch Loss: 1.4619 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12054/12542 | Batch Loss: 1.6073 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12055/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12056/12542 | Batch Loss: 1.0918 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12057/12542 | Batch Loss: 2.0692 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12058/12542 | Batch Loss: 0.9920 | Learning Rate: 0.000346 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12059/12542 | Batch Loss: 3.3476 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12060/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12061/12542 | Batch Loss: 0.6909 | Learning Rate: 0.000346 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12062/12542 | Batch Loss: 1.3350 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12063/12542 | Batch Loss: 1.0665 | Learning Rate: 0.000346 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12064/12542 | Batch Loss: 0.6300 | Learning Rate: 0.000346 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12065/12542 | Batch Loss: 0.7640 | Learning Rate: 0.000346 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12066/12542 | Batch Loss: 0.6673 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12067/12542 | Batch Loss: 2.3436 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12068/12542 | Batch Loss: 1.1150 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12069/12542 | Batch Loss: 1.4256 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12070/12542 | Batch Loss: 3.1960 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12071/12542 | Batch Loss: 0.6346 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12072/12542 | Batch Loss: 0.5635 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12073/12542 | Batch Loss: 1.1501 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12074/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12075/12542 | Batch Loss: 0.6538 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12076/12542 | Batch Loss: 1.2419 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12077/12542 | Batch Loss: 0.2496 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12078/12542 | Batch Loss: 0.7309 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12079/12542 | Batch Loss: 1.4622 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12080/12542 | Batch Loss: 1.3302 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12081/12542 | Batch Loss: 0.3564 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12082/12542 | Batch Loss: 2.0432 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12083/12542 | Batch Loss: 0.7846 | Learning Rate: 0.000346 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12084/12542 | Batch Loss: 1.6900 | Learning Rate: 0.000346 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12085/12542 | Batch Loss: 1.1065 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12086/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12087/12542 | Batch Loss: 3.6912 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12088/12542 | Batch Loss: 1.4520 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12089/12542 | Batch Loss: 2.4120 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12090/12542 | Batch Loss: 0.9639 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12091/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12092/12542 | Batch Loss: 1.1171 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12093/12542 | Batch Loss: 0.7826 | Learning Rate: 0.000345 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12094/12542 | Batch Loss: 0.6520 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12095/12542 | Batch Loss: 1.4032 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12096/12542 | Batch Loss: 1.1616 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12097/12542 | Batch Loss: 1.2102 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12098/12542 | Batch Loss: 1.4799 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12099/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12100/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12101/12542 | Batch Loss: 2.7706 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12102/12542 | Batch Loss: 0.8422 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12103/12542 | Batch Loss: 0.9353 | Learning Rate: 0.000345 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12104/12542 | Batch Loss: 1.1828 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12105/12542 | Batch Loss: 0.9490 | Learning Rate: 0.000345 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12106/12542 | Batch Loss: 2.2176 | Learning Rate: 0.000345 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12107/12542 | Batch Loss: 0.8548 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12108/12542 | Batch Loss: 1.3216 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12109/12542 | Batch Loss: 0.7197 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12110/12542 | Batch Loss: 0.7581 | Learning Rate: 0.000345 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12111/12542 | Batch Loss: 0.7062 | Learning Rate: 0.000345 | Batch Time: 0.56s\n",
      "Epoch 2 | Step 12112/12542 | Batch Loss: 0.7804 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12113/12542 | Batch Loss: 0.7030 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12114/12542 | Batch Loss: 0.4287 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12115/12542 | Batch Loss: 2.1885 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12116/12542 | Batch Loss: 1.9611 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12117/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000345 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12118/12542 | Batch Loss: 1.1955 | Learning Rate: 0.000345 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12119/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000345 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12120/12542 | Batch Loss: 1.4023 | Learning Rate: 0.000345 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12121/12542 | Batch Loss: 1.6918 | Learning Rate: 0.000345 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12122/12542 | Batch Loss: 1.3141 | Learning Rate: 0.000344 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12123/12542 | Batch Loss: 1.2023 | Learning Rate: 0.000344 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12124/12542 | Batch Loss: 1.4607 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12125/12542 | Batch Loss: 1.2140 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12126/12542 | Batch Loss: 1.1705 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12127/12542 | Batch Loss: 1.1489 | Learning Rate: 0.000344 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12128/12542 | Batch Loss: 1.1743 | Learning Rate: 0.000344 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12129/12542 | Batch Loss: 0.9968 | Learning Rate: 0.000344 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12130/12542 | Batch Loss: 0.6983 | Learning Rate: 0.000344 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12131/12542 | Batch Loss: 2.6355 | Learning Rate: 0.000344 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12132/12542 | Batch Loss: 0.9075 | Learning Rate: 0.000344 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12133/12542 | Batch Loss: 1.4081 | Learning Rate: 0.000344 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12134/12542 | Batch Loss: 0.7198 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12135/12542 | Batch Loss: 1.6759 | Learning Rate: 0.000344 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12136/12542 | Batch Loss: 0.7234 | Learning Rate: 0.000344 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12137/12542 | Batch Loss: 2.1833 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12138/12542 | Batch Loss: 1.2010 | Learning Rate: 0.000344 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12139/12542 | Batch Loss: 0.8654 | Learning Rate: 0.000344 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12140/12542 | Batch Loss: 2.4613 | Learning Rate: 0.000344 | Batch Time: 0.69s\n",
      "Epoch 2 | Step 12141/12542 | Batch Loss: 0.8047 | Learning Rate: 0.000344 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12142/12542 | Batch Loss: 1.7578 | Learning Rate: 0.000344 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12143/12542 | Batch Loss: 1.3174 | Learning Rate: 0.000344 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12144/12542 | Batch Loss: 1.0808 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12145/12542 | Batch Loss: 1.2536 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12146/12542 | Batch Loss: 1.3674 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12147/12542 | Batch Loss: 0.9136 | Learning Rate: 0.000344 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12148/12542 | Batch Loss: 0.3889 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12149/12542 | Batch Loss: 1.1735 | Learning Rate: 0.000344 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12150/12542 | Batch Loss: 1.0725 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12151/12542 | Batch Loss: 1.0900 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12152/12542 | Batch Loss: 0.8250 | Learning Rate: 0.000344 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12153/12542 | Batch Loss: 0.9650 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12154/12542 | Batch Loss: 0.7525 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12155/12542 | Batch Loss: 1.4637 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12156/12542 | Batch Loss: 1.3529 | Learning Rate: 0.000344 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12157/12542 | Batch Loss: 1.4802 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12158/12542 | Batch Loss: 0.9892 | Learning Rate: 0.000344 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12159/12542 | Batch Loss: 1.3952 | Learning Rate: 0.000344 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12160/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000343 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12161/12542 | Batch Loss: 0.7385 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12162/12542 | Batch Loss: 3.0069 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12163/12542 | Batch Loss: 3.0830 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12164/12542 | Batch Loss: 0.9011 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12165/12542 | Batch Loss: 3.2514 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12166/12542 | Batch Loss: 1.8742 | Learning Rate: 0.000343 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12167/12542 | Batch Loss: 2.0402 | Learning Rate: 0.000343 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12168/12542 | Batch Loss: 1.3040 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12169/12542 | Batch Loss: 1.3979 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12170/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12171/12542 | Batch Loss: 0.7070 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12172/12542 | Batch Loss: 1.7721 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12173/12542 | Batch Loss: 2.0084 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12174/12542 | Batch Loss: 1.6553 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12175/12542 | Batch Loss: 1.6574 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12176/12542 | Batch Loss: 3.2115 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12177/12542 | Batch Loss: 1.1615 | Learning Rate: 0.000343 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12178/12542 | Batch Loss: 1.8239 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12179/12542 | Batch Loss: 1.0600 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12180/12542 | Batch Loss: 0.9130 | Learning Rate: 0.000343 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12181/12542 | Batch Loss: 1.9672 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12182/12542 | Batch Loss: 2.1373 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12183/12542 | Batch Loss: 1.1582 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12184/12542 | Batch Loss: 1.4461 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12185/12542 | Batch Loss: 0.8534 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12186/12542 | Batch Loss: 0.3923 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12187/12542 | Batch Loss: 1.8142 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12188/12542 | Batch Loss: 0.8639 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12189/12542 | Batch Loss: 0.7672 | Learning Rate: 0.000343 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12190/12542 | Batch Loss: 1.8886 | Learning Rate: 0.000343 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12191/12542 | Batch Loss: 2.4019 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12192/12542 | Batch Loss: 1.9953 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12193/12542 | Batch Loss: 1.1165 | Learning Rate: 0.000343 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12194/12542 | Batch Loss: 1.4610 | Learning Rate: 0.000343 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12195/12542 | Batch Loss: 0.8364 | Learning Rate: 0.000343 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12196/12542 | Batch Loss: 1.6626 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12197/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000343 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12198/12542 | Batch Loss: 2.2467 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12199/12542 | Batch Loss: 0.9412 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12200/12542 | Batch Loss: 0.6584 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12201/12542 | Batch Loss: 1.4556 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12202/12542 | Batch Loss: 2.0779 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12203/12542 | Batch Loss: 1.6476 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12204/12542 | Batch Loss: 0.7925 | Learning Rate: 0.000342 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12205/12542 | Batch Loss: 2.7150 | Learning Rate: 0.000342 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12206/12542 | Batch Loss: 1.2218 | Learning Rate: 0.000342 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12207/12542 | Batch Loss: 0.6929 | Learning Rate: 0.000342 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12208/12542 | Batch Loss: 1.7084 | Learning Rate: 0.000342 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12209/12542 | Batch Loss: 1.9908 | Learning Rate: 0.000342 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12210/12542 | Batch Loss: 1.1229 | Learning Rate: 0.000342 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12211/12542 | Batch Loss: 1.1664 | Learning Rate: 0.000342 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12212/12542 | Batch Loss: 0.8982 | Learning Rate: 0.000342 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12213/12542 | Batch Loss: 0.8964 | Learning Rate: 0.000342 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12214/12542 | Batch Loss: 1.3691 | Learning Rate: 0.000342 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12215/12542 | Batch Loss: 1.3970 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12216/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12217/12542 | Batch Loss: 1.5931 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12218/12542 | Batch Loss: 1.9081 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12219/12542 | Batch Loss: 0.6287 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12220/12542 | Batch Loss: 0.7814 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12221/12542 | Batch Loss: 0.6804 | Learning Rate: 0.000342 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12222/12542 | Batch Loss: 1.2392 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12223/12542 | Batch Loss: 1.1301 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12224/12542 | Batch Loss: 0.8450 | Learning Rate: 0.000342 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12225/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000342 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12226/12542 | Batch Loss: 1.6617 | Learning Rate: 0.000342 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12227/12542 | Batch Loss: 2.4047 | Learning Rate: 0.000342 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12228/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000342 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12229/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000342 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12230/12542 | Batch Loss: 0.9443 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12231/12542 | Batch Loss: 0.8572 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12232/12542 | Batch Loss: 1.6762 | Learning Rate: 0.000342 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12233/12542 | Batch Loss: 1.0825 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12234/12542 | Batch Loss: 3.1416 | Learning Rate: 0.000342 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12235/12542 | Batch Loss: 0.8664 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12236/12542 | Batch Loss: 1.5529 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12237/12542 | Batch Loss: 1.4550 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12238/12542 | Batch Loss: 1.3409 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12239/12542 | Batch Loss: 1.9342 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12240/12542 | Batch Loss: 1.4343 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12241/12542 | Batch Loss: 0.7891 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12242/12542 | Batch Loss: 0.9018 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12243/12542 | Batch Loss: 1.3939 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12244/12542 | Batch Loss: 1.3254 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12245/12542 | Batch Loss: 1.5304 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12246/12542 | Batch Loss: 1.4106 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12247/12542 | Batch Loss: 1.5510 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12248/12542 | Batch Loss: 1.1686 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12249/12542 | Batch Loss: 0.4851 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12250/12542 | Batch Loss: 0.5700 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12251/12542 | Batch Loss: 2.1999 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12252/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12253/12542 | Batch Loss: 0.7729 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12254/12542 | Batch Loss: 1.1471 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12255/12542 | Batch Loss: 2.9947 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12256/12542 | Batch Loss: 1.1228 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12257/12542 | Batch Loss: 0.6042 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12258/12542 | Batch Loss: 1.9341 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12259/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12260/12542 | Batch Loss: 0.9799 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12261/12542 | Batch Loss: 2.2847 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12262/12542 | Batch Loss: 0.6091 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12263/12542 | Batch Loss: 0.6736 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12264/12542 | Batch Loss: 0.9238 | Learning Rate: 0.000341 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12265/12542 | Batch Loss: 2.7484 | Learning Rate: 0.000341 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12266/12542 | Batch Loss: 1.3141 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12267/12542 | Batch Loss: 2.0182 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12268/12542 | Batch Loss: 2.1309 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12269/12542 | Batch Loss: 1.2964 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12270/12542 | Batch Loss: 1.6973 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12271/12542 | Batch Loss: 2.1198 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12272/12542 | Batch Loss: 1.0461 | Learning Rate: 0.000341 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12273/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12274/12542 | Batch Loss: 1.0651 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12275/12542 | Batch Loss: 2.0245 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12276/12542 | Batch Loss: 0.9179 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12277/12542 | Batch Loss: 1.4845 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12278/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12279/12542 | Batch Loss: 0.8418 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12280/12542 | Batch Loss: 1.7733 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12281/12542 | Batch Loss: 0.8774 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12282/12542 | Batch Loss: 1.4047 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12283/12542 | Batch Loss: 0.8407 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12284/12542 | Batch Loss: 0.6748 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12285/12542 | Batch Loss: 1.6937 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12286/12542 | Batch Loss: 1.3972 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12287/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12288/12542 | Batch Loss: 1.4496 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12289/12542 | Batch Loss: 1.8093 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12290/12542 | Batch Loss: 0.9148 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12291/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12292/12542 | Batch Loss: 1.2043 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12293/12542 | Batch Loss: 1.9754 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12294/12542 | Batch Loss: 1.7331 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12295/12542 | Batch Loss: 0.9181 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12296/12542 | Batch Loss: 1.4297 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12297/12542 | Batch Loss: 1.7493 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12298/12542 | Batch Loss: 1.0787 | Learning Rate: 0.000340 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12299/12542 | Batch Loss: 1.3339 | Learning Rate: 0.000340 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12300/12542 | Batch Loss: 1.3095 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12301/12542 | Batch Loss: 1.0885 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12302/12542 | Batch Loss: 0.5429 | Learning Rate: 0.000340 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12303/12542 | Batch Loss: 2.4817 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12304/12542 | Batch Loss: 1.2591 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12305/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12306/12542 | Batch Loss: 1.3565 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12307/12542 | Batch Loss: 1.7629 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12308/12542 | Batch Loss: 1.2539 | Learning Rate: 0.000340 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12309/12542 | Batch Loss: 0.7543 | Learning Rate: 0.000340 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12310/12542 | Batch Loss: 0.3308 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12311/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12312/12542 | Batch Loss: 0.7793 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12313/12542 | Batch Loss: 1.9668 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12314/12542 | Batch Loss: 1.2642 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12315/12542 | Batch Loss: 1.8494 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12316/12542 | Batch Loss: 2.6104 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12317/12542 | Batch Loss: 1.3469 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12318/12542 | Batch Loss: 1.1620 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12319/12542 | Batch Loss: 0.4449 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12320/12542 | Batch Loss: 0.6567 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12321/12542 | Batch Loss: 2.1800 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12322/12542 | Batch Loss: 0.6552 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12323/12542 | Batch Loss: 0.8933 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12324/12542 | Batch Loss: 1.2076 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12325/12542 | Batch Loss: 0.9678 | Learning Rate: 0.000339 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12326/12542 | Batch Loss: 0.6193 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12327/12542 | Batch Loss: 0.8459 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12328/12542 | Batch Loss: 1.6979 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12329/12542 | Batch Loss: 3.3938 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12330/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12331/12542 | Batch Loss: 1.4542 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12332/12542 | Batch Loss: 0.8869 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12333/12542 | Batch Loss: 1.0673 | Learning Rate: 0.000339 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12334/12542 | Batch Loss: 1.9918 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12335/12542 | Batch Loss: 2.5237 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12336/12542 | Batch Loss: 1.6408 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12337/12542 | Batch Loss: 1.2136 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12338/12542 | Batch Loss: 3.5531 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12339/12542 | Batch Loss: 1.6584 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12340/12542 | Batch Loss: 0.7661 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12341/12542 | Batch Loss: 2.2222 | Learning Rate: 0.000339 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12342/12542 | Batch Loss: 1.0794 | Learning Rate: 0.000339 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12343/12542 | Batch Loss: 1.2875 | Learning Rate: 0.000339 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12344/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000339 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12345/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000339 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12346/12542 | Batch Loss: 1.5813 | Learning Rate: 0.000339 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12347/12542 | Batch Loss: 0.8600 | Learning Rate: 0.000339 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12348/12542 | Batch Loss: 1.4270 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12349/12542 | Batch Loss: 1.6735 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12350/12542 | Batch Loss: 1.3759 | Learning Rate: 0.000338 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12351/12542 | Batch Loss: 0.6794 | Learning Rate: 0.000338 | Batch Time: 0.65s\n",
      "Epoch 2 | Step 12352/12542 | Batch Loss: 1.6996 | Learning Rate: 0.000338 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12353/12542 | Batch Loss: 1.6837 | Learning Rate: 0.000338 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12354/12542 | Batch Loss: 0.7202 | Learning Rate: 0.000338 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12355/12542 | Batch Loss: 1.8045 | Learning Rate: 0.000338 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12356/12542 | Batch Loss: 1.2129 | Learning Rate: 0.000338 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12357/12542 | Batch Loss: 1.3386 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12358/12542 | Batch Loss: 1.2306 | Learning Rate: 0.000338 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12359/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000338 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12360/12542 | Batch Loss: 1.3108 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12361/12542 | Batch Loss: 0.6878 | Learning Rate: 0.000338 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12362/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000338 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12363/12542 | Batch Loss: 2.4710 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12364/12542 | Batch Loss: 1.0562 | Learning Rate: 0.000338 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12365/12542 | Batch Loss: 0.8562 | Learning Rate: 0.000338 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12366/12542 | Batch Loss: 1.8634 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12367/12542 | Batch Loss: 0.5799 | Learning Rate: 0.000338 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12368/12542 | Batch Loss: 2.4087 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12369/12542 | Batch Loss: 1.3481 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12370/12542 | Batch Loss: 1.0994 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12371/12542 | Batch Loss: 0.7691 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12372/12542 | Batch Loss: 2.0868 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12373/12542 | Batch Loss: 0.8500 | Learning Rate: 0.000338 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12374/12542 | Batch Loss: 2.4643 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12375/12542 | Batch Loss: 1.0678 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12376/12542 | Batch Loss: 0.8605 | Learning Rate: 0.000338 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12377/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000338 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12378/12542 | Batch Loss: 1.3877 | Learning Rate: 0.000338 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12379/12542 | Batch Loss: 1.7208 | Learning Rate: 0.000338 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12380/12542 | Batch Loss: 1.8256 | Learning Rate: 0.000338 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12381/12542 | Batch Loss: 1.0914 | Learning Rate: 0.000338 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12382/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12383/12542 | Batch Loss: 1.4223 | Learning Rate: 0.000338 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12384/12542 | Batch Loss: 1.1541 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12385/12542 | Batch Loss: 1.0827 | Learning Rate: 0.000338 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12386/12542 | Batch Loss: 1.1145 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12387/12542 | Batch Loss: 2.0225 | Learning Rate: 0.000337 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12388/12542 | Batch Loss: 1.4795 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12389/12542 | Batch Loss: 0.8385 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12390/12542 | Batch Loss: 0.6107 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12391/12542 | Batch Loss: 2.1771 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12392/12542 | Batch Loss: 0.6561 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12393/12542 | Batch Loss: 2.0266 | Learning Rate: 0.000337 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12394/12542 | Batch Loss: 1.3566 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12395/12542 | Batch Loss: 0.8903 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12396/12542 | Batch Loss: 0.6640 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12397/12542 | Batch Loss: 1.1160 | Learning Rate: 0.000337 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12398/12542 | Batch Loss: 1.1728 | Learning Rate: 0.000337 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12399/12542 | Batch Loss: 1.5337 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12400/12542 | Batch Loss: 0.8058 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12401/12542 | Batch Loss: 1.9425 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12402/12542 | Batch Loss: 1.6481 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12403/12542 | Batch Loss: 1.6731 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12404/12542 | Batch Loss: 1.0470 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12405/12542 | Batch Loss: 0.7904 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12406/12542 | Batch Loss: 0.6449 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12407/12542 | Batch Loss: 0.8504 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12408/12542 | Batch Loss: 0.5215 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12409/12542 | Batch Loss: 2.2159 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12410/12542 | Batch Loss: 1.3039 | Learning Rate: 0.000337 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12411/12542 | Batch Loss: 0.7317 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12412/12542 | Batch Loss: 1.1949 | Learning Rate: 0.000337 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12413/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12414/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000337 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12415/12542 | Batch Loss: 1.6108 | Learning Rate: 0.000337 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12416/12542 | Batch Loss: 1.0923 | Learning Rate: 0.000337 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12417/12542 | Batch Loss: 1.3740 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12418/12542 | Batch Loss: 1.0228 | Learning Rate: 0.000337 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12419/12542 | Batch Loss: 1.1536 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12420/12542 | Batch Loss: 1.0093 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12421/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000337 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12422/12542 | Batch Loss: 1.6568 | Learning Rate: 0.000337 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12423/12542 | Batch Loss: 1.1504 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12424/12542 | Batch Loss: 1.1149 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12425/12542 | Batch Loss: 0.8539 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12426/12542 | Batch Loss: 0.7894 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12427/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12428/12542 | Batch Loss: 2.1654 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12429/12542 | Batch Loss: 1.8235 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12430/12542 | Batch Loss: 1.2239 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12431/12542 | Batch Loss: 1.2031 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12432/12542 | Batch Loss: 1.0597 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12433/12542 | Batch Loss: 2.0859 | Learning Rate: 0.000336 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12434/12542 | Batch Loss: 0.5216 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12435/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12436/12542 | Batch Loss: 1.7381 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12437/12542 | Batch Loss: 2.6717 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12438/12542 | Batch Loss: 1.5513 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12439/12542 | Batch Loss: 1.8058 | Learning Rate: 0.000336 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12440/12542 | Batch Loss: 1.2652 | Learning Rate: 0.000336 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12441/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000336 | Batch Time: 0.64s\n",
      "Epoch 2 | Step 12442/12542 | Batch Loss: 1.7771 | Learning Rate: 0.000336 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12443/12542 | Batch Loss: 1.7764 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12444/12542 | Batch Loss: 1.3731 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12445/12542 | Batch Loss: 0.8561 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12446/12542 | Batch Loss: 1.2945 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12447/12542 | Batch Loss: 1.2568 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12448/12542 | Batch Loss: 1.9467 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12449/12542 | Batch Loss: 1.5717 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12450/12542 | Batch Loss: 1.5366 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12451/12542 | Batch Loss: 1.2352 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12452/12542 | Batch Loss: 1.4813 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12453/12542 | Batch Loss: 1.3747 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12454/12542 | Batch Loss: 1.3976 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12455/12542 | Batch Loss: 1.3013 | Learning Rate: 0.000336 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12456/12542 | Batch Loss: 1.0389 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12457/12542 | Batch Loss: 1.9978 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12458/12542 | Batch Loss: 2.1332 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12459/12542 | Batch Loss: 1.3539 | Learning Rate: 0.000336 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12460/12542 | Batch Loss: 0.5382 | Learning Rate: 0.000336 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12461/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12462/12542 | Batch Loss: 1.5626 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12463/12542 | Batch Loss: 0.8713 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12464/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000335 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12465/12542 | Batch Loss: 0.6107 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12466/12542 | Batch Loss: 1.7517 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12467/12542 | Batch Loss: 1.2164 | Learning Rate: 0.000335 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12468/12542 | Batch Loss: 0.7206 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12469/12542 | Batch Loss: 1.5980 | Learning Rate: 0.000335 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12470/12542 | Batch Loss: 1.8589 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12471/12542 | Batch Loss: 0.5900 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12472/12542 | Batch Loss: 1.3821 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12473/12542 | Batch Loss: 0.3755 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12474/12542 | Batch Loss: 1.2107 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12475/12542 | Batch Loss: 1.1634 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12476/12542 | Batch Loss: 1.2583 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12477/12542 | Batch Loss: 1.5246 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12478/12542 | Batch Loss: 1.1534 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12479/12542 | Batch Loss: 1.5315 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12480/12542 | Batch Loss: 0.6492 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12481/12542 | Batch Loss: 1.0065 | Learning Rate: 0.000335 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12482/12542 | Batch Loss: 1.4642 | Learning Rate: 0.000335 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12483/12542 | Batch Loss: 1.4134 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12484/12542 | Batch Loss: 2.1496 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12485/12542 | Batch Loss: 1.6915 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12486/12542 | Batch Loss: 1.6004 | Learning Rate: 0.000335 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12487/12542 | Batch Loss: 0.8598 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12488/12542 | Batch Loss: 0.5764 | Learning Rate: 0.000335 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12489/12542 | Batch Loss: 0.2952 | Learning Rate: 0.000335 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12490/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000335 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12491/12542 | Batch Loss: 0.6920 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12492/12542 | Batch Loss: 1.7328 | Learning Rate: 0.000335 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12493/12542 | Batch Loss: 0.3741 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12494/12542 | Batch Loss: 0.4244 | Learning Rate: 0.000335 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12495/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12496/12542 | Batch Loss: 3.7584 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12497/12542 | Batch Loss: 0.8758 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12498/12542 | Batch Loss: 0.9382 | Learning Rate: 0.000335 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12499/12542 | Batch Loss: 3.1131 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12500/12542 | Batch Loss: 1.5012 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12501/12542 | Batch Loss: 0.7879 | Learning Rate: 0.000334 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12502/12542 | Batch Loss: 1.1369 | Learning Rate: 0.000334 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12503/12542 | Batch Loss: 1.6878 | Learning Rate: 0.000334 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12504/12542 | Batch Loss: 1.0206 | Learning Rate: 0.000334 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12505/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000334 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12506/12542 | Batch Loss: 0.9188 | Learning Rate: 0.000334 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12507/12542 | Batch Loss: 0.7092 | Learning Rate: 0.000334 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12508/12542 | Batch Loss: 0.8900 | Learning Rate: 0.000334 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12509/12542 | Batch Loss: 1.4458 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12510/12542 | Batch Loss: 0.9774 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12511/12542 | Batch Loss: 1.0521 | Learning Rate: 0.000334 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12512/12542 | Batch Loss: 1.0755 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12513/12542 | Batch Loss: 1.0535 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12514/12542 | Batch Loss: 0.8891 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12515/12542 | Batch Loss: 1.4469 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12516/12542 | Batch Loss: 1.5159 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12517/12542 | Batch Loss: 1.2442 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12518/12542 | Batch Loss: 1.7153 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12519/12542 | Batch Loss: 0.5649 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12520/12542 | Batch Loss: 2.8179 | Learning Rate: 0.000334 | Batch Time: 0.57s\n",
      "Epoch 2 | Step 12521/12542 | Batch Loss: 0.5005 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12522/12542 | Batch Loss: 1.5353 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12523/12542 | Batch Loss: 0.6512 | Learning Rate: 0.000334 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12524/12542 | Batch Loss: 3.5638 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12525/12542 | Batch Loss: 1.0839 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12526/12542 | Batch Loss: 0.8989 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12527/12542 | Batch Loss: 1.2243 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12528/12542 | Batch Loss: 1.4578 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12529/12542 | Batch Loss: 0.7328 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12530/12542 | Batch Loss: 0.9704 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12531/12542 | Batch Loss: 1.2755 | Learning Rate: 0.000334 | Batch Time: 0.58s\n",
      "Epoch 2 | Step 12532/12542 | Batch Loss: 1.3160 | Learning Rate: 0.000334 | Batch Time: 0.60s\n",
      "Epoch 2 | Step 12533/12542 | Batch Loss: 0.9399 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12534/12542 | Batch Loss: 1.6892 | Learning Rate: 0.000334 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12535/12542 | Batch Loss: 1.0611 | Learning Rate: 0.000334 | Batch Time: 0.61s\n",
      "Epoch 2 | Step 12536/12542 | Batch Loss: 1.2721 | Learning Rate: 0.000333 | Batch Time: 0.59s\n",
      "Epoch 2 | Step 12537/12542 | Batch Loss: 3.5927 | Learning Rate: 0.000333 | Batch Time: 0.63s\n",
      "Epoch 2 | Step 12538/12542 | Batch Loss: 0.9815 | Learning Rate: 0.000333 | Batch Time: 0.62s\n",
      "Epoch 2 | Step 12539/12542 | Batch Loss: 0.8199 | Learning Rate: 0.000333 | Batch Time: 0.66s\n",
      "Epoch 2 | Step 12540/12542 | Batch Loss: 1.1846 | Learning Rate: 0.000333 | Batch Time: 0.68s\n",
      "Epoch 2 | Step 12541/12542 | Batch Loss: 1.2763 | Learning Rate: 0.000333 | Batch Time: 0.67s\n",
      "Epoch 2 | Step 12542/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000333 | Batch Time: 0.21s\n",
      "Epoch 2 completed. Average Loss: 1.3443 | Epoch Time: 7948.57s\n",
      "Epoch 3/3\n",
      "Epoch 3 | Step 1/12542 | Batch Loss: 1.0445 | Learning Rate: 0.000333 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 2/12542 | Batch Loss: 0.8788 | Learning Rate: 0.000333 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3/12542 | Batch Loss: 0.7050 | Learning Rate: 0.000333 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4/12542 | Batch Loss: 0.8959 | Learning Rate: 0.000333 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5/12542 | Batch Loss: 0.8664 | Learning Rate: 0.000333 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6/12542 | Batch Loss: 1.1373 | Learning Rate: 0.000333 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7/12542 | Batch Loss: 2.7646 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8/12542 | Batch Loss: 1.5641 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9/12542 | Batch Loss: 1.5779 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10/12542 | Batch Loss: 0.8486 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 11/12542 | Batch Loss: 1.4243 | Learning Rate: 0.000333 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 12/12542 | Batch Loss: 1.4872 | Learning Rate: 0.000333 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 13/12542 | Batch Loss: 1.3288 | Learning Rate: 0.000333 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 14/12542 | Batch Loss: 0.8852 | Learning Rate: 0.000333 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 15/12542 | Batch Loss: 1.6399 | Learning Rate: 0.000333 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 16/12542 | Batch Loss: 2.3505 | Learning Rate: 0.000333 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 17/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000333 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 18/12542 | Batch Loss: 2.0816 | Learning Rate: 0.000333 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 19/12542 | Batch Loss: 1.3743 | Learning Rate: 0.000333 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 20/12542 | Batch Loss: 0.6985 | Learning Rate: 0.000333 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 21/12542 | Batch Loss: 2.8885 | Learning Rate: 0.000333 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 22/12542 | Batch Loss: 1.9360 | Learning Rate: 0.000333 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 23/12542 | Batch Loss: 1.9926 | Learning Rate: 0.000333 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 24/12542 | Batch Loss: 1.3287 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 25/12542 | Batch Loss: 1.2784 | Learning Rate: 0.000333 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 26/12542 | Batch Loss: 1.2148 | Learning Rate: 0.000333 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 27/12542 | Batch Loss: 0.7253 | Learning Rate: 0.000333 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 28/12542 | Batch Loss: 1.4140 | Learning Rate: 0.000333 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 29/12542 | Batch Loss: 0.9023 | Learning Rate: 0.000333 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 30/12542 | Batch Loss: 0.7949 | Learning Rate: 0.000333 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 31/12542 | Batch Loss: 0.8139 | Learning Rate: 0.000333 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 32/12542 | Batch Loss: 0.8523 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 33/12542 | Batch Loss: 0.7826 | Learning Rate: 0.000332 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 34/12542 | Batch Loss: 2.3936 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 35/12542 | Batch Loss: 2.6023 | Learning Rate: 0.000332 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 36/12542 | Batch Loss: 1.6517 | Learning Rate: 0.000332 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 37/12542 | Batch Loss: 1.8132 | Learning Rate: 0.000332 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 38/12542 | Batch Loss: 2.1036 | Learning Rate: 0.000332 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 39/12542 | Batch Loss: 0.5031 | Learning Rate: 0.000332 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 40/12542 | Batch Loss: 1.4259 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 41/12542 | Batch Loss: 1.0731 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 42/12542 | Batch Loss: 0.6315 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 43/12542 | Batch Loss: 1.9233 | Learning Rate: 0.000332 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 44/12542 | Batch Loss: 2.0193 | Learning Rate: 0.000332 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 45/12542 | Batch Loss: 1.5215 | Learning Rate: 0.000332 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 46/12542 | Batch Loss: 1.6149 | Learning Rate: 0.000332 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 47/12542 | Batch Loss: 1.6264 | Learning Rate: 0.000332 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 48/12542 | Batch Loss: 1.2310 | Learning Rate: 0.000332 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 49/12542 | Batch Loss: 1.0386 | Learning Rate: 0.000332 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 50/12542 | Batch Loss: 1.2295 | Learning Rate: 0.000332 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 51/12542 | Batch Loss: 3.2454 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 52/12542 | Batch Loss: 1.0249 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 53/12542 | Batch Loss: 0.8404 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 54/12542 | Batch Loss: 2.6182 | Learning Rate: 0.000332 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 55/12542 | Batch Loss: 1.8301 | Learning Rate: 0.000332 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 56/12542 | Batch Loss: 1.2504 | Learning Rate: 0.000332 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 57/12542 | Batch Loss: 1.4152 | Learning Rate: 0.000332 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 58/12542 | Batch Loss: 2.0577 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 59/12542 | Batch Loss: 2.2557 | Learning Rate: 0.000332 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 60/12542 | Batch Loss: 1.1578 | Learning Rate: 0.000332 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 61/12542 | Batch Loss: 0.7841 | Learning Rate: 0.000332 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 62/12542 | Batch Loss: 1.6770 | Learning Rate: 0.000332 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 63/12542 | Batch Loss: 3.4802 | Learning Rate: 0.000332 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 64/12542 | Batch Loss: 0.8758 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 65/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000332 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 66/12542 | Batch Loss: 0.9220 | Learning Rate: 0.000332 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 67/12542 | Batch Loss: 0.9149 | Learning Rate: 0.000332 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 68/12542 | Batch Loss: 0.7779 | Learning Rate: 0.000332 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 69/12542 | Batch Loss: 1.8815 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 70/12542 | Batch Loss: 0.3896 | Learning Rate: 0.000331 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 71/12542 | Batch Loss: 1.4944 | Learning Rate: 0.000331 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 72/12542 | Batch Loss: 2.1940 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 73/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000331 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 74/12542 | Batch Loss: 1.0988 | Learning Rate: 0.000331 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 75/12542 | Batch Loss: 0.8202 | Learning Rate: 0.000331 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 76/12542 | Batch Loss: 0.7975 | Learning Rate: 0.000331 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 77/12542 | Batch Loss: 0.7479 | Learning Rate: 0.000331 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 78/12542 | Batch Loss: 1.6319 | Learning Rate: 0.000331 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 79/12542 | Batch Loss: 1.7401 | Learning Rate: 0.000331 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 80/12542 | Batch Loss: 1.9183 | Learning Rate: 0.000331 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 81/12542 | Batch Loss: 0.6488 | Learning Rate: 0.000331 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 82/12542 | Batch Loss: 1.0835 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 83/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 84/12542 | Batch Loss: 0.9479 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 85/12542 | Batch Loss: 0.7959 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 86/12542 | Batch Loss: 1.1878 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 87/12542 | Batch Loss: 0.5464 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 88/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000331 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 89/12542 | Batch Loss: 1.7053 | Learning Rate: 0.000331 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 90/12542 | Batch Loss: 0.6403 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 91/12542 | Batch Loss: 1.1075 | Learning Rate: 0.000331 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 92/12542 | Batch Loss: 0.9758 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 93/12542 | Batch Loss: 1.5824 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 94/12542 | Batch Loss: 1.7178 | Learning Rate: 0.000331 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 95/12542 | Batch Loss: 0.9178 | Learning Rate: 0.000331 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 96/12542 | Batch Loss: 2.8209 | Learning Rate: 0.000331 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 97/12542 | Batch Loss: 0.5446 | Learning Rate: 0.000331 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 98/12542 | Batch Loss: 1.4226 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 99/12542 | Batch Loss: 0.8114 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 100/12542 | Batch Loss: 1.1810 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 101/12542 | Batch Loss: 0.7179 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 102/12542 | Batch Loss: 1.6553 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 103/12542 | Batch Loss: 1.4214 | Learning Rate: 0.000331 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 104/12542 | Batch Loss: 1.5644 | Learning Rate: 0.000331 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 105/12542 | Batch Loss: 1.2138 | Learning Rate: 0.000331 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 106/12542 | Batch Loss: 1.5632 | Learning Rate: 0.000331 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 107/12542 | Batch Loss: 0.9713 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 108/12542 | Batch Loss: 1.3922 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 109/12542 | Batch Loss: 1.0601 | Learning Rate: 0.000330 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 110/12542 | Batch Loss: 1.0226 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 111/12542 | Batch Loss: 1.1980 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 112/12542 | Batch Loss: 1.5294 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 113/12542 | Batch Loss: 2.3369 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 114/12542 | Batch Loss: 1.1979 | Learning Rate: 0.000330 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 115/12542 | Batch Loss: 1.4396 | Learning Rate: 0.000330 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 116/12542 | Batch Loss: 0.5736 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 117/12542 | Batch Loss: 1.9350 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 118/12542 | Batch Loss: 1.5312 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 119/12542 | Batch Loss: 1.5471 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 120/12542 | Batch Loss: 0.9619 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 121/12542 | Batch Loss: 0.6080 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 122/12542 | Batch Loss: 1.1881 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 123/12542 | Batch Loss: 1.9741 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 124/12542 | Batch Loss: 2.3411 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 125/12542 | Batch Loss: 2.1747 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 126/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000330 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 127/12542 | Batch Loss: 0.9196 | Learning Rate: 0.000330 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 128/12542 | Batch Loss: 1.0837 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 129/12542 | Batch Loss: 0.8039 | Learning Rate: 0.000330 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 130/12542 | Batch Loss: 0.8717 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 131/12542 | Batch Loss: 0.8737 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 132/12542 | Batch Loss: 1.4481 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 133/12542 | Batch Loss: 0.8538 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 134/12542 | Batch Loss: 1.6687 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 135/12542 | Batch Loss: 1.0052 | Learning Rate: 0.000330 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 136/12542 | Batch Loss: 0.8138 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 137/12542 | Batch Loss: 1.0221 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 138/12542 | Batch Loss: 0.7870 | Learning Rate: 0.000330 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 139/12542 | Batch Loss: 1.9595 | Learning Rate: 0.000330 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 140/12542 | Batch Loss: 1.4083 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 141/12542 | Batch Loss: 1.7184 | Learning Rate: 0.000330 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 142/12542 | Batch Loss: 3.5769 | Learning Rate: 0.000330 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 143/12542 | Batch Loss: 0.9604 | Learning Rate: 0.000330 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 144/12542 | Batch Loss: 0.7927 | Learning Rate: 0.000330 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 145/12542 | Batch Loss: 0.6234 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 146/12542 | Batch Loss: 2.6377 | Learning Rate: 0.000329 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 147/12542 | Batch Loss: 0.9135 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 148/12542 | Batch Loss: 2.2108 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 149/12542 | Batch Loss: 1.2614 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 150/12542 | Batch Loss: 1.6500 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 151/12542 | Batch Loss: 0.9807 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 152/12542 | Batch Loss: 0.8746 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 153/12542 | Batch Loss: 1.5569 | Learning Rate: 0.000329 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 154/12542 | Batch Loss: 1.3772 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 155/12542 | Batch Loss: 0.9781 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 156/12542 | Batch Loss: 0.6187 | Learning Rate: 0.000329 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 157/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000329 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 158/12542 | Batch Loss: 1.7129 | Learning Rate: 0.000329 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 159/12542 | Batch Loss: 0.5271 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 160/12542 | Batch Loss: 1.0463 | Learning Rate: 0.000329 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 161/12542 | Batch Loss: 2.0816 | Learning Rate: 0.000329 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 162/12542 | Batch Loss: 0.8597 | Learning Rate: 0.000329 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 163/12542 | Batch Loss: 0.6592 | Learning Rate: 0.000329 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 164/12542 | Batch Loss: 1.4349 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 165/12542 | Batch Loss: 1.0532 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 166/12542 | Batch Loss: 1.9619 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 167/12542 | Batch Loss: 1.5726 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 168/12542 | Batch Loss: 0.9706 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 169/12542 | Batch Loss: 1.0662 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 170/12542 | Batch Loss: 2.5738 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 171/12542 | Batch Loss: 1.0340 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 172/12542 | Batch Loss: 1.5118 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 173/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000329 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 174/12542 | Batch Loss: 4.0559 | Learning Rate: 0.000329 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 175/12542 | Batch Loss: 2.3861 | Learning Rate: 0.000329 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 176/12542 | Batch Loss: 1.4350 | Learning Rate: 0.000329 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 177/12542 | Batch Loss: 1.2340 | Learning Rate: 0.000329 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 178/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000329 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 179/12542 | Batch Loss: 1.9180 | Learning Rate: 0.000329 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 180/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000329 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 181/12542 | Batch Loss: 1.6358 | Learning Rate: 0.000329 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 182/12542 | Batch Loss: 1.6045 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 183/12542 | Batch Loss: 1.6421 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 184/12542 | Batch Loss: 1.1692 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 185/12542 | Batch Loss: 1.0503 | Learning Rate: 0.000328 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 186/12542 | Batch Loss: 1.2199 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 187/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 188/12542 | Batch Loss: 1.0740 | Learning Rate: 0.000328 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 189/12542 | Batch Loss: 1.6865 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 190/12542 | Batch Loss: 1.1573 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 191/12542 | Batch Loss: 1.1870 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 192/12542 | Batch Loss: 1.2181 | Learning Rate: 0.000328 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 193/12542 | Batch Loss: 1.7219 | Learning Rate: 0.000328 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 194/12542 | Batch Loss: 0.8035 | Learning Rate: 0.000328 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 195/12542 | Batch Loss: 1.8263 | Learning Rate: 0.000328 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 196/12542 | Batch Loss: 1.9067 | Learning Rate: 0.000328 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 197/12542 | Batch Loss: 1.6171 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 198/12542 | Batch Loss: 1.2863 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 199/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000328 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 200/12542 | Batch Loss: 0.7145 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 201/12542 | Batch Loss: 0.5304 | Learning Rate: 0.000328 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 202/12542 | Batch Loss: 0.7229 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 203/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 204/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 205/12542 | Batch Loss: 1.1879 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 206/12542 | Batch Loss: 0.7459 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 207/12542 | Batch Loss: 2.7428 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 208/12542 | Batch Loss: 1.3086 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 209/12542 | Batch Loss: 0.9250 | Learning Rate: 0.000328 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 210/12542 | Batch Loss: 1.4121 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 211/12542 | Batch Loss: 1.3703 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 212/12542 | Batch Loss: 0.9712 | Learning Rate: 0.000328 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 213/12542 | Batch Loss: 0.9829 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 214/12542 | Batch Loss: 0.8725 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 215/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000328 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 216/12542 | Batch Loss: 0.7885 | Learning Rate: 0.000328 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 217/12542 | Batch Loss: 0.9664 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 218/12542 | Batch Loss: 0.9326 | Learning Rate: 0.000328 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 219/12542 | Batch Loss: 0.6679 | Learning Rate: 0.000328 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 220/12542 | Batch Loss: 0.8366 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 221/12542 | Batch Loss: 0.7048 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 222/12542 | Batch Loss: 2.1297 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 223/12542 | Batch Loss: 1.4993 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 224/12542 | Batch Loss: 1.1792 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 225/12542 | Batch Loss: 0.4005 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 226/12542 | Batch Loss: 1.7587 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 227/12542 | Batch Loss: 1.8201 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 228/12542 | Batch Loss: 1.3518 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 229/12542 | Batch Loss: 0.7794 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 230/12542 | Batch Loss: 0.5525 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 231/12542 | Batch Loss: 0.9424 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 232/12542 | Batch Loss: 1.9262 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 233/12542 | Batch Loss: 1.0601 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 234/12542 | Batch Loss: 1.2624 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 235/12542 | Batch Loss: 1.8050 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 236/12542 | Batch Loss: 1.4492 | Learning Rate: 0.000327 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 237/12542 | Batch Loss: 0.6018 | Learning Rate: 0.000327 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 238/12542 | Batch Loss: 1.3364 | Learning Rate: 0.000327 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 239/12542 | Batch Loss: 1.2944 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 240/12542 | Batch Loss: 1.2174 | Learning Rate: 0.000327 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 241/12542 | Batch Loss: 1.6537 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 242/12542 | Batch Loss: 1.0841 | Learning Rate: 0.000327 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 243/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000327 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 244/12542 | Batch Loss: 1.8138 | Learning Rate: 0.000327 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 245/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000327 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 246/12542 | Batch Loss: 1.0929 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 247/12542 | Batch Loss: 3.3599 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 248/12542 | Batch Loss: 0.6091 | Learning Rate: 0.000327 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 249/12542 | Batch Loss: 1.7879 | Learning Rate: 0.000327 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 250/12542 | Batch Loss: 0.9138 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 251/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000327 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 252/12542 | Batch Loss: 1.3402 | Learning Rate: 0.000327 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 253/12542 | Batch Loss: 0.9275 | Learning Rate: 0.000327 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 254/12542 | Batch Loss: 2.5032 | Learning Rate: 0.000327 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 255/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000327 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 256/12542 | Batch Loss: 2.9091 | Learning Rate: 0.000327 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 257/12542 | Batch Loss: 1.8965 | Learning Rate: 0.000327 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 258/12542 | Batch Loss: 0.9091 | Learning Rate: 0.000326 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 259/12542 | Batch Loss: 1.0052 | Learning Rate: 0.000326 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 260/12542 | Batch Loss: 1.4705 | Learning Rate: 0.000326 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 261/12542 | Batch Loss: 0.4794 | Learning Rate: 0.000326 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 262/12542 | Batch Loss: 1.6339 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 263/12542 | Batch Loss: 2.3808 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 264/12542 | Batch Loss: 1.1996 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 265/12542 | Batch Loss: 2.2557 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 266/12542 | Batch Loss: 1.1687 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 267/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 268/12542 | Batch Loss: 0.8201 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 269/12542 | Batch Loss: 1.5554 | Learning Rate: 0.000326 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 270/12542 | Batch Loss: 1.1536 | Learning Rate: 0.000326 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 271/12542 | Batch Loss: 1.3573 | Learning Rate: 0.000326 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 272/12542 | Batch Loss: 1.1762 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 273/12542 | Batch Loss: 1.7299 | Learning Rate: 0.000326 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 274/12542 | Batch Loss: 2.3197 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 275/12542 | Batch Loss: 1.3826 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 276/12542 | Batch Loss: 1.3111 | Learning Rate: 0.000326 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 277/12542 | Batch Loss: 0.7888 | Learning Rate: 0.000326 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 278/12542 | Batch Loss: 1.4081 | Learning Rate: 0.000326 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 279/12542 | Batch Loss: 1.8899 | Learning Rate: 0.000326 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 280/12542 | Batch Loss: 1.7351 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 281/12542 | Batch Loss: 2.1663 | Learning Rate: 0.000326 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 282/12542 | Batch Loss: 0.7787 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 283/12542 | Batch Loss: 0.5763 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 284/12542 | Batch Loss: 1.1603 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 285/12542 | Batch Loss: 0.2931 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 286/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 287/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 288/12542 | Batch Loss: 1.0510 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 289/12542 | Batch Loss: 1.7139 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 290/12542 | Batch Loss: 0.6666 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 291/12542 | Batch Loss: 1.0584 | Learning Rate: 0.000326 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 292/12542 | Batch Loss: 0.5848 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 293/12542 | Batch Loss: 1.8044 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 294/12542 | Batch Loss: 0.6276 | Learning Rate: 0.000326 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 295/12542 | Batch Loss: 2.3118 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 296/12542 | Batch Loss: 2.1272 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 297/12542 | Batch Loss: 1.5919 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 298/12542 | Batch Loss: 0.5669 | Learning Rate: 0.000325 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 299/12542 | Batch Loss: 0.8213 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 300/12542 | Batch Loss: 2.2305 | Learning Rate: 0.000325 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 301/12542 | Batch Loss: 0.4846 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 302/12542 | Batch Loss: 1.2889 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 303/12542 | Batch Loss: 0.8594 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 304/12542 | Batch Loss: 1.7507 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 305/12542 | Batch Loss: 0.7799 | Learning Rate: 0.000325 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 306/12542 | Batch Loss: 0.8813 | Learning Rate: 0.000325 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 307/12542 | Batch Loss: 0.7443 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 308/12542 | Batch Loss: 2.0964 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 309/12542 | Batch Loss: 1.9187 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 310/12542 | Batch Loss: 0.8299 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 311/12542 | Batch Loss: 1.8262 | Learning Rate: 0.000325 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 312/12542 | Batch Loss: 1.9772 | Learning Rate: 0.000325 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 313/12542 | Batch Loss: 0.5510 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 314/12542 | Batch Loss: 1.3615 | Learning Rate: 0.000325 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 315/12542 | Batch Loss: 0.9854 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 316/12542 | Batch Loss: 2.1609 | Learning Rate: 0.000325 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 317/12542 | Batch Loss: 0.9488 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 318/12542 | Batch Loss: 0.8072 | Learning Rate: 0.000325 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 319/12542 | Batch Loss: 0.7721 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 320/12542 | Batch Loss: 0.5971 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 321/12542 | Batch Loss: 0.8418 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 322/12542 | Batch Loss: 1.4801 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 323/12542 | Batch Loss: 0.8991 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 324/12542 | Batch Loss: 1.3755 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 325/12542 | Batch Loss: 0.9678 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 326/12542 | Batch Loss: 0.6161 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 327/12542 | Batch Loss: 1.0694 | Learning Rate: 0.000325 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 328/12542 | Batch Loss: 0.7747 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 329/12542 | Batch Loss: 2.2042 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 330/12542 | Batch Loss: 0.5269 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 331/12542 | Batch Loss: 1.3252 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 332/12542 | Batch Loss: 2.0094 | Learning Rate: 0.000325 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 333/12542 | Batch Loss: 1.4046 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 334/12542 | Batch Loss: 2.7145 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 335/12542 | Batch Loss: 1.8404 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 336/12542 | Batch Loss: 0.4939 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 337/12542 | Batch Loss: 0.6115 | Learning Rate: 0.000324 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 338/12542 | Batch Loss: 2.1764 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 339/12542 | Batch Loss: 1.4355 | Learning Rate: 0.000324 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 340/12542 | Batch Loss: 2.0390 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 341/12542 | Batch Loss: 0.9076 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 342/12542 | Batch Loss: 1.7822 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 343/12542 | Batch Loss: 1.7666 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 344/12542 | Batch Loss: 1.3598 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 345/12542 | Batch Loss: 0.9461 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 346/12542 | Batch Loss: 1.1213 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 347/12542 | Batch Loss: 1.5255 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 348/12542 | Batch Loss: 1.0952 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 349/12542 | Batch Loss: 0.6506 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 350/12542 | Batch Loss: 2.2957 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 351/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 352/12542 | Batch Loss: 1.2070 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 353/12542 | Batch Loss: 1.0105 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 354/12542 | Batch Loss: 0.8661 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 355/12542 | Batch Loss: 0.6257 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 356/12542 | Batch Loss: 1.4126 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 357/12542 | Batch Loss: 1.3507 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 358/12542 | Batch Loss: 0.8098 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 359/12542 | Batch Loss: 1.2530 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 360/12542 | Batch Loss: 1.0355 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 361/12542 | Batch Loss: 1.3169 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 362/12542 | Batch Loss: 1.9062 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 363/12542 | Batch Loss: 2.4269 | Learning Rate: 0.000324 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 364/12542 | Batch Loss: 1.2794 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 365/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 366/12542 | Batch Loss: 2.2497 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 367/12542 | Batch Loss: 0.8629 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 368/12542 | Batch Loss: 1.9579 | Learning Rate: 0.000324 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 369/12542 | Batch Loss: 1.7660 | Learning Rate: 0.000324 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 370/12542 | Batch Loss: 1.7296 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 371/12542 | Batch Loss: 0.7273 | Learning Rate: 0.000323 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 372/12542 | Batch Loss: 1.1378 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 373/12542 | Batch Loss: 1.7264 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 374/12542 | Batch Loss: 0.6250 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 375/12542 | Batch Loss: 0.7048 | Learning Rate: 0.000323 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 376/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000323 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 377/12542 | Batch Loss: 1.4384 | Learning Rate: 0.000323 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 378/12542 | Batch Loss: 1.4751 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 379/12542 | Batch Loss: 0.8827 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 380/12542 | Batch Loss: 1.0460 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 381/12542 | Batch Loss: 0.5485 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 382/12542 | Batch Loss: 1.4947 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 383/12542 | Batch Loss: 0.6811 | Learning Rate: 0.000323 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 384/12542 | Batch Loss: 1.0814 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 385/12542 | Batch Loss: 1.8275 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 386/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 387/12542 | Batch Loss: 1.3054 | Learning Rate: 0.000323 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 388/12542 | Batch Loss: 1.5371 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 389/12542 | Batch Loss: 1.8810 | Learning Rate: 0.000323 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 390/12542 | Batch Loss: 0.8678 | Learning Rate: 0.000323 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 391/12542 | Batch Loss: 2.7554 | Learning Rate: 0.000323 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 392/12542 | Batch Loss: 1.4095 | Learning Rate: 0.000323 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 393/12542 | Batch Loss: 0.9098 | Learning Rate: 0.000323 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 394/12542 | Batch Loss: 1.0604 | Learning Rate: 0.000323 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 395/12542 | Batch Loss: 1.5838 | Learning Rate: 0.000323 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 396/12542 | Batch Loss: 0.6439 | Learning Rate: 0.000323 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 397/12542 | Batch Loss: 1.4664 | Learning Rate: 0.000323 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 398/12542 | Batch Loss: 1.1676 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 399/12542 | Batch Loss: 1.5005 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 400/12542 | Batch Loss: 0.8393 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 401/12542 | Batch Loss: 0.8010 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 402/12542 | Batch Loss: 1.4900 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 403/12542 | Batch Loss: 0.8181 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 404/12542 | Batch Loss: 1.3440 | Learning Rate: 0.000323 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 405/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 406/12542 | Batch Loss: 0.9742 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 407/12542 | Batch Loss: 0.8980 | Learning Rate: 0.000323 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 408/12542 | Batch Loss: 0.5575 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 409/12542 | Batch Loss: 1.0238 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 410/12542 | Batch Loss: 1.1740 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 411/12542 | Batch Loss: 1.1405 | Learning Rate: 0.000322 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 412/12542 | Batch Loss: 3.8338 | Learning Rate: 0.000322 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 413/12542 | Batch Loss: 1.0577 | Learning Rate: 0.000322 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 414/12542 | Batch Loss: 0.4859 | Learning Rate: 0.000322 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 415/12542 | Batch Loss: 2.0254 | Learning Rate: 0.000322 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 416/12542 | Batch Loss: 0.7822 | Learning Rate: 0.000322 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 417/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 418/12542 | Batch Loss: 3.0122 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 419/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 420/12542 | Batch Loss: 1.1404 | Learning Rate: 0.000322 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 421/12542 | Batch Loss: 1.5425 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 422/12542 | Batch Loss: 1.0865 | Learning Rate: 0.000322 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 423/12542 | Batch Loss: 2.1808 | Learning Rate: 0.000322 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 424/12542 | Batch Loss: 1.8090 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 425/12542 | Batch Loss: 1.1005 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 426/12542 | Batch Loss: 1.2283 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 427/12542 | Batch Loss: 0.8991 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 428/12542 | Batch Loss: 0.6445 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 429/12542 | Batch Loss: 0.7084 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 430/12542 | Batch Loss: 1.7582 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 431/12542 | Batch Loss: 2.5245 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 432/12542 | Batch Loss: 0.7919 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 433/12542 | Batch Loss: 1.4393 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 434/12542 | Batch Loss: 1.2837 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 435/12542 | Batch Loss: 2.7285 | Learning Rate: 0.000322 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 436/12542 | Batch Loss: 0.5449 | Learning Rate: 0.000322 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 437/12542 | Batch Loss: 0.9922 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 438/12542 | Batch Loss: 2.9449 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 439/12542 | Batch Loss: 0.7453 | Learning Rate: 0.000322 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 440/12542 | Batch Loss: 1.0607 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 441/12542 | Batch Loss: 1.8053 | Learning Rate: 0.000322 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 442/12542 | Batch Loss: 0.7517 | Learning Rate: 0.000322 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 443/12542 | Batch Loss: 1.5279 | Learning Rate: 0.000322 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 444/12542 | Batch Loss: 1.9900 | Learning Rate: 0.000322 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 445/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000322 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 446/12542 | Batch Loss: 0.8296 | Learning Rate: 0.000321 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 447/12542 | Batch Loss: 1.1074 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 448/12542 | Batch Loss: 0.8157 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 449/12542 | Batch Loss: 1.9202 | Learning Rate: 0.000321 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 450/12542 | Batch Loss: 1.6807 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 451/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 452/12542 | Batch Loss: 0.5657 | Learning Rate: 0.000321 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 453/12542 | Batch Loss: 1.0269 | Learning Rate: 0.000321 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 454/12542 | Batch Loss: 1.2428 | Learning Rate: 0.000321 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 455/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 456/12542 | Batch Loss: 2.6805 | Learning Rate: 0.000321 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 457/12542 | Batch Loss: 1.2047 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 458/12542 | Batch Loss: 1.2293 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 459/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 460/12542 | Batch Loss: 1.0986 | Learning Rate: 0.000321 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 461/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 462/12542 | Batch Loss: 1.5557 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 463/12542 | Batch Loss: 1.7182 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 464/12542 | Batch Loss: 2.4793 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 465/12542 | Batch Loss: 0.8155 | Learning Rate: 0.000321 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 466/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 467/12542 | Batch Loss: 1.9052 | Learning Rate: 0.000321 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 468/12542 | Batch Loss: 0.8256 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 469/12542 | Batch Loss: 0.7391 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 470/12542 | Batch Loss: 1.2315 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 471/12542 | Batch Loss: 1.5300 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 472/12542 | Batch Loss: 0.8773 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 473/12542 | Batch Loss: 1.0125 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 474/12542 | Batch Loss: 1.5816 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 475/12542 | Batch Loss: 1.1457 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 476/12542 | Batch Loss: 0.9210 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 477/12542 | Batch Loss: 1.5917 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 478/12542 | Batch Loss: 1.5998 | Learning Rate: 0.000321 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 479/12542 | Batch Loss: 0.8454 | Learning Rate: 0.000321 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 480/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000321 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 481/12542 | Batch Loss: 0.7438 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 482/12542 | Batch Loss: 1.2294 | Learning Rate: 0.000321 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 483/12542 | Batch Loss: 1.0469 | Learning Rate: 0.000320 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 484/12542 | Batch Loss: 1.6682 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 485/12542 | Batch Loss: 1.6318 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 486/12542 | Batch Loss: 1.1191 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 487/12542 | Batch Loss: 0.8778 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 488/12542 | Batch Loss: 1.2121 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 489/12542 | Batch Loss: 1.3818 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 490/12542 | Batch Loss: 1.1295 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 491/12542 | Batch Loss: 1.2428 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 492/12542 | Batch Loss: 0.9958 | Learning Rate: 0.000320 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 493/12542 | Batch Loss: 0.8458 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 494/12542 | Batch Loss: 1.6968 | Learning Rate: 0.000320 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 495/12542 | Batch Loss: 2.5600 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 496/12542 | Batch Loss: 0.4720 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 497/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 498/12542 | Batch Loss: 0.5098 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 499/12542 | Batch Loss: 1.8049 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 500/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 501/12542 | Batch Loss: 1.5835 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 502/12542 | Batch Loss: 1.4920 | Learning Rate: 0.000320 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 503/12542 | Batch Loss: 0.6345 | Learning Rate: 0.000320 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 504/12542 | Batch Loss: 1.1706 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 505/12542 | Batch Loss: 0.9467 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 506/12542 | Batch Loss: 2.5361 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 507/12542 | Batch Loss: 1.2672 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 508/12542 | Batch Loss: 0.9025 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 509/12542 | Batch Loss: 0.5797 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 510/12542 | Batch Loss: 3.3114 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 511/12542 | Batch Loss: 0.5724 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 512/12542 | Batch Loss: 1.5888 | Learning Rate: 0.000320 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 513/12542 | Batch Loss: 1.0220 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 514/12542 | Batch Loss: 2.0391 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 515/12542 | Batch Loss: 1.9938 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 516/12542 | Batch Loss: 0.8775 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 517/12542 | Batch Loss: 1.5955 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 518/12542 | Batch Loss: 1.2328 | Learning Rate: 0.000320 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 519/12542 | Batch Loss: 1.6588 | Learning Rate: 0.000320 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 520/12542 | Batch Loss: 1.9309 | Learning Rate: 0.000320 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 521/12542 | Batch Loss: 0.8428 | Learning Rate: 0.000319 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 522/12542 | Batch Loss: 1.8944 | Learning Rate: 0.000319 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 523/12542 | Batch Loss: 0.7472 | Learning Rate: 0.000319 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 524/12542 | Batch Loss: 1.2493 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 525/12542 | Batch Loss: 1.4021 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 526/12542 | Batch Loss: 0.9612 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 527/12542 | Batch Loss: 1.2850 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 528/12542 | Batch Loss: 2.4886 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 529/12542 | Batch Loss: 1.4859 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 530/12542 | Batch Loss: 1.5332 | Learning Rate: 0.000319 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 531/12542 | Batch Loss: 0.7715 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 532/12542 | Batch Loss: 1.8074 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 533/12542 | Batch Loss: 1.3944 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 534/12542 | Batch Loss: 0.5229 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 535/12542 | Batch Loss: 1.2586 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 536/12542 | Batch Loss: 0.9419 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 537/12542 | Batch Loss: 0.7481 | Learning Rate: 0.000319 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 538/12542 | Batch Loss: 2.2891 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 539/12542 | Batch Loss: 0.9948 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 540/12542 | Batch Loss: 1.2983 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 541/12542 | Batch Loss: 1.3145 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 542/12542 | Batch Loss: 1.5346 | Learning Rate: 0.000319 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 543/12542 | Batch Loss: 0.7972 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 544/12542 | Batch Loss: 1.2839 | Learning Rate: 0.000319 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 545/12542 | Batch Loss: 1.2496 | Learning Rate: 0.000319 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 546/12542 | Batch Loss: 1.1591 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 547/12542 | Batch Loss: 0.9818 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 548/12542 | Batch Loss: 0.8494 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 549/12542 | Batch Loss: 0.9394 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 550/12542 | Batch Loss: 1.6738 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 551/12542 | Batch Loss: 0.8845 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 552/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 553/12542 | Batch Loss: 1.3177 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 554/12542 | Batch Loss: 0.6075 | Learning Rate: 0.000319 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 555/12542 | Batch Loss: 1.5701 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 556/12542 | Batch Loss: 1.3593 | Learning Rate: 0.000319 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 557/12542 | Batch Loss: 1.4938 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 558/12542 | Batch Loss: 0.9524 | Learning Rate: 0.000319 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 559/12542 | Batch Loss: 1.7597 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 560/12542 | Batch Loss: 1.6574 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 561/12542 | Batch Loss: 0.7393 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 562/12542 | Batch Loss: 1.0640 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 563/12542 | Batch Loss: 0.9044 | Learning Rate: 0.000318 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 564/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 565/12542 | Batch Loss: 1.4972 | Learning Rate: 0.000318 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 566/12542 | Batch Loss: 1.4969 | Learning Rate: 0.000318 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 567/12542 | Batch Loss: 0.7270 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 568/12542 | Batch Loss: 0.4593 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 569/12542 | Batch Loss: 1.2839 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 570/12542 | Batch Loss: 1.6430 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 571/12542 | Batch Loss: 1.1007 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 572/12542 | Batch Loss: 0.9999 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 573/12542 | Batch Loss: 2.4692 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 574/12542 | Batch Loss: 1.0013 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 575/12542 | Batch Loss: 0.6410 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 576/12542 | Batch Loss: 1.3112 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 577/12542 | Batch Loss: 0.7612 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 578/12542 | Batch Loss: 0.7042 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 579/12542 | Batch Loss: 0.9550 | Learning Rate: 0.000318 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 580/12542 | Batch Loss: 1.0205 | Learning Rate: 0.000318 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 581/12542 | Batch Loss: 1.1905 | Learning Rate: 0.000318 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 582/12542 | Batch Loss: 0.8938 | Learning Rate: 0.000318 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 583/12542 | Batch Loss: 0.7486 | Learning Rate: 0.000318 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 584/12542 | Batch Loss: 1.1137 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 585/12542 | Batch Loss: 0.6378 | Learning Rate: 0.000318 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 586/12542 | Batch Loss: 0.8111 | Learning Rate: 0.000318 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 587/12542 | Batch Loss: 2.5765 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 588/12542 | Batch Loss: 1.6821 | Learning Rate: 0.000318 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 589/12542 | Batch Loss: 0.6191 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 590/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 591/12542 | Batch Loss: 0.5211 | Learning Rate: 0.000318 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 592/12542 | Batch Loss: 0.8896 | Learning Rate: 0.000318 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 593/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000318 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 594/12542 | Batch Loss: 1.5504 | Learning Rate: 0.000318 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 595/12542 | Batch Loss: 1.3481 | Learning Rate: 0.000318 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 596/12542 | Batch Loss: 1.9988 | Learning Rate: 0.000317 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 597/12542 | Batch Loss: 0.8384 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 598/12542 | Batch Loss: 1.0355 | Learning Rate: 0.000317 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 599/12542 | Batch Loss: 1.4678 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 600/12542 | Batch Loss: 1.2557 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 601/12542 | Batch Loss: 1.9226 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 602/12542 | Batch Loss: 0.9331 | Learning Rate: 0.000317 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 603/12542 | Batch Loss: 0.7400 | Learning Rate: 0.000317 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 604/12542 | Batch Loss: 0.9093 | Learning Rate: 0.000317 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 605/12542 | Batch Loss: 2.1784 | Learning Rate: 0.000317 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 606/12542 | Batch Loss: 1.3871 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 607/12542 | Batch Loss: 0.8644 | Learning Rate: 0.000317 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 608/12542 | Batch Loss: 1.5329 | Learning Rate: 0.000317 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 609/12542 | Batch Loss: 1.9744 | Learning Rate: 0.000317 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 610/12542 | Batch Loss: 0.6792 | Learning Rate: 0.000317 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 611/12542 | Batch Loss: 1.0778 | Learning Rate: 0.000317 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 612/12542 | Batch Loss: 0.7851 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 613/12542 | Batch Loss: 1.0389 | Learning Rate: 0.000317 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 614/12542 | Batch Loss: 1.7711 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 615/12542 | Batch Loss: 1.5468 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 616/12542 | Batch Loss: 1.2587 | Learning Rate: 0.000317 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 617/12542 | Batch Loss: 0.9493 | Learning Rate: 0.000317 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 618/12542 | Batch Loss: 1.3752 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 619/12542 | Batch Loss: 2.0357 | Learning Rate: 0.000317 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 620/12542 | Batch Loss: 0.5754 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 621/12542 | Batch Loss: 0.4959 | Learning Rate: 0.000317 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 622/12542 | Batch Loss: 1.3304 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 623/12542 | Batch Loss: 2.3183 | Learning Rate: 0.000317 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 624/12542 | Batch Loss: 2.2155 | Learning Rate: 0.000317 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 625/12542 | Batch Loss: 2.5212 | Learning Rate: 0.000317 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 626/12542 | Batch Loss: 2.9956 | Learning Rate: 0.000317 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 627/12542 | Batch Loss: 1.2265 | Learning Rate: 0.000317 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 628/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000317 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 629/12542 | Batch Loss: 1.1431 | Learning Rate: 0.000317 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 630/12542 | Batch Loss: 1.3025 | Learning Rate: 0.000317 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 631/12542 | Batch Loss: 1.8245 | Learning Rate: 0.000317 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 632/12542 | Batch Loss: 0.8329 | Learning Rate: 0.000317 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 633/12542 | Batch Loss: 0.4909 | Learning Rate: 0.000317 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 634/12542 | Batch Loss: 0.9415 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 635/12542 | Batch Loss: 0.9273 | Learning Rate: 0.000316 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 636/12542 | Batch Loss: 2.2426 | Learning Rate: 0.000316 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 637/12542 | Batch Loss: 1.6443 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 638/12542 | Batch Loss: 1.9810 | Learning Rate: 0.000316 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 639/12542 | Batch Loss: 1.5570 | Learning Rate: 0.000316 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 640/12542 | Batch Loss: 0.7551 | Learning Rate: 0.000316 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 641/12542 | Batch Loss: 1.1754 | Learning Rate: 0.000316 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 642/12542 | Batch Loss: 0.7386 | Learning Rate: 0.000316 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 643/12542 | Batch Loss: 1.2940 | Learning Rate: 0.000316 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 644/12542 | Batch Loss: 1.4820 | Learning Rate: 0.000316 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 645/12542 | Batch Loss: 1.6463 | Learning Rate: 0.000316 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 646/12542 | Batch Loss: 1.0889 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 647/12542 | Batch Loss: 0.5583 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 648/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000316 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 649/12542 | Batch Loss: 1.3920 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 650/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000316 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 651/12542 | Batch Loss: 0.8511 | Learning Rate: 0.000316 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 652/12542 | Batch Loss: 3.1039 | Learning Rate: 0.000316 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 653/12542 | Batch Loss: 1.5146 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 654/12542 | Batch Loss: 1.2052 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 655/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000316 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 656/12542 | Batch Loss: 0.9201 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 657/12542 | Batch Loss: 1.0133 | Learning Rate: 0.000316 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 658/12542 | Batch Loss: 1.0011 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 659/12542 | Batch Loss: 0.8325 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 660/12542 | Batch Loss: 1.3149 | Learning Rate: 0.000316 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 661/12542 | Batch Loss: 1.6105 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 662/12542 | Batch Loss: 1.6879 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 663/12542 | Batch Loss: 0.4808 | Learning Rate: 0.000316 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 664/12542 | Batch Loss: 1.5027 | Learning Rate: 0.000316 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 665/12542 | Batch Loss: 1.0723 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 666/12542 | Batch Loss: 2.2378 | Learning Rate: 0.000316 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 667/12542 | Batch Loss: 2.3058 | Learning Rate: 0.000316 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 668/12542 | Batch Loss: 1.5633 | Learning Rate: 0.000316 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 669/12542 | Batch Loss: 0.6676 | Learning Rate: 0.000316 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 670/12542 | Batch Loss: 1.4365 | Learning Rate: 0.000316 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 671/12542 | Batch Loss: 0.9822 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 672/12542 | Batch Loss: 1.5384 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 673/12542 | Batch Loss: 1.4222 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 674/12542 | Batch Loss: 0.9351 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 675/12542 | Batch Loss: 3.6661 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 676/12542 | Batch Loss: 0.9714 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 677/12542 | Batch Loss: 2.2399 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 678/12542 | Batch Loss: 2.9037 | Learning Rate: 0.000315 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 679/12542 | Batch Loss: 1.5356 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 680/12542 | Batch Loss: 0.8967 | Learning Rate: 0.000315 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 681/12542 | Batch Loss: 0.9699 | Learning Rate: 0.000315 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 682/12542 | Batch Loss: 1.6025 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 683/12542 | Batch Loss: 1.2654 | Learning Rate: 0.000315 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 684/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 685/12542 | Batch Loss: 2.3325 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 686/12542 | Batch Loss: 0.4931 | Learning Rate: 0.000315 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 687/12542 | Batch Loss: 0.5696 | Learning Rate: 0.000315 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 688/12542 | Batch Loss: 2.6010 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 689/12542 | Batch Loss: 1.4295 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 690/12542 | Batch Loss: 1.3778 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 691/12542 | Batch Loss: 0.7909 | Learning Rate: 0.000315 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 692/12542 | Batch Loss: 1.7354 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 693/12542 | Batch Loss: 1.0091 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 694/12542 | Batch Loss: 1.2573 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 695/12542 | Batch Loss: 0.5365 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 696/12542 | Batch Loss: 1.9497 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 697/12542 | Batch Loss: 0.7399 | Learning Rate: 0.000315 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 698/12542 | Batch Loss: 2.3032 | Learning Rate: 0.000315 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 699/12542 | Batch Loss: 0.9908 | Learning Rate: 0.000315 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 700/12542 | Batch Loss: 1.1371 | Learning Rate: 0.000315 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 701/12542 | Batch Loss: 1.8629 | Learning Rate: 0.000315 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 702/12542 | Batch Loss: 1.7494 | Learning Rate: 0.000315 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 703/12542 | Batch Loss: 1.2610 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 704/12542 | Batch Loss: 1.6910 | Learning Rate: 0.000315 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 705/12542 | Batch Loss: 0.8015 | Learning Rate: 0.000315 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 706/12542 | Batch Loss: 0.8537 | Learning Rate: 0.000315 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 707/12542 | Batch Loss: 1.0281 | Learning Rate: 0.000315 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 708/12542 | Batch Loss: 0.9032 | Learning Rate: 0.000315 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 709/12542 | Batch Loss: 1.1998 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 710/12542 | Batch Loss: 1.4031 | Learning Rate: 0.000314 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 711/12542 | Batch Loss: 1.2117 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 712/12542 | Batch Loss: 0.8281 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 713/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 714/12542 | Batch Loss: 1.6705 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 715/12542 | Batch Loss: 0.6648 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 716/12542 | Batch Loss: 0.5260 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 717/12542 | Batch Loss: 1.2149 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 718/12542 | Batch Loss: 2.4736 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 719/12542 | Batch Loss: 2.0646 | Learning Rate: 0.000314 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 720/12542 | Batch Loss: 1.1768 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 721/12542 | Batch Loss: 1.7744 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 722/12542 | Batch Loss: 0.5570 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 723/12542 | Batch Loss: 2.0701 | Learning Rate: 0.000314 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 724/12542 | Batch Loss: 1.1151 | Learning Rate: 0.000314 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 725/12542 | Batch Loss: 1.1977 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 726/12542 | Batch Loss: 0.6405 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 727/12542 | Batch Loss: 2.0120 | Learning Rate: 0.000314 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 728/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000314 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 729/12542 | Batch Loss: 1.1602 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 730/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000314 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 731/12542 | Batch Loss: 2.1782 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 732/12542 | Batch Loss: 2.0237 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 733/12542 | Batch Loss: 0.6171 | Learning Rate: 0.000314 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 734/12542 | Batch Loss: 2.0187 | Learning Rate: 0.000314 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 735/12542 | Batch Loss: 1.0994 | Learning Rate: 0.000314 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 736/12542 | Batch Loss: 0.8292 | Learning Rate: 0.000314 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 737/12542 | Batch Loss: 1.7462 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 738/12542 | Batch Loss: 1.0819 | Learning Rate: 0.000314 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 739/12542 | Batch Loss: 1.8059 | Learning Rate: 0.000314 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 740/12542 | Batch Loss: 1.2368 | Learning Rate: 0.000314 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 741/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000314 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 742/12542 | Batch Loss: 1.0625 | Learning Rate: 0.000314 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 743/12542 | Batch Loss: 1.3803 | Learning Rate: 0.000314 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 744/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000314 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 745/12542 | Batch Loss: 0.8413 | Learning Rate: 0.000314 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 746/12542 | Batch Loss: 0.4752 | Learning Rate: 0.000314 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 747/12542 | Batch Loss: 0.9128 | Learning Rate: 0.000313 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 748/12542 | Batch Loss: 1.5169 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 749/12542 | Batch Loss: 0.5827 | Learning Rate: 0.000313 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 750/12542 | Batch Loss: 0.5315 | Learning Rate: 0.000313 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 751/12542 | Batch Loss: 0.8760 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 752/12542 | Batch Loss: 0.4543 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 753/12542 | Batch Loss: 2.6343 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 754/12542 | Batch Loss: 1.4655 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 755/12542 | Batch Loss: 1.3074 | Learning Rate: 0.000313 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 756/12542 | Batch Loss: 0.6207 | Learning Rate: 0.000313 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 757/12542 | Batch Loss: 1.1311 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 758/12542 | Batch Loss: 0.9294 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 759/12542 | Batch Loss: 0.8690 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 760/12542 | Batch Loss: 2.1174 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 761/12542 | Batch Loss: 2.2115 | Learning Rate: 0.000313 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 762/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000313 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 763/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000313 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 764/12542 | Batch Loss: 1.9670 | Learning Rate: 0.000313 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 765/12542 | Batch Loss: 0.9805 | Learning Rate: 0.000313 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 766/12542 | Batch Loss: 1.5343 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 767/12542 | Batch Loss: 0.8286 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 768/12542 | Batch Loss: 1.2091 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 769/12542 | Batch Loss: 1.3232 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 770/12542 | Batch Loss: 1.5423 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 771/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 772/12542 | Batch Loss: 1.4090 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 773/12542 | Batch Loss: 1.3498 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 774/12542 | Batch Loss: 1.2252 | Learning Rate: 0.000313 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 775/12542 | Batch Loss: 1.3218 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 776/12542 | Batch Loss: 0.7301 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 777/12542 | Batch Loss: 1.3397 | Learning Rate: 0.000313 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 778/12542 | Batch Loss: 0.3364 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 779/12542 | Batch Loss: 0.9907 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 780/12542 | Batch Loss: 1.5934 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 781/12542 | Batch Loss: 1.3915 | Learning Rate: 0.000313 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 782/12542 | Batch Loss: 1.3178 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 783/12542 | Batch Loss: 1.3944 | Learning Rate: 0.000313 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 784/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 785/12542 | Batch Loss: 0.4401 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 786/12542 | Batch Loss: 1.9677 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 787/12542 | Batch Loss: 0.6715 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 788/12542 | Batch Loss: 1.1683 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 789/12542 | Batch Loss: 2.9667 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 790/12542 | Batch Loss: 1.0245 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 791/12542 | Batch Loss: 1.0102 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 792/12542 | Batch Loss: 1.8140 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 793/12542 | Batch Loss: 0.8601 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 794/12542 | Batch Loss: 1.7936 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 795/12542 | Batch Loss: 1.1511 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 796/12542 | Batch Loss: 0.3857 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 797/12542 | Batch Loss: 1.7723 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 798/12542 | Batch Loss: 1.2712 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 799/12542 | Batch Loss: 1.0654 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 800/12542 | Batch Loss: 0.4896 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 801/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000312 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 802/12542 | Batch Loss: 0.7708 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 803/12542 | Batch Loss: 2.1380 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 804/12542 | Batch Loss: 1.3248 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 805/12542 | Batch Loss: 1.4649 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 806/12542 | Batch Loss: 1.4813 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 807/12542 | Batch Loss: 1.2666 | Learning Rate: 0.000312 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 808/12542 | Batch Loss: 1.2937 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 809/12542 | Batch Loss: 1.3239 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 810/12542 | Batch Loss: 1.4338 | Learning Rate: 0.000312 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 811/12542 | Batch Loss: 1.0573 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 812/12542 | Batch Loss: 1.0508 | Learning Rate: 0.000312 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 813/12542 | Batch Loss: 1.7662 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 814/12542 | Batch Loss: 1.5700 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 815/12542 | Batch Loss: 2.1769 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 816/12542 | Batch Loss: 0.7291 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 817/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 818/12542 | Batch Loss: 1.5655 | Learning Rate: 0.000312 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 819/12542 | Batch Loss: 0.7352 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 820/12542 | Batch Loss: 1.4815 | Learning Rate: 0.000312 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 821/12542 | Batch Loss: 1.4807 | Learning Rate: 0.000312 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 822/12542 | Batch Loss: 1.3489 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 823/12542 | Batch Loss: 1.1098 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 824/12542 | Batch Loss: 1.4300 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 825/12542 | Batch Loss: 1.1732 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 826/12542 | Batch Loss: 1.5959 | Learning Rate: 0.000311 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 827/12542 | Batch Loss: 0.7033 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 828/12542 | Batch Loss: 0.8058 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 829/12542 | Batch Loss: 0.8123 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 830/12542 | Batch Loss: 0.5118 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 831/12542 | Batch Loss: 1.2713 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 832/12542 | Batch Loss: 1.3838 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 833/12542 | Batch Loss: 1.6806 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 834/12542 | Batch Loss: 0.7511 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 835/12542 | Batch Loss: 2.8718 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 836/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 837/12542 | Batch Loss: 0.8349 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 838/12542 | Batch Loss: 0.3098 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 839/12542 | Batch Loss: 0.8405 | Learning Rate: 0.000311 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 840/12542 | Batch Loss: 1.9906 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 841/12542 | Batch Loss: 0.8149 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 842/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 843/12542 | Batch Loss: 1.8945 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 844/12542 | Batch Loss: 1.3522 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 845/12542 | Batch Loss: 1.5710 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 846/12542 | Batch Loss: 0.7861 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 847/12542 | Batch Loss: 2.2065 | Learning Rate: 0.000311 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 848/12542 | Batch Loss: 2.0652 | Learning Rate: 0.000311 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 849/12542 | Batch Loss: 0.7250 | Learning Rate: 0.000311 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 850/12542 | Batch Loss: 1.3475 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 851/12542 | Batch Loss: 1.6052 | Learning Rate: 0.000311 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 852/12542 | Batch Loss: 2.1387 | Learning Rate: 0.000311 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 853/12542 | Batch Loss: 1.2025 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 854/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 855/12542 | Batch Loss: 0.4239 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 856/12542 | Batch Loss: 1.3954 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 857/12542 | Batch Loss: 1.1941 | Learning Rate: 0.000311 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 858/12542 | Batch Loss: 1.2007 | Learning Rate: 0.000311 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 859/12542 | Batch Loss: 1.4239 | Learning Rate: 0.000311 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 860/12542 | Batch Loss: 2.8173 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 861/12542 | Batch Loss: 1.4227 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 862/12542 | Batch Loss: 2.2544 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 863/12542 | Batch Loss: 1.6983 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 864/12542 | Batch Loss: 1.4692 | Learning Rate: 0.000310 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 865/12542 | Batch Loss: 2.1774 | Learning Rate: 0.000310 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 866/12542 | Batch Loss: 0.7634 | Learning Rate: 0.000310 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 867/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000310 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 868/12542 | Batch Loss: 1.8516 | Learning Rate: 0.000310 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 869/12542 | Batch Loss: 1.4856 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 870/12542 | Batch Loss: 0.4600 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 871/12542 | Batch Loss: 1.5583 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 872/12542 | Batch Loss: 1.0549 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 873/12542 | Batch Loss: 1.2837 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 874/12542 | Batch Loss: 1.4305 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 875/12542 | Batch Loss: 0.7429 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 876/12542 | Batch Loss: 0.6945 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 877/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 878/12542 | Batch Loss: 1.3540 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 879/12542 | Batch Loss: 1.5058 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 880/12542 | Batch Loss: 2.3657 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 881/12542 | Batch Loss: 1.2775 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 882/12542 | Batch Loss: 2.2488 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 883/12542 | Batch Loss: 1.2564 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 884/12542 | Batch Loss: 0.5504 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 885/12542 | Batch Loss: 1.2228 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 886/12542 | Batch Loss: 1.0607 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 887/12542 | Batch Loss: 1.5324 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 888/12542 | Batch Loss: 1.4230 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 889/12542 | Batch Loss: 1.3684 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 890/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 891/12542 | Batch Loss: 2.9069 | Learning Rate: 0.000310 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 892/12542 | Batch Loss: 1.9623 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 893/12542 | Batch Loss: 1.7839 | Learning Rate: 0.000310 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 894/12542 | Batch Loss: 1.2736 | Learning Rate: 0.000310 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 895/12542 | Batch Loss: 0.9266 | Learning Rate: 0.000310 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 896/12542 | Batch Loss: 1.1062 | Learning Rate: 0.000310 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 897/12542 | Batch Loss: 1.2484 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 898/12542 | Batch Loss: 0.9289 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 899/12542 | Batch Loss: 1.3130 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 900/12542 | Batch Loss: 0.6415 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 901/12542 | Batch Loss: 2.1859 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 902/12542 | Batch Loss: 1.4177 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 903/12542 | Batch Loss: 0.8796 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 904/12542 | Batch Loss: 1.9008 | Learning Rate: 0.000309 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 905/12542 | Batch Loss: 0.6546 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 906/12542 | Batch Loss: 1.5599 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 907/12542 | Batch Loss: 1.0795 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 908/12542 | Batch Loss: 1.4211 | Learning Rate: 0.000309 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 909/12542 | Batch Loss: 0.6682 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 910/12542 | Batch Loss: 1.6667 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 911/12542 | Batch Loss: 2.2114 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 912/12542 | Batch Loss: 1.4239 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 913/12542 | Batch Loss: 2.3815 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 914/12542 | Batch Loss: 1.1392 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 915/12542 | Batch Loss: 0.8347 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 916/12542 | Batch Loss: 1.5522 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 917/12542 | Batch Loss: 1.6210 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 918/12542 | Batch Loss: 1.1546 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 919/12542 | Batch Loss: 1.9537 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 920/12542 | Batch Loss: 1.2678 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 921/12542 | Batch Loss: 1.8126 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 922/12542 | Batch Loss: 0.9409 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 923/12542 | Batch Loss: 1.1260 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 924/12542 | Batch Loss: 2.0864 | Learning Rate: 0.000309 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 925/12542 | Batch Loss: 1.4403 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 926/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 927/12542 | Batch Loss: 2.2796 | Learning Rate: 0.000309 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 928/12542 | Batch Loss: 0.6083 | Learning Rate: 0.000309 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 929/12542 | Batch Loss: 1.2484 | Learning Rate: 0.000309 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 930/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000309 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 931/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 932/12542 | Batch Loss: 0.3289 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 933/12542 | Batch Loss: 1.4508 | Learning Rate: 0.000309 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 934/12542 | Batch Loss: 1.2769 | Learning Rate: 0.000309 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 935/12542 | Batch Loss: 1.5315 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 936/12542 | Batch Loss: 1.4408 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 937/12542 | Batch Loss: 1.4892 | Learning Rate: 0.000308 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 938/12542 | Batch Loss: 1.1952 | Learning Rate: 0.000308 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 939/12542 | Batch Loss: 2.2116 | Learning Rate: 0.000308 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 940/12542 | Batch Loss: 1.0815 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 941/12542 | Batch Loss: 1.0168 | Learning Rate: 0.000308 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 942/12542 | Batch Loss: 0.8335 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 943/12542 | Batch Loss: 0.7427 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 944/12542 | Batch Loss: 1.3786 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 945/12542 | Batch Loss: 0.7656 | Learning Rate: 0.000308 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 946/12542 | Batch Loss: 1.2205 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 947/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 948/12542 | Batch Loss: 1.8703 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 949/12542 | Batch Loss: 0.4487 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 950/12542 | Batch Loss: 1.8173 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 951/12542 | Batch Loss: 1.4887 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 952/12542 | Batch Loss: 2.0572 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 953/12542 | Batch Loss: 0.5072 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 954/12542 | Batch Loss: 0.9883 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 955/12542 | Batch Loss: 1.1863 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 956/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 957/12542 | Batch Loss: 0.5616 | Learning Rate: 0.000308 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 958/12542 | Batch Loss: 1.8537 | Learning Rate: 0.000308 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 959/12542 | Batch Loss: 1.3386 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 960/12542 | Batch Loss: 0.7572 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 961/12542 | Batch Loss: 0.8682 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 962/12542 | Batch Loss: 2.0529 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 963/12542 | Batch Loss: 1.1854 | Learning Rate: 0.000308 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 964/12542 | Batch Loss: 1.3497 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 965/12542 | Batch Loss: 2.2710 | Learning Rate: 0.000308 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 966/12542 | Batch Loss: 1.2734 | Learning Rate: 0.000308 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 967/12542 | Batch Loss: 1.3992 | Learning Rate: 0.000308 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 968/12542 | Batch Loss: 1.1720 | Learning Rate: 0.000308 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 969/12542 | Batch Loss: 1.5920 | Learning Rate: 0.000308 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 970/12542 | Batch Loss: 1.6022 | Learning Rate: 0.000308 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 971/12542 | Batch Loss: 1.8160 | Learning Rate: 0.000308 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 972/12542 | Batch Loss: 1.0741 | Learning Rate: 0.000308 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 973/12542 | Batch Loss: 1.0351 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 974/12542 | Batch Loss: 1.3806 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 975/12542 | Batch Loss: 1.5743 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 976/12542 | Batch Loss: 0.6990 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 977/12542 | Batch Loss: 0.7641 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 978/12542 | Batch Loss: 1.1353 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 979/12542 | Batch Loss: 2.7911 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 980/12542 | Batch Loss: 1.3458 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 981/12542 | Batch Loss: 0.9600 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 982/12542 | Batch Loss: 1.4616 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 983/12542 | Batch Loss: 1.4202 | Learning Rate: 0.000307 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 984/12542 | Batch Loss: 1.7563 | Learning Rate: 0.000307 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 985/12542 | Batch Loss: 0.6636 | Learning Rate: 0.000307 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 986/12542 | Batch Loss: 1.4450 | Learning Rate: 0.000307 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 987/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 988/12542 | Batch Loss: 2.0878 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 989/12542 | Batch Loss: 2.2855 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 990/12542 | Batch Loss: 0.9349 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 991/12542 | Batch Loss: 1.3843 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 992/12542 | Batch Loss: 0.5192 | Learning Rate: 0.000307 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 993/12542 | Batch Loss: 2.2314 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 994/12542 | Batch Loss: 1.9175 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 995/12542 | Batch Loss: 2.2520 | Learning Rate: 0.000307 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 996/12542 | Batch Loss: 1.0066 | Learning Rate: 0.000307 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 997/12542 | Batch Loss: 1.7831 | Learning Rate: 0.000307 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 998/12542 | Batch Loss: 1.4660 | Learning Rate: 0.000307 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 999/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000307 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1000/12542 | Batch Loss: 1.1441 | Learning Rate: 0.000307 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1001/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000307 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1002/12542 | Batch Loss: 1.0587 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1003/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000307 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1004/12542 | Batch Loss: 1.8780 | Learning Rate: 0.000307 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1005/12542 | Batch Loss: 1.0552 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1006/12542 | Batch Loss: 1.8206 | Learning Rate: 0.000307 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1007/12542 | Batch Loss: 1.4836 | Learning Rate: 0.000307 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1008/12542 | Batch Loss: 1.0508 | Learning Rate: 0.000307 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1009/12542 | Batch Loss: 3.4213 | Learning Rate: 0.000307 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1010/12542 | Batch Loss: 2.1932 | Learning Rate: 0.000306 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1011/12542 | Batch Loss: 1.0251 | Learning Rate: 0.000306 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1012/12542 | Batch Loss: 0.9898 | Learning Rate: 0.000306 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1013/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000306 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1014/12542 | Batch Loss: 0.8890 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1015/12542 | Batch Loss: 1.7927 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1016/12542 | Batch Loss: 2.1185 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1017/12542 | Batch Loss: 1.1374 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1018/12542 | Batch Loss: 0.6180 | Learning Rate: 0.000306 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1019/12542 | Batch Loss: 1.6668 | Learning Rate: 0.000306 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1020/12542 | Batch Loss: 1.2386 | Learning Rate: 0.000306 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1021/12542 | Batch Loss: 2.0163 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1022/12542 | Batch Loss: 0.9015 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1023/12542 | Batch Loss: 1.3333 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1024/12542 | Batch Loss: 1.5021 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1025/12542 | Batch Loss: 1.0610 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1026/12542 | Batch Loss: 2.9546 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1027/12542 | Batch Loss: 1.0286 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1028/12542 | Batch Loss: 1.4396 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1029/12542 | Batch Loss: 0.7845 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1030/12542 | Batch Loss: 2.2415 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1031/12542 | Batch Loss: 0.9596 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1032/12542 | Batch Loss: 1.2789 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1033/12542 | Batch Loss: 1.1993 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1034/12542 | Batch Loss: 1.0668 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1035/12542 | Batch Loss: 2.7258 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1036/12542 | Batch Loss: 1.0126 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1037/12542 | Batch Loss: 2.2242 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1038/12542 | Batch Loss: 0.8144 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1039/12542 | Batch Loss: 0.9181 | Learning Rate: 0.000306 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1040/12542 | Batch Loss: 0.8832 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1041/12542 | Batch Loss: 1.1894 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1042/12542 | Batch Loss: 0.8007 | Learning Rate: 0.000306 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1043/12542 | Batch Loss: 1.9190 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1044/12542 | Batch Loss: 1.1353 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1045/12542 | Batch Loss: 1.2865 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1046/12542 | Batch Loss: 1.0204 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1047/12542 | Batch Loss: 0.8852 | Learning Rate: 0.000306 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1048/12542 | Batch Loss: 0.8957 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1049/12542 | Batch Loss: 1.1451 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1050/12542 | Batch Loss: 1.5678 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1051/12542 | Batch Loss: 1.3599 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1052/12542 | Batch Loss: 0.8198 | Learning Rate: 0.000305 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 1053/12542 | Batch Loss: 2.0826 | Learning Rate: 0.000305 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1054/12542 | Batch Loss: 1.5379 | Learning Rate: 0.000305 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1055/12542 | Batch Loss: 1.4913 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1056/12542 | Batch Loss: 1.9306 | Learning Rate: 0.000305 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1057/12542 | Batch Loss: 2.7759 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1058/12542 | Batch Loss: 1.3467 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1059/12542 | Batch Loss: 1.5300 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1060/12542 | Batch Loss: 1.2493 | Learning Rate: 0.000305 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1061/12542 | Batch Loss: 1.2055 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1062/12542 | Batch Loss: 1.0650 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1063/12542 | Batch Loss: 0.8035 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1064/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1065/12542 | Batch Loss: 1.3311 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1066/12542 | Batch Loss: 1.3362 | Learning Rate: 0.000305 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1067/12542 | Batch Loss: 0.7334 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1068/12542 | Batch Loss: 0.7919 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1069/12542 | Batch Loss: 1.1923 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1070/12542 | Batch Loss: 1.9092 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1071/12542 | Batch Loss: 1.0158 | Learning Rate: 0.000305 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1072/12542 | Batch Loss: 0.8315 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1073/12542 | Batch Loss: 0.8944 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1074/12542 | Batch Loss: 1.1182 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1075/12542 | Batch Loss: 1.7206 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1076/12542 | Batch Loss: 0.6657 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1077/12542 | Batch Loss: 1.3087 | Learning Rate: 0.000305 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 1078/12542 | Batch Loss: 2.4392 | Learning Rate: 0.000305 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1079/12542 | Batch Loss: 2.0764 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1080/12542 | Batch Loss: 1.1181 | Learning Rate: 0.000305 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1081/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000305 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1082/12542 | Batch Loss: 1.0421 | Learning Rate: 0.000305 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1083/12542 | Batch Loss: 0.3501 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1084/12542 | Batch Loss: 0.8758 | Learning Rate: 0.000305 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1085/12542 | Batch Loss: 1.6948 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1086/12542 | Batch Loss: 0.6644 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1087/12542 | Batch Loss: 1.1746 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1088/12542 | Batch Loss: 1.5541 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1089/12542 | Batch Loss: 1.1757 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1090/12542 | Batch Loss: 0.9757 | Learning Rate: 0.000304 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1091/12542 | Batch Loss: 0.5641 | Learning Rate: 0.000304 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1092/12542 | Batch Loss: 0.5498 | Learning Rate: 0.000304 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1093/12542 | Batch Loss: 1.0242 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1094/12542 | Batch Loss: 1.1742 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1095/12542 | Batch Loss: 0.9065 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1096/12542 | Batch Loss: 2.0011 | Learning Rate: 0.000304 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1097/12542 | Batch Loss: 1.1843 | Learning Rate: 0.000304 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1098/12542 | Batch Loss: 0.3485 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1099/12542 | Batch Loss: 1.5276 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1100/12542 | Batch Loss: 0.8151 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1101/12542 | Batch Loss: 1.2008 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1102/12542 | Batch Loss: 1.3472 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1103/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1104/12542 | Batch Loss: 0.7168 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1105/12542 | Batch Loss: 1.7642 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1106/12542 | Batch Loss: 0.7055 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1107/12542 | Batch Loss: 1.7212 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1108/12542 | Batch Loss: 0.4563 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1109/12542 | Batch Loss: 2.3982 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1110/12542 | Batch Loss: 0.8052 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1111/12542 | Batch Loss: 0.8930 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1112/12542 | Batch Loss: 3.5490 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1113/12542 | Batch Loss: 1.4105 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1114/12542 | Batch Loss: 1.5822 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1115/12542 | Batch Loss: 1.6263 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1116/12542 | Batch Loss: 0.4772 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1117/12542 | Batch Loss: 1.3063 | Learning Rate: 0.000304 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1118/12542 | Batch Loss: 1.7513 | Learning Rate: 0.000304 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1119/12542 | Batch Loss: 1.3498 | Learning Rate: 0.000304 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1120/12542 | Batch Loss: 0.5742 | Learning Rate: 0.000304 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1121/12542 | Batch Loss: 1.6062 | Learning Rate: 0.000304 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1122/12542 | Batch Loss: 1.0351 | Learning Rate: 0.000304 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1123/12542 | Batch Loss: 1.0794 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1124/12542 | Batch Loss: 1.1064 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1125/12542 | Batch Loss: 2.0730 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1126/12542 | Batch Loss: 0.8694 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1127/12542 | Batch Loss: 0.6555 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1128/12542 | Batch Loss: 0.8877 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1129/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1130/12542 | Batch Loss: 0.9313 | Learning Rate: 0.000303 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1131/12542 | Batch Loss: 0.5228 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1132/12542 | Batch Loss: 1.3516 | Learning Rate: 0.000303 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1133/12542 | Batch Loss: 1.5380 | Learning Rate: 0.000303 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1134/12542 | Batch Loss: 1.6019 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1135/12542 | Batch Loss: 1.4776 | Learning Rate: 0.000303 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1136/12542 | Batch Loss: 1.0299 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1137/12542 | Batch Loss: 1.3443 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1138/12542 | Batch Loss: 2.6783 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1139/12542 | Batch Loss: 1.1489 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1140/12542 | Batch Loss: 1.3859 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1141/12542 | Batch Loss: 1.0827 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1142/12542 | Batch Loss: 0.9990 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1143/12542 | Batch Loss: 2.6099 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1144/12542 | Batch Loss: 0.7331 | Learning Rate: 0.000303 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1145/12542 | Batch Loss: 0.8888 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1146/12542 | Batch Loss: 1.0522 | Learning Rate: 0.000303 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1147/12542 | Batch Loss: 0.9555 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1148/12542 | Batch Loss: 2.7045 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1149/12542 | Batch Loss: 0.9462 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1150/12542 | Batch Loss: 1.2000 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1151/12542 | Batch Loss: 1.9747 | Learning Rate: 0.000303 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1152/12542 | Batch Loss: 0.7511 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1153/12542 | Batch Loss: 1.3042 | Learning Rate: 0.000303 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1154/12542 | Batch Loss: 2.1846 | Learning Rate: 0.000303 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1155/12542 | Batch Loss: 1.4872 | Learning Rate: 0.000303 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1156/12542 | Batch Loss: 1.8918 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1157/12542 | Batch Loss: 2.0813 | Learning Rate: 0.000303 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1158/12542 | Batch Loss: 1.2401 | Learning Rate: 0.000303 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1159/12542 | Batch Loss: 0.9685 | Learning Rate: 0.000303 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1160/12542 | Batch Loss: 0.9125 | Learning Rate: 0.000303 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1161/12542 | Batch Loss: 0.5917 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1162/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1163/12542 | Batch Loss: 2.8615 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1164/12542 | Batch Loss: 1.6072 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1165/12542 | Batch Loss: 2.1187 | Learning Rate: 0.000302 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1166/12542 | Batch Loss: 1.4706 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1167/12542 | Batch Loss: 0.8935 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1168/12542 | Batch Loss: 0.8509 | Learning Rate: 0.000302 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1169/12542 | Batch Loss: 0.6393 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1170/12542 | Batch Loss: 1.8771 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1171/12542 | Batch Loss: 0.5179 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1172/12542 | Batch Loss: 0.7500 | Learning Rate: 0.000302 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1173/12542 | Batch Loss: 0.9261 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1174/12542 | Batch Loss: 1.3362 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1175/12542 | Batch Loss: 1.3075 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1176/12542 | Batch Loss: 1.3695 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1177/12542 | Batch Loss: 1.4431 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1178/12542 | Batch Loss: 1.2391 | Learning Rate: 0.000302 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1179/12542 | Batch Loss: 1.3933 | Learning Rate: 0.000302 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1180/12542 | Batch Loss: 1.0939 | Learning Rate: 0.000302 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1181/12542 | Batch Loss: 1.9483 | Learning Rate: 0.000302 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1182/12542 | Batch Loss: 1.1140 | Learning Rate: 0.000302 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1183/12542 | Batch Loss: 1.0528 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1184/12542 | Batch Loss: 1.0262 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1185/12542 | Batch Loss: 0.7797 | Learning Rate: 0.000302 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1186/12542 | Batch Loss: 1.6571 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1187/12542 | Batch Loss: 0.9542 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1188/12542 | Batch Loss: 0.6452 | Learning Rate: 0.000302 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1189/12542 | Batch Loss: 1.4772 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1190/12542 | Batch Loss: 0.5888 | Learning Rate: 0.000302 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1191/12542 | Batch Loss: 0.8902 | Learning Rate: 0.000302 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1192/12542 | Batch Loss: 3.6571 | Learning Rate: 0.000302 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1193/12542 | Batch Loss: 1.1059 | Learning Rate: 0.000302 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1194/12542 | Batch Loss: 0.7201 | Learning Rate: 0.000302 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1195/12542 | Batch Loss: 0.7659 | Learning Rate: 0.000302 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 1196/12542 | Batch Loss: 1.5147 | Learning Rate: 0.000302 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1197/12542 | Batch Loss: 1.1405 | Learning Rate: 0.000302 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1198/12542 | Batch Loss: 3.1583 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1199/12542 | Batch Loss: 0.7143 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1200/12542 | Batch Loss: 0.5658 | Learning Rate: 0.000301 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1201/12542 | Batch Loss: 1.5506 | Learning Rate: 0.000301 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1202/12542 | Batch Loss: 2.0614 | Learning Rate: 0.000301 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1203/12542 | Batch Loss: 0.8360 | Learning Rate: 0.000301 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1204/12542 | Batch Loss: 0.8815 | Learning Rate: 0.000301 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1205/12542 | Batch Loss: 0.8249 | Learning Rate: 0.000301 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1206/12542 | Batch Loss: 0.7118 | Learning Rate: 0.000301 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1207/12542 | Batch Loss: 1.7584 | Learning Rate: 0.000301 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1208/12542 | Batch Loss: 1.5891 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1209/12542 | Batch Loss: 0.7497 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1210/12542 | Batch Loss: 0.8971 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1211/12542 | Batch Loss: 0.5581 | Learning Rate: 0.000301 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1212/12542 | Batch Loss: 0.7104 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1213/12542 | Batch Loss: 0.7635 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1214/12542 | Batch Loss: 1.2662 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1215/12542 | Batch Loss: 1.4584 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1216/12542 | Batch Loss: 0.4216 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1217/12542 | Batch Loss: 0.5873 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1218/12542 | Batch Loss: 1.1070 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1219/12542 | Batch Loss: 0.9587 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1220/12542 | Batch Loss: 0.7563 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1221/12542 | Batch Loss: 1.7626 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1222/12542 | Batch Loss: 0.6103 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1223/12542 | Batch Loss: 0.9924 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1224/12542 | Batch Loss: 1.0183 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1225/12542 | Batch Loss: 1.6429 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1226/12542 | Batch Loss: 0.9659 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1227/12542 | Batch Loss: 1.0826 | Learning Rate: 0.000301 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 1228/12542 | Batch Loss: 0.4613 | Learning Rate: 0.000301 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1229/12542 | Batch Loss: 1.6114 | Learning Rate: 0.000301 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1230/12542 | Batch Loss: 0.7670 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1231/12542 | Batch Loss: 1.1047 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1232/12542 | Batch Loss: 1.9956 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1233/12542 | Batch Loss: 1.5390 | Learning Rate: 0.000301 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1234/12542 | Batch Loss: 0.6085 | Learning Rate: 0.000301 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1235/12542 | Batch Loss: 2.4244 | Learning Rate: 0.000301 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1236/12542 | Batch Loss: 1.6923 | Learning Rate: 0.000300 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1237/12542 | Batch Loss: 1.6426 | Learning Rate: 0.000300 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1238/12542 | Batch Loss: 0.9204 | Learning Rate: 0.000300 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1239/12542 | Batch Loss: 2.0518 | Learning Rate: 0.000300 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1240/12542 | Batch Loss: 1.4636 | Learning Rate: 0.000300 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1241/12542 | Batch Loss: 1.0484 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1242/12542 | Batch Loss: 0.9151 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1243/12542 | Batch Loss: 1.8019 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1244/12542 | Batch Loss: 0.8927 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1245/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000300 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1246/12542 | Batch Loss: 1.6368 | Learning Rate: 0.000300 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1247/12542 | Batch Loss: 0.7861 | Learning Rate: 0.000300 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1248/12542 | Batch Loss: 3.0590 | Learning Rate: 0.000300 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1249/12542 | Batch Loss: 0.5241 | Learning Rate: 0.000300 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1250/12542 | Batch Loss: 2.0871 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1251/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1252/12542 | Batch Loss: 2.3090 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1253/12542 | Batch Loss: 1.8509 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1254/12542 | Batch Loss: 1.8204 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1255/12542 | Batch Loss: 1.0701 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1256/12542 | Batch Loss: 0.9907 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1257/12542 | Batch Loss: 0.9290 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1258/12542 | Batch Loss: 0.9344 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1259/12542 | Batch Loss: 0.9349 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1260/12542 | Batch Loss: 2.5239 | Learning Rate: 0.000300 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1261/12542 | Batch Loss: 2.1162 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1262/12542 | Batch Loss: 2.8986 | Learning Rate: 0.000300 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1263/12542 | Batch Loss: 1.6105 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1264/12542 | Batch Loss: 1.6242 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1265/12542 | Batch Loss: 0.7709 | Learning Rate: 0.000300 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1266/12542 | Batch Loss: 0.6757 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1267/12542 | Batch Loss: 0.7865 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1268/12542 | Batch Loss: 1.6901 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1269/12542 | Batch Loss: 0.4701 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1270/12542 | Batch Loss: 2.0057 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1271/12542 | Batch Loss: 0.9378 | Learning Rate: 0.000300 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1272/12542 | Batch Loss: 0.7119 | Learning Rate: 0.000300 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1273/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000300 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1274/12542 | Batch Loss: 1.1075 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1275/12542 | Batch Loss: 1.6457 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1276/12542 | Batch Loss: 2.6516 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1277/12542 | Batch Loss: 1.7358 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1278/12542 | Batch Loss: 0.7575 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1279/12542 | Batch Loss: 0.6426 | Learning Rate: 0.000299 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1280/12542 | Batch Loss: 0.7274 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1281/12542 | Batch Loss: 0.9758 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1282/12542 | Batch Loss: 1.0067 | Learning Rate: 0.000299 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1283/12542 | Batch Loss: 0.9115 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1284/12542 | Batch Loss: 0.9992 | Learning Rate: 0.000299 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1285/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1286/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1287/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1288/12542 | Batch Loss: 0.5911 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1289/12542 | Batch Loss: 0.6570 | Learning Rate: 0.000299 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1290/12542 | Batch Loss: 0.5667 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1291/12542 | Batch Loss: 0.7330 | Learning Rate: 0.000299 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1292/12542 | Batch Loss: 2.9493 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1293/12542 | Batch Loss: 0.8010 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1294/12542 | Batch Loss: 0.9775 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1295/12542 | Batch Loss: 0.8034 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1296/12542 | Batch Loss: 0.8516 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1297/12542 | Batch Loss: 1.3542 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1298/12542 | Batch Loss: 1.7347 | Learning Rate: 0.000299 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1299/12542 | Batch Loss: 0.8008 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1300/12542 | Batch Loss: 2.0125 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1301/12542 | Batch Loss: 1.3151 | Learning Rate: 0.000299 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1302/12542 | Batch Loss: 1.0036 | Learning Rate: 0.000299 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1303/12542 | Batch Loss: 0.6725 | Learning Rate: 0.000299 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1304/12542 | Batch Loss: 1.5423 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1305/12542 | Batch Loss: 1.2803 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1306/12542 | Batch Loss: 0.4826 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1307/12542 | Batch Loss: 1.7679 | Learning Rate: 0.000299 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1308/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1309/12542 | Batch Loss: 1.2222 | Learning Rate: 0.000299 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1310/12542 | Batch Loss: 1.2489 | Learning Rate: 0.000299 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1311/12542 | Batch Loss: 1.0675 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1312/12542 | Batch Loss: 1.7650 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1313/12542 | Batch Loss: 1.3196 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1314/12542 | Batch Loss: 1.1718 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1315/12542 | Batch Loss: 0.9709 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1316/12542 | Batch Loss: 1.2792 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1317/12542 | Batch Loss: 0.6423 | Learning Rate: 0.000298 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1318/12542 | Batch Loss: 1.0898 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1319/12542 | Batch Loss: 0.7564 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1320/12542 | Batch Loss: 0.6506 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1321/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1322/12542 | Batch Loss: 1.1490 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1323/12542 | Batch Loss: 0.8673 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1324/12542 | Batch Loss: 1.4035 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1325/12542 | Batch Loss: 1.4411 | Learning Rate: 0.000298 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1326/12542 | Batch Loss: 1.5614 | Learning Rate: 0.000298 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1327/12542 | Batch Loss: 2.3120 | Learning Rate: 0.000298 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1328/12542 | Batch Loss: 0.8353 | Learning Rate: 0.000298 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1329/12542 | Batch Loss: 0.5606 | Learning Rate: 0.000298 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1330/12542 | Batch Loss: 0.8210 | Learning Rate: 0.000298 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1331/12542 | Batch Loss: 1.2829 | Learning Rate: 0.000298 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1332/12542 | Batch Loss: 1.9377 | Learning Rate: 0.000298 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1333/12542 | Batch Loss: 1.6745 | Learning Rate: 0.000298 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1334/12542 | Batch Loss: 1.2131 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1335/12542 | Batch Loss: 1.9986 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1336/12542 | Batch Loss: 1.1984 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1337/12542 | Batch Loss: 0.5800 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1338/12542 | Batch Loss: 1.4423 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1339/12542 | Batch Loss: 0.8432 | Learning Rate: 0.000298 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1340/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1341/12542 | Batch Loss: 1.1528 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1342/12542 | Batch Loss: 2.1660 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1343/12542 | Batch Loss: 1.3923 | Learning Rate: 0.000298 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1344/12542 | Batch Loss: 1.9499 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1345/12542 | Batch Loss: 1.5833 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1346/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000298 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1347/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1348/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000298 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1349/12542 | Batch Loss: 0.4179 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1350/12542 | Batch Loss: 1.8706 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1351/12542 | Batch Loss: 1.5838 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1352/12542 | Batch Loss: 1.8223 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1353/12542 | Batch Loss: 2.6627 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1354/12542 | Batch Loss: 1.0330 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1355/12542 | Batch Loss: 0.8003 | Learning Rate: 0.000297 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1356/12542 | Batch Loss: 0.4796 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1357/12542 | Batch Loss: 1.7554 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1358/12542 | Batch Loss: 1.3121 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1359/12542 | Batch Loss: 0.6178 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1360/12542 | Batch Loss: 1.0683 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1361/12542 | Batch Loss: 1.0363 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1362/12542 | Batch Loss: 1.3998 | Learning Rate: 0.000297 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1363/12542 | Batch Loss: 1.3508 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1364/12542 | Batch Loss: 1.4394 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1365/12542 | Batch Loss: 1.2756 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1366/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1367/12542 | Batch Loss: 0.9215 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1368/12542 | Batch Loss: 0.5550 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1369/12542 | Batch Loss: 1.2678 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1370/12542 | Batch Loss: 0.6415 | Learning Rate: 0.000297 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1371/12542 | Batch Loss: 1.4187 | Learning Rate: 0.000297 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1372/12542 | Batch Loss: 0.4037 | Learning Rate: 0.000297 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1373/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1374/12542 | Batch Loss: 2.5295 | Learning Rate: 0.000297 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1375/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000297 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1376/12542 | Batch Loss: 1.3187 | Learning Rate: 0.000297 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1377/12542 | Batch Loss: 0.5724 | Learning Rate: 0.000297 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1378/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000297 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1379/12542 | Batch Loss: 0.6089 | Learning Rate: 0.000297 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1380/12542 | Batch Loss: 1.9448 | Learning Rate: 0.000297 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1381/12542 | Batch Loss: 1.9346 | Learning Rate: 0.000297 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1382/12542 | Batch Loss: 0.6428 | Learning Rate: 0.000297 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1383/12542 | Batch Loss: 1.7439 | Learning Rate: 0.000297 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1384/12542 | Batch Loss: 0.7753 | Learning Rate: 0.000297 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1385/12542 | Batch Loss: 0.7176 | Learning Rate: 0.000297 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1386/12542 | Batch Loss: 2.6606 | Learning Rate: 0.000296 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1387/12542 | Batch Loss: 0.5813 | Learning Rate: 0.000296 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1388/12542 | Batch Loss: 0.8548 | Learning Rate: 0.000296 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1389/12542 | Batch Loss: 1.9505 | Learning Rate: 0.000296 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1390/12542 | Batch Loss: 1.8220 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1391/12542 | Batch Loss: 0.8114 | Learning Rate: 0.000296 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1392/12542 | Batch Loss: 0.5499 | Learning Rate: 0.000296 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1393/12542 | Batch Loss: 1.8888 | Learning Rate: 0.000296 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1394/12542 | Batch Loss: 1.4208 | Learning Rate: 0.000296 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1395/12542 | Batch Loss: 2.4537 | Learning Rate: 0.000296 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1396/12542 | Batch Loss: 1.4467 | Learning Rate: 0.000296 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1397/12542 | Batch Loss: 1.0597 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1398/12542 | Batch Loss: 1.7588 | Learning Rate: 0.000296 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1399/12542 | Batch Loss: 0.9148 | Learning Rate: 0.000296 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1400/12542 | Batch Loss: 1.2699 | Learning Rate: 0.000296 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1401/12542 | Batch Loss: 0.9434 | Learning Rate: 0.000296 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1402/12542 | Batch Loss: 1.1089 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1403/12542 | Batch Loss: 1.6156 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1404/12542 | Batch Loss: 1.4052 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1405/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1406/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000296 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1407/12542 | Batch Loss: 1.1619 | Learning Rate: 0.000296 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1408/12542 | Batch Loss: 1.0938 | Learning Rate: 0.000296 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1409/12542 | Batch Loss: 1.2545 | Learning Rate: 0.000296 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1410/12542 | Batch Loss: 1.8509 | Learning Rate: 0.000296 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1411/12542 | Batch Loss: 0.9629 | Learning Rate: 0.000296 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1412/12542 | Batch Loss: 1.1314 | Learning Rate: 0.000296 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1413/12542 | Batch Loss: 1.0293 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1414/12542 | Batch Loss: 0.5049 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1415/12542 | Batch Loss: 2.4051 | Learning Rate: 0.000296 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1416/12542 | Batch Loss: 2.9541 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1417/12542 | Batch Loss: 0.8338 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1418/12542 | Batch Loss: 1.5238 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1419/12542 | Batch Loss: 1.5437 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1420/12542 | Batch Loss: 0.9694 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1421/12542 | Batch Loss: 0.7528 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1422/12542 | Batch Loss: 1.1779 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1423/12542 | Batch Loss: 1.7884 | Learning Rate: 0.000296 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1424/12542 | Batch Loss: 0.6166 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1425/12542 | Batch Loss: 3.1862 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1426/12542 | Batch Loss: 1.1665 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1427/12542 | Batch Loss: 3.3591 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1428/12542 | Batch Loss: 2.3311 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1429/12542 | Batch Loss: 0.9526 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1430/12542 | Batch Loss: 1.5318 | Learning Rate: 0.000295 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1431/12542 | Batch Loss: 1.2576 | Learning Rate: 0.000295 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1432/12542 | Batch Loss: 0.7107 | Learning Rate: 0.000295 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1433/12542 | Batch Loss: 1.3668 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1434/12542 | Batch Loss: 1.5633 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1435/12542 | Batch Loss: 0.6110 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1436/12542 | Batch Loss: 1.1232 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1437/12542 | Batch Loss: 1.8236 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1438/12542 | Batch Loss: 0.7123 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1439/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1440/12542 | Batch Loss: 1.4731 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1441/12542 | Batch Loss: 1.1895 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1442/12542 | Batch Loss: 1.6631 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1443/12542 | Batch Loss: 1.5649 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1444/12542 | Batch Loss: 0.9133 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1445/12542 | Batch Loss: 1.2705 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1446/12542 | Batch Loss: 2.1419 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1447/12542 | Batch Loss: 1.1712 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1448/12542 | Batch Loss: 0.6009 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1449/12542 | Batch Loss: 0.6092 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1450/12542 | Batch Loss: 0.5001 | Learning Rate: 0.000295 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1451/12542 | Batch Loss: 0.8348 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1452/12542 | Batch Loss: 1.4458 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1453/12542 | Batch Loss: 1.2558 | Learning Rate: 0.000295 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1454/12542 | Batch Loss: 1.5351 | Learning Rate: 0.000295 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1455/12542 | Batch Loss: 0.6816 | Learning Rate: 0.000295 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1456/12542 | Batch Loss: 1.1703 | Learning Rate: 0.000295 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1457/12542 | Batch Loss: 2.4330 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1458/12542 | Batch Loss: 1.6116 | Learning Rate: 0.000295 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1459/12542 | Batch Loss: 0.8549 | Learning Rate: 0.000295 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1460/12542 | Batch Loss: 1.5462 | Learning Rate: 0.000295 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1461/12542 | Batch Loss: 0.9461 | Learning Rate: 0.000295 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1462/12542 | Batch Loss: 1.4757 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1463/12542 | Batch Loss: 0.8444 | Learning Rate: 0.000294 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1464/12542 | Batch Loss: 2.2781 | Learning Rate: 0.000294 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1465/12542 | Batch Loss: 1.8794 | Learning Rate: 0.000294 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1466/12542 | Batch Loss: 1.7915 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1467/12542 | Batch Loss: 1.0466 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1468/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1469/12542 | Batch Loss: 1.5532 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1470/12542 | Batch Loss: 1.3347 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1471/12542 | Batch Loss: 1.1759 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1472/12542 | Batch Loss: 1.5684 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1473/12542 | Batch Loss: 1.5061 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1474/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1475/12542 | Batch Loss: 2.0204 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1476/12542 | Batch Loss: 1.0777 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1477/12542 | Batch Loss: 2.7097 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1478/12542 | Batch Loss: 0.7478 | Learning Rate: 0.000294 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1479/12542 | Batch Loss: 2.3956 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1480/12542 | Batch Loss: 0.3715 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1481/12542 | Batch Loss: 1.7073 | Learning Rate: 0.000294 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1482/12542 | Batch Loss: 2.0416 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1483/12542 | Batch Loss: 0.8264 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1484/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1485/12542 | Batch Loss: 1.6175 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1486/12542 | Batch Loss: 1.1890 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1487/12542 | Batch Loss: 0.9784 | Learning Rate: 0.000294 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1488/12542 | Batch Loss: 1.1587 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1489/12542 | Batch Loss: 1.1103 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1490/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1491/12542 | Batch Loss: 1.3332 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1492/12542 | Batch Loss: 1.9689 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1493/12542 | Batch Loss: 2.4404 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1494/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1495/12542 | Batch Loss: 1.0323 | Learning Rate: 0.000294 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1496/12542 | Batch Loss: 1.4564 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1497/12542 | Batch Loss: 0.9459 | Learning Rate: 0.000294 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1498/12542 | Batch Loss: 0.8426 | Learning Rate: 0.000294 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1499/12542 | Batch Loss: 2.7463 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1500/12542 | Batch Loss: 0.9784 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1501/12542 | Batch Loss: 1.2907 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1502/12542 | Batch Loss: 0.7787 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1503/12542 | Batch Loss: 1.2303 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1504/12542 | Batch Loss: 0.9446 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1505/12542 | Batch Loss: 1.3582 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1506/12542 | Batch Loss: 1.8278 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1507/12542 | Batch Loss: 1.2367 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1508/12542 | Batch Loss: 0.8388 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1509/12542 | Batch Loss: 0.5062 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1510/12542 | Batch Loss: 1.2622 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1511/12542 | Batch Loss: 1.1464 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1512/12542 | Batch Loss: 1.1755 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1513/12542 | Batch Loss: 1.4477 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1514/12542 | Batch Loss: 2.9447 | Learning Rate: 0.000293 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1515/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000293 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1516/12542 | Batch Loss: 0.5437 | Learning Rate: 0.000293 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1517/12542 | Batch Loss: 2.5337 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1518/12542 | Batch Loss: 0.8713 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1519/12542 | Batch Loss: 0.8641 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1520/12542 | Batch Loss: 0.8717 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1521/12542 | Batch Loss: 0.9881 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1522/12542 | Batch Loss: 1.2645 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1523/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1524/12542 | Batch Loss: 1.8285 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1525/12542 | Batch Loss: 1.6292 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1526/12542 | Batch Loss: 1.1218 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1527/12542 | Batch Loss: 1.6771 | Learning Rate: 0.000293 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1528/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1529/12542 | Batch Loss: 2.1126 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1530/12542 | Batch Loss: 1.7930 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1531/12542 | Batch Loss: 1.1350 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1532/12542 | Batch Loss: 2.8216 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1533/12542 | Batch Loss: 0.7489 | Learning Rate: 0.000293 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1534/12542 | Batch Loss: 1.0154 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1535/12542 | Batch Loss: 1.0740 | Learning Rate: 0.000293 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1536/12542 | Batch Loss: 1.4079 | Learning Rate: 0.000293 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1537/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1538/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1539/12542 | Batch Loss: 1.4526 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1540/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1541/12542 | Batch Loss: 1.0849 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1542/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1543/12542 | Batch Loss: 3.0673 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1544/12542 | Batch Loss: 2.4330 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1545/12542 | Batch Loss: 1.3612 | Learning Rate: 0.000292 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1546/12542 | Batch Loss: 1.4652 | Learning Rate: 0.000292 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1547/12542 | Batch Loss: 1.5686 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1548/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1549/12542 | Batch Loss: 1.7795 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1550/12542 | Batch Loss: 2.5785 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1551/12542 | Batch Loss: 1.6245 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1552/12542 | Batch Loss: 0.6817 | Learning Rate: 0.000292 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1553/12542 | Batch Loss: 0.7308 | Learning Rate: 0.000292 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1554/12542 | Batch Loss: 2.1170 | Learning Rate: 0.000292 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1555/12542 | Batch Loss: 0.5144 | Learning Rate: 0.000292 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1556/12542 | Batch Loss: 1.6715 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1557/12542 | Batch Loss: 0.7705 | Learning Rate: 0.000292 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1558/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000292 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1559/12542 | Batch Loss: 3.1043 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1560/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1561/12542 | Batch Loss: 0.7378 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1562/12542 | Batch Loss: 1.5786 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1563/12542 | Batch Loss: 2.9486 | Learning Rate: 0.000292 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1564/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1565/12542 | Batch Loss: 2.1027 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1566/12542 | Batch Loss: 1.8922 | Learning Rate: 0.000292 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1567/12542 | Batch Loss: 0.9096 | Learning Rate: 0.000292 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1568/12542 | Batch Loss: 0.6712 | Learning Rate: 0.000292 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1569/12542 | Batch Loss: 0.8398 | Learning Rate: 0.000292 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1570/12542 | Batch Loss: 1.0853 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1571/12542 | Batch Loss: 0.8675 | Learning Rate: 0.000292 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1572/12542 | Batch Loss: 1.8174 | Learning Rate: 0.000292 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1573/12542 | Batch Loss: 0.8044 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1574/12542 | Batch Loss: 0.9119 | Learning Rate: 0.000292 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1575/12542 | Batch Loss: 0.8555 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1576/12542 | Batch Loss: 1.2778 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1577/12542 | Batch Loss: 2.3765 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1578/12542 | Batch Loss: 0.7810 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1579/12542 | Batch Loss: 0.5829 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1580/12542 | Batch Loss: 2.3649 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1581/12542 | Batch Loss: 2.9148 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1582/12542 | Batch Loss: 3.5934 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1583/12542 | Batch Loss: 1.7454 | Learning Rate: 0.000291 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1584/12542 | Batch Loss: 1.6078 | Learning Rate: 0.000291 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1585/12542 | Batch Loss: 1.3227 | Learning Rate: 0.000291 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1586/12542 | Batch Loss: 2.3246 | Learning Rate: 0.000291 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1587/12542 | Batch Loss: 0.7604 | Learning Rate: 0.000291 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1588/12542 | Batch Loss: 1.9677 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1589/12542 | Batch Loss: 1.7852 | Learning Rate: 0.000291 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1590/12542 | Batch Loss: 1.1934 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1591/12542 | Batch Loss: 1.2060 | Learning Rate: 0.000291 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1592/12542 | Batch Loss: 1.5808 | Learning Rate: 0.000291 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1593/12542 | Batch Loss: 1.8977 | Learning Rate: 0.000291 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1594/12542 | Batch Loss: 2.0951 | Learning Rate: 0.000291 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1595/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000291 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1596/12542 | Batch Loss: 1.0800 | Learning Rate: 0.000291 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1597/12542 | Batch Loss: 1.5656 | Learning Rate: 0.000291 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1598/12542 | Batch Loss: 0.3674 | Learning Rate: 0.000291 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1599/12542 | Batch Loss: 1.5065 | Learning Rate: 0.000291 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1600/12542 | Batch Loss: 0.9178 | Learning Rate: 0.000291 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1601/12542 | Batch Loss: 2.2008 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1602/12542 | Batch Loss: 1.2935 | Learning Rate: 0.000291 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1603/12542 | Batch Loss: 0.7728 | Learning Rate: 0.000291 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1604/12542 | Batch Loss: 2.7007 | Learning Rate: 0.000291 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1605/12542 | Batch Loss: 1.2942 | Learning Rate: 0.000291 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1606/12542 | Batch Loss: 0.6751 | Learning Rate: 0.000291 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1607/12542 | Batch Loss: 1.3965 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1608/12542 | Batch Loss: 1.2461 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1609/12542 | Batch Loss: 0.7680 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1610/12542 | Batch Loss: 1.5157 | Learning Rate: 0.000291 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1611/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000291 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1612/12542 | Batch Loss: 1.0284 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1613/12542 | Batch Loss: 1.5185 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1614/12542 | Batch Loss: 0.8469 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1615/12542 | Batch Loss: 0.6245 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1616/12542 | Batch Loss: 2.0213 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1617/12542 | Batch Loss: 0.9865 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1618/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1619/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000290 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1620/12542 | Batch Loss: 1.6764 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1621/12542 | Batch Loss: 0.8367 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1622/12542 | Batch Loss: 1.3372 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1623/12542 | Batch Loss: 1.6111 | Learning Rate: 0.000290 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1624/12542 | Batch Loss: 1.8451 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1625/12542 | Batch Loss: 1.8391 | Learning Rate: 0.000290 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1626/12542 | Batch Loss: 1.2108 | Learning Rate: 0.000290 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1627/12542 | Batch Loss: 0.4548 | Learning Rate: 0.000290 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1628/12542 | Batch Loss: 1.1381 | Learning Rate: 0.000290 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1629/12542 | Batch Loss: 1.6523 | Learning Rate: 0.000290 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1630/12542 | Batch Loss: 1.5850 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1631/12542 | Batch Loss: 0.6966 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1632/12542 | Batch Loss: 1.8113 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1633/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000290 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 1634/12542 | Batch Loss: 1.4471 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1635/12542 | Batch Loss: 1.4498 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1636/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1637/12542 | Batch Loss: 1.0739 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1638/12542 | Batch Loss: 1.7603 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1639/12542 | Batch Loss: 1.8737 | Learning Rate: 0.000290 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1640/12542 | Batch Loss: 1.9307 | Learning Rate: 0.000290 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1641/12542 | Batch Loss: 1.2432 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1642/12542 | Batch Loss: 1.6184 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1643/12542 | Batch Loss: 1.4039 | Learning Rate: 0.000290 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1644/12542 | Batch Loss: 1.2086 | Learning Rate: 0.000290 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1645/12542 | Batch Loss: 0.7862 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1646/12542 | Batch Loss: 0.6973 | Learning Rate: 0.000290 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1647/12542 | Batch Loss: 0.8890 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1648/12542 | Batch Loss: 1.7773 | Learning Rate: 0.000290 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1649/12542 | Batch Loss: 1.5108 | Learning Rate: 0.000290 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1650/12542 | Batch Loss: 1.1762 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1651/12542 | Batch Loss: 1.2263 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1652/12542 | Batch Loss: 0.8862 | Learning Rate: 0.000289 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1653/12542 | Batch Loss: 1.1168 | Learning Rate: 0.000289 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1654/12542 | Batch Loss: 1.0794 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1655/12542 | Batch Loss: 1.2375 | Learning Rate: 0.000289 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1656/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1657/12542 | Batch Loss: 1.8609 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1658/12542 | Batch Loss: 1.6007 | Learning Rate: 0.000289 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1659/12542 | Batch Loss: 1.9317 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1660/12542 | Batch Loss: 1.3649 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1661/12542 | Batch Loss: 1.1984 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1662/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1663/12542 | Batch Loss: 0.7254 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1664/12542 | Batch Loss: 1.4282 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1665/12542 | Batch Loss: 0.8916 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1666/12542 | Batch Loss: 0.7739 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1667/12542 | Batch Loss: 0.6640 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1668/12542 | Batch Loss: 0.5383 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1669/12542 | Batch Loss: 0.9923 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1670/12542 | Batch Loss: 0.8065 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1671/12542 | Batch Loss: 1.2912 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1672/12542 | Batch Loss: 0.8077 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1673/12542 | Batch Loss: 1.5251 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1674/12542 | Batch Loss: 1.8031 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1675/12542 | Batch Loss: 2.4201 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1676/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000289 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1677/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1678/12542 | Batch Loss: 2.3814 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1679/12542 | Batch Loss: 1.0765 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1680/12542 | Batch Loss: 1.3964 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1681/12542 | Batch Loss: 0.5181 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1682/12542 | Batch Loss: 1.2737 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1683/12542 | Batch Loss: 1.3731 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1684/12542 | Batch Loss: 1.6106 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1685/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000289 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1686/12542 | Batch Loss: 2.5194 | Learning Rate: 0.000289 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1687/12542 | Batch Loss: 1.3334 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1688/12542 | Batch Loss: 1.3554 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1689/12542 | Batch Loss: 1.0682 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1690/12542 | Batch Loss: 1.2331 | Learning Rate: 0.000288 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1691/12542 | Batch Loss: 0.9631 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1692/12542 | Batch Loss: 1.3511 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1693/12542 | Batch Loss: 1.6880 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1694/12542 | Batch Loss: 1.8759 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1695/12542 | Batch Loss: 1.2013 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1696/12542 | Batch Loss: 0.4138 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1697/12542 | Batch Loss: 1.0284 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1698/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1699/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1700/12542 | Batch Loss: 1.2663 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1701/12542 | Batch Loss: 2.4873 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1702/12542 | Batch Loss: 2.1571 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1703/12542 | Batch Loss: 1.0340 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1704/12542 | Batch Loss: 1.6611 | Learning Rate: 0.000288 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1705/12542 | Batch Loss: 2.2818 | Learning Rate: 0.000288 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1706/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000288 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1707/12542 | Batch Loss: 1.3658 | Learning Rate: 0.000288 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1708/12542 | Batch Loss: 1.5216 | Learning Rate: 0.000288 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1709/12542 | Batch Loss: 0.6689 | Learning Rate: 0.000288 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1710/12542 | Batch Loss: 1.2591 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1711/12542 | Batch Loss: 0.9514 | Learning Rate: 0.000288 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1712/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1713/12542 | Batch Loss: 2.8789 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1714/12542 | Batch Loss: 2.4953 | Learning Rate: 0.000288 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1715/12542 | Batch Loss: 1.7238 | Learning Rate: 0.000288 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1716/12542 | Batch Loss: 1.9361 | Learning Rate: 0.000288 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1717/12542 | Batch Loss: 1.0076 | Learning Rate: 0.000288 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1718/12542 | Batch Loss: 1.2595 | Learning Rate: 0.000288 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1719/12542 | Batch Loss: 0.8986 | Learning Rate: 0.000288 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1720/12542 | Batch Loss: 0.9295 | Learning Rate: 0.000288 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1721/12542 | Batch Loss: 1.0853 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1722/12542 | Batch Loss: 0.5861 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1723/12542 | Batch Loss: 1.7612 | Learning Rate: 0.000288 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1724/12542 | Batch Loss: 2.1525 | Learning Rate: 0.000288 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1725/12542 | Batch Loss: 1.7959 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1726/12542 | Batch Loss: 0.8179 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1727/12542 | Batch Loss: 1.1962 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1728/12542 | Batch Loss: 0.8725 | Learning Rate: 0.000287 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1729/12542 | Batch Loss: 1.6980 | Learning Rate: 0.000287 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1730/12542 | Batch Loss: 1.0140 | Learning Rate: 0.000287 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1731/12542 | Batch Loss: 0.8530 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1732/12542 | Batch Loss: 1.0185 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1733/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1734/12542 | Batch Loss: 1.4181 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1735/12542 | Batch Loss: 1.4446 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1736/12542 | Batch Loss: 0.7176 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1737/12542 | Batch Loss: 1.2344 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1738/12542 | Batch Loss: 1.0183 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1739/12542 | Batch Loss: 1.8809 | Learning Rate: 0.000287 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1740/12542 | Batch Loss: 0.8864 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1741/12542 | Batch Loss: 1.2105 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1742/12542 | Batch Loss: 1.2932 | Learning Rate: 0.000287 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1743/12542 | Batch Loss: 0.7020 | Learning Rate: 0.000287 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1744/12542 | Batch Loss: 0.6060 | Learning Rate: 0.000287 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1745/12542 | Batch Loss: 1.5335 | Learning Rate: 0.000287 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1746/12542 | Batch Loss: 2.5400 | Learning Rate: 0.000287 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1747/12542 | Batch Loss: 1.2467 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1748/12542 | Batch Loss: 1.3943 | Learning Rate: 0.000287 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1749/12542 | Batch Loss: 1.3254 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1750/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000287 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1751/12542 | Batch Loss: 2.8586 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1752/12542 | Batch Loss: 1.7758 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1753/12542 | Batch Loss: 3.3101 | Learning Rate: 0.000287 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1754/12542 | Batch Loss: 0.7962 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1755/12542 | Batch Loss: 0.7017 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1756/12542 | Batch Loss: 2.1107 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1757/12542 | Batch Loss: 0.6997 | Learning Rate: 0.000287 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1758/12542 | Batch Loss: 2.7791 | Learning Rate: 0.000287 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1759/12542 | Batch Loss: 0.8318 | Learning Rate: 0.000287 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1760/12542 | Batch Loss: 1.3250 | Learning Rate: 0.000287 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1761/12542 | Batch Loss: 0.9956 | Learning Rate: 0.000287 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1762/12542 | Batch Loss: 0.9255 | Learning Rate: 0.000287 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1763/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1764/12542 | Batch Loss: 0.6687 | Learning Rate: 0.000286 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1765/12542 | Batch Loss: 1.2497 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1766/12542 | Batch Loss: 1.2356 | Learning Rate: 0.000286 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1767/12542 | Batch Loss: 1.0978 | Learning Rate: 0.000286 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1768/12542 | Batch Loss: 1.0891 | Learning Rate: 0.000286 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1769/12542 | Batch Loss: 1.2988 | Learning Rate: 0.000286 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1770/12542 | Batch Loss: 0.6222 | Learning Rate: 0.000286 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1771/12542 | Batch Loss: 1.2993 | Learning Rate: 0.000286 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1772/12542 | Batch Loss: 1.6698 | Learning Rate: 0.000286 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1773/12542 | Batch Loss: 0.6300 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1774/12542 | Batch Loss: 1.2004 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1775/12542 | Batch Loss: 2.3006 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1776/12542 | Batch Loss: 1.4619 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1777/12542 | Batch Loss: 0.8571 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1778/12542 | Batch Loss: 1.5625 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1779/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1780/12542 | Batch Loss: 0.8395 | Learning Rate: 0.000286 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1781/12542 | Batch Loss: 0.7751 | Learning Rate: 0.000286 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1782/12542 | Batch Loss: 0.5547 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1783/12542 | Batch Loss: 1.3290 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1784/12542 | Batch Loss: 0.7642 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1785/12542 | Batch Loss: 2.5392 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1786/12542 | Batch Loss: 1.1946 | Learning Rate: 0.000286 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1787/12542 | Batch Loss: 2.5681 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1788/12542 | Batch Loss: 0.9093 | Learning Rate: 0.000286 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1789/12542 | Batch Loss: 0.4560 | Learning Rate: 0.000286 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1790/12542 | Batch Loss: 1.5798 | Learning Rate: 0.000286 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1791/12542 | Batch Loss: 1.1209 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1792/12542 | Batch Loss: 1.0677 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1793/12542 | Batch Loss: 1.0574 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1794/12542 | Batch Loss: 0.6871 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1795/12542 | Batch Loss: 1.7195 | Learning Rate: 0.000286 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1796/12542 | Batch Loss: 1.1999 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1797/12542 | Batch Loss: 1.1512 | Learning Rate: 0.000286 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1798/12542 | Batch Loss: 1.5777 | Learning Rate: 0.000286 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1799/12542 | Batch Loss: 2.2227 | Learning Rate: 0.000286 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1800/12542 | Batch Loss: 0.9756 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1801/12542 | Batch Loss: 1.1477 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1802/12542 | Batch Loss: 2.4026 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1803/12542 | Batch Loss: 0.5963 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1804/12542 | Batch Loss: 1.6488 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1805/12542 | Batch Loss: 0.4091 | Learning Rate: 0.000285 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1806/12542 | Batch Loss: 0.8843 | Learning Rate: 0.000285 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1807/12542 | Batch Loss: 0.9378 | Learning Rate: 0.000285 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1808/12542 | Batch Loss: 2.5553 | Learning Rate: 0.000285 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1809/12542 | Batch Loss: 2.3728 | Learning Rate: 0.000285 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1810/12542 | Batch Loss: 1.1079 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1811/12542 | Batch Loss: 1.6687 | Learning Rate: 0.000285 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1812/12542 | Batch Loss: 1.6670 | Learning Rate: 0.000285 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1813/12542 | Batch Loss: 1.2409 | Learning Rate: 0.000285 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1814/12542 | Batch Loss: 0.9212 | Learning Rate: 0.000285 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 1815/12542 | Batch Loss: 1.3095 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1816/12542 | Batch Loss: 1.8598 | Learning Rate: 0.000285 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1817/12542 | Batch Loss: 1.1546 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1818/12542 | Batch Loss: 2.1753 | Learning Rate: 0.000285 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1819/12542 | Batch Loss: 0.8410 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1820/12542 | Batch Loss: 1.5217 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1821/12542 | Batch Loss: 1.4535 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1822/12542 | Batch Loss: 1.1535 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1823/12542 | Batch Loss: 1.1037 | Learning Rate: 0.000285 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1824/12542 | Batch Loss: 0.8887 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1825/12542 | Batch Loss: 1.6384 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1826/12542 | Batch Loss: 2.0070 | Learning Rate: 0.000285 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1827/12542 | Batch Loss: 1.5369 | Learning Rate: 0.000285 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1828/12542 | Batch Loss: 1.9401 | Learning Rate: 0.000285 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1829/12542 | Batch Loss: 1.1316 | Learning Rate: 0.000285 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1830/12542 | Batch Loss: 2.0435 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1831/12542 | Batch Loss: 1.7630 | Learning Rate: 0.000285 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1832/12542 | Batch Loss: 1.1728 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1833/12542 | Batch Loss: 1.1387 | Learning Rate: 0.000285 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1834/12542 | Batch Loss: 0.5936 | Learning Rate: 0.000285 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1835/12542 | Batch Loss: 0.9221 | Learning Rate: 0.000285 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 1836/12542 | Batch Loss: 2.0087 | Learning Rate: 0.000285 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1837/12542 | Batch Loss: 0.8685 | Learning Rate: 0.000285 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1838/12542 | Batch Loss: 1.2121 | Learning Rate: 0.000284 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1839/12542 | Batch Loss: 1.8230 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1840/12542 | Batch Loss: 1.3270 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1841/12542 | Batch Loss: 1.8692 | Learning Rate: 0.000284 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1842/12542 | Batch Loss: 0.8552 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1843/12542 | Batch Loss: 1.2677 | Learning Rate: 0.000284 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1844/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1845/12542 | Batch Loss: 0.5332 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1846/12542 | Batch Loss: 1.6163 | Learning Rate: 0.000284 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1847/12542 | Batch Loss: 1.6096 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1848/12542 | Batch Loss: 1.5725 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1849/12542 | Batch Loss: 1.0914 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1850/12542 | Batch Loss: 0.5560 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1851/12542 | Batch Loss: 2.5238 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1852/12542 | Batch Loss: 1.1726 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1853/12542 | Batch Loss: 1.0646 | Learning Rate: 0.000284 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1854/12542 | Batch Loss: 2.4195 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1855/12542 | Batch Loss: 3.1103 | Learning Rate: 0.000284 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1856/12542 | Batch Loss: 0.5547 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1857/12542 | Batch Loss: 0.7738 | Learning Rate: 0.000284 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1858/12542 | Batch Loss: 1.2594 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1859/12542 | Batch Loss: 0.7136 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1860/12542 | Batch Loss: 1.4662 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1861/12542 | Batch Loss: 0.6869 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1862/12542 | Batch Loss: 1.5789 | Learning Rate: 0.000284 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1863/12542 | Batch Loss: 0.6056 | Learning Rate: 0.000284 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1864/12542 | Batch Loss: 1.1626 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1865/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1866/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000284 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1867/12542 | Batch Loss: 1.8581 | Learning Rate: 0.000284 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1868/12542 | Batch Loss: 0.7166 | Learning Rate: 0.000284 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1869/12542 | Batch Loss: 1.2571 | Learning Rate: 0.000284 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1870/12542 | Batch Loss: 1.3714 | Learning Rate: 0.000284 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1871/12542 | Batch Loss: 1.6671 | Learning Rate: 0.000284 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1872/12542 | Batch Loss: 1.5803 | Learning Rate: 0.000284 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1873/12542 | Batch Loss: 0.6409 | Learning Rate: 0.000284 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1874/12542 | Batch Loss: 2.2885 | Learning Rate: 0.000284 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1875/12542 | Batch Loss: 0.7671 | Learning Rate: 0.000284 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1876/12542 | Batch Loss: 1.7566 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1877/12542 | Batch Loss: 0.6474 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1878/12542 | Batch Loss: 1.0392 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1879/12542 | Batch Loss: 1.8722 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1880/12542 | Batch Loss: 1.7143 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1881/12542 | Batch Loss: 2.1705 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1882/12542 | Batch Loss: 0.5641 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1883/12542 | Batch Loss: 1.0907 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1884/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1885/12542 | Batch Loss: 1.4214 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1886/12542 | Batch Loss: 0.6145 | Learning Rate: 0.000283 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1887/12542 | Batch Loss: 1.4262 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1888/12542 | Batch Loss: 2.2130 | Learning Rate: 0.000283 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 1889/12542 | Batch Loss: 0.9935 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1890/12542 | Batch Loss: 1.8935 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1891/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1892/12542 | Batch Loss: 0.6177 | Learning Rate: 0.000283 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1893/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1894/12542 | Batch Loss: 0.7625 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1895/12542 | Batch Loss: 1.8105 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1896/12542 | Batch Loss: 1.5682 | Learning Rate: 0.000283 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1897/12542 | Batch Loss: 0.9216 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1898/12542 | Batch Loss: 1.2816 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1899/12542 | Batch Loss: 0.7693 | Learning Rate: 0.000283 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1900/12542 | Batch Loss: 1.8567 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1901/12542 | Batch Loss: 1.5208 | Learning Rate: 0.000283 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1902/12542 | Batch Loss: 1.1747 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1903/12542 | Batch Loss: 1.5871 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1904/12542 | Batch Loss: 2.5358 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1905/12542 | Batch Loss: 1.3363 | Learning Rate: 0.000283 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1906/12542 | Batch Loss: 1.3110 | Learning Rate: 0.000283 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1907/12542 | Batch Loss: 1.9328 | Learning Rate: 0.000283 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1908/12542 | Batch Loss: 1.5540 | Learning Rate: 0.000283 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1909/12542 | Batch Loss: 1.5389 | Learning Rate: 0.000283 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1910/12542 | Batch Loss: 2.4227 | Learning Rate: 0.000283 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1911/12542 | Batch Loss: 1.0032 | Learning Rate: 0.000283 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1912/12542 | Batch Loss: 1.4047 | Learning Rate: 0.000283 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1913/12542 | Batch Loss: 1.9794 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1914/12542 | Batch Loss: 1.2404 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1915/12542 | Batch Loss: 2.0754 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1916/12542 | Batch Loss: 1.8732 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1917/12542 | Batch Loss: 1.0555 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1918/12542 | Batch Loss: 1.3338 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1919/12542 | Batch Loss: 0.6784 | Learning Rate: 0.000282 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1920/12542 | Batch Loss: 2.2880 | Learning Rate: 0.000282 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1921/12542 | Batch Loss: 1.6715 | Learning Rate: 0.000282 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1922/12542 | Batch Loss: 0.8599 | Learning Rate: 0.000282 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1923/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1924/12542 | Batch Loss: 2.8693 | Learning Rate: 0.000282 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1925/12542 | Batch Loss: 1.9885 | Learning Rate: 0.000282 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1926/12542 | Batch Loss: 0.8433 | Learning Rate: 0.000282 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1927/12542 | Batch Loss: 1.0316 | Learning Rate: 0.000282 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1928/12542 | Batch Loss: 0.5687 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1929/12542 | Batch Loss: 1.4933 | Learning Rate: 0.000282 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1930/12542 | Batch Loss: 1.2299 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1931/12542 | Batch Loss: 1.0691 | Learning Rate: 0.000282 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1932/12542 | Batch Loss: 1.2195 | Learning Rate: 0.000282 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1933/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000282 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1934/12542 | Batch Loss: 1.3705 | Learning Rate: 0.000282 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1935/12542 | Batch Loss: 2.3155 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1936/12542 | Batch Loss: 2.3793 | Learning Rate: 0.000282 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1937/12542 | Batch Loss: 1.6231 | Learning Rate: 0.000282 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1938/12542 | Batch Loss: 1.2278 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1939/12542 | Batch Loss: 1.0576 | Learning Rate: 0.000282 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1940/12542 | Batch Loss: 1.8382 | Learning Rate: 0.000282 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1941/12542 | Batch Loss: 0.5191 | Learning Rate: 0.000282 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1942/12542 | Batch Loss: 1.1490 | Learning Rate: 0.000282 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1943/12542 | Batch Loss: 2.2590 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1944/12542 | Batch Loss: 0.5857 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1945/12542 | Batch Loss: 3.8552 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1946/12542 | Batch Loss: 1.2607 | Learning Rate: 0.000282 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1947/12542 | Batch Loss: 2.2633 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1948/12542 | Batch Loss: 2.6584 | Learning Rate: 0.000282 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1949/12542 | Batch Loss: 1.9852 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1950/12542 | Batch Loss: 0.7591 | Learning Rate: 0.000282 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1951/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1952/12542 | Batch Loss: 1.9332 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1953/12542 | Batch Loss: 1.6794 | Learning Rate: 0.000281 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1954/12542 | Batch Loss: 1.0812 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1955/12542 | Batch Loss: 0.8959 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1956/12542 | Batch Loss: 0.9182 | Learning Rate: 0.000281 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1957/12542 | Batch Loss: 1.2186 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1958/12542 | Batch Loss: 1.7106 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1959/12542 | Batch Loss: 0.8958 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1960/12542 | Batch Loss: 2.6469 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1961/12542 | Batch Loss: 1.7509 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1962/12542 | Batch Loss: 1.6959 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1963/12542 | Batch Loss: 2.1919 | Learning Rate: 0.000281 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 1964/12542 | Batch Loss: 2.0094 | Learning Rate: 0.000281 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1965/12542 | Batch Loss: 0.9575 | Learning Rate: 0.000281 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1966/12542 | Batch Loss: 1.6015 | Learning Rate: 0.000281 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1967/12542 | Batch Loss: 1.8237 | Learning Rate: 0.000281 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 1968/12542 | Batch Loss: 1.3419 | Learning Rate: 0.000281 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1969/12542 | Batch Loss: 1.4579 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1970/12542 | Batch Loss: 0.6794 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1971/12542 | Batch Loss: 1.0924 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1972/12542 | Batch Loss: 1.2063 | Learning Rate: 0.000281 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1973/12542 | Batch Loss: 0.5483 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1974/12542 | Batch Loss: 2.6060 | Learning Rate: 0.000281 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1975/12542 | Batch Loss: 0.7803 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1976/12542 | Batch Loss: 2.1734 | Learning Rate: 0.000281 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 1977/12542 | Batch Loss: 1.0080 | Learning Rate: 0.000281 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1978/12542 | Batch Loss: 0.9599 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1979/12542 | Batch Loss: 2.2378 | Learning Rate: 0.000281 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1980/12542 | Batch Loss: 1.2778 | Learning Rate: 0.000281 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 1981/12542 | Batch Loss: 1.6250 | Learning Rate: 0.000281 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 1982/12542 | Batch Loss: 0.9755 | Learning Rate: 0.000281 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1983/12542 | Batch Loss: 1.7559 | Learning Rate: 0.000281 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 1984/12542 | Batch Loss: 0.9937 | Learning Rate: 0.000281 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1985/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000281 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1986/12542 | Batch Loss: 1.2985 | Learning Rate: 0.000281 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1987/12542 | Batch Loss: 0.6379 | Learning Rate: 0.000281 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1988/12542 | Batch Loss: 1.9030 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1989/12542 | Batch Loss: 2.7539 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1990/12542 | Batch Loss: 1.0432 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1991/12542 | Batch Loss: 1.6827 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 1992/12542 | Batch Loss: 2.5384 | Learning Rate: 0.000280 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1993/12542 | Batch Loss: 2.4374 | Learning Rate: 0.000280 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1994/12542 | Batch Loss: 1.0560 | Learning Rate: 0.000280 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 1995/12542 | Batch Loss: 1.4897 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1996/12542 | Batch Loss: 1.5904 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 1997/12542 | Batch Loss: 1.1883 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1998/12542 | Batch Loss: 0.7226 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 1999/12542 | Batch Loss: 1.9154 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2000/12542 | Batch Loss: 0.8357 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2001/12542 | Batch Loss: 0.7409 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2002/12542 | Batch Loss: 1.3181 | Learning Rate: 0.000280 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2003/12542 | Batch Loss: 1.0676 | Learning Rate: 0.000280 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2004/12542 | Batch Loss: 1.3381 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2005/12542 | Batch Loss: 2.6270 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2006/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000280 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2007/12542 | Batch Loss: 0.7464 | Learning Rate: 0.000280 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2008/12542 | Batch Loss: 1.7311 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2009/12542 | Batch Loss: 0.6985 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2010/12542 | Batch Loss: 1.1363 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2011/12542 | Batch Loss: 1.0403 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2012/12542 | Batch Loss: 1.3356 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2013/12542 | Batch Loss: 1.2331 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2014/12542 | Batch Loss: 2.6450 | Learning Rate: 0.000280 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2015/12542 | Batch Loss: 0.5530 | Learning Rate: 0.000280 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2016/12542 | Batch Loss: 0.6962 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2017/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000280 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2018/12542 | Batch Loss: 1.0560 | Learning Rate: 0.000280 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2019/12542 | Batch Loss: 1.4306 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2020/12542 | Batch Loss: 0.9030 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2021/12542 | Batch Loss: 1.8941 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2022/12542 | Batch Loss: 2.7248 | Learning Rate: 0.000280 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2023/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000280 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2024/12542 | Batch Loss: 1.1613 | Learning Rate: 0.000280 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2025/12542 | Batch Loss: 2.2535 | Learning Rate: 0.000280 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2026/12542 | Batch Loss: 2.3584 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2027/12542 | Batch Loss: 1.2914 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2028/12542 | Batch Loss: 3.0547 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2029/12542 | Batch Loss: 1.3044 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2030/12542 | Batch Loss: 0.9324 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2031/12542 | Batch Loss: 1.0830 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2032/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000279 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2033/12542 | Batch Loss: 2.2177 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2034/12542 | Batch Loss: 0.6090 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2035/12542 | Batch Loss: 0.7519 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2036/12542 | Batch Loss: 1.4844 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2037/12542 | Batch Loss: 1.5630 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2038/12542 | Batch Loss: 1.2723 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2039/12542 | Batch Loss: 3.3543 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2040/12542 | Batch Loss: 1.9430 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2041/12542 | Batch Loss: 1.4513 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2042/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2043/12542 | Batch Loss: 0.9987 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2044/12542 | Batch Loss: 1.4710 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2045/12542 | Batch Loss: 1.9457 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2046/12542 | Batch Loss: 2.7588 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2047/12542 | Batch Loss: 1.0853 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2048/12542 | Batch Loss: 1.5191 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2049/12542 | Batch Loss: 3.0534 | Learning Rate: 0.000279 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2050/12542 | Batch Loss: 3.0055 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2051/12542 | Batch Loss: 2.4748 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2052/12542 | Batch Loss: 0.8747 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2053/12542 | Batch Loss: 0.4704 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2054/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000279 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2055/12542 | Batch Loss: 1.1690 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2056/12542 | Batch Loss: 0.8498 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2057/12542 | Batch Loss: 1.4510 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2058/12542 | Batch Loss: 0.6965 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2059/12542 | Batch Loss: 0.5404 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2060/12542 | Batch Loss: 0.5058 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2061/12542 | Batch Loss: 0.6369 | Learning Rate: 0.000279 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2062/12542 | Batch Loss: 1.2304 | Learning Rate: 0.000279 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2063/12542 | Batch Loss: 0.7279 | Learning Rate: 0.000279 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2064/12542 | Batch Loss: 0.5462 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2065/12542 | Batch Loss: 1.3984 | Learning Rate: 0.000278 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2066/12542 | Batch Loss: 2.3376 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2067/12542 | Batch Loss: 0.7497 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2068/12542 | Batch Loss: 0.9754 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2069/12542 | Batch Loss: 1.9050 | Learning Rate: 0.000278 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2070/12542 | Batch Loss: 2.6614 | Learning Rate: 0.000278 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2071/12542 | Batch Loss: 0.8862 | Learning Rate: 0.000278 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2072/12542 | Batch Loss: 2.7561 | Learning Rate: 0.000278 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2073/12542 | Batch Loss: 0.6227 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2074/12542 | Batch Loss: 1.2505 | Learning Rate: 0.000278 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2075/12542 | Batch Loss: 1.5598 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2076/12542 | Batch Loss: 1.8841 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2077/12542 | Batch Loss: 2.9786 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2078/12542 | Batch Loss: 1.1868 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2079/12542 | Batch Loss: 1.5430 | Learning Rate: 0.000278 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2080/12542 | Batch Loss: 1.0722 | Learning Rate: 0.000278 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2081/12542 | Batch Loss: 2.4284 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2082/12542 | Batch Loss: 2.9483 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2083/12542 | Batch Loss: 0.6837 | Learning Rate: 0.000278 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2084/12542 | Batch Loss: 1.1222 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2085/12542 | Batch Loss: 1.9598 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2086/12542 | Batch Loss: 1.3930 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2087/12542 | Batch Loss: 1.8779 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2088/12542 | Batch Loss: 2.5779 | Learning Rate: 0.000278 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2089/12542 | Batch Loss: 1.2910 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2090/12542 | Batch Loss: 0.6734 | Learning Rate: 0.000278 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2091/12542 | Batch Loss: 2.0970 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2092/12542 | Batch Loss: 1.6172 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2093/12542 | Batch Loss: 0.7562 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2094/12542 | Batch Loss: 0.6534 | Learning Rate: 0.000278 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2095/12542 | Batch Loss: 3.8121 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2096/12542 | Batch Loss: 1.6209 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2097/12542 | Batch Loss: 0.8222 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2098/12542 | Batch Loss: 0.8805 | Learning Rate: 0.000278 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2099/12542 | Batch Loss: 1.0588 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2100/12542 | Batch Loss: 0.6393 | Learning Rate: 0.000278 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2101/12542 | Batch Loss: 2.0083 | Learning Rate: 0.000277 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2102/12542 | Batch Loss: 1.2680 | Learning Rate: 0.000277 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2103/12542 | Batch Loss: 0.9375 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2104/12542 | Batch Loss: 0.6648 | Learning Rate: 0.000277 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2105/12542 | Batch Loss: 1.2228 | Learning Rate: 0.000277 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2106/12542 | Batch Loss: 1.1714 | Learning Rate: 0.000277 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2107/12542 | Batch Loss: 0.6562 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2108/12542 | Batch Loss: 0.6185 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2109/12542 | Batch Loss: 0.5403 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2110/12542 | Batch Loss: 0.6631 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2111/12542 | Batch Loss: 0.9293 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2112/12542 | Batch Loss: 0.6952 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2113/12542 | Batch Loss: 1.2450 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2114/12542 | Batch Loss: 1.3853 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2115/12542 | Batch Loss: 0.5605 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2116/12542 | Batch Loss: 2.0433 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2117/12542 | Batch Loss: 0.6827 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2118/12542 | Batch Loss: 2.0217 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2119/12542 | Batch Loss: 1.7593 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2120/12542 | Batch Loss: 0.6280 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2121/12542 | Batch Loss: 1.7699 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2122/12542 | Batch Loss: 0.7737 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2123/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2124/12542 | Batch Loss: 1.3202 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2125/12542 | Batch Loss: 1.3764 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2126/12542 | Batch Loss: 1.6982 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2127/12542 | Batch Loss: 1.1950 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2128/12542 | Batch Loss: 0.7122 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2129/12542 | Batch Loss: 1.7859 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2130/12542 | Batch Loss: 0.8695 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2131/12542 | Batch Loss: 1.0069 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2132/12542 | Batch Loss: 1.0469 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2133/12542 | Batch Loss: 2.4618 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2134/12542 | Batch Loss: 0.8579 | Learning Rate: 0.000277 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2135/12542 | Batch Loss: 0.9849 | Learning Rate: 0.000277 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2136/12542 | Batch Loss: 0.8855 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2137/12542 | Batch Loss: 0.5768 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2138/12542 | Batch Loss: 0.6103 | Learning Rate: 0.000277 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2139/12542 | Batch Loss: 1.3876 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2140/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2141/12542 | Batch Loss: 1.3305 | Learning Rate: 0.000276 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2142/12542 | Batch Loss: 0.9787 | Learning Rate: 0.000276 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2143/12542 | Batch Loss: 3.5038 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2144/12542 | Batch Loss: 1.0929 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2145/12542 | Batch Loss: 0.7057 | Learning Rate: 0.000276 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2146/12542 | Batch Loss: 0.8143 | Learning Rate: 0.000276 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2147/12542 | Batch Loss: 1.0651 | Learning Rate: 0.000276 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2148/12542 | Batch Loss: 1.2518 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2149/12542 | Batch Loss: 2.1564 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2150/12542 | Batch Loss: 1.4466 | Learning Rate: 0.000276 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2151/12542 | Batch Loss: 1.5858 | Learning Rate: 0.000276 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2152/12542 | Batch Loss: 1.3571 | Learning Rate: 0.000276 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2153/12542 | Batch Loss: 1.8478 | Learning Rate: 0.000276 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2154/12542 | Batch Loss: 0.5531 | Learning Rate: 0.000276 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2155/12542 | Batch Loss: 1.2951 | Learning Rate: 0.000276 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2156/12542 | Batch Loss: 1.0675 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2157/12542 | Batch Loss: 0.8104 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2158/12542 | Batch Loss: 1.4221 | Learning Rate: 0.000276 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2159/12542 | Batch Loss: 1.0797 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2160/12542 | Batch Loss: 1.4661 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2161/12542 | Batch Loss: 0.6721 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2162/12542 | Batch Loss: 2.5157 | Learning Rate: 0.000276 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2163/12542 | Batch Loss: 1.5886 | Learning Rate: 0.000276 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 2164/12542 | Batch Loss: 1.6341 | Learning Rate: 0.000276 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 2165/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000276 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2166/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000276 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2167/12542 | Batch Loss: 1.9735 | Learning Rate: 0.000276 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2168/12542 | Batch Loss: 1.0420 | Learning Rate: 0.000276 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2169/12542 | Batch Loss: 1.6967 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2170/12542 | Batch Loss: 0.7563 | Learning Rate: 0.000276 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2171/12542 | Batch Loss: 2.8252 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2172/12542 | Batch Loss: 1.2164 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2173/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2174/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2175/12542 | Batch Loss: 0.7807 | Learning Rate: 0.000276 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2176/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000276 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2177/12542 | Batch Loss: 0.7579 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2178/12542 | Batch Loss: 1.2481 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2179/12542 | Batch Loss: 1.3524 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2180/12542 | Batch Loss: 1.8251 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2181/12542 | Batch Loss: 0.9376 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2182/12542 | Batch Loss: 0.8104 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2183/12542 | Batch Loss: 1.6742 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2184/12542 | Batch Loss: 1.1972 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2185/12542 | Batch Loss: 1.5299 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2186/12542 | Batch Loss: 1.9421 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2187/12542 | Batch Loss: 1.0379 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2188/12542 | Batch Loss: 1.4937 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2189/12542 | Batch Loss: 2.7688 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2190/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2191/12542 | Batch Loss: 0.9382 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2192/12542 | Batch Loss: 0.8953 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2193/12542 | Batch Loss: 2.6452 | Learning Rate: 0.000275 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2194/12542 | Batch Loss: 2.1855 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2195/12542 | Batch Loss: 1.0227 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2196/12542 | Batch Loss: 1.1296 | Learning Rate: 0.000275 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2197/12542 | Batch Loss: 1.6006 | Learning Rate: 0.000275 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2198/12542 | Batch Loss: 1.3836 | Learning Rate: 0.000275 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2199/12542 | Batch Loss: 1.2126 | Learning Rate: 0.000275 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2200/12542 | Batch Loss: 1.6956 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2201/12542 | Batch Loss: 0.7457 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2202/12542 | Batch Loss: 1.8763 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2203/12542 | Batch Loss: 0.7897 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2204/12542 | Batch Loss: 0.9113 | Learning Rate: 0.000275 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2205/12542 | Batch Loss: 0.6943 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2206/12542 | Batch Loss: 0.8355 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2207/12542 | Batch Loss: 0.7036 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2208/12542 | Batch Loss: 1.3891 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2209/12542 | Batch Loss: 1.2416 | Learning Rate: 0.000275 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2210/12542 | Batch Loss: 1.1110 | Learning Rate: 0.000275 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2211/12542 | Batch Loss: 1.8905 | Learning Rate: 0.000275 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2212/12542 | Batch Loss: 1.1124 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2213/12542 | Batch Loss: 1.6606 | Learning Rate: 0.000275 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2214/12542 | Batch Loss: 1.4619 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2215/12542 | Batch Loss: 1.1089 | Learning Rate: 0.000274 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 2216/12542 | Batch Loss: 1.4147 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2217/12542 | Batch Loss: 1.3757 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2218/12542 | Batch Loss: 0.9367 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2219/12542 | Batch Loss: 0.5686 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2220/12542 | Batch Loss: 1.3499 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2221/12542 | Batch Loss: 1.6136 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2222/12542 | Batch Loss: 1.4723 | Learning Rate: 0.000274 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 2223/12542 | Batch Loss: 1.0121 | Learning Rate: 0.000274 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2224/12542 | Batch Loss: 1.0546 | Learning Rate: 0.000274 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2225/12542 | Batch Loss: 1.1972 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2226/12542 | Batch Loss: 1.4100 | Learning Rate: 0.000274 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 2227/12542 | Batch Loss: 0.7558 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2228/12542 | Batch Loss: 2.2189 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2229/12542 | Batch Loss: 1.2093 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2230/12542 | Batch Loss: 2.0979 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2231/12542 | Batch Loss: 1.5795 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2232/12542 | Batch Loss: 0.9701 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2233/12542 | Batch Loss: 0.4574 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2234/12542 | Batch Loss: 0.9727 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2235/12542 | Batch Loss: 0.9832 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2236/12542 | Batch Loss: 0.8917 | Learning Rate: 0.000274 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 2237/12542 | Batch Loss: 0.4050 | Learning Rate: 0.000274 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2238/12542 | Batch Loss: 1.4023 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2239/12542 | Batch Loss: 1.5080 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2240/12542 | Batch Loss: 0.4577 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2241/12542 | Batch Loss: 0.6946 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2242/12542 | Batch Loss: 2.0776 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2243/12542 | Batch Loss: 0.5820 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2244/12542 | Batch Loss: 1.0903 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2245/12542 | Batch Loss: 0.8052 | Learning Rate: 0.000274 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2246/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000274 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2247/12542 | Batch Loss: 1.3444 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2248/12542 | Batch Loss: 1.5036 | Learning Rate: 0.000274 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2249/12542 | Batch Loss: 1.2975 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2250/12542 | Batch Loss: 1.8030 | Learning Rate: 0.000274 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2251/12542 | Batch Loss: 1.2774 | Learning Rate: 0.000274 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2252/12542 | Batch Loss: 0.8789 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2253/12542 | Batch Loss: 2.1590 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2254/12542 | Batch Loss: 0.6110 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2255/12542 | Batch Loss: 1.0896 | Learning Rate: 0.000273 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2256/12542 | Batch Loss: 0.6746 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2257/12542 | Batch Loss: 1.7661 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2258/12542 | Batch Loss: 0.9709 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2259/12542 | Batch Loss: 0.8965 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2260/12542 | Batch Loss: 1.9140 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2261/12542 | Batch Loss: 1.5197 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2262/12542 | Batch Loss: 1.0838 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2263/12542 | Batch Loss: 1.4592 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2264/12542 | Batch Loss: 2.5863 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2265/12542 | Batch Loss: 0.4347 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2266/12542 | Batch Loss: 1.8414 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2267/12542 | Batch Loss: 1.7101 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2268/12542 | Batch Loss: 0.8847 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2269/12542 | Batch Loss: 2.5754 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2270/12542 | Batch Loss: 3.0666 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2271/12542 | Batch Loss: 1.8432 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2272/12542 | Batch Loss: 1.4088 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2273/12542 | Batch Loss: 1.3949 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2274/12542 | Batch Loss: 1.4064 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2275/12542 | Batch Loss: 0.6237 | Learning Rate: 0.000273 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2276/12542 | Batch Loss: 0.9306 | Learning Rate: 0.000273 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2277/12542 | Batch Loss: 2.0219 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2278/12542 | Batch Loss: 0.7384 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2279/12542 | Batch Loss: 2.8617 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2280/12542 | Batch Loss: 2.1180 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2281/12542 | Batch Loss: 1.2045 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2282/12542 | Batch Loss: 1.2222 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2283/12542 | Batch Loss: 1.4507 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2284/12542 | Batch Loss: 2.1048 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2285/12542 | Batch Loss: 1.3789 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2286/12542 | Batch Loss: 1.2819 | Learning Rate: 0.000273 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2287/12542 | Batch Loss: 1.0215 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2288/12542 | Batch Loss: 1.1344 | Learning Rate: 0.000273 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2289/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2290/12542 | Batch Loss: 1.9272 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2291/12542 | Batch Loss: 2.3718 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2292/12542 | Batch Loss: 0.9247 | Learning Rate: 0.000272 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2293/12542 | Batch Loss: 0.6664 | Learning Rate: 0.000272 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2294/12542 | Batch Loss: 1.0551 | Learning Rate: 0.000272 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2295/12542 | Batch Loss: 0.5744 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2296/12542 | Batch Loss: 0.9001 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2297/12542 | Batch Loss: 1.9693 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2298/12542 | Batch Loss: 2.0147 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2299/12542 | Batch Loss: 0.9330 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2300/12542 | Batch Loss: 2.5666 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2301/12542 | Batch Loss: 1.6763 | Learning Rate: 0.000272 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2302/12542 | Batch Loss: 1.1418 | Learning Rate: 0.000272 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2303/12542 | Batch Loss: 2.3242 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2304/12542 | Batch Loss: 0.4638 | Learning Rate: 0.000272 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2305/12542 | Batch Loss: 1.3199 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2306/12542 | Batch Loss: 0.5334 | Learning Rate: 0.000272 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2307/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000272 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 2308/12542 | Batch Loss: 1.0451 | Learning Rate: 0.000272 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2309/12542 | Batch Loss: 1.4920 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2310/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2311/12542 | Batch Loss: 0.8579 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2312/12542 | Batch Loss: 0.5285 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2313/12542 | Batch Loss: 1.2037 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2314/12542 | Batch Loss: 3.2099 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2315/12542 | Batch Loss: 1.6334 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2316/12542 | Batch Loss: 0.4512 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2317/12542 | Batch Loss: 1.1099 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2318/12542 | Batch Loss: 1.5750 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2319/12542 | Batch Loss: 0.6762 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2320/12542 | Batch Loss: 0.7544 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2321/12542 | Batch Loss: 1.3537 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2322/12542 | Batch Loss: 0.6484 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2323/12542 | Batch Loss: 1.0365 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2324/12542 | Batch Loss: 1.2898 | Learning Rate: 0.000272 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2325/12542 | Batch Loss: 0.9034 | Learning Rate: 0.000272 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2326/12542 | Batch Loss: 1.2235 | Learning Rate: 0.000272 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2327/12542 | Batch Loss: 1.7601 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2328/12542 | Batch Loss: 1.2881 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2329/12542 | Batch Loss: 0.6300 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2330/12542 | Batch Loss: 1.8314 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2331/12542 | Batch Loss: 1.7538 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2332/12542 | Batch Loss: 1.6822 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2333/12542 | Batch Loss: 0.4759 | Learning Rate: 0.000271 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2334/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000271 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2335/12542 | Batch Loss: 1.2383 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2336/12542 | Batch Loss: 2.6029 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2337/12542 | Batch Loss: 1.0955 | Learning Rate: 0.000271 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2338/12542 | Batch Loss: 1.1653 | Learning Rate: 0.000271 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 2339/12542 | Batch Loss: 2.3953 | Learning Rate: 0.000271 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2340/12542 | Batch Loss: 1.6416 | Learning Rate: 0.000271 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2341/12542 | Batch Loss: 1.1876 | Learning Rate: 0.000271 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2342/12542 | Batch Loss: 2.1319 | Learning Rate: 0.000271 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2343/12542 | Batch Loss: 1.2504 | Learning Rate: 0.000271 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2344/12542 | Batch Loss: 0.7572 | Learning Rate: 0.000271 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2345/12542 | Batch Loss: 1.7478 | Learning Rate: 0.000271 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2346/12542 | Batch Loss: 0.4360 | Learning Rate: 0.000271 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2347/12542 | Batch Loss: 1.2795 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2348/12542 | Batch Loss: 3.2828 | Learning Rate: 0.000271 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2349/12542 | Batch Loss: 1.0666 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2350/12542 | Batch Loss: 1.9565 | Learning Rate: 0.000271 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2351/12542 | Batch Loss: 1.9642 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2352/12542 | Batch Loss: 1.6354 | Learning Rate: 0.000271 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2353/12542 | Batch Loss: 0.4704 | Learning Rate: 0.000271 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2354/12542 | Batch Loss: 0.7687 | Learning Rate: 0.000271 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2355/12542 | Batch Loss: 1.9057 | Learning Rate: 0.000271 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2356/12542 | Batch Loss: 0.8541 | Learning Rate: 0.000271 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2357/12542 | Batch Loss: 0.8657 | Learning Rate: 0.000271 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2358/12542 | Batch Loss: 1.2720 | Learning Rate: 0.000271 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2359/12542 | Batch Loss: 1.5204 | Learning Rate: 0.000271 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2360/12542 | Batch Loss: 1.1017 | Learning Rate: 0.000271 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2361/12542 | Batch Loss: 1.9941 | Learning Rate: 0.000271 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2362/12542 | Batch Loss: 0.7193 | Learning Rate: 0.000271 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2363/12542 | Batch Loss: 0.6096 | Learning Rate: 0.000271 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2364/12542 | Batch Loss: 0.5005 | Learning Rate: 0.000271 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2365/12542 | Batch Loss: 2.4045 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2366/12542 | Batch Loss: 2.3333 | Learning Rate: 0.000270 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2367/12542 | Batch Loss: 0.5178 | Learning Rate: 0.000270 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2368/12542 | Batch Loss: 0.9140 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2369/12542 | Batch Loss: 1.7537 | Learning Rate: 0.000270 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2370/12542 | Batch Loss: 1.9372 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2371/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2372/12542 | Batch Loss: 1.1485 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2373/12542 | Batch Loss: 0.9056 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2374/12542 | Batch Loss: 2.0486 | Learning Rate: 0.000270 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2375/12542 | Batch Loss: 1.1514 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2376/12542 | Batch Loss: 2.7123 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2377/12542 | Batch Loss: 1.1555 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2378/12542 | Batch Loss: 0.9741 | Learning Rate: 0.000270 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2379/12542 | Batch Loss: 1.2524 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2380/12542 | Batch Loss: 0.5536 | Learning Rate: 0.000270 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2381/12542 | Batch Loss: 0.5087 | Learning Rate: 0.000270 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2382/12542 | Batch Loss: 1.5736 | Learning Rate: 0.000270 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2383/12542 | Batch Loss: 1.1470 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2384/12542 | Batch Loss: 1.1359 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2385/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2386/12542 | Batch Loss: 0.9757 | Learning Rate: 0.000270 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2387/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000270 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2388/12542 | Batch Loss: 1.4240 | Learning Rate: 0.000270 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2389/12542 | Batch Loss: 2.3720 | Learning Rate: 0.000270 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2390/12542 | Batch Loss: 0.7052 | Learning Rate: 0.000270 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2391/12542 | Batch Loss: 1.4635 | Learning Rate: 0.000270 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2392/12542 | Batch Loss: 0.5484 | Learning Rate: 0.000270 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2393/12542 | Batch Loss: 1.7944 | Learning Rate: 0.000270 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2394/12542 | Batch Loss: 1.0237 | Learning Rate: 0.000270 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2395/12542 | Batch Loss: 0.4525 | Learning Rate: 0.000270 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2396/12542 | Batch Loss: 1.9329 | Learning Rate: 0.000270 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2397/12542 | Batch Loss: 1.1059 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2398/12542 | Batch Loss: 1.5368 | Learning Rate: 0.000270 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 2399/12542 | Batch Loss: 0.9234 | Learning Rate: 0.000270 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2400/12542 | Batch Loss: 1.4413 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2401/12542 | Batch Loss: 0.6790 | Learning Rate: 0.000270 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2402/12542 | Batch Loss: 1.4421 | Learning Rate: 0.000269 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2403/12542 | Batch Loss: 1.1391 | Learning Rate: 0.000269 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2404/12542 | Batch Loss: 1.2932 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2405/12542 | Batch Loss: 0.7729 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2406/12542 | Batch Loss: 1.1171 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2407/12542 | Batch Loss: 2.3293 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2408/12542 | Batch Loss: 1.1836 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2409/12542 | Batch Loss: 0.8186 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2410/12542 | Batch Loss: 0.9380 | Learning Rate: 0.000269 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2411/12542 | Batch Loss: 0.5442 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2412/12542 | Batch Loss: 0.9358 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2413/12542 | Batch Loss: 1.2826 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2414/12542 | Batch Loss: 0.8549 | Learning Rate: 0.000269 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2415/12542 | Batch Loss: 0.6156 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2416/12542 | Batch Loss: 1.2395 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2417/12542 | Batch Loss: 2.6021 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2418/12542 | Batch Loss: 1.1036 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2419/12542 | Batch Loss: 1.6074 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2420/12542 | Batch Loss: 0.7855 | Learning Rate: 0.000269 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2421/12542 | Batch Loss: 0.8138 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2422/12542 | Batch Loss: 0.7835 | Learning Rate: 0.000269 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2423/12542 | Batch Loss: 1.2124 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2424/12542 | Batch Loss: 1.1767 | Learning Rate: 0.000269 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2425/12542 | Batch Loss: 2.1311 | Learning Rate: 0.000269 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2426/12542 | Batch Loss: 1.0749 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2427/12542 | Batch Loss: 0.6998 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2428/12542 | Batch Loss: 0.9369 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2429/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2430/12542 | Batch Loss: 1.8035 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2431/12542 | Batch Loss: 2.6512 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2432/12542 | Batch Loss: 0.6534 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2433/12542 | Batch Loss: 1.5358 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2434/12542 | Batch Loss: 2.5987 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2435/12542 | Batch Loss: 1.0405 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2436/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000269 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2437/12542 | Batch Loss: 1.4149 | Learning Rate: 0.000269 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2438/12542 | Batch Loss: 1.2019 | Learning Rate: 0.000269 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 2439/12542 | Batch Loss: 1.0164 | Learning Rate: 0.000269 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2440/12542 | Batch Loss: 0.5941 | Learning Rate: 0.000268 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2441/12542 | Batch Loss: 1.4583 | Learning Rate: 0.000268 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2442/12542 | Batch Loss: 0.6810 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2443/12542 | Batch Loss: 0.9283 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2444/12542 | Batch Loss: 1.8086 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2445/12542 | Batch Loss: 1.6446 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2446/12542 | Batch Loss: 0.8156 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2447/12542 | Batch Loss: 0.8360 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2448/12542 | Batch Loss: 2.1380 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2449/12542 | Batch Loss: 2.0210 | Learning Rate: 0.000268 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2450/12542 | Batch Loss: 0.8229 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2451/12542 | Batch Loss: 2.2901 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2452/12542 | Batch Loss: 1.3559 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2453/12542 | Batch Loss: 0.6080 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2454/12542 | Batch Loss: 0.4762 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2455/12542 | Batch Loss: 3.0127 | Learning Rate: 0.000268 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2456/12542 | Batch Loss: 1.6071 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2457/12542 | Batch Loss: 1.4956 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2458/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2459/12542 | Batch Loss: 0.9725 | Learning Rate: 0.000268 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2460/12542 | Batch Loss: 0.7603 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2461/12542 | Batch Loss: 1.3769 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2462/12542 | Batch Loss: 1.1266 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2463/12542 | Batch Loss: 1.0561 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2464/12542 | Batch Loss: 1.0317 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2465/12542 | Batch Loss: 1.7069 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2466/12542 | Batch Loss: 1.1289 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2467/12542 | Batch Loss: 0.5636 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2468/12542 | Batch Loss: 1.1343 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2469/12542 | Batch Loss: 1.3145 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2470/12542 | Batch Loss: 1.0462 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2471/12542 | Batch Loss: 0.8945 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2472/12542 | Batch Loss: 1.2568 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2473/12542 | Batch Loss: 2.2834 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2474/12542 | Batch Loss: 1.2073 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2475/12542 | Batch Loss: 1.0772 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2476/12542 | Batch Loss: 0.7882 | Learning Rate: 0.000268 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2477/12542 | Batch Loss: 1.0035 | Learning Rate: 0.000268 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2478/12542 | Batch Loss: 2.0530 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2479/12542 | Batch Loss: 1.5033 | Learning Rate: 0.000267 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2480/12542 | Batch Loss: 0.6720 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2481/12542 | Batch Loss: 1.9391 | Learning Rate: 0.000267 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2482/12542 | Batch Loss: 0.7453 | Learning Rate: 0.000267 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2483/12542 | Batch Loss: 0.8779 | Learning Rate: 0.000267 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2484/12542 | Batch Loss: 1.1502 | Learning Rate: 0.000267 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2485/12542 | Batch Loss: 1.2586 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2486/12542 | Batch Loss: 0.9656 | Learning Rate: 0.000267 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2487/12542 | Batch Loss: 2.1367 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2488/12542 | Batch Loss: 2.0177 | Learning Rate: 0.000267 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2489/12542 | Batch Loss: 0.8447 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2490/12542 | Batch Loss: 1.7336 | Learning Rate: 0.000267 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2491/12542 | Batch Loss: 1.0777 | Learning Rate: 0.000267 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2492/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000267 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2493/12542 | Batch Loss: 0.7556 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2494/12542 | Batch Loss: 1.5979 | Learning Rate: 0.000267 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2495/12542 | Batch Loss: 1.6403 | Learning Rate: 0.000267 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2496/12542 | Batch Loss: 0.9322 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2497/12542 | Batch Loss: 2.0560 | Learning Rate: 0.000267 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2498/12542 | Batch Loss: 1.9157 | Learning Rate: 0.000267 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2499/12542 | Batch Loss: 1.9257 | Learning Rate: 0.000267 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2500/12542 | Batch Loss: 2.6674 | Learning Rate: 0.000267 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2501/12542 | Batch Loss: 0.7488 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2502/12542 | Batch Loss: 1.1597 | Learning Rate: 0.000267 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2503/12542 | Batch Loss: 0.8460 | Learning Rate: 0.000267 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2504/12542 | Batch Loss: 1.5339 | Learning Rate: 0.000267 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2505/12542 | Batch Loss: 0.4790 | Learning Rate: 0.000267 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2506/12542 | Batch Loss: 1.6465 | Learning Rate: 0.000267 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2507/12542 | Batch Loss: 0.6586 | Learning Rate: 0.000267 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2508/12542 | Batch Loss: 0.5067 | Learning Rate: 0.000267 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2509/12542 | Batch Loss: 1.7170 | Learning Rate: 0.000267 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2510/12542 | Batch Loss: 1.1127 | Learning Rate: 0.000267 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2511/12542 | Batch Loss: 2.0522 | Learning Rate: 0.000267 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2512/12542 | Batch Loss: 1.4535 | Learning Rate: 0.000267 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2513/12542 | Batch Loss: 1.7370 | Learning Rate: 0.000267 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2514/12542 | Batch Loss: 0.3938 | Learning Rate: 0.000267 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2515/12542 | Batch Loss: 0.8434 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2516/12542 | Batch Loss: 0.8905 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2517/12542 | Batch Loss: 1.8351 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2518/12542 | Batch Loss: 1.0235 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2519/12542 | Batch Loss: 0.8102 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2520/12542 | Batch Loss: 1.7518 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2521/12542 | Batch Loss: 0.8393 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2522/12542 | Batch Loss: 1.8201 | Learning Rate: 0.000266 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2523/12542 | Batch Loss: 1.5553 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2524/12542 | Batch Loss: 1.3492 | Learning Rate: 0.000266 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2525/12542 | Batch Loss: 1.9645 | Learning Rate: 0.000266 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 2526/12542 | Batch Loss: 1.3861 | Learning Rate: 0.000266 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2527/12542 | Batch Loss: 0.9824 | Learning Rate: 0.000266 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2528/12542 | Batch Loss: 0.5854 | Learning Rate: 0.000266 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2529/12542 | Batch Loss: 1.1437 | Learning Rate: 0.000266 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2530/12542 | Batch Loss: 1.2822 | Learning Rate: 0.000266 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2531/12542 | Batch Loss: 2.1210 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2532/12542 | Batch Loss: 2.6081 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2533/12542 | Batch Loss: 1.5731 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2534/12542 | Batch Loss: 2.5821 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2535/12542 | Batch Loss: 0.9860 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2536/12542 | Batch Loss: 3.0709 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2537/12542 | Batch Loss: 1.3537 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2538/12542 | Batch Loss: 1.5629 | Learning Rate: 0.000266 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2539/12542 | Batch Loss: 0.5351 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2540/12542 | Batch Loss: 1.2570 | Learning Rate: 0.000266 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2541/12542 | Batch Loss: 1.8878 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2542/12542 | Batch Loss: 1.5178 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2543/12542 | Batch Loss: 1.0456 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2544/12542 | Batch Loss: 1.1483 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2545/12542 | Batch Loss: 1.4724 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2546/12542 | Batch Loss: 1.2473 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2547/12542 | Batch Loss: 1.2454 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2548/12542 | Batch Loss: 1.3173 | Learning Rate: 0.000266 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2549/12542 | Batch Loss: 1.3398 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2550/12542 | Batch Loss: 1.5383 | Learning Rate: 0.000266 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2551/12542 | Batch Loss: 1.6266 | Learning Rate: 0.000266 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2552/12542 | Batch Loss: 1.6624 | Learning Rate: 0.000266 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2553/12542 | Batch Loss: 1.9645 | Learning Rate: 0.000265 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 2554/12542 | Batch Loss: 1.4261 | Learning Rate: 0.000265 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2555/12542 | Batch Loss: 1.4058 | Learning Rate: 0.000265 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2556/12542 | Batch Loss: 0.9046 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2557/12542 | Batch Loss: 1.5665 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2558/12542 | Batch Loss: 1.7026 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2559/12542 | Batch Loss: 0.9554 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2560/12542 | Batch Loss: 1.1930 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2561/12542 | Batch Loss: 0.7629 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2562/12542 | Batch Loss: 2.3239 | Learning Rate: 0.000265 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2563/12542 | Batch Loss: 2.5514 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2564/12542 | Batch Loss: 2.5656 | Learning Rate: 0.000265 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2565/12542 | Batch Loss: 0.7443 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2566/12542 | Batch Loss: 1.0066 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2567/12542 | Batch Loss: 0.9132 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2568/12542 | Batch Loss: 0.9336 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2569/12542 | Batch Loss: 1.5966 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2570/12542 | Batch Loss: 0.4390 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2571/12542 | Batch Loss: 2.6360 | Learning Rate: 0.000265 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2572/12542 | Batch Loss: 1.9391 | Learning Rate: 0.000265 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2573/12542 | Batch Loss: 1.4663 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2574/12542 | Batch Loss: 1.6232 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2575/12542 | Batch Loss: 0.9634 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2576/12542 | Batch Loss: 2.1388 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2577/12542 | Batch Loss: 1.1580 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2578/12542 | Batch Loss: 1.8485 | Learning Rate: 0.000265 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2579/12542 | Batch Loss: 1.5151 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2580/12542 | Batch Loss: 1.7869 | Learning Rate: 0.000265 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2581/12542 | Batch Loss: 0.6325 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2582/12542 | Batch Loss: 1.4285 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2583/12542 | Batch Loss: 1.4825 | Learning Rate: 0.000265 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2584/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2585/12542 | Batch Loss: 1.9997 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2586/12542 | Batch Loss: 0.7744 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2587/12542 | Batch Loss: 1.4474 | Learning Rate: 0.000265 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2588/12542 | Batch Loss: 1.3285 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2589/12542 | Batch Loss: 2.6690 | Learning Rate: 0.000265 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2590/12542 | Batch Loss: 0.6969 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2591/12542 | Batch Loss: 1.2008 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2592/12542 | Batch Loss: 0.7627 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2593/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2594/12542 | Batch Loss: 0.8729 | Learning Rate: 0.000264 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2595/12542 | Batch Loss: 1.7835 | Learning Rate: 0.000264 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2596/12542 | Batch Loss: 0.6037 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2597/12542 | Batch Loss: 0.8958 | Learning Rate: 0.000264 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2598/12542 | Batch Loss: 1.9363 | Learning Rate: 0.000264 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2599/12542 | Batch Loss: 0.7684 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2600/12542 | Batch Loss: 0.9218 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2601/12542 | Batch Loss: 3.2223 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2602/12542 | Batch Loss: 1.3836 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2603/12542 | Batch Loss: 1.1216 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2604/12542 | Batch Loss: 2.5616 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2605/12542 | Batch Loss: 1.1820 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2606/12542 | Batch Loss: 0.7817 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2607/12542 | Batch Loss: 1.0832 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2608/12542 | Batch Loss: 0.9640 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2609/12542 | Batch Loss: 1.2936 | Learning Rate: 0.000264 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2610/12542 | Batch Loss: 1.2560 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2611/12542 | Batch Loss: 1.9355 | Learning Rate: 0.000264 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2612/12542 | Batch Loss: 1.7606 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2613/12542 | Batch Loss: 0.9108 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2614/12542 | Batch Loss: 1.3936 | Learning Rate: 0.000264 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2615/12542 | Batch Loss: 1.0779 | Learning Rate: 0.000264 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2616/12542 | Batch Loss: 1.6255 | Learning Rate: 0.000264 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2617/12542 | Batch Loss: 1.3116 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2618/12542 | Batch Loss: 0.5292 | Learning Rate: 0.000264 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2619/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2620/12542 | Batch Loss: 1.7760 | Learning Rate: 0.000264 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2621/12542 | Batch Loss: 1.5893 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2622/12542 | Batch Loss: 0.8481 | Learning Rate: 0.000264 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2623/12542 | Batch Loss: 1.1621 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2624/12542 | Batch Loss: 0.5460 | Learning Rate: 0.000264 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2625/12542 | Batch Loss: 1.5507 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2626/12542 | Batch Loss: 0.9808 | Learning Rate: 0.000264 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2627/12542 | Batch Loss: 1.7100 | Learning Rate: 0.000264 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2628/12542 | Batch Loss: 0.8526 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2629/12542 | Batch Loss: 1.7503 | Learning Rate: 0.000263 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2630/12542 | Batch Loss: 1.0134 | Learning Rate: 0.000263 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2631/12542 | Batch Loss: 0.8106 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2632/12542 | Batch Loss: 1.0241 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2633/12542 | Batch Loss: 1.5441 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2634/12542 | Batch Loss: 3.1829 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2635/12542 | Batch Loss: 1.2725 | Learning Rate: 0.000263 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2636/12542 | Batch Loss: 1.5379 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2637/12542 | Batch Loss: 0.8096 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2638/12542 | Batch Loss: 2.4993 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2639/12542 | Batch Loss: 1.2596 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2640/12542 | Batch Loss: 0.6603 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2641/12542 | Batch Loss: 0.8227 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2642/12542 | Batch Loss: 1.3324 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2643/12542 | Batch Loss: 1.2744 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2644/12542 | Batch Loss: 0.6778 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2645/12542 | Batch Loss: 1.8538 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2646/12542 | Batch Loss: 2.7886 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2647/12542 | Batch Loss: 2.6296 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2648/12542 | Batch Loss: 0.9273 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2649/12542 | Batch Loss: 2.8676 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2650/12542 | Batch Loss: 0.7186 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2651/12542 | Batch Loss: 0.7505 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2652/12542 | Batch Loss: 0.8855 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2653/12542 | Batch Loss: 0.8555 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2654/12542 | Batch Loss: 2.3294 | Learning Rate: 0.000263 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2655/12542 | Batch Loss: 2.0183 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2656/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2657/12542 | Batch Loss: 0.4012 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2658/12542 | Batch Loss: 1.4516 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2659/12542 | Batch Loss: 1.3949 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2660/12542 | Batch Loss: 1.0107 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2661/12542 | Batch Loss: 2.8755 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2662/12542 | Batch Loss: 0.7712 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2663/12542 | Batch Loss: 0.8657 | Learning Rate: 0.000263 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2664/12542 | Batch Loss: 1.3061 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2665/12542 | Batch Loss: 1.3243 | Learning Rate: 0.000263 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2666/12542 | Batch Loss: 0.6606 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2667/12542 | Batch Loss: 1.1541 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2668/12542 | Batch Loss: 1.2401 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2669/12542 | Batch Loss: 0.8348 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2670/12542 | Batch Loss: 1.0834 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2671/12542 | Batch Loss: 1.3179 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2672/12542 | Batch Loss: 0.6854 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2673/12542 | Batch Loss: 1.5138 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2674/12542 | Batch Loss: 1.6283 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2675/12542 | Batch Loss: 2.2545 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2676/12542 | Batch Loss: 2.3233 | Learning Rate: 0.000262 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2677/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000262 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2678/12542 | Batch Loss: 0.8281 | Learning Rate: 0.000262 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2679/12542 | Batch Loss: 1.9101 | Learning Rate: 0.000262 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2680/12542 | Batch Loss: 1.3436 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2681/12542 | Batch Loss: 1.1798 | Learning Rate: 0.000262 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2682/12542 | Batch Loss: 1.2688 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2683/12542 | Batch Loss: 1.4835 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2684/12542 | Batch Loss: 1.9230 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2685/12542 | Batch Loss: 1.5422 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2686/12542 | Batch Loss: 1.1626 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2687/12542 | Batch Loss: 0.8157 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2688/12542 | Batch Loss: 1.0008 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2689/12542 | Batch Loss: 1.4560 | Learning Rate: 0.000262 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2690/12542 | Batch Loss: 0.9237 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2691/12542 | Batch Loss: 0.7404 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2692/12542 | Batch Loss: 1.1789 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2693/12542 | Batch Loss: 1.0958 | Learning Rate: 0.000262 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2694/12542 | Batch Loss: 1.3150 | Learning Rate: 0.000262 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2695/12542 | Batch Loss: 0.7954 | Learning Rate: 0.000262 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2696/12542 | Batch Loss: 1.7999 | Learning Rate: 0.000262 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2697/12542 | Batch Loss: 0.6394 | Learning Rate: 0.000262 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2698/12542 | Batch Loss: 2.2769 | Learning Rate: 0.000262 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2699/12542 | Batch Loss: 2.1912 | Learning Rate: 0.000262 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2700/12542 | Batch Loss: 1.9649 | Learning Rate: 0.000262 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2701/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000262 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2702/12542 | Batch Loss: 0.7447 | Learning Rate: 0.000262 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2703/12542 | Batch Loss: 1.5447 | Learning Rate: 0.000261 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2704/12542 | Batch Loss: 1.3731 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2705/12542 | Batch Loss: 1.5071 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2706/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2707/12542 | Batch Loss: 1.3991 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2708/12542 | Batch Loss: 1.6056 | Learning Rate: 0.000261 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2709/12542 | Batch Loss: 0.7295 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2710/12542 | Batch Loss: 0.9576 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2711/12542 | Batch Loss: 1.4484 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2712/12542 | Batch Loss: 1.6013 | Learning Rate: 0.000261 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2713/12542 | Batch Loss: 1.8449 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2714/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2715/12542 | Batch Loss: 1.8276 | Learning Rate: 0.000261 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2716/12542 | Batch Loss: 0.5539 | Learning Rate: 0.000261 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2717/12542 | Batch Loss: 1.0282 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2718/12542 | Batch Loss: 0.8838 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2719/12542 | Batch Loss: 1.0749 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2720/12542 | Batch Loss: 1.5493 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2721/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000261 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2722/12542 | Batch Loss: 1.1398 | Learning Rate: 0.000261 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2723/12542 | Batch Loss: 0.9257 | Learning Rate: 0.000261 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2724/12542 | Batch Loss: 0.9353 | Learning Rate: 0.000261 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2725/12542 | Batch Loss: 0.7727 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2726/12542 | Batch Loss: 0.6564 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2727/12542 | Batch Loss: 1.0412 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2728/12542 | Batch Loss: 1.6100 | Learning Rate: 0.000261 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2729/12542 | Batch Loss: 1.1109 | Learning Rate: 0.000261 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2730/12542 | Batch Loss: 1.4865 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2731/12542 | Batch Loss: 0.9287 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2732/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2733/12542 | Batch Loss: 0.9631 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2734/12542 | Batch Loss: 2.1186 | Learning Rate: 0.000261 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2735/12542 | Batch Loss: 1.7922 | Learning Rate: 0.000261 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2736/12542 | Batch Loss: 0.6757 | Learning Rate: 0.000261 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2737/12542 | Batch Loss: 1.3144 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2738/12542 | Batch Loss: 2.2273 | Learning Rate: 0.000261 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2739/12542 | Batch Loss: 1.2865 | Learning Rate: 0.000261 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2740/12542 | Batch Loss: 1.0031 | Learning Rate: 0.000261 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2741/12542 | Batch Loss: 0.8382 | Learning Rate: 0.000260 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2742/12542 | Batch Loss: 0.6521 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2743/12542 | Batch Loss: 0.8119 | Learning Rate: 0.000260 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2744/12542 | Batch Loss: 0.9467 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2745/12542 | Batch Loss: 0.6389 | Learning Rate: 0.000260 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2746/12542 | Batch Loss: 1.7811 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2747/12542 | Batch Loss: 1.6244 | Learning Rate: 0.000260 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2748/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000260 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2749/12542 | Batch Loss: 1.3074 | Learning Rate: 0.000260 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2750/12542 | Batch Loss: 1.7143 | Learning Rate: 0.000260 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2751/12542 | Batch Loss: 2.3390 | Learning Rate: 0.000260 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2752/12542 | Batch Loss: 1.6027 | Learning Rate: 0.000260 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2753/12542 | Batch Loss: 1.0156 | Learning Rate: 0.000260 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2754/12542 | Batch Loss: 1.8952 | Learning Rate: 0.000260 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2755/12542 | Batch Loss: 0.8151 | Learning Rate: 0.000260 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2756/12542 | Batch Loss: 2.0397 | Learning Rate: 0.000260 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2757/12542 | Batch Loss: 1.4628 | Learning Rate: 0.000260 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2758/12542 | Batch Loss: 1.1460 | Learning Rate: 0.000260 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2759/12542 | Batch Loss: 0.9570 | Learning Rate: 0.000260 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2760/12542 | Batch Loss: 1.1199 | Learning Rate: 0.000260 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2761/12542 | Batch Loss: 0.7301 | Learning Rate: 0.000260 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2762/12542 | Batch Loss: 1.4261 | Learning Rate: 0.000260 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2763/12542 | Batch Loss: 1.6490 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2764/12542 | Batch Loss: 3.0297 | Learning Rate: 0.000260 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2765/12542 | Batch Loss: 0.6427 | Learning Rate: 0.000260 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2766/12542 | Batch Loss: 0.7681 | Learning Rate: 0.000260 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2767/12542 | Batch Loss: 2.6148 | Learning Rate: 0.000260 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2768/12542 | Batch Loss: 1.4222 | Learning Rate: 0.000260 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2769/12542 | Batch Loss: 1.3509 | Learning Rate: 0.000260 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2770/12542 | Batch Loss: 0.9992 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2771/12542 | Batch Loss: 1.4182 | Learning Rate: 0.000260 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2772/12542 | Batch Loss: 2.1325 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2773/12542 | Batch Loss: 0.8231 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2774/12542 | Batch Loss: 0.6319 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2775/12542 | Batch Loss: 2.2352 | Learning Rate: 0.000260 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2776/12542 | Batch Loss: 1.7897 | Learning Rate: 0.000260 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2777/12542 | Batch Loss: 1.2817 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2778/12542 | Batch Loss: 1.7008 | Learning Rate: 0.000260 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2779/12542 | Batch Loss: 1.5039 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2780/12542 | Batch Loss: 1.4777 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2781/12542 | Batch Loss: 0.6464 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2782/12542 | Batch Loss: 2.8028 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2783/12542 | Batch Loss: 3.0416 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2784/12542 | Batch Loss: 0.5331 | Learning Rate: 0.000259 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2785/12542 | Batch Loss: 2.4542 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2786/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2787/12542 | Batch Loss: 0.8135 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2788/12542 | Batch Loss: 1.4114 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2789/12542 | Batch Loss: 1.2840 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2790/12542 | Batch Loss: 1.2804 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2791/12542 | Batch Loss: 1.8107 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2792/12542 | Batch Loss: 3.0778 | Learning Rate: 0.000259 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2793/12542 | Batch Loss: 0.8877 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2794/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000259 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2795/12542 | Batch Loss: 1.4941 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2796/12542 | Batch Loss: 1.0550 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2797/12542 | Batch Loss: 1.7030 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2798/12542 | Batch Loss: 1.5490 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2799/12542 | Batch Loss: 0.6802 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2800/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2801/12542 | Batch Loss: 1.1332 | Learning Rate: 0.000259 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2802/12542 | Batch Loss: 0.5839 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2803/12542 | Batch Loss: 1.1619 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2804/12542 | Batch Loss: 1.1520 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2805/12542 | Batch Loss: 1.2904 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2806/12542 | Batch Loss: 0.8204 | Learning Rate: 0.000259 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2807/12542 | Batch Loss: 1.5269 | Learning Rate: 0.000259 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2808/12542 | Batch Loss: 2.0644 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2809/12542 | Batch Loss: 0.3667 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2810/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000259 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2811/12542 | Batch Loss: 0.7540 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2812/12542 | Batch Loss: 0.7717 | Learning Rate: 0.000259 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2813/12542 | Batch Loss: 0.8128 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2814/12542 | Batch Loss: 0.6322 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2815/12542 | Batch Loss: 1.6309 | Learning Rate: 0.000259 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2816/12542 | Batch Loss: 2.1624 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2817/12542 | Batch Loss: 1.7189 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2818/12542 | Batch Loss: 0.9872 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2819/12542 | Batch Loss: 1.2347 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2820/12542 | Batch Loss: 0.7203 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2821/12542 | Batch Loss: 1.0695 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2822/12542 | Batch Loss: 0.9940 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2823/12542 | Batch Loss: 1.1748 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2824/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000258 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2825/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2826/12542 | Batch Loss: 1.1218 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2827/12542 | Batch Loss: 1.5264 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2828/12542 | Batch Loss: 1.3011 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2829/12542 | Batch Loss: 1.0611 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2830/12542 | Batch Loss: 1.7780 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2831/12542 | Batch Loss: 1.8679 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2832/12542 | Batch Loss: 0.9471 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2833/12542 | Batch Loss: 0.6680 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2834/12542 | Batch Loss: 0.7455 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2835/12542 | Batch Loss: 0.9015 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2836/12542 | Batch Loss: 0.8214 | Learning Rate: 0.000258 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2837/12542 | Batch Loss: 1.9383 | Learning Rate: 0.000258 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2838/12542 | Batch Loss: 0.7097 | Learning Rate: 0.000258 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2839/12542 | Batch Loss: 1.5195 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2840/12542 | Batch Loss: 0.7428 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2841/12542 | Batch Loss: 1.4804 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2842/12542 | Batch Loss: 0.9769 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2843/12542 | Batch Loss: 0.3618 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2844/12542 | Batch Loss: 0.9028 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2845/12542 | Batch Loss: 1.1589 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2846/12542 | Batch Loss: 1.3220 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2847/12542 | Batch Loss: 1.1963 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2848/12542 | Batch Loss: 0.4830 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2849/12542 | Batch Loss: 0.9013 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2850/12542 | Batch Loss: 0.9948 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2851/12542 | Batch Loss: 0.7682 | Learning Rate: 0.000258 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2852/12542 | Batch Loss: 1.4887 | Learning Rate: 0.000258 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2853/12542 | Batch Loss: 1.9350 | Learning Rate: 0.000258 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2854/12542 | Batch Loss: 1.3595 | Learning Rate: 0.000257 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2855/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000257 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2856/12542 | Batch Loss: 1.0289 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2857/12542 | Batch Loss: 1.1452 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2858/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2859/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2860/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2861/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2862/12542 | Batch Loss: 1.6260 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2863/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2864/12542 | Batch Loss: 1.2407 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2865/12542 | Batch Loss: 1.9560 | Learning Rate: 0.000257 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2866/12542 | Batch Loss: 1.3129 | Learning Rate: 0.000257 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2867/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000257 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2868/12542 | Batch Loss: 0.9790 | Learning Rate: 0.000257 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2869/12542 | Batch Loss: 1.2143 | Learning Rate: 0.000257 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2870/12542 | Batch Loss: 2.0771 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2871/12542 | Batch Loss: 1.6991 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2872/12542 | Batch Loss: 1.4749 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2873/12542 | Batch Loss: 1.4525 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2874/12542 | Batch Loss: 1.4095 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2875/12542 | Batch Loss: 1.7415 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2876/12542 | Batch Loss: 1.5674 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2877/12542 | Batch Loss: 0.6353 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2878/12542 | Batch Loss: 1.3510 | Learning Rate: 0.000257 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2879/12542 | Batch Loss: 2.1887 | Learning Rate: 0.000257 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 2880/12542 | Batch Loss: 0.6508 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2881/12542 | Batch Loss: 1.5146 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2882/12542 | Batch Loss: 0.7355 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2883/12542 | Batch Loss: 1.5619 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2884/12542 | Batch Loss: 1.5836 | Learning Rate: 0.000257 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2885/12542 | Batch Loss: 2.6933 | Learning Rate: 0.000257 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2886/12542 | Batch Loss: 0.9770 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2887/12542 | Batch Loss: 1.0009 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2888/12542 | Batch Loss: 0.5805 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2889/12542 | Batch Loss: 1.0941 | Learning Rate: 0.000257 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2890/12542 | Batch Loss: 1.5482 | Learning Rate: 0.000257 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2891/12542 | Batch Loss: 1.2305 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2892/12542 | Batch Loss: 1.7420 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2893/12542 | Batch Loss: 0.4740 | Learning Rate: 0.000256 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2894/12542 | Batch Loss: 0.5581 | Learning Rate: 0.000256 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2895/12542 | Batch Loss: 1.5490 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2896/12542 | Batch Loss: 1.5065 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2897/12542 | Batch Loss: 1.6631 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2898/12542 | Batch Loss: 0.6537 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2899/12542 | Batch Loss: 1.0992 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2900/12542 | Batch Loss: 1.4238 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2901/12542 | Batch Loss: 0.7961 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2902/12542 | Batch Loss: 0.9749 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2903/12542 | Batch Loss: 1.0339 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2904/12542 | Batch Loss: 1.0053 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2905/12542 | Batch Loss: 0.8520 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2906/12542 | Batch Loss: 1.2628 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2907/12542 | Batch Loss: 1.4378 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2908/12542 | Batch Loss: 1.1482 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2909/12542 | Batch Loss: 3.3905 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2910/12542 | Batch Loss: 0.8093 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2911/12542 | Batch Loss: 0.7619 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2912/12542 | Batch Loss: 0.4408 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2913/12542 | Batch Loss: 1.5700 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2914/12542 | Batch Loss: 1.1637 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2915/12542 | Batch Loss: 0.6024 | Learning Rate: 0.000256 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2916/12542 | Batch Loss: 1.5027 | Learning Rate: 0.000256 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2917/12542 | Batch Loss: 0.5759 | Learning Rate: 0.000256 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2918/12542 | Batch Loss: 1.2046 | Learning Rate: 0.000256 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2919/12542 | Batch Loss: 1.2349 | Learning Rate: 0.000256 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2920/12542 | Batch Loss: 1.0583 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2921/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000256 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2922/12542 | Batch Loss: 1.0722 | Learning Rate: 0.000256 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2923/12542 | Batch Loss: 0.7781 | Learning Rate: 0.000256 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2924/12542 | Batch Loss: 1.6495 | Learning Rate: 0.000256 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2925/12542 | Batch Loss: 2.1673 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2926/12542 | Batch Loss: 1.9530 | Learning Rate: 0.000256 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2927/12542 | Batch Loss: 1.0603 | Learning Rate: 0.000256 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2928/12542 | Batch Loss: 0.6688 | Learning Rate: 0.000256 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2929/12542 | Batch Loss: 1.0034 | Learning Rate: 0.000255 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 2930/12542 | Batch Loss: 1.2532 | Learning Rate: 0.000255 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2931/12542 | Batch Loss: 0.6707 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2932/12542 | Batch Loss: 1.6062 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2933/12542 | Batch Loss: 0.5591 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2934/12542 | Batch Loss: 1.8193 | Learning Rate: 0.000255 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2935/12542 | Batch Loss: 0.7827 | Learning Rate: 0.000255 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2936/12542 | Batch Loss: 2.2530 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2937/12542 | Batch Loss: 0.4311 | Learning Rate: 0.000255 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2938/12542 | Batch Loss: 1.8598 | Learning Rate: 0.000255 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 2939/12542 | Batch Loss: 2.7737 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2940/12542 | Batch Loss: 0.7690 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2941/12542 | Batch Loss: 0.4917 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2942/12542 | Batch Loss: 0.7117 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2943/12542 | Batch Loss: 1.9990 | Learning Rate: 0.000255 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2944/12542 | Batch Loss: 0.1257 | Learning Rate: 0.000255 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 2945/12542 | Batch Loss: 1.2529 | Learning Rate: 0.000255 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2946/12542 | Batch Loss: 0.7258 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2947/12542 | Batch Loss: 1.2185 | Learning Rate: 0.000255 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 2948/12542 | Batch Loss: 0.6071 | Learning Rate: 0.000255 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2949/12542 | Batch Loss: 0.8578 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2950/12542 | Batch Loss: 0.9620 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2951/12542 | Batch Loss: 1.6254 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2952/12542 | Batch Loss: 1.1138 | Learning Rate: 0.000255 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2953/12542 | Batch Loss: 0.8315 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2954/12542 | Batch Loss: 1.4041 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2955/12542 | Batch Loss: 0.8523 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2956/12542 | Batch Loss: 0.7059 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2957/12542 | Batch Loss: 1.0007 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2958/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000255 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2959/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000255 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2960/12542 | Batch Loss: 0.8920 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2961/12542 | Batch Loss: 2.4366 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2962/12542 | Batch Loss: 1.1686 | Learning Rate: 0.000255 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2963/12542 | Batch Loss: 0.9786 | Learning Rate: 0.000255 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2964/12542 | Batch Loss: 1.4457 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2965/12542 | Batch Loss: 1.4993 | Learning Rate: 0.000255 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2966/12542 | Batch Loss: 1.4342 | Learning Rate: 0.000255 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2967/12542 | Batch Loss: 1.4053 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2968/12542 | Batch Loss: 1.1178 | Learning Rate: 0.000254 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2969/12542 | Batch Loss: 1.7254 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2970/12542 | Batch Loss: 0.5275 | Learning Rate: 0.000254 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2971/12542 | Batch Loss: 1.0554 | Learning Rate: 0.000254 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 2972/12542 | Batch Loss: 0.4979 | Learning Rate: 0.000254 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 2973/12542 | Batch Loss: 0.8002 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2974/12542 | Batch Loss: 0.7557 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2975/12542 | Batch Loss: 1.3900 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2976/12542 | Batch Loss: 0.6854 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2977/12542 | Batch Loss: 1.3948 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2978/12542 | Batch Loss: 0.9996 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2979/12542 | Batch Loss: 1.0556 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2980/12542 | Batch Loss: 1.4299 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2981/12542 | Batch Loss: 0.8371 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2982/12542 | Batch Loss: 0.6913 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2983/12542 | Batch Loss: 0.7100 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2984/12542 | Batch Loss: 0.9629 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2985/12542 | Batch Loss: 0.9339 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2986/12542 | Batch Loss: 2.9345 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 2987/12542 | Batch Loss: 1.2212 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2988/12542 | Batch Loss: 0.7004 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2989/12542 | Batch Loss: 1.2282 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2990/12542 | Batch Loss: 1.1111 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2991/12542 | Batch Loss: 0.4077 | Learning Rate: 0.000254 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 2992/12542 | Batch Loss: 0.7105 | Learning Rate: 0.000254 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 2993/12542 | Batch Loss: 1.4649 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2994/12542 | Batch Loss: 0.8673 | Learning Rate: 0.000254 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2995/12542 | Batch Loss: 0.7301 | Learning Rate: 0.000254 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 2996/12542 | Batch Loss: 0.9950 | Learning Rate: 0.000254 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2997/12542 | Batch Loss: 1.9060 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 2998/12542 | Batch Loss: 0.7708 | Learning Rate: 0.000254 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 2999/12542 | Batch Loss: 0.6767 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3000/12542 | Batch Loss: 0.8540 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3001/12542 | Batch Loss: 0.6524 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3002/12542 | Batch Loss: 1.0443 | Learning Rate: 0.000254 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3003/12542 | Batch Loss: 1.2684 | Learning Rate: 0.000254 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3004/12542 | Batch Loss: 1.1664 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3005/12542 | Batch Loss: 3.6397 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3006/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3007/12542 | Batch Loss: 1.6711 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3008/12542 | Batch Loss: 0.5010 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3009/12542 | Batch Loss: 1.8004 | Learning Rate: 0.000253 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3010/12542 | Batch Loss: 1.6160 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3011/12542 | Batch Loss: 0.8941 | Learning Rate: 0.000253 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3012/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000253 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3013/12542 | Batch Loss: 1.4183 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3014/12542 | Batch Loss: 0.9675 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3015/12542 | Batch Loss: 0.5703 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3016/12542 | Batch Loss: 2.5728 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3017/12542 | Batch Loss: 0.9829 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3018/12542 | Batch Loss: 1.8680 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3019/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3020/12542 | Batch Loss: 0.8139 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3021/12542 | Batch Loss: 1.1169 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3022/12542 | Batch Loss: 1.7038 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3023/12542 | Batch Loss: 2.0447 | Learning Rate: 0.000253 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3024/12542 | Batch Loss: 0.6467 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3025/12542 | Batch Loss: 1.2724 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3026/12542 | Batch Loss: 1.5500 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3027/12542 | Batch Loss: 0.7273 | Learning Rate: 0.000253 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3028/12542 | Batch Loss: 1.4096 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3029/12542 | Batch Loss: 0.8043 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3030/12542 | Batch Loss: 2.5272 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3031/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3032/12542 | Batch Loss: 0.7405 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3033/12542 | Batch Loss: 2.2666 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3034/12542 | Batch Loss: 2.0225 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3035/12542 | Batch Loss: 0.6854 | Learning Rate: 0.000253 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3036/12542 | Batch Loss: 1.3386 | Learning Rate: 0.000253 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3037/12542 | Batch Loss: 1.4548 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3038/12542 | Batch Loss: 1.5398 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3039/12542 | Batch Loss: 1.0456 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3040/12542 | Batch Loss: 0.4366 | Learning Rate: 0.000253 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3041/12542 | Batch Loss: 0.8449 | Learning Rate: 0.000253 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3042/12542 | Batch Loss: 1.6466 | Learning Rate: 0.000252 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3043/12542 | Batch Loss: 2.8243 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3044/12542 | Batch Loss: 1.1298 | Learning Rate: 0.000252 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3045/12542 | Batch Loss: 0.6144 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3046/12542 | Batch Loss: 1.9334 | Learning Rate: 0.000252 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3047/12542 | Batch Loss: 1.6674 | Learning Rate: 0.000252 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3048/12542 | Batch Loss: 0.7994 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3049/12542 | Batch Loss: 1.1129 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3050/12542 | Batch Loss: 1.7850 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3051/12542 | Batch Loss: 1.5686 | Learning Rate: 0.000252 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3052/12542 | Batch Loss: 0.9208 | Learning Rate: 0.000252 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3053/12542 | Batch Loss: 1.0806 | Learning Rate: 0.000252 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3054/12542 | Batch Loss: 0.7170 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3055/12542 | Batch Loss: 1.1807 | Learning Rate: 0.000252 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3056/12542 | Batch Loss: 1.2737 | Learning Rate: 0.000252 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3057/12542 | Batch Loss: 1.0351 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3058/12542 | Batch Loss: 0.9513 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3059/12542 | Batch Loss: 1.8807 | Learning Rate: 0.000252 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3060/12542 | Batch Loss: 0.7538 | Learning Rate: 0.000252 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3061/12542 | Batch Loss: 0.7781 | Learning Rate: 0.000252 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3062/12542 | Batch Loss: 1.4942 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3063/12542 | Batch Loss: 4.3231 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3064/12542 | Batch Loss: 2.8830 | Learning Rate: 0.000252 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3065/12542 | Batch Loss: 0.9219 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3066/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3067/12542 | Batch Loss: 2.0688 | Learning Rate: 0.000252 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3068/12542 | Batch Loss: 1.2150 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3069/12542 | Batch Loss: 2.5116 | Learning Rate: 0.000252 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3070/12542 | Batch Loss: 1.3757 | Learning Rate: 0.000252 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3071/12542 | Batch Loss: 1.0226 | Learning Rate: 0.000252 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3072/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000252 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3073/12542 | Batch Loss: 0.5452 | Learning Rate: 0.000252 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3074/12542 | Batch Loss: 1.0553 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3075/12542 | Batch Loss: 0.6594 | Learning Rate: 0.000252 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3076/12542 | Batch Loss: 1.8378 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3077/12542 | Batch Loss: 1.1321 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3078/12542 | Batch Loss: 1.4813 | Learning Rate: 0.000252 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3079/12542 | Batch Loss: 1.6159 | Learning Rate: 0.000252 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3080/12542 | Batch Loss: 1.9514 | Learning Rate: 0.000251 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3081/12542 | Batch Loss: 1.6977 | Learning Rate: 0.000251 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3082/12542 | Batch Loss: 1.5058 | Learning Rate: 0.000251 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3083/12542 | Batch Loss: 1.4122 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3084/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3085/12542 | Batch Loss: 1.4019 | Learning Rate: 0.000251 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3086/12542 | Batch Loss: 1.0095 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3087/12542 | Batch Loss: 1.0183 | Learning Rate: 0.000251 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3088/12542 | Batch Loss: 1.5441 | Learning Rate: 0.000251 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3089/12542 | Batch Loss: 1.8682 | Learning Rate: 0.000251 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3090/12542 | Batch Loss: 1.1716 | Learning Rate: 0.000251 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3091/12542 | Batch Loss: 1.6520 | Learning Rate: 0.000251 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3092/12542 | Batch Loss: 1.6316 | Learning Rate: 0.000251 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3093/12542 | Batch Loss: 1.8124 | Learning Rate: 0.000251 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3094/12542 | Batch Loss: 1.7606 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3095/12542 | Batch Loss: 1.1125 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3096/12542 | Batch Loss: 1.5523 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3097/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3098/12542 | Batch Loss: 0.2973 | Learning Rate: 0.000251 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3099/12542 | Batch Loss: 0.9206 | Learning Rate: 0.000251 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3100/12542 | Batch Loss: 1.7023 | Learning Rate: 0.000251 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3101/12542 | Batch Loss: 1.0063 | Learning Rate: 0.000251 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3102/12542 | Batch Loss: 0.9412 | Learning Rate: 0.000251 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3103/12542 | Batch Loss: 1.9662 | Learning Rate: 0.000251 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3104/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000251 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3105/12542 | Batch Loss: 1.3927 | Learning Rate: 0.000251 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3106/12542 | Batch Loss: 0.8680 | Learning Rate: 0.000251 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3107/12542 | Batch Loss: 2.0035 | Learning Rate: 0.000251 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3108/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000251 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3109/12542 | Batch Loss: 0.9969 | Learning Rate: 0.000251 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3110/12542 | Batch Loss: 1.1205 | Learning Rate: 0.000251 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3111/12542 | Batch Loss: 1.4337 | Learning Rate: 0.000251 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3112/12542 | Batch Loss: 1.6188 | Learning Rate: 0.000251 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3113/12542 | Batch Loss: 1.5193 | Learning Rate: 0.000251 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3114/12542 | Batch Loss: 2.0415 | Learning Rate: 0.000251 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3115/12542 | Batch Loss: 0.8205 | Learning Rate: 0.000251 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3116/12542 | Batch Loss: 0.8382 | Learning Rate: 0.000251 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3117/12542 | Batch Loss: 1.8909 | Learning Rate: 0.000250 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3118/12542 | Batch Loss: 1.4641 | Learning Rate: 0.000250 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3119/12542 | Batch Loss: 3.1709 | Learning Rate: 0.000250 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3120/12542 | Batch Loss: 0.8718 | Learning Rate: 0.000250 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3121/12542 | Batch Loss: 2.3489 | Learning Rate: 0.000250 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3122/12542 | Batch Loss: 2.5252 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3123/12542 | Batch Loss: 0.9052 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3124/12542 | Batch Loss: 2.0772 | Learning Rate: 0.000250 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3125/12542 | Batch Loss: 0.9279 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3126/12542 | Batch Loss: 1.4049 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3127/12542 | Batch Loss: 2.4759 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3128/12542 | Batch Loss: 0.7604 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3129/12542 | Batch Loss: 2.1157 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3130/12542 | Batch Loss: 1.3709 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3131/12542 | Batch Loss: 1.7676 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3132/12542 | Batch Loss: 2.4845 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3133/12542 | Batch Loss: 0.3965 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3134/12542 | Batch Loss: 0.5215 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3135/12542 | Batch Loss: 1.7220 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3136/12542 | Batch Loss: 1.4143 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3137/12542 | Batch Loss: 0.5533 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3138/12542 | Batch Loss: 2.6107 | Learning Rate: 0.000250 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3139/12542 | Batch Loss: 0.8879 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3140/12542 | Batch Loss: 2.0384 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3141/12542 | Batch Loss: 0.6883 | Learning Rate: 0.000250 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3142/12542 | Batch Loss: 0.8069 | Learning Rate: 0.000250 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3143/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3144/12542 | Batch Loss: 1.6118 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3145/12542 | Batch Loss: 0.7902 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3146/12542 | Batch Loss: 1.7024 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3147/12542 | Batch Loss: 0.8405 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3148/12542 | Batch Loss: 1.2824 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3149/12542 | Batch Loss: 1.5595 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3150/12542 | Batch Loss: 0.6286 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3151/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000250 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3152/12542 | Batch Loss: 1.7031 | Learning Rate: 0.000250 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3153/12542 | Batch Loss: 1.2541 | Learning Rate: 0.000250 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3154/12542 | Batch Loss: 1.4440 | Learning Rate: 0.000250 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3155/12542 | Batch Loss: 1.7118 | Learning Rate: 0.000249 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3156/12542 | Batch Loss: 0.9419 | Learning Rate: 0.000249 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3157/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000249 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3158/12542 | Batch Loss: 0.7368 | Learning Rate: 0.000249 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3159/12542 | Batch Loss: 0.8069 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3160/12542 | Batch Loss: 1.0966 | Learning Rate: 0.000249 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3161/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3162/12542 | Batch Loss: 0.8414 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3163/12542 | Batch Loss: 0.5920 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3164/12542 | Batch Loss: 2.4481 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3165/12542 | Batch Loss: 2.3922 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3166/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3167/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3168/12542 | Batch Loss: 0.7906 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3169/12542 | Batch Loss: 1.4212 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3170/12542 | Batch Loss: 0.8730 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3171/12542 | Batch Loss: 0.6487 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3172/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3173/12542 | Batch Loss: 1.2481 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3174/12542 | Batch Loss: 2.7917 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3175/12542 | Batch Loss: 1.9033 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3176/12542 | Batch Loss: 2.2701 | Learning Rate: 0.000249 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3177/12542 | Batch Loss: 2.0259 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3178/12542 | Batch Loss: 1.2900 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3179/12542 | Batch Loss: 1.8432 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3180/12542 | Batch Loss: 0.9773 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3181/12542 | Batch Loss: 1.1809 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3182/12542 | Batch Loss: 1.5803 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3183/12542 | Batch Loss: 0.7490 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3184/12542 | Batch Loss: 0.5911 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3185/12542 | Batch Loss: 1.5517 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3186/12542 | Batch Loss: 0.8965 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3187/12542 | Batch Loss: 0.9272 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3188/12542 | Batch Loss: 1.6500 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3189/12542 | Batch Loss: 0.3747 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3190/12542 | Batch Loss: 1.8426 | Learning Rate: 0.000249 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3191/12542 | Batch Loss: 1.0687 | Learning Rate: 0.000249 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3192/12542 | Batch Loss: 0.6782 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3193/12542 | Batch Loss: 1.5728 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3194/12542 | Batch Loss: 0.9331 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3195/12542 | Batch Loss: 2.0997 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3196/12542 | Batch Loss: 1.5682 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3197/12542 | Batch Loss: 0.5576 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3198/12542 | Batch Loss: 1.6992 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3199/12542 | Batch Loss: 0.7890 | Learning Rate: 0.000248 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3200/12542 | Batch Loss: 2.3918 | Learning Rate: 0.000248 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3201/12542 | Batch Loss: 0.7705 | Learning Rate: 0.000248 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3202/12542 | Batch Loss: 0.5431 | Learning Rate: 0.000248 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3203/12542 | Batch Loss: 0.8786 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3204/12542 | Batch Loss: 1.0578 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3205/12542 | Batch Loss: 0.7759 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3206/12542 | Batch Loss: 1.0766 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3207/12542 | Batch Loss: 1.1045 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3208/12542 | Batch Loss: 0.8110 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3209/12542 | Batch Loss: 0.9411 | Learning Rate: 0.000248 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3210/12542 | Batch Loss: 1.6661 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3211/12542 | Batch Loss: 1.1068 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3212/12542 | Batch Loss: 1.1525 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3213/12542 | Batch Loss: 0.7010 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3214/12542 | Batch Loss: 1.6161 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3215/12542 | Batch Loss: 2.5522 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3216/12542 | Batch Loss: 0.6454 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3217/12542 | Batch Loss: 1.2870 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3218/12542 | Batch Loss: 1.9325 | Learning Rate: 0.000248 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3219/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000248 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3220/12542 | Batch Loss: 2.4250 | Learning Rate: 0.000248 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3221/12542 | Batch Loss: 1.8692 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3222/12542 | Batch Loss: 0.7239 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3223/12542 | Batch Loss: 1.3550 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3224/12542 | Batch Loss: 1.3633 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3225/12542 | Batch Loss: 0.8992 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3226/12542 | Batch Loss: 0.4149 | Learning Rate: 0.000248 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3227/12542 | Batch Loss: 0.7061 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3228/12542 | Batch Loss: 1.3945 | Learning Rate: 0.000248 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3229/12542 | Batch Loss: 0.9681 | Learning Rate: 0.000248 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3230/12542 | Batch Loss: 1.3481 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3231/12542 | Batch Loss: 1.7656 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3232/12542 | Batch Loss: 0.6896 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3233/12542 | Batch Loss: 1.5724 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3234/12542 | Batch Loss: 0.8292 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3235/12542 | Batch Loss: 1.5001 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3236/12542 | Batch Loss: 2.5218 | Learning Rate: 0.000247 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3237/12542 | Batch Loss: 0.8626 | Learning Rate: 0.000247 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3238/12542 | Batch Loss: 1.7097 | Learning Rate: 0.000247 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3239/12542 | Batch Loss: 1.2934 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3240/12542 | Batch Loss: 1.7728 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3241/12542 | Batch Loss: 1.1239 | Learning Rate: 0.000247 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3242/12542 | Batch Loss: 1.6655 | Learning Rate: 0.000247 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3243/12542 | Batch Loss: 0.9002 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3244/12542 | Batch Loss: 0.8738 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3245/12542 | Batch Loss: 0.9026 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3246/12542 | Batch Loss: 0.8665 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3247/12542 | Batch Loss: 1.5670 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3248/12542 | Batch Loss: 1.7724 | Learning Rate: 0.000247 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3249/12542 | Batch Loss: 0.5471 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3250/12542 | Batch Loss: 1.1734 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3251/12542 | Batch Loss: 0.8803 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3252/12542 | Batch Loss: 1.3613 | Learning Rate: 0.000247 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3253/12542 | Batch Loss: 1.4984 | Learning Rate: 0.000247 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3254/12542 | Batch Loss: 1.0825 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3255/12542 | Batch Loss: 1.8573 | Learning Rate: 0.000247 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3256/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000247 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3257/12542 | Batch Loss: 0.7152 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3258/12542 | Batch Loss: 1.2922 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3259/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3260/12542 | Batch Loss: 0.8002 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3261/12542 | Batch Loss: 0.5734 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3262/12542 | Batch Loss: 1.4337 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3263/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3264/12542 | Batch Loss: 0.6193 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3265/12542 | Batch Loss: 2.2660 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3266/12542 | Batch Loss: 0.8300 | Learning Rate: 0.000247 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3267/12542 | Batch Loss: 1.2217 | Learning Rate: 0.000247 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3268/12542 | Batch Loss: 2.0812 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3269/12542 | Batch Loss: 1.4861 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3270/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3271/12542 | Batch Loss: 2.1266 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3272/12542 | Batch Loss: 1.3827 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3273/12542 | Batch Loss: 1.3351 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3274/12542 | Batch Loss: 0.9167 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3275/12542 | Batch Loss: 1.3946 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3276/12542 | Batch Loss: 1.2635 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3277/12542 | Batch Loss: 3.0196 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3278/12542 | Batch Loss: 1.2193 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3279/12542 | Batch Loss: 1.0429 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3280/12542 | Batch Loss: 1.0718 | Learning Rate: 0.000246 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3281/12542 | Batch Loss: 1.0465 | Learning Rate: 0.000246 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3282/12542 | Batch Loss: 2.1920 | Learning Rate: 0.000246 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3283/12542 | Batch Loss: 2.3678 | Learning Rate: 0.000246 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3284/12542 | Batch Loss: 1.0677 | Learning Rate: 0.000246 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3285/12542 | Batch Loss: 1.3115 | Learning Rate: 0.000246 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3286/12542 | Batch Loss: 1.3613 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3287/12542 | Batch Loss: 1.0301 | Learning Rate: 0.000246 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3288/12542 | Batch Loss: 2.0244 | Learning Rate: 0.000246 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3289/12542 | Batch Loss: 2.1794 | Learning Rate: 0.000246 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3290/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000246 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3291/12542 | Batch Loss: 0.6411 | Learning Rate: 0.000246 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3292/12542 | Batch Loss: 1.4131 | Learning Rate: 0.000246 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3293/12542 | Batch Loss: 0.7287 | Learning Rate: 0.000246 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3294/12542 | Batch Loss: 2.0179 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3295/12542 | Batch Loss: 1.8634 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3296/12542 | Batch Loss: 1.2886 | Learning Rate: 0.000246 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3297/12542 | Batch Loss: 1.6467 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3298/12542 | Batch Loss: 1.3853 | Learning Rate: 0.000246 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3299/12542 | Batch Loss: 1.6997 | Learning Rate: 0.000246 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3300/12542 | Batch Loss: 1.4670 | Learning Rate: 0.000246 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3301/12542 | Batch Loss: 0.6700 | Learning Rate: 0.000246 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3302/12542 | Batch Loss: 0.8771 | Learning Rate: 0.000246 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3303/12542 | Batch Loss: 1.0339 | Learning Rate: 0.000246 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3304/12542 | Batch Loss: 0.6033 | Learning Rate: 0.000246 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3305/12542 | Batch Loss: 1.3060 | Learning Rate: 0.000245 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3306/12542 | Batch Loss: 0.9329 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3307/12542 | Batch Loss: 1.2455 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3308/12542 | Batch Loss: 1.1989 | Learning Rate: 0.000245 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3309/12542 | Batch Loss: 1.2658 | Learning Rate: 0.000245 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3310/12542 | Batch Loss: 1.1690 | Learning Rate: 0.000245 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3311/12542 | Batch Loss: 1.0817 | Learning Rate: 0.000245 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3312/12542 | Batch Loss: 0.4976 | Learning Rate: 0.000245 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3313/12542 | Batch Loss: 1.2949 | Learning Rate: 0.000245 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3314/12542 | Batch Loss: 1.1949 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3315/12542 | Batch Loss: 0.5378 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3316/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3317/12542 | Batch Loss: 0.6360 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3318/12542 | Batch Loss: 2.1065 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3319/12542 | Batch Loss: 1.7339 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3320/12542 | Batch Loss: 0.6934 | Learning Rate: 0.000245 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3321/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000245 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3322/12542 | Batch Loss: 1.2281 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3323/12542 | Batch Loss: 1.7102 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3324/12542 | Batch Loss: 2.8616 | Learning Rate: 0.000245 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3325/12542 | Batch Loss: 1.7229 | Learning Rate: 0.000245 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3326/12542 | Batch Loss: 0.9545 | Learning Rate: 0.000245 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3327/12542 | Batch Loss: 0.9230 | Learning Rate: 0.000245 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3328/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000245 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3329/12542 | Batch Loss: 1.9129 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3330/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3331/12542 | Batch Loss: 3.0587 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3332/12542 | Batch Loss: 1.0352 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3333/12542 | Batch Loss: 1.3176 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3334/12542 | Batch Loss: 1.2821 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3335/12542 | Batch Loss: 1.2129 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3336/12542 | Batch Loss: 0.9873 | Learning Rate: 0.000245 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3337/12542 | Batch Loss: 1.3872 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3338/12542 | Batch Loss: 1.3538 | Learning Rate: 0.000245 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3339/12542 | Batch Loss: 1.0423 | Learning Rate: 0.000245 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3340/12542 | Batch Loss: 1.0609 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3341/12542 | Batch Loss: 0.6122 | Learning Rate: 0.000245 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3342/12542 | Batch Loss: 0.7752 | Learning Rate: 0.000245 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3343/12542 | Batch Loss: 1.0651 | Learning Rate: 0.000244 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3344/12542 | Batch Loss: 1.7244 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3345/12542 | Batch Loss: 1.2518 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3346/12542 | Batch Loss: 0.7312 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3347/12542 | Batch Loss: 1.5860 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3348/12542 | Batch Loss: 2.0116 | Learning Rate: 0.000244 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3349/12542 | Batch Loss: 1.1100 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3350/12542 | Batch Loss: 0.7120 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3351/12542 | Batch Loss: 1.4763 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3352/12542 | Batch Loss: 2.6872 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3353/12542 | Batch Loss: 1.5650 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3354/12542 | Batch Loss: 0.6639 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3355/12542 | Batch Loss: 1.5565 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3356/12542 | Batch Loss: 1.8185 | Learning Rate: 0.000244 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3357/12542 | Batch Loss: 2.3867 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3358/12542 | Batch Loss: 2.7031 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3359/12542 | Batch Loss: 1.0908 | Learning Rate: 0.000244 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3360/12542 | Batch Loss: 1.4363 | Learning Rate: 0.000244 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3361/12542 | Batch Loss: 1.2162 | Learning Rate: 0.000244 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3362/12542 | Batch Loss: 1.3461 | Learning Rate: 0.000244 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3363/12542 | Batch Loss: 1.8580 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3364/12542 | Batch Loss: 2.1760 | Learning Rate: 0.000244 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3365/12542 | Batch Loss: 0.9773 | Learning Rate: 0.000244 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3366/12542 | Batch Loss: 2.0058 | Learning Rate: 0.000244 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3367/12542 | Batch Loss: 1.5984 | Learning Rate: 0.000244 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3368/12542 | Batch Loss: 1.7395 | Learning Rate: 0.000244 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3369/12542 | Batch Loss: 2.7652 | Learning Rate: 0.000244 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3370/12542 | Batch Loss: 1.3594 | Learning Rate: 0.000244 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3371/12542 | Batch Loss: 1.7674 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3372/12542 | Batch Loss: 1.1118 | Learning Rate: 0.000244 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3373/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3374/12542 | Batch Loss: 0.9834 | Learning Rate: 0.000244 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3375/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000244 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3376/12542 | Batch Loss: 1.8633 | Learning Rate: 0.000244 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3377/12542 | Batch Loss: 1.1598 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3378/12542 | Batch Loss: 1.0032 | Learning Rate: 0.000244 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3379/12542 | Batch Loss: 1.2944 | Learning Rate: 0.000244 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3380/12542 | Batch Loss: 1.3425 | Learning Rate: 0.000244 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3381/12542 | Batch Loss: 0.9135 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3382/12542 | Batch Loss: 1.5723 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3383/12542 | Batch Loss: 0.9935 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3384/12542 | Batch Loss: 0.9865 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3385/12542 | Batch Loss: 1.5800 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3386/12542 | Batch Loss: 0.8547 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3387/12542 | Batch Loss: 0.6960 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3388/12542 | Batch Loss: 1.4183 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3389/12542 | Batch Loss: 1.7651 | Learning Rate: 0.000243 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3390/12542 | Batch Loss: 0.8649 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3391/12542 | Batch Loss: 1.2295 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3392/12542 | Batch Loss: 1.9496 | Learning Rate: 0.000243 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3393/12542 | Batch Loss: 1.0575 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3394/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3395/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3396/12542 | Batch Loss: 1.5003 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3397/12542 | Batch Loss: 0.4873 | Learning Rate: 0.000243 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3398/12542 | Batch Loss: 2.1226 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3399/12542 | Batch Loss: 1.9917 | Learning Rate: 0.000243 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3400/12542 | Batch Loss: 1.7400 | Learning Rate: 0.000243 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3401/12542 | Batch Loss: 1.4079 | Learning Rate: 0.000243 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3402/12542 | Batch Loss: 0.5995 | Learning Rate: 0.000243 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3403/12542 | Batch Loss: 1.0591 | Learning Rate: 0.000243 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3404/12542 | Batch Loss: 1.3530 | Learning Rate: 0.000243 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3405/12542 | Batch Loss: 0.3890 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3406/12542 | Batch Loss: 0.9316 | Learning Rate: 0.000243 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3407/12542 | Batch Loss: 1.0896 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3408/12542 | Batch Loss: 1.4076 | Learning Rate: 0.000243 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3409/12542 | Batch Loss: 1.4769 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3410/12542 | Batch Loss: 1.6177 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3411/12542 | Batch Loss: 1.3883 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3412/12542 | Batch Loss: 1.6063 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3413/12542 | Batch Loss: 0.8415 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3414/12542 | Batch Loss: 1.3123 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3415/12542 | Batch Loss: 1.9575 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3416/12542 | Batch Loss: 1.4223 | Learning Rate: 0.000243 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3417/12542 | Batch Loss: 1.4886 | Learning Rate: 0.000243 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3418/12542 | Batch Loss: 2.2070 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3419/12542 | Batch Loss: 0.5826 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3420/12542 | Batch Loss: 1.6258 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3421/12542 | Batch Loss: 1.2295 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3422/12542 | Batch Loss: 0.8278 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3423/12542 | Batch Loss: 0.9326 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3424/12542 | Batch Loss: 1.6325 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3425/12542 | Batch Loss: 2.3003 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3426/12542 | Batch Loss: 1.5870 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3427/12542 | Batch Loss: 1.1641 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3428/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3429/12542 | Batch Loss: 1.7652 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3430/12542 | Batch Loss: 1.4693 | Learning Rate: 0.000242 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3431/12542 | Batch Loss: 1.1299 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3432/12542 | Batch Loss: 0.6873 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3433/12542 | Batch Loss: 1.7006 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3434/12542 | Batch Loss: 2.9724 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3435/12542 | Batch Loss: 1.1354 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3436/12542 | Batch Loss: 1.2624 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3437/12542 | Batch Loss: 1.3584 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3438/12542 | Batch Loss: 1.5569 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3439/12542 | Batch Loss: 2.0077 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3440/12542 | Batch Loss: 0.5867 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3441/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3442/12542 | Batch Loss: 1.1332 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3443/12542 | Batch Loss: 1.4354 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3444/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3445/12542 | Batch Loss: 1.6788 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3446/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3447/12542 | Batch Loss: 0.7948 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3448/12542 | Batch Loss: 1.0622 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3449/12542 | Batch Loss: 0.5521 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3450/12542 | Batch Loss: 1.4356 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3451/12542 | Batch Loss: 2.1703 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3452/12542 | Batch Loss: 1.0530 | Learning Rate: 0.000242 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3453/12542 | Batch Loss: 1.8540 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3454/12542 | Batch Loss: 2.4962 | Learning Rate: 0.000242 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3455/12542 | Batch Loss: 1.4222 | Learning Rate: 0.000242 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3456/12542 | Batch Loss: 0.9074 | Learning Rate: 0.000241 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3457/12542 | Batch Loss: 1.7050 | Learning Rate: 0.000241 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3458/12542 | Batch Loss: 0.9825 | Learning Rate: 0.000241 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3459/12542 | Batch Loss: 2.2273 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3460/12542 | Batch Loss: 2.1783 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3461/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000241 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3462/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3463/12542 | Batch Loss: 0.6447 | Learning Rate: 0.000241 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3464/12542 | Batch Loss: 0.9239 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3465/12542 | Batch Loss: 1.8143 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3466/12542 | Batch Loss: 2.2707 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3467/12542 | Batch Loss: 1.7506 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3468/12542 | Batch Loss: 0.8542 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3469/12542 | Batch Loss: 1.1988 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3470/12542 | Batch Loss: 1.5443 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3471/12542 | Batch Loss: 2.5157 | Learning Rate: 0.000241 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3472/12542 | Batch Loss: 0.8890 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3473/12542 | Batch Loss: 1.0813 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3474/12542 | Batch Loss: 0.8954 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3475/12542 | Batch Loss: 0.9970 | Learning Rate: 0.000241 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3476/12542 | Batch Loss: 1.0724 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3477/12542 | Batch Loss: 2.7398 | Learning Rate: 0.000241 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3478/12542 | Batch Loss: 0.9196 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3479/12542 | Batch Loss: 1.5560 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3480/12542 | Batch Loss: 0.9146 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3481/12542 | Batch Loss: 1.2090 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3482/12542 | Batch Loss: 1.6499 | Learning Rate: 0.000241 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3483/12542 | Batch Loss: 1.5570 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3484/12542 | Batch Loss: 0.5505 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3485/12542 | Batch Loss: 0.8565 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3486/12542 | Batch Loss: 2.0708 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3487/12542 | Batch Loss: 0.9845 | Learning Rate: 0.000241 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3488/12542 | Batch Loss: 2.6275 | Learning Rate: 0.000241 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3489/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000241 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3490/12542 | Batch Loss: 1.7790 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3491/12542 | Batch Loss: 1.5774 | Learning Rate: 0.000241 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3492/12542 | Batch Loss: 1.0003 | Learning Rate: 0.000241 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3493/12542 | Batch Loss: 1.3751 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3494/12542 | Batch Loss: 2.5654 | Learning Rate: 0.000240 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3495/12542 | Batch Loss: 0.5723 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3496/12542 | Batch Loss: 0.5100 | Learning Rate: 0.000240 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3497/12542 | Batch Loss: 1.6532 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3498/12542 | Batch Loss: 0.5341 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3499/12542 | Batch Loss: 1.1055 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3500/12542 | Batch Loss: 0.6525 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3501/12542 | Batch Loss: 1.3079 | Learning Rate: 0.000240 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3502/12542 | Batch Loss: 1.2152 | Learning Rate: 0.000240 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3503/12542 | Batch Loss: 2.2246 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3504/12542 | Batch Loss: 1.4503 | Learning Rate: 0.000240 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3505/12542 | Batch Loss: 1.4195 | Learning Rate: 0.000240 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3506/12542 | Batch Loss: 1.0920 | Learning Rate: 0.000240 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3507/12542 | Batch Loss: 2.6172 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3508/12542 | Batch Loss: 1.2444 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3509/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3510/12542 | Batch Loss: 1.4648 | Learning Rate: 0.000240 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3511/12542 | Batch Loss: 1.4098 | Learning Rate: 0.000240 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3512/12542 | Batch Loss: 1.6113 | Learning Rate: 0.000240 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3513/12542 | Batch Loss: 0.7982 | Learning Rate: 0.000240 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3514/12542 | Batch Loss: 1.0057 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3515/12542 | Batch Loss: 1.6556 | Learning Rate: 0.000240 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3516/12542 | Batch Loss: 0.8948 | Learning Rate: 0.000240 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3517/12542 | Batch Loss: 1.1772 | Learning Rate: 0.000240 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3518/12542 | Batch Loss: 1.1420 | Learning Rate: 0.000240 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3519/12542 | Batch Loss: 0.8789 | Learning Rate: 0.000240 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3520/12542 | Batch Loss: 1.9033 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3521/12542 | Batch Loss: 1.6143 | Learning Rate: 0.000240 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3522/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000240 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3523/12542 | Batch Loss: 0.5719 | Learning Rate: 0.000240 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3524/12542 | Batch Loss: 0.7890 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3525/12542 | Batch Loss: 0.7580 | Learning Rate: 0.000240 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3526/12542 | Batch Loss: 0.9432 | Learning Rate: 0.000240 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3527/12542 | Batch Loss: 3.3055 | Learning Rate: 0.000240 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3528/12542 | Batch Loss: 1.2462 | Learning Rate: 0.000240 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3529/12542 | Batch Loss: 1.8072 | Learning Rate: 0.000240 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3530/12542 | Batch Loss: 0.8620 | Learning Rate: 0.000240 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3531/12542 | Batch Loss: 1.9034 | Learning Rate: 0.000239 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3532/12542 | Batch Loss: 1.4211 | Learning Rate: 0.000239 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3533/12542 | Batch Loss: 1.0994 | Learning Rate: 0.000239 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3534/12542 | Batch Loss: 1.4772 | Learning Rate: 0.000239 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3535/12542 | Batch Loss: 0.9880 | Learning Rate: 0.000239 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3536/12542 | Batch Loss: 0.5619 | Learning Rate: 0.000239 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 3537/12542 | Batch Loss: 0.8151 | Learning Rate: 0.000239 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3538/12542 | Batch Loss: 2.2893 | Learning Rate: 0.000239 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3539/12542 | Batch Loss: 1.2769 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3540/12542 | Batch Loss: 0.9900 | Learning Rate: 0.000239 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3541/12542 | Batch Loss: 1.3738 | Learning Rate: 0.000239 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3542/12542 | Batch Loss: 0.8794 | Learning Rate: 0.000239 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3543/12542 | Batch Loss: 1.1942 | Learning Rate: 0.000239 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3544/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3545/12542 | Batch Loss: 1.4600 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3546/12542 | Batch Loss: 2.0112 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3547/12542 | Batch Loss: 0.7887 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3548/12542 | Batch Loss: 2.6588 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3549/12542 | Batch Loss: 1.6204 | Learning Rate: 0.000239 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3550/12542 | Batch Loss: 2.0823 | Learning Rate: 0.000239 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3551/12542 | Batch Loss: 1.6566 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3552/12542 | Batch Loss: 1.4154 | Learning Rate: 0.000239 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3553/12542 | Batch Loss: 0.8325 | Learning Rate: 0.000239 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3554/12542 | Batch Loss: 1.9889 | Learning Rate: 0.000239 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3555/12542 | Batch Loss: 1.2118 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3556/12542 | Batch Loss: 1.2496 | Learning Rate: 0.000239 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3557/12542 | Batch Loss: 0.6119 | Learning Rate: 0.000239 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3558/12542 | Batch Loss: 1.2168 | Learning Rate: 0.000239 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3559/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000239 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3560/12542 | Batch Loss: 1.0928 | Learning Rate: 0.000239 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3561/12542 | Batch Loss: 1.9151 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3562/12542 | Batch Loss: 0.7934 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3563/12542 | Batch Loss: 1.1523 | Learning Rate: 0.000239 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3564/12542 | Batch Loss: 2.1057 | Learning Rate: 0.000239 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3565/12542 | Batch Loss: 1.6395 | Learning Rate: 0.000239 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3566/12542 | Batch Loss: 1.5276 | Learning Rate: 0.000239 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3567/12542 | Batch Loss: 2.0309 | Learning Rate: 0.000239 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3568/12542 | Batch Loss: 1.8548 | Learning Rate: 0.000239 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3569/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000238 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3570/12542 | Batch Loss: 1.4239 | Learning Rate: 0.000238 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3571/12542 | Batch Loss: 0.4315 | Learning Rate: 0.000238 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3572/12542 | Batch Loss: 2.0886 | Learning Rate: 0.000238 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3573/12542 | Batch Loss: 2.6306 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3574/12542 | Batch Loss: 0.6093 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3575/12542 | Batch Loss: 1.5474 | Learning Rate: 0.000238 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3576/12542 | Batch Loss: 1.5153 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3577/12542 | Batch Loss: 1.3636 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3578/12542 | Batch Loss: 1.1617 | Learning Rate: 0.000238 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3579/12542 | Batch Loss: 1.8054 | Learning Rate: 0.000238 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3580/12542 | Batch Loss: 1.3508 | Learning Rate: 0.000238 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3581/12542 | Batch Loss: 0.8024 | Learning Rate: 0.000238 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3582/12542 | Batch Loss: 1.1180 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3583/12542 | Batch Loss: 0.9667 | Learning Rate: 0.000238 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3584/12542 | Batch Loss: 2.7266 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3585/12542 | Batch Loss: 0.9655 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3586/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3587/12542 | Batch Loss: 1.4143 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3588/12542 | Batch Loss: 1.8131 | Learning Rate: 0.000238 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3589/12542 | Batch Loss: 1.3392 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3590/12542 | Batch Loss: 1.4405 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3591/12542 | Batch Loss: 0.6172 | Learning Rate: 0.000238 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3592/12542 | Batch Loss: 0.4481 | Learning Rate: 0.000238 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3593/12542 | Batch Loss: 0.8202 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3594/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3595/12542 | Batch Loss: 0.8799 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3596/12542 | Batch Loss: 1.6841 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3597/12542 | Batch Loss: 0.9766 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3598/12542 | Batch Loss: 1.3856 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3599/12542 | Batch Loss: 1.9548 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3600/12542 | Batch Loss: 0.6698 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3601/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3602/12542 | Batch Loss: 0.8852 | Learning Rate: 0.000238 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3603/12542 | Batch Loss: 1.5143 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3604/12542 | Batch Loss: 0.6632 | Learning Rate: 0.000238 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3605/12542 | Batch Loss: 1.5328 | Learning Rate: 0.000238 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3606/12542 | Batch Loss: 1.0420 | Learning Rate: 0.000237 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3607/12542 | Batch Loss: 1.6444 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3608/12542 | Batch Loss: 1.9705 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3609/12542 | Batch Loss: 1.9646 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3610/12542 | Batch Loss: 1.4440 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3611/12542 | Batch Loss: 1.0364 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3612/12542 | Batch Loss: 1.6615 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3613/12542 | Batch Loss: 1.3073 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3614/12542 | Batch Loss: 2.4070 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3615/12542 | Batch Loss: 0.7924 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3616/12542 | Batch Loss: 2.1505 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3617/12542 | Batch Loss: 0.7898 | Learning Rate: 0.000237 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3618/12542 | Batch Loss: 0.7724 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3619/12542 | Batch Loss: 1.6016 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3620/12542 | Batch Loss: 1.1263 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3621/12542 | Batch Loss: 2.0838 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3622/12542 | Batch Loss: 1.6443 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3623/12542 | Batch Loss: 0.7894 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3624/12542 | Batch Loss: 0.8856 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3625/12542 | Batch Loss: 0.8776 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3626/12542 | Batch Loss: 1.5383 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3627/12542 | Batch Loss: 1.6577 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3628/12542 | Batch Loss: 1.3299 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3629/12542 | Batch Loss: 2.8176 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3630/12542 | Batch Loss: 1.5554 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3631/12542 | Batch Loss: 1.6135 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3632/12542 | Batch Loss: 0.9046 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3633/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3634/12542 | Batch Loss: 1.0964 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3635/12542 | Batch Loss: 1.5515 | Learning Rate: 0.000237 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3636/12542 | Batch Loss: 1.2281 | Learning Rate: 0.000237 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3637/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000237 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3638/12542 | Batch Loss: 1.1235 | Learning Rate: 0.000237 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3639/12542 | Batch Loss: 2.6845 | Learning Rate: 0.000237 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3640/12542 | Batch Loss: 0.5438 | Learning Rate: 0.000237 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3641/12542 | Batch Loss: 0.4906 | Learning Rate: 0.000237 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 3642/12542 | Batch Loss: 1.9284 | Learning Rate: 0.000237 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3643/12542 | Batch Loss: 2.5070 | Learning Rate: 0.000237 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3644/12542 | Batch Loss: 1.5489 | Learning Rate: 0.000236 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3645/12542 | Batch Loss: 1.1889 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3646/12542 | Batch Loss: 1.1468 | Learning Rate: 0.000236 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3647/12542 | Batch Loss: 1.4915 | Learning Rate: 0.000236 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3648/12542 | Batch Loss: 1.6763 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3649/12542 | Batch Loss: 2.7768 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3650/12542 | Batch Loss: 1.7986 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3651/12542 | Batch Loss: 1.1767 | Learning Rate: 0.000236 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3652/12542 | Batch Loss: 1.0250 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3653/12542 | Batch Loss: 1.6592 | Learning Rate: 0.000236 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3654/12542 | Batch Loss: 1.8593 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3655/12542 | Batch Loss: 1.0064 | Learning Rate: 0.000236 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3656/12542 | Batch Loss: 0.6596 | Learning Rate: 0.000236 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3657/12542 | Batch Loss: 3.1447 | Learning Rate: 0.000236 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3658/12542 | Batch Loss: 2.2795 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3659/12542 | Batch Loss: 1.0696 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3660/12542 | Batch Loss: 2.3566 | Learning Rate: 0.000236 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3661/12542 | Batch Loss: 0.5456 | Learning Rate: 0.000236 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3662/12542 | Batch Loss: 0.8926 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3663/12542 | Batch Loss: 0.4524 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3664/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000236 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3665/12542 | Batch Loss: 0.7445 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3666/12542 | Batch Loss: 1.5446 | Learning Rate: 0.000236 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3667/12542 | Batch Loss: 1.0838 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3668/12542 | Batch Loss: 1.3332 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3669/12542 | Batch Loss: 2.2249 | Learning Rate: 0.000236 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3670/12542 | Batch Loss: 1.4177 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3671/12542 | Batch Loss: 1.3723 | Learning Rate: 0.000236 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3672/12542 | Batch Loss: 0.4817 | Learning Rate: 0.000236 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3673/12542 | Batch Loss: 1.2713 | Learning Rate: 0.000236 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3674/12542 | Batch Loss: 3.5124 | Learning Rate: 0.000236 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3675/12542 | Batch Loss: 0.6038 | Learning Rate: 0.000236 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3676/12542 | Batch Loss: 1.4246 | Learning Rate: 0.000236 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3677/12542 | Batch Loss: 2.6649 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3678/12542 | Batch Loss: 3.8295 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3679/12542 | Batch Loss: 1.8633 | Learning Rate: 0.000236 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3680/12542 | Batch Loss: 1.8217 | Learning Rate: 0.000236 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3681/12542 | Batch Loss: 1.4702 | Learning Rate: 0.000236 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3682/12542 | Batch Loss: 2.1122 | Learning Rate: 0.000235 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3683/12542 | Batch Loss: 0.6800 | Learning Rate: 0.000235 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3684/12542 | Batch Loss: 1.3149 | Learning Rate: 0.000235 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3685/12542 | Batch Loss: 1.8047 | Learning Rate: 0.000235 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3686/12542 | Batch Loss: 2.6164 | Learning Rate: 0.000235 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3687/12542 | Batch Loss: 2.0024 | Learning Rate: 0.000235 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3688/12542 | Batch Loss: 2.2916 | Learning Rate: 0.000235 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3689/12542 | Batch Loss: 3.1423 | Learning Rate: 0.000235 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3690/12542 | Batch Loss: 1.1418 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3691/12542 | Batch Loss: 3.1072 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3692/12542 | Batch Loss: 0.7722 | Learning Rate: 0.000235 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3693/12542 | Batch Loss: 1.5779 | Learning Rate: 0.000235 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3694/12542 | Batch Loss: 2.3030 | Learning Rate: 0.000235 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3695/12542 | Batch Loss: 1.5152 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3696/12542 | Batch Loss: 0.7747 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3697/12542 | Batch Loss: 1.3572 | Learning Rate: 0.000235 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3698/12542 | Batch Loss: 0.9581 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3699/12542 | Batch Loss: 1.1693 | Learning Rate: 0.000235 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3700/12542 | Batch Loss: 1.3535 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3701/12542 | Batch Loss: 0.4534 | Learning Rate: 0.000235 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3702/12542 | Batch Loss: 0.5385 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3703/12542 | Batch Loss: 2.2180 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3704/12542 | Batch Loss: 1.5957 | Learning Rate: 0.000235 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3705/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3706/12542 | Batch Loss: 1.2999 | Learning Rate: 0.000235 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3707/12542 | Batch Loss: 1.6241 | Learning Rate: 0.000235 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3708/12542 | Batch Loss: 0.6705 | Learning Rate: 0.000235 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3709/12542 | Batch Loss: 1.5158 | Learning Rate: 0.000235 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3710/12542 | Batch Loss: 2.2174 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3711/12542 | Batch Loss: 0.6122 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3712/12542 | Batch Loss: 1.2235 | Learning Rate: 0.000235 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3713/12542 | Batch Loss: 1.6548 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3714/12542 | Batch Loss: 2.1943 | Learning Rate: 0.000235 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3715/12542 | Batch Loss: 1.1080 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3716/12542 | Batch Loss: 3.1065 | Learning Rate: 0.000235 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3717/12542 | Batch Loss: 2.4027 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3718/12542 | Batch Loss: 0.9141 | Learning Rate: 0.000235 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3719/12542 | Batch Loss: 1.1814 | Learning Rate: 0.000234 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3720/12542 | Batch Loss: 1.1287 | Learning Rate: 0.000234 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3721/12542 | Batch Loss: 1.4192 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3722/12542 | Batch Loss: 0.7894 | Learning Rate: 0.000234 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3723/12542 | Batch Loss: 1.3965 | Learning Rate: 0.000234 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3724/12542 | Batch Loss: 1.3658 | Learning Rate: 0.000234 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3725/12542 | Batch Loss: 1.2979 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3726/12542 | Batch Loss: 1.7233 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3727/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3728/12542 | Batch Loss: 0.6077 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3729/12542 | Batch Loss: 0.9210 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3730/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3731/12542 | Batch Loss: 0.7503 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3732/12542 | Batch Loss: 1.8983 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3733/12542 | Batch Loss: 0.8256 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3734/12542 | Batch Loss: 0.9626 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3735/12542 | Batch Loss: 1.3527 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3736/12542 | Batch Loss: 1.8066 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3737/12542 | Batch Loss: 0.7654 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3738/12542 | Batch Loss: 2.2037 | Learning Rate: 0.000234 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3739/12542 | Batch Loss: 2.2314 | Learning Rate: 0.000234 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3740/12542 | Batch Loss: 0.7283 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3741/12542 | Batch Loss: 2.6249 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3742/12542 | Batch Loss: 1.0251 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3743/12542 | Batch Loss: 0.8069 | Learning Rate: 0.000234 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3744/12542 | Batch Loss: 0.6149 | Learning Rate: 0.000234 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3745/12542 | Batch Loss: 0.8944 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3746/12542 | Batch Loss: 1.0284 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3747/12542 | Batch Loss: 2.2439 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3748/12542 | Batch Loss: 3.0756 | Learning Rate: 0.000234 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3749/12542 | Batch Loss: 0.3240 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3750/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3751/12542 | Batch Loss: 2.1702 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3752/12542 | Batch Loss: 1.5593 | Learning Rate: 0.000234 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3753/12542 | Batch Loss: 1.6184 | Learning Rate: 0.000234 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3754/12542 | Batch Loss: 1.3167 | Learning Rate: 0.000234 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3755/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000234 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3756/12542 | Batch Loss: 0.7852 | Learning Rate: 0.000234 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3757/12542 | Batch Loss: 1.3427 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3758/12542 | Batch Loss: 0.9818 | Learning Rate: 0.000233 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3759/12542 | Batch Loss: 1.4557 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3760/12542 | Batch Loss: 0.6653 | Learning Rate: 0.000233 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3761/12542 | Batch Loss: 0.6852 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3762/12542 | Batch Loss: 0.4943 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3763/12542 | Batch Loss: 0.7270 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3764/12542 | Batch Loss: 1.2338 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3765/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3766/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3767/12542 | Batch Loss: 0.7573 | Learning Rate: 0.000233 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3768/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3769/12542 | Batch Loss: 1.2659 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3770/12542 | Batch Loss: 1.2265 | Learning Rate: 0.000233 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3771/12542 | Batch Loss: 4.0891 | Learning Rate: 0.000233 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3772/12542 | Batch Loss: 2.0846 | Learning Rate: 0.000233 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3773/12542 | Batch Loss: 1.3413 | Learning Rate: 0.000233 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3774/12542 | Batch Loss: 1.5882 | Learning Rate: 0.000233 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3775/12542 | Batch Loss: 1.0523 | Learning Rate: 0.000233 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3776/12542 | Batch Loss: 1.7284 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3777/12542 | Batch Loss: 0.7894 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3778/12542 | Batch Loss: 1.2359 | Learning Rate: 0.000233 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3779/12542 | Batch Loss: 0.4169 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3780/12542 | Batch Loss: 0.7083 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3781/12542 | Batch Loss: 2.0180 | Learning Rate: 0.000233 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3782/12542 | Batch Loss: 0.8805 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3783/12542 | Batch Loss: 1.0581 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3784/12542 | Batch Loss: 1.1636 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3785/12542 | Batch Loss: 0.7945 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3786/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3787/12542 | Batch Loss: 0.5300 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3788/12542 | Batch Loss: 0.8370 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3789/12542 | Batch Loss: 0.5878 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3790/12542 | Batch Loss: 1.7402 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3791/12542 | Batch Loss: 1.6163 | Learning Rate: 0.000233 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3792/12542 | Batch Loss: 1.8283 | Learning Rate: 0.000233 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3793/12542 | Batch Loss: 1.7895 | Learning Rate: 0.000233 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3794/12542 | Batch Loss: 1.8428 | Learning Rate: 0.000232 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3795/12542 | Batch Loss: 2.5630 | Learning Rate: 0.000232 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3796/12542 | Batch Loss: 1.2525 | Learning Rate: 0.000232 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3797/12542 | Batch Loss: 2.7531 | Learning Rate: 0.000232 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3798/12542 | Batch Loss: 2.7925 | Learning Rate: 0.000232 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3799/12542 | Batch Loss: 0.6230 | Learning Rate: 0.000232 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3800/12542 | Batch Loss: 1.3163 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3801/12542 | Batch Loss: 1.5271 | Learning Rate: 0.000232 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3802/12542 | Batch Loss: 1.4420 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3803/12542 | Batch Loss: 0.8980 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3804/12542 | Batch Loss: 1.3307 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3805/12542 | Batch Loss: 1.7081 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3806/12542 | Batch Loss: 1.5884 | Learning Rate: 0.000232 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3807/12542 | Batch Loss: 0.8261 | Learning Rate: 0.000232 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3808/12542 | Batch Loss: 1.2811 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3809/12542 | Batch Loss: 1.0489 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3810/12542 | Batch Loss: 0.8251 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3811/12542 | Batch Loss: 1.0786 | Learning Rate: 0.000232 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3812/12542 | Batch Loss: 0.7980 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3813/12542 | Batch Loss: 0.9292 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3814/12542 | Batch Loss: 1.3382 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3815/12542 | Batch Loss: 1.0165 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3816/12542 | Batch Loss: 1.2733 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3817/12542 | Batch Loss: 0.9906 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3818/12542 | Batch Loss: 2.0950 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3819/12542 | Batch Loss: 1.8405 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3820/12542 | Batch Loss: 1.6585 | Learning Rate: 0.000232 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3821/12542 | Batch Loss: 1.6254 | Learning Rate: 0.000232 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3822/12542 | Batch Loss: 0.6782 | Learning Rate: 0.000232 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 3823/12542 | Batch Loss: 1.2619 | Learning Rate: 0.000232 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3824/12542 | Batch Loss: 1.1284 | Learning Rate: 0.000232 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3825/12542 | Batch Loss: 1.9276 | Learning Rate: 0.000232 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3826/12542 | Batch Loss: 1.0398 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3827/12542 | Batch Loss: 1.5429 | Learning Rate: 0.000232 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3828/12542 | Batch Loss: 0.8507 | Learning Rate: 0.000232 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3829/12542 | Batch Loss: 0.4745 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3830/12542 | Batch Loss: 1.1576 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3831/12542 | Batch Loss: 1.2208 | Learning Rate: 0.000232 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3832/12542 | Batch Loss: 0.8639 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3833/12542 | Batch Loss: 1.1256 | Learning Rate: 0.000231 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3834/12542 | Batch Loss: 0.8623 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3835/12542 | Batch Loss: 1.0745 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3836/12542 | Batch Loss: 0.9349 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3837/12542 | Batch Loss: 2.0307 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3838/12542 | Batch Loss: 0.9592 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3839/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3840/12542 | Batch Loss: 0.8104 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3841/12542 | Batch Loss: 1.4873 | Learning Rate: 0.000231 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3842/12542 | Batch Loss: 1.6239 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3843/12542 | Batch Loss: 2.2117 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3844/12542 | Batch Loss: 1.0106 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3845/12542 | Batch Loss: 0.6183 | Learning Rate: 0.000231 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3846/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3847/12542 | Batch Loss: 0.9655 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3848/12542 | Batch Loss: 0.5477 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3849/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3850/12542 | Batch Loss: 1.8383 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3851/12542 | Batch Loss: 0.8320 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3852/12542 | Batch Loss: 1.7096 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3853/12542 | Batch Loss: 3.8196 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3854/12542 | Batch Loss: 1.1701 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3855/12542 | Batch Loss: 1.5801 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3856/12542 | Batch Loss: 1.2348 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3857/12542 | Batch Loss: 0.8348 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3858/12542 | Batch Loss: 1.8609 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3859/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000231 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3860/12542 | Batch Loss: 1.2293 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3861/12542 | Batch Loss: 2.3017 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3862/12542 | Batch Loss: 0.8130 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3863/12542 | Batch Loss: 0.7128 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3864/12542 | Batch Loss: 1.0486 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3865/12542 | Batch Loss: 2.4381 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3866/12542 | Batch Loss: 1.4769 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3867/12542 | Batch Loss: 1.2957 | Learning Rate: 0.000231 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3868/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000231 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3869/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000231 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3870/12542 | Batch Loss: 0.9751 | Learning Rate: 0.000230 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3871/12542 | Batch Loss: 1.4122 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3872/12542 | Batch Loss: 1.8548 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3873/12542 | Batch Loss: 1.0192 | Learning Rate: 0.000230 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3874/12542 | Batch Loss: 2.0759 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3875/12542 | Batch Loss: 0.7010 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3876/12542 | Batch Loss: 1.5550 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3877/12542 | Batch Loss: 1.4512 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3878/12542 | Batch Loss: 2.0842 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3879/12542 | Batch Loss: 1.5655 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3880/12542 | Batch Loss: 1.0446 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3881/12542 | Batch Loss: 1.0171 | Learning Rate: 0.000230 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3882/12542 | Batch Loss: 0.8604 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3883/12542 | Batch Loss: 0.8745 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3884/12542 | Batch Loss: 1.0453 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3885/12542 | Batch Loss: 3.5483 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3886/12542 | Batch Loss: 1.6220 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3887/12542 | Batch Loss: 1.5452 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3888/12542 | Batch Loss: 1.4380 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3889/12542 | Batch Loss: 2.0512 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3890/12542 | Batch Loss: 0.4214 | Learning Rate: 0.000230 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3891/12542 | Batch Loss: 0.8543 | Learning Rate: 0.000230 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3892/12542 | Batch Loss: 1.9559 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3893/12542 | Batch Loss: 1.4306 | Learning Rate: 0.000230 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3894/12542 | Batch Loss: 0.8378 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3895/12542 | Batch Loss: 1.2345 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3896/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3897/12542 | Batch Loss: 0.8781 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3898/12542 | Batch Loss: 1.1950 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3899/12542 | Batch Loss: 2.0699 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3900/12542 | Batch Loss: 1.0834 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3901/12542 | Batch Loss: 0.6986 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3902/12542 | Batch Loss: 1.1303 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3903/12542 | Batch Loss: 0.9625 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3904/12542 | Batch Loss: 0.7665 | Learning Rate: 0.000230 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3905/12542 | Batch Loss: 1.0875 | Learning Rate: 0.000230 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3906/12542 | Batch Loss: 0.9608 | Learning Rate: 0.000230 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3907/12542 | Batch Loss: 2.5281 | Learning Rate: 0.000229 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3908/12542 | Batch Loss: 1.5443 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3909/12542 | Batch Loss: 1.1630 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3910/12542 | Batch Loss: 1.1296 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3911/12542 | Batch Loss: 1.1380 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3912/12542 | Batch Loss: 1.0859 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3913/12542 | Batch Loss: 1.6819 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3914/12542 | Batch Loss: 2.0289 | Learning Rate: 0.000229 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3915/12542 | Batch Loss: 0.7371 | Learning Rate: 0.000229 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 3916/12542 | Batch Loss: 1.0251 | Learning Rate: 0.000229 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3917/12542 | Batch Loss: 1.5558 | Learning Rate: 0.000229 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 3918/12542 | Batch Loss: 0.9577 | Learning Rate: 0.000229 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 3919/12542 | Batch Loss: 2.6359 | Learning Rate: 0.000229 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3920/12542 | Batch Loss: 0.8094 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3921/12542 | Batch Loss: 1.2784 | Learning Rate: 0.000229 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3922/12542 | Batch Loss: 1.4131 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3923/12542 | Batch Loss: 0.6846 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3924/12542 | Batch Loss: 1.5541 | Learning Rate: 0.000229 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3925/12542 | Batch Loss: 0.5228 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3926/12542 | Batch Loss: 1.2456 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3927/12542 | Batch Loss: 0.9833 | Learning Rate: 0.000229 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3928/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3929/12542 | Batch Loss: 1.7360 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3930/12542 | Batch Loss: 1.8148 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3931/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3932/12542 | Batch Loss: 0.6783 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3933/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3934/12542 | Batch Loss: 0.4179 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3935/12542 | Batch Loss: 1.2136 | Learning Rate: 0.000229 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3936/12542 | Batch Loss: 0.6853 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3937/12542 | Batch Loss: 0.7649 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3938/12542 | Batch Loss: 0.6275 | Learning Rate: 0.000229 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3939/12542 | Batch Loss: 0.6223 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3940/12542 | Batch Loss: 0.7109 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3941/12542 | Batch Loss: 1.1809 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3942/12542 | Batch Loss: 1.2960 | Learning Rate: 0.000229 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3943/12542 | Batch Loss: 3.3272 | Learning Rate: 0.000229 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3944/12542 | Batch Loss: 1.2464 | Learning Rate: 0.000229 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3945/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000228 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3946/12542 | Batch Loss: 1.0171 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3947/12542 | Batch Loss: 1.3403 | Learning Rate: 0.000228 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3948/12542 | Batch Loss: 0.7237 | Learning Rate: 0.000228 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3949/12542 | Batch Loss: 1.0749 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3950/12542 | Batch Loss: 1.1615 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3951/12542 | Batch Loss: 2.5962 | Learning Rate: 0.000228 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3952/12542 | Batch Loss: 0.9297 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3953/12542 | Batch Loss: 2.4009 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3954/12542 | Batch Loss: 2.7665 | Learning Rate: 0.000228 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 3955/12542 | Batch Loss: 1.0538 | Learning Rate: 0.000228 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3956/12542 | Batch Loss: 1.3401 | Learning Rate: 0.000228 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 3957/12542 | Batch Loss: 0.7861 | Learning Rate: 0.000228 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 3958/12542 | Batch Loss: 0.8140 | Learning Rate: 0.000228 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3959/12542 | Batch Loss: 1.6681 | Learning Rate: 0.000228 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 3960/12542 | Batch Loss: 1.2388 | Learning Rate: 0.000228 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 3961/12542 | Batch Loss: 1.4801 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3962/12542 | Batch Loss: 0.9315 | Learning Rate: 0.000228 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3963/12542 | Batch Loss: 0.5969 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3964/12542 | Batch Loss: 1.5554 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3965/12542 | Batch Loss: 0.7688 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3966/12542 | Batch Loss: 1.0180 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3967/12542 | Batch Loss: 0.7639 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3968/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3969/12542 | Batch Loss: 2.1203 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3970/12542 | Batch Loss: 0.9201 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3971/12542 | Batch Loss: 1.1683 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3972/12542 | Batch Loss: 0.9067 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3973/12542 | Batch Loss: 0.8084 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3974/12542 | Batch Loss: 0.8544 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3975/12542 | Batch Loss: 1.2474 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3976/12542 | Batch Loss: 1.6593 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3977/12542 | Batch Loss: 0.4462 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3978/12542 | Batch Loss: 1.6599 | Learning Rate: 0.000228 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3979/12542 | Batch Loss: 0.9810 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3980/12542 | Batch Loss: 1.2092 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3981/12542 | Batch Loss: 2.1217 | Learning Rate: 0.000228 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 3982/12542 | Batch Loss: 0.9777 | Learning Rate: 0.000228 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3983/12542 | Batch Loss: 1.6119 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3984/12542 | Batch Loss: 2.7824 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3985/12542 | Batch Loss: 1.4718 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3986/12542 | Batch Loss: 0.7743 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3987/12542 | Batch Loss: 1.1256 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3988/12542 | Batch Loss: 1.8475 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3989/12542 | Batch Loss: 1.5218 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3990/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3991/12542 | Batch Loss: 1.1257 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3992/12542 | Batch Loss: 1.3139 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3993/12542 | Batch Loss: 2.5195 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3994/12542 | Batch Loss: 1.3726 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3995/12542 | Batch Loss: 1.6309 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3996/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3997/12542 | Batch Loss: 1.0618 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 3998/12542 | Batch Loss: 1.8801 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 3999/12542 | Batch Loss: 1.1827 | Learning Rate: 0.000227 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4000/12542 | Batch Loss: 0.9247 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4001/12542 | Batch Loss: 3.2745 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4002/12542 | Batch Loss: 1.6625 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4003/12542 | Batch Loss: 1.0269 | Learning Rate: 0.000227 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4004/12542 | Batch Loss: 1.2831 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4005/12542 | Batch Loss: 1.9125 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4006/12542 | Batch Loss: 1.3779 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4007/12542 | Batch Loss: 1.0290 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4008/12542 | Batch Loss: 0.8932 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4009/12542 | Batch Loss: 1.4989 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4010/12542 | Batch Loss: 0.8640 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4011/12542 | Batch Loss: 1.0517 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4012/12542 | Batch Loss: 0.5775 | Learning Rate: 0.000227 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4013/12542 | Batch Loss: 0.4480 | Learning Rate: 0.000227 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4014/12542 | Batch Loss: 0.5243 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4015/12542 | Batch Loss: 0.9075 | Learning Rate: 0.000227 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4016/12542 | Batch Loss: 1.0055 | Learning Rate: 0.000227 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4017/12542 | Batch Loss: 0.5971 | Learning Rate: 0.000227 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4018/12542 | Batch Loss: 1.0472 | Learning Rate: 0.000227 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4019/12542 | Batch Loss: 0.6885 | Learning Rate: 0.000227 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4020/12542 | Batch Loss: 1.4057 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4021/12542 | Batch Loss: 1.7689 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4022/12542 | Batch Loss: 1.3505 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4023/12542 | Batch Loss: 0.6084 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4024/12542 | Batch Loss: 1.2177 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4025/12542 | Batch Loss: 0.7631 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4026/12542 | Batch Loss: 1.4946 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4027/12542 | Batch Loss: 1.3816 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4028/12542 | Batch Loss: 0.8319 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4029/12542 | Batch Loss: 1.0875 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4030/12542 | Batch Loss: 0.8536 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4031/12542 | Batch Loss: 0.7155 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4032/12542 | Batch Loss: 3.1191 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4033/12542 | Batch Loss: 2.0933 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4034/12542 | Batch Loss: 2.7169 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4035/12542 | Batch Loss: 0.6519 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4036/12542 | Batch Loss: 0.6724 | Learning Rate: 0.000226 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4037/12542 | Batch Loss: 0.5052 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4038/12542 | Batch Loss: 1.4907 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4039/12542 | Batch Loss: 1.6225 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4040/12542 | Batch Loss: 2.2537 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4041/12542 | Batch Loss: 3.9370 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4042/12542 | Batch Loss: 1.2507 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4043/12542 | Batch Loss: 0.9986 | Learning Rate: 0.000226 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4044/12542 | Batch Loss: 2.0983 | Learning Rate: 0.000226 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4045/12542 | Batch Loss: 0.8814 | Learning Rate: 0.000226 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4046/12542 | Batch Loss: 0.6609 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4047/12542 | Batch Loss: 1.9308 | Learning Rate: 0.000226 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4048/12542 | Batch Loss: 1.7508 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4049/12542 | Batch Loss: 0.8826 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4050/12542 | Batch Loss: 2.2347 | Learning Rate: 0.000226 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4051/12542 | Batch Loss: 2.7369 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4052/12542 | Batch Loss: 2.2062 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4053/12542 | Batch Loss: 1.3900 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4054/12542 | Batch Loss: 1.2799 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4055/12542 | Batch Loss: 1.2606 | Learning Rate: 0.000226 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4056/12542 | Batch Loss: 1.7346 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4057/12542 | Batch Loss: 1.2940 | Learning Rate: 0.000226 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4058/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4059/12542 | Batch Loss: 1.1187 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4060/12542 | Batch Loss: 0.7469 | Learning Rate: 0.000225 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4061/12542 | Batch Loss: 1.2813 | Learning Rate: 0.000225 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4062/12542 | Batch Loss: 1.5512 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4063/12542 | Batch Loss: 1.1994 | Learning Rate: 0.000225 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4064/12542 | Batch Loss: 1.4727 | Learning Rate: 0.000225 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4065/12542 | Batch Loss: 0.6369 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4066/12542 | Batch Loss: 1.3232 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4067/12542 | Batch Loss: 0.8561 | Learning Rate: 0.000225 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4068/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000225 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4069/12542 | Batch Loss: 0.8460 | Learning Rate: 0.000225 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4070/12542 | Batch Loss: 0.7387 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4071/12542 | Batch Loss: 0.6133 | Learning Rate: 0.000225 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4072/12542 | Batch Loss: 1.0883 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4073/12542 | Batch Loss: 1.3677 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4074/12542 | Batch Loss: 0.9790 | Learning Rate: 0.000225 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4075/12542 | Batch Loss: 3.0102 | Learning Rate: 0.000225 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4076/12542 | Batch Loss: 1.0500 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4077/12542 | Batch Loss: 1.7296 | Learning Rate: 0.000225 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4078/12542 | Batch Loss: 0.8131 | Learning Rate: 0.000225 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4079/12542 | Batch Loss: 1.7910 | Learning Rate: 0.000225 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4080/12542 | Batch Loss: 1.5488 | Learning Rate: 0.000225 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4081/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000225 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4082/12542 | Batch Loss: 0.3980 | Learning Rate: 0.000225 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4083/12542 | Batch Loss: 1.0373 | Learning Rate: 0.000225 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4084/12542 | Batch Loss: 1.3592 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4085/12542 | Batch Loss: 0.5134 | Learning Rate: 0.000225 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4086/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000225 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4087/12542 | Batch Loss: 1.3544 | Learning Rate: 0.000225 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4088/12542 | Batch Loss: 1.4712 | Learning Rate: 0.000225 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4089/12542 | Batch Loss: 1.2169 | Learning Rate: 0.000225 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4090/12542 | Batch Loss: 1.4947 | Learning Rate: 0.000225 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4091/12542 | Batch Loss: 0.7543 | Learning Rate: 0.000225 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4092/12542 | Batch Loss: 1.2191 | Learning Rate: 0.000225 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4093/12542 | Batch Loss: 0.7585 | Learning Rate: 0.000225 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4094/12542 | Batch Loss: 1.9383 | Learning Rate: 0.000225 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4095/12542 | Batch Loss: 0.5959 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4096/12542 | Batch Loss: 1.4616 | Learning Rate: 0.000224 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4097/12542 | Batch Loss: 1.0931 | Learning Rate: 0.000224 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4098/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4099/12542 | Batch Loss: 1.0662 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4100/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000224 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4101/12542 | Batch Loss: 1.2368 | Learning Rate: 0.000224 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4102/12542 | Batch Loss: 2.1066 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4103/12542 | Batch Loss: 1.2361 | Learning Rate: 0.000224 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4104/12542 | Batch Loss: 1.5487 | Learning Rate: 0.000224 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4105/12542 | Batch Loss: 0.8557 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4106/12542 | Batch Loss: 0.7559 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4107/12542 | Batch Loss: 1.6729 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4108/12542 | Batch Loss: 0.7709 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4109/12542 | Batch Loss: 2.0190 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4110/12542 | Batch Loss: 0.8288 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4111/12542 | Batch Loss: 0.3679 | Learning Rate: 0.000224 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4112/12542 | Batch Loss: 2.7015 | Learning Rate: 0.000224 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4113/12542 | Batch Loss: 1.4977 | Learning Rate: 0.000224 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4114/12542 | Batch Loss: 1.7130 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4115/12542 | Batch Loss: 1.3108 | Learning Rate: 0.000224 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4116/12542 | Batch Loss: 1.3002 | Learning Rate: 0.000224 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4117/12542 | Batch Loss: 1.9451 | Learning Rate: 0.000224 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4118/12542 | Batch Loss: 1.1153 | Learning Rate: 0.000224 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4119/12542 | Batch Loss: 1.4915 | Learning Rate: 0.000224 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4120/12542 | Batch Loss: 0.7529 | Learning Rate: 0.000224 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4121/12542 | Batch Loss: 0.9386 | Learning Rate: 0.000224 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4122/12542 | Batch Loss: 1.5930 | Learning Rate: 0.000224 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4123/12542 | Batch Loss: 1.4701 | Learning Rate: 0.000224 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4124/12542 | Batch Loss: 1.2101 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4125/12542 | Batch Loss: 1.9221 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4126/12542 | Batch Loss: 0.6490 | Learning Rate: 0.000224 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4127/12542 | Batch Loss: 1.5121 | Learning Rate: 0.000224 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4128/12542 | Batch Loss: 0.9864 | Learning Rate: 0.000224 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4129/12542 | Batch Loss: 1.3175 | Learning Rate: 0.000224 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4130/12542 | Batch Loss: 1.5045 | Learning Rate: 0.000224 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4131/12542 | Batch Loss: 1.3206 | Learning Rate: 0.000224 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4132/12542 | Batch Loss: 0.9830 | Learning Rate: 0.000224 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4133/12542 | Batch Loss: 1.8435 | Learning Rate: 0.000223 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4134/12542 | Batch Loss: 1.1640 | Learning Rate: 0.000223 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4135/12542 | Batch Loss: 0.8089 | Learning Rate: 0.000223 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4136/12542 | Batch Loss: 1.5962 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4137/12542 | Batch Loss: 1.0555 | Learning Rate: 0.000223 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4138/12542 | Batch Loss: 2.8465 | Learning Rate: 0.000223 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4139/12542 | Batch Loss: 1.0875 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4140/12542 | Batch Loss: 1.8134 | Learning Rate: 0.000223 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4141/12542 | Batch Loss: 0.8654 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4142/12542 | Batch Loss: 1.6231 | Learning Rate: 0.000223 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4143/12542 | Batch Loss: 0.8680 | Learning Rate: 0.000223 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4144/12542 | Batch Loss: 2.4982 | Learning Rate: 0.000223 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4145/12542 | Batch Loss: 1.2483 | Learning Rate: 0.000223 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4146/12542 | Batch Loss: 1.5627 | Learning Rate: 0.000223 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4147/12542 | Batch Loss: 1.3284 | Learning Rate: 0.000223 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4148/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4149/12542 | Batch Loss: 0.4822 | Learning Rate: 0.000223 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4150/12542 | Batch Loss: 1.8877 | Learning Rate: 0.000223 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4151/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000223 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4152/12542 | Batch Loss: 1.0967 | Learning Rate: 0.000223 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4153/12542 | Batch Loss: 3.0025 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4154/12542 | Batch Loss: 0.6575 | Learning Rate: 0.000223 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4155/12542 | Batch Loss: 2.5100 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4156/12542 | Batch Loss: 0.9269 | Learning Rate: 0.000223 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4157/12542 | Batch Loss: 1.8150 | Learning Rate: 0.000223 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4158/12542 | Batch Loss: 0.8524 | Learning Rate: 0.000223 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4159/12542 | Batch Loss: 0.7400 | Learning Rate: 0.000223 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4160/12542 | Batch Loss: 1.5291 | Learning Rate: 0.000223 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4161/12542 | Batch Loss: 1.1337 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4162/12542 | Batch Loss: 0.9659 | Learning Rate: 0.000223 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4163/12542 | Batch Loss: 0.5121 | Learning Rate: 0.000223 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4164/12542 | Batch Loss: 0.5512 | Learning Rate: 0.000223 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4165/12542 | Batch Loss: 0.7926 | Learning Rate: 0.000223 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4166/12542 | Batch Loss: 0.6991 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4167/12542 | Batch Loss: 0.6971 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4168/12542 | Batch Loss: 0.7269 | Learning Rate: 0.000223 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4169/12542 | Batch Loss: 0.9600 | Learning Rate: 0.000223 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4170/12542 | Batch Loss: 1.5964 | Learning Rate: 0.000223 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4171/12542 | Batch Loss: 2.0792 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4172/12542 | Batch Loss: 0.6123 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4173/12542 | Batch Loss: 1.4568 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4174/12542 | Batch Loss: 0.9985 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4175/12542 | Batch Loss: 1.0394 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4176/12542 | Batch Loss: 0.4914 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4177/12542 | Batch Loss: 0.8129 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4178/12542 | Batch Loss: 1.0032 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4179/12542 | Batch Loss: 3.0241 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4180/12542 | Batch Loss: 0.3958 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4181/12542 | Batch Loss: 2.1685 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4182/12542 | Batch Loss: 1.3096 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4183/12542 | Batch Loss: 2.6478 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4184/12542 | Batch Loss: 2.0820 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4185/12542 | Batch Loss: 1.0447 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4186/12542 | Batch Loss: 1.7778 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4187/12542 | Batch Loss: 1.6582 | Learning Rate: 0.000222 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4188/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000222 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4189/12542 | Batch Loss: 0.7583 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4190/12542 | Batch Loss: 1.4426 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4191/12542 | Batch Loss: 1.2762 | Learning Rate: 0.000222 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4192/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000222 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4193/12542 | Batch Loss: 1.0193 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4194/12542 | Batch Loss: 3.0236 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4195/12542 | Batch Loss: 0.9411 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4196/12542 | Batch Loss: 1.3455 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4197/12542 | Batch Loss: 1.5692 | Learning Rate: 0.000222 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4198/12542 | Batch Loss: 1.4138 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4199/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4200/12542 | Batch Loss: 0.6825 | Learning Rate: 0.000222 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4201/12542 | Batch Loss: 0.9155 | Learning Rate: 0.000222 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4202/12542 | Batch Loss: 1.1372 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4203/12542 | Batch Loss: 2.1514 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4204/12542 | Batch Loss: 2.6984 | Learning Rate: 0.000222 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4205/12542 | Batch Loss: 1.5902 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4206/12542 | Batch Loss: 0.9927 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4207/12542 | Batch Loss: 0.9222 | Learning Rate: 0.000222 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4208/12542 | Batch Loss: 0.7824 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4209/12542 | Batch Loss: 0.8169 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4210/12542 | Batch Loss: 2.1076 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4211/12542 | Batch Loss: 1.4380 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4212/12542 | Batch Loss: 1.5744 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4213/12542 | Batch Loss: 0.7976 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4214/12542 | Batch Loss: 1.4147 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4215/12542 | Batch Loss: 2.1431 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4216/12542 | Batch Loss: 2.4456 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4217/12542 | Batch Loss: 2.6399 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4218/12542 | Batch Loss: 0.7842 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4219/12542 | Batch Loss: 2.1681 | Learning Rate: 0.000221 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4220/12542 | Batch Loss: 2.0035 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4221/12542 | Batch Loss: 0.8141 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4222/12542 | Batch Loss: 0.9858 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4223/12542 | Batch Loss: 1.4337 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4224/12542 | Batch Loss: 0.4074 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4225/12542 | Batch Loss: 2.0971 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4226/12542 | Batch Loss: 1.3138 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4227/12542 | Batch Loss: 2.3156 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4228/12542 | Batch Loss: 2.6604 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4229/12542 | Batch Loss: 0.9377 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4230/12542 | Batch Loss: 0.9974 | Learning Rate: 0.000221 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4231/12542 | Batch Loss: 0.6642 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4232/12542 | Batch Loss: 1.4775 | Learning Rate: 0.000221 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4233/12542 | Batch Loss: 1.0093 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4234/12542 | Batch Loss: 0.5026 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4235/12542 | Batch Loss: 1.0052 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4236/12542 | Batch Loss: 0.7633 | Learning Rate: 0.000221 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4237/12542 | Batch Loss: 0.8289 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4238/12542 | Batch Loss: 1.9302 | Learning Rate: 0.000221 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 4239/12542 | Batch Loss: 1.1223 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4240/12542 | Batch Loss: 0.8236 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4241/12542 | Batch Loss: 1.0798 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4242/12542 | Batch Loss: 0.6664 | Learning Rate: 0.000221 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4243/12542 | Batch Loss: 3.7191 | Learning Rate: 0.000221 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4244/12542 | Batch Loss: 1.4869 | Learning Rate: 0.000221 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4245/12542 | Batch Loss: 1.5651 | Learning Rate: 0.000221 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4246/12542 | Batch Loss: 1.2778 | Learning Rate: 0.000220 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4247/12542 | Batch Loss: 2.6766 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4248/12542 | Batch Loss: 1.7897 | Learning Rate: 0.000220 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4249/12542 | Batch Loss: 0.5009 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4250/12542 | Batch Loss: 0.5427 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4251/12542 | Batch Loss: 0.6984 | Learning Rate: 0.000220 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4252/12542 | Batch Loss: 1.3629 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4253/12542 | Batch Loss: 1.4262 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4254/12542 | Batch Loss: 1.7733 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4255/12542 | Batch Loss: 0.9554 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4256/12542 | Batch Loss: 1.1733 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4257/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000220 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4258/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4259/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4260/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4261/12542 | Batch Loss: 2.3387 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4262/12542 | Batch Loss: 0.9039 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4263/12542 | Batch Loss: 0.8931 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4264/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4265/12542 | Batch Loss: 2.1315 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4266/12542 | Batch Loss: 0.3910 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4267/12542 | Batch Loss: 0.7537 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4268/12542 | Batch Loss: 0.9099 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4269/12542 | Batch Loss: 0.4835 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4270/12542 | Batch Loss: 0.7566 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4271/12542 | Batch Loss: 0.9297 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4272/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4273/12542 | Batch Loss: 1.8576 | Learning Rate: 0.000220 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4274/12542 | Batch Loss: 1.2153 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4275/12542 | Batch Loss: 1.1636 | Learning Rate: 0.000220 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4276/12542 | Batch Loss: 0.9434 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4277/12542 | Batch Loss: 1.0940 | Learning Rate: 0.000220 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4278/12542 | Batch Loss: 1.5032 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4279/12542 | Batch Loss: 1.9591 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4280/12542 | Batch Loss: 1.4691 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4281/12542 | Batch Loss: 1.4564 | Learning Rate: 0.000220 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4282/12542 | Batch Loss: 2.0501 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4283/12542 | Batch Loss: 1.7438 | Learning Rate: 0.000220 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4284/12542 | Batch Loss: 0.6615 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4285/12542 | Batch Loss: 0.5807 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4286/12542 | Batch Loss: 2.7201 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4287/12542 | Batch Loss: 1.4413 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4288/12542 | Batch Loss: 1.5727 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4289/12542 | Batch Loss: 1.5058 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4290/12542 | Batch Loss: 2.2974 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4291/12542 | Batch Loss: 1.0503 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4292/12542 | Batch Loss: 0.8850 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4293/12542 | Batch Loss: 0.9082 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4294/12542 | Batch Loss: 1.1783 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4295/12542 | Batch Loss: 2.0635 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4296/12542 | Batch Loss: 0.6673 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4297/12542 | Batch Loss: 0.7757 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4298/12542 | Batch Loss: 2.1750 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4299/12542 | Batch Loss: 1.5565 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4300/12542 | Batch Loss: 0.8784 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4301/12542 | Batch Loss: 1.1160 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4302/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4303/12542 | Batch Loss: 0.6000 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4304/12542 | Batch Loss: 0.7682 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4305/12542 | Batch Loss: 0.6675 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4306/12542 | Batch Loss: 2.9473 | Learning Rate: 0.000219 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4307/12542 | Batch Loss: 1.2356 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4308/12542 | Batch Loss: 1.4557 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4309/12542 | Batch Loss: 0.8494 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4310/12542 | Batch Loss: 1.5742 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4311/12542 | Batch Loss: 0.5824 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4312/12542 | Batch Loss: 2.9147 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4313/12542 | Batch Loss: 1.3708 | Learning Rate: 0.000219 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4314/12542 | Batch Loss: 2.9135 | Learning Rate: 0.000219 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4315/12542 | Batch Loss: 0.9652 | Learning Rate: 0.000219 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4316/12542 | Batch Loss: 2.3657 | Learning Rate: 0.000219 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4317/12542 | Batch Loss: 0.9060 | Learning Rate: 0.000219 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4318/12542 | Batch Loss: 1.3556 | Learning Rate: 0.000219 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4319/12542 | Batch Loss: 1.0596 | Learning Rate: 0.000219 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4320/12542 | Batch Loss: 1.6138 | Learning Rate: 0.000219 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4321/12542 | Batch Loss: 2.4329 | Learning Rate: 0.000218 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4322/12542 | Batch Loss: 0.7311 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4323/12542 | Batch Loss: 0.9741 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4324/12542 | Batch Loss: 1.1330 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4325/12542 | Batch Loss: 2.4807 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4326/12542 | Batch Loss: 2.9046 | Learning Rate: 0.000218 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4327/12542 | Batch Loss: 1.5928 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4328/12542 | Batch Loss: 0.6394 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4329/12542 | Batch Loss: 1.3336 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4330/12542 | Batch Loss: 1.5353 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4331/12542 | Batch Loss: 1.2619 | Learning Rate: 0.000218 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4332/12542 | Batch Loss: 1.6692 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4333/12542 | Batch Loss: 1.9575 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4334/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000218 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4335/12542 | Batch Loss: 1.1292 | Learning Rate: 0.000218 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4336/12542 | Batch Loss: 0.7389 | Learning Rate: 0.000218 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4337/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4338/12542 | Batch Loss: 0.8325 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4339/12542 | Batch Loss: 0.6841 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4340/12542 | Batch Loss: 1.8939 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4341/12542 | Batch Loss: 0.9736 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4342/12542 | Batch Loss: 0.9962 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4343/12542 | Batch Loss: 1.4944 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4344/12542 | Batch Loss: 0.6104 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4345/12542 | Batch Loss: 1.5190 | Learning Rate: 0.000218 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4346/12542 | Batch Loss: 2.4644 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4347/12542 | Batch Loss: 1.3088 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4348/12542 | Batch Loss: 1.1236 | Learning Rate: 0.000218 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4349/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000218 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4350/12542 | Batch Loss: 2.9923 | Learning Rate: 0.000218 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4351/12542 | Batch Loss: 1.3342 | Learning Rate: 0.000218 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4352/12542 | Batch Loss: 0.8309 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4353/12542 | Batch Loss: 1.8287 | Learning Rate: 0.000218 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4354/12542 | Batch Loss: 0.8000 | Learning Rate: 0.000218 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4355/12542 | Batch Loss: 1.7140 | Learning Rate: 0.000218 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4356/12542 | Batch Loss: 0.6372 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4357/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000218 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4358/12542 | Batch Loss: 0.9162 | Learning Rate: 0.000218 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4359/12542 | Batch Loss: 2.1146 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4360/12542 | Batch Loss: 1.5700 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4361/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4362/12542 | Batch Loss: 3.5207 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4363/12542 | Batch Loss: 0.4980 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4364/12542 | Batch Loss: 1.2464 | Learning Rate: 0.000217 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4365/12542 | Batch Loss: 1.7704 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4366/12542 | Batch Loss: 1.2441 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4367/12542 | Batch Loss: 0.6209 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4368/12542 | Batch Loss: 0.3326 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4369/12542 | Batch Loss: 1.2962 | Learning Rate: 0.000217 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 4370/12542 | Batch Loss: 0.5314 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4371/12542 | Batch Loss: 0.6077 | Learning Rate: 0.000217 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4372/12542 | Batch Loss: 1.3799 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4373/12542 | Batch Loss: 1.4558 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4374/12542 | Batch Loss: 0.4230 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4375/12542 | Batch Loss: 2.6885 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4376/12542 | Batch Loss: 1.6870 | Learning Rate: 0.000217 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4377/12542 | Batch Loss: 0.4112 | Learning Rate: 0.000217 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4378/12542 | Batch Loss: 1.2390 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4379/12542 | Batch Loss: 2.2862 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4380/12542 | Batch Loss: 0.8740 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4381/12542 | Batch Loss: 0.3782 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4382/12542 | Batch Loss: 1.6861 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4383/12542 | Batch Loss: 0.9013 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4384/12542 | Batch Loss: 1.1356 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4385/12542 | Batch Loss: 1.0988 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4386/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4387/12542 | Batch Loss: 0.9194 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4388/12542 | Batch Loss: 1.3210 | Learning Rate: 0.000217 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4389/12542 | Batch Loss: 2.4164 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4390/12542 | Batch Loss: 1.8070 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4391/12542 | Batch Loss: 1.5484 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4392/12542 | Batch Loss: 2.6974 | Learning Rate: 0.000217 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4393/12542 | Batch Loss: 0.7461 | Learning Rate: 0.000217 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4394/12542 | Batch Loss: 0.9086 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4395/12542 | Batch Loss: 0.9118 | Learning Rate: 0.000217 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4396/12542 | Batch Loss: 1.5877 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4397/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4398/12542 | Batch Loss: 0.9821 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4399/12542 | Batch Loss: 0.8593 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4400/12542 | Batch Loss: 0.5775 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4401/12542 | Batch Loss: 1.4364 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4402/12542 | Batch Loss: 0.8364 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4403/12542 | Batch Loss: 1.7933 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4404/12542 | Batch Loss: 2.6087 | Learning Rate: 0.000216 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4405/12542 | Batch Loss: 1.1155 | Learning Rate: 0.000216 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4406/12542 | Batch Loss: 2.5603 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4407/12542 | Batch Loss: 1.8548 | Learning Rate: 0.000216 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4408/12542 | Batch Loss: 1.6924 | Learning Rate: 0.000216 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4409/12542 | Batch Loss: 0.6255 | Learning Rate: 0.000216 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4410/12542 | Batch Loss: 1.8682 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4411/12542 | Batch Loss: 2.2270 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4412/12542 | Batch Loss: 1.7844 | Learning Rate: 0.000216 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4413/12542 | Batch Loss: 0.9628 | Learning Rate: 0.000216 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4414/12542 | Batch Loss: 1.2148 | Learning Rate: 0.000216 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4415/12542 | Batch Loss: 2.2375 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4416/12542 | Batch Loss: 1.1592 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4417/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4418/12542 | Batch Loss: 1.7175 | Learning Rate: 0.000216 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4419/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000216 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4420/12542 | Batch Loss: 0.7204 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4421/12542 | Batch Loss: 0.6513 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4422/12542 | Batch Loss: 1.8275 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4423/12542 | Batch Loss: 1.4875 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4424/12542 | Batch Loss: 0.5666 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4425/12542 | Batch Loss: 2.2550 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4426/12542 | Batch Loss: 1.5022 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4427/12542 | Batch Loss: 2.1390 | Learning Rate: 0.000216 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4428/12542 | Batch Loss: 1.9007 | Learning Rate: 0.000216 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4429/12542 | Batch Loss: 1.2919 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4430/12542 | Batch Loss: 0.9920 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4431/12542 | Batch Loss: 1.1315 | Learning Rate: 0.000216 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4432/12542 | Batch Loss: 1.0242 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4433/12542 | Batch Loss: 0.5577 | Learning Rate: 0.000216 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4434/12542 | Batch Loss: 1.5399 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4435/12542 | Batch Loss: 1.7053 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4436/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4437/12542 | Batch Loss: 1.0657 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4438/12542 | Batch Loss: 1.4524 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4439/12542 | Batch Loss: 1.5866 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4440/12542 | Batch Loss: 0.9965 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4441/12542 | Batch Loss: 3.4803 | Learning Rate: 0.000215 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4442/12542 | Batch Loss: 0.9763 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4443/12542 | Batch Loss: 1.3238 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4444/12542 | Batch Loss: 1.3955 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4445/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4446/12542 | Batch Loss: 1.3692 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4447/12542 | Batch Loss: 1.5981 | Learning Rate: 0.000215 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4448/12542 | Batch Loss: 1.2837 | Learning Rate: 0.000215 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4449/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000215 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4450/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4451/12542 | Batch Loss: 1.4254 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4452/12542 | Batch Loss: 1.2643 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4453/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4454/12542 | Batch Loss: 1.4390 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4455/12542 | Batch Loss: 0.8079 | Learning Rate: 0.000215 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4456/12542 | Batch Loss: 1.7564 | Learning Rate: 0.000215 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4457/12542 | Batch Loss: 1.1409 | Learning Rate: 0.000215 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4458/12542 | Batch Loss: 0.6203 | Learning Rate: 0.000215 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4459/12542 | Batch Loss: 0.6781 | Learning Rate: 0.000215 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4460/12542 | Batch Loss: 0.3749 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4461/12542 | Batch Loss: 1.7495 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4462/12542 | Batch Loss: 2.1338 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4463/12542 | Batch Loss: 0.7991 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4464/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000215 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4465/12542 | Batch Loss: 1.4845 | Learning Rate: 0.000215 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4466/12542 | Batch Loss: 1.2384 | Learning Rate: 0.000215 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4467/12542 | Batch Loss: 3.6503 | Learning Rate: 0.000215 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4468/12542 | Batch Loss: 1.5329 | Learning Rate: 0.000215 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4469/12542 | Batch Loss: 2.2501 | Learning Rate: 0.000215 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4470/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000215 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4471/12542 | Batch Loss: 1.2250 | Learning Rate: 0.000215 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4472/12542 | Batch Loss: 2.7601 | Learning Rate: 0.000214 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4473/12542 | Batch Loss: 1.8927 | Learning Rate: 0.000214 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4474/12542 | Batch Loss: 0.6399 | Learning Rate: 0.000214 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4475/12542 | Batch Loss: 1.7084 | Learning Rate: 0.000214 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4476/12542 | Batch Loss: 2.5340 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4477/12542 | Batch Loss: 0.3109 | Learning Rate: 0.000214 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4478/12542 | Batch Loss: 1.1223 | Learning Rate: 0.000214 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4479/12542 | Batch Loss: 0.9113 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4480/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000214 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4481/12542 | Batch Loss: 0.8607 | Learning Rate: 0.000214 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4482/12542 | Batch Loss: 1.0761 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4483/12542 | Batch Loss: 0.7798 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4484/12542 | Batch Loss: 1.2064 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4485/12542 | Batch Loss: 0.5732 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4486/12542 | Batch Loss: 0.8564 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4487/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4488/12542 | Batch Loss: 2.3295 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4489/12542 | Batch Loss: 1.8818 | Learning Rate: 0.000214 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4490/12542 | Batch Loss: 0.8244 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4491/12542 | Batch Loss: 2.2442 | Learning Rate: 0.000214 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4492/12542 | Batch Loss: 1.2270 | Learning Rate: 0.000214 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4493/12542 | Batch Loss: 0.4660 | Learning Rate: 0.000214 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4494/12542 | Batch Loss: 2.6334 | Learning Rate: 0.000214 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4495/12542 | Batch Loss: 1.8652 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4496/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4497/12542 | Batch Loss: 1.5681 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4498/12542 | Batch Loss: 1.5523 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4499/12542 | Batch Loss: 0.9200 | Learning Rate: 0.000214 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4500/12542 | Batch Loss: 2.2393 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4501/12542 | Batch Loss: 1.2051 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4502/12542 | Batch Loss: 2.1787 | Learning Rate: 0.000214 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4503/12542 | Batch Loss: 1.4144 | Learning Rate: 0.000214 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4504/12542 | Batch Loss: 1.3862 | Learning Rate: 0.000214 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 4505/12542 | Batch Loss: 0.8928 | Learning Rate: 0.000214 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4506/12542 | Batch Loss: 1.5777 | Learning Rate: 0.000214 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4507/12542 | Batch Loss: 1.0631 | Learning Rate: 0.000214 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4508/12542 | Batch Loss: 1.4925 | Learning Rate: 0.000214 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4509/12542 | Batch Loss: 0.6648 | Learning Rate: 0.000213 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4510/12542 | Batch Loss: 1.3461 | Learning Rate: 0.000213 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4511/12542 | Batch Loss: 2.2190 | Learning Rate: 0.000213 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4512/12542 | Batch Loss: 1.1565 | Learning Rate: 0.000213 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4513/12542 | Batch Loss: 2.6909 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4514/12542 | Batch Loss: 0.9278 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4515/12542 | Batch Loss: 1.0097 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4516/12542 | Batch Loss: 2.3882 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4517/12542 | Batch Loss: 0.7365 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4518/12542 | Batch Loss: 1.0788 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4519/12542 | Batch Loss: 1.4290 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4520/12542 | Batch Loss: 1.4477 | Learning Rate: 0.000213 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4521/12542 | Batch Loss: 0.5656 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4522/12542 | Batch Loss: 2.4047 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4523/12542 | Batch Loss: 1.2478 | Learning Rate: 0.000213 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4524/12542 | Batch Loss: 1.4552 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4525/12542 | Batch Loss: 0.7121 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4526/12542 | Batch Loss: 1.3300 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4527/12542 | Batch Loss: 1.9387 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4528/12542 | Batch Loss: 1.5585 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4529/12542 | Batch Loss: 1.5124 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4530/12542 | Batch Loss: 1.1206 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4531/12542 | Batch Loss: 1.0439 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4532/12542 | Batch Loss: 3.6936 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4533/12542 | Batch Loss: 3.4884 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4534/12542 | Batch Loss: 1.3106 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4535/12542 | Batch Loss: 1.9915 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4536/12542 | Batch Loss: 0.6503 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4537/12542 | Batch Loss: 3.3658 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4538/12542 | Batch Loss: 0.8987 | Learning Rate: 0.000213 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4539/12542 | Batch Loss: 0.6999 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4540/12542 | Batch Loss: 1.0111 | Learning Rate: 0.000213 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4541/12542 | Batch Loss: 1.6479 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4542/12542 | Batch Loss: 2.0368 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4543/12542 | Batch Loss: 0.8047 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4544/12542 | Batch Loss: 1.4244 | Learning Rate: 0.000213 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4545/12542 | Batch Loss: 2.0445 | Learning Rate: 0.000213 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4546/12542 | Batch Loss: 1.4368 | Learning Rate: 0.000213 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4547/12542 | Batch Loss: 0.7765 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4548/12542 | Batch Loss: 1.8891 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4549/12542 | Batch Loss: 3.2558 | Learning Rate: 0.000212 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4550/12542 | Batch Loss: 1.3413 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4551/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4552/12542 | Batch Loss: 0.8053 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4553/12542 | Batch Loss: 0.7562 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4554/12542 | Batch Loss: 1.0359 | Learning Rate: 0.000212 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4555/12542 | Batch Loss: 1.5337 | Learning Rate: 0.000212 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4556/12542 | Batch Loss: 1.2178 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4557/12542 | Batch Loss: 1.0961 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4558/12542 | Batch Loss: 0.9413 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4559/12542 | Batch Loss: 1.2347 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4560/12542 | Batch Loss: 1.0508 | Learning Rate: 0.000212 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4561/12542 | Batch Loss: 2.5825 | Learning Rate: 0.000212 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4562/12542 | Batch Loss: 1.2712 | Learning Rate: 0.000212 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4563/12542 | Batch Loss: 3.1489 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4564/12542 | Batch Loss: 1.4436 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4565/12542 | Batch Loss: 1.2933 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4566/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000212 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4567/12542 | Batch Loss: 1.4751 | Learning Rate: 0.000212 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4568/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000212 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4569/12542 | Batch Loss: 0.8401 | Learning Rate: 0.000212 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4570/12542 | Batch Loss: 0.8087 | Learning Rate: 0.000212 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4571/12542 | Batch Loss: 0.8306 | Learning Rate: 0.000212 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4572/12542 | Batch Loss: 1.5368 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4573/12542 | Batch Loss: 2.0169 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4574/12542 | Batch Loss: 1.0687 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4575/12542 | Batch Loss: 1.4320 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4576/12542 | Batch Loss: 1.2178 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4577/12542 | Batch Loss: 1.2294 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4578/12542 | Batch Loss: 0.7809 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4579/12542 | Batch Loss: 1.4303 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4580/12542 | Batch Loss: 0.6928 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4581/12542 | Batch Loss: 2.1012 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4582/12542 | Batch Loss: 1.9398 | Learning Rate: 0.000212 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4583/12542 | Batch Loss: 1.7318 | Learning Rate: 0.000212 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4584/12542 | Batch Loss: 0.8332 | Learning Rate: 0.000212 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4585/12542 | Batch Loss: 1.4033 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4586/12542 | Batch Loss: 1.2595 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4587/12542 | Batch Loss: 0.7622 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4588/12542 | Batch Loss: 0.6210 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4589/12542 | Batch Loss: 0.8505 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4590/12542 | Batch Loss: 2.1290 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4591/12542 | Batch Loss: 1.4660 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4592/12542 | Batch Loss: 1.1314 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4593/12542 | Batch Loss: 1.0839 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4594/12542 | Batch Loss: 0.6688 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4595/12542 | Batch Loss: 0.9180 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4596/12542 | Batch Loss: 0.4494 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4597/12542 | Batch Loss: 1.8545 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4598/12542 | Batch Loss: 1.2938 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4599/12542 | Batch Loss: 1.8407 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4600/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4601/12542 | Batch Loss: 1.8511 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4602/12542 | Batch Loss: 0.9926 | Learning Rate: 0.000211 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4603/12542 | Batch Loss: 0.4791 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4604/12542 | Batch Loss: 0.6264 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4605/12542 | Batch Loss: 1.4574 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4606/12542 | Batch Loss: 1.3591 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4607/12542 | Batch Loss: 0.6690 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4608/12542 | Batch Loss: 1.2313 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4609/12542 | Batch Loss: 0.5276 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4610/12542 | Batch Loss: 1.2193 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4611/12542 | Batch Loss: 0.6712 | Learning Rate: 0.000211 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4612/12542 | Batch Loss: 0.5208 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4613/12542 | Batch Loss: 1.6697 | Learning Rate: 0.000211 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4614/12542 | Batch Loss: 2.1601 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4615/12542 | Batch Loss: 1.0643 | Learning Rate: 0.000211 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4616/12542 | Batch Loss: 1.2339 | Learning Rate: 0.000211 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4617/12542 | Batch Loss: 0.9411 | Learning Rate: 0.000211 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4618/12542 | Batch Loss: 2.1625 | Learning Rate: 0.000211 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4619/12542 | Batch Loss: 1.3597 | Learning Rate: 0.000211 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4620/12542 | Batch Loss: 0.8214 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4621/12542 | Batch Loss: 1.0450 | Learning Rate: 0.000211 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4622/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4623/12542 | Batch Loss: 1.6176 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4624/12542 | Batch Loss: 0.7463 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4625/12542 | Batch Loss: 1.4859 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4626/12542 | Batch Loss: 1.2212 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4627/12542 | Batch Loss: 0.9497 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4628/12542 | Batch Loss: 0.5691 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4629/12542 | Batch Loss: 0.8085 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4630/12542 | Batch Loss: 0.9223 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4631/12542 | Batch Loss: 0.5178 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4632/12542 | Batch Loss: 3.2995 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4633/12542 | Batch Loss: 1.3648 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4634/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000210 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4635/12542 | Batch Loss: 0.8522 | Learning Rate: 0.000210 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4636/12542 | Batch Loss: 1.6027 | Learning Rate: 0.000210 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4637/12542 | Batch Loss: 0.8037 | Learning Rate: 0.000210 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4638/12542 | Batch Loss: 1.1618 | Learning Rate: 0.000210 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4639/12542 | Batch Loss: 1.0036 | Learning Rate: 0.000210 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4640/12542 | Batch Loss: 0.3337 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4641/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4642/12542 | Batch Loss: 1.6232 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4643/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4644/12542 | Batch Loss: 1.5839 | Learning Rate: 0.000210 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4645/12542 | Batch Loss: 0.9107 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4646/12542 | Batch Loss: 1.6342 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4647/12542 | Batch Loss: 1.1998 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4648/12542 | Batch Loss: 1.1321 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4649/12542 | Batch Loss: 0.9777 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4650/12542 | Batch Loss: 2.5854 | Learning Rate: 0.000210 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4651/12542 | Batch Loss: 0.8011 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4652/12542 | Batch Loss: 1.5976 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4653/12542 | Batch Loss: 1.2582 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4654/12542 | Batch Loss: 1.8961 | Learning Rate: 0.000210 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4655/12542 | Batch Loss: 1.1426 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4656/12542 | Batch Loss: 0.7435 | Learning Rate: 0.000210 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4657/12542 | Batch Loss: 2.2654 | Learning Rate: 0.000210 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4658/12542 | Batch Loss: 0.8458 | Learning Rate: 0.000210 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4659/12542 | Batch Loss: 0.8108 | Learning Rate: 0.000210 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4660/12542 | Batch Loss: 2.0492 | Learning Rate: 0.000209 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4661/12542 | Batch Loss: 1.1617 | Learning Rate: 0.000209 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4662/12542 | Batch Loss: 1.4566 | Learning Rate: 0.000209 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4663/12542 | Batch Loss: 3.2184 | Learning Rate: 0.000209 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4664/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000209 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4665/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000209 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 4666/12542 | Batch Loss: 2.0994 | Learning Rate: 0.000209 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4667/12542 | Batch Loss: 0.9570 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4668/12542 | Batch Loss: 1.4377 | Learning Rate: 0.000209 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4669/12542 | Batch Loss: 1.1201 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4670/12542 | Batch Loss: 0.7590 | Learning Rate: 0.000209 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4671/12542 | Batch Loss: 2.1248 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4672/12542 | Batch Loss: 1.2574 | Learning Rate: 0.000209 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4673/12542 | Batch Loss: 1.7228 | Learning Rate: 0.000209 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4674/12542 | Batch Loss: 1.6302 | Learning Rate: 0.000209 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4675/12542 | Batch Loss: 0.5491 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4676/12542 | Batch Loss: 2.3688 | Learning Rate: 0.000209 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4677/12542 | Batch Loss: 1.4019 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4678/12542 | Batch Loss: 1.4939 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4679/12542 | Batch Loss: 1.4060 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4680/12542 | Batch Loss: 1.4309 | Learning Rate: 0.000209 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4681/12542 | Batch Loss: 0.6035 | Learning Rate: 0.000209 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4682/12542 | Batch Loss: 1.1566 | Learning Rate: 0.000209 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4683/12542 | Batch Loss: 1.1102 | Learning Rate: 0.000209 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4684/12542 | Batch Loss: 1.9500 | Learning Rate: 0.000209 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4685/12542 | Batch Loss: 0.7307 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4686/12542 | Batch Loss: 2.3277 | Learning Rate: 0.000209 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4687/12542 | Batch Loss: 2.6716 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4688/12542 | Batch Loss: 1.0698 | Learning Rate: 0.000209 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4689/12542 | Batch Loss: 1.4938 | Learning Rate: 0.000209 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4690/12542 | Batch Loss: 0.9150 | Learning Rate: 0.000209 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4691/12542 | Batch Loss: 0.6611 | Learning Rate: 0.000209 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4692/12542 | Batch Loss: 0.8411 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4693/12542 | Batch Loss: 0.4170 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4694/12542 | Batch Loss: 0.6834 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4695/12542 | Batch Loss: 0.7484 | Learning Rate: 0.000209 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4696/12542 | Batch Loss: 0.9683 | Learning Rate: 0.000209 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4697/12542 | Batch Loss: 1.8337 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4698/12542 | Batch Loss: 1.7876 | Learning Rate: 0.000208 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4699/12542 | Batch Loss: 0.6885 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4700/12542 | Batch Loss: 0.7017 | Learning Rate: 0.000208 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4701/12542 | Batch Loss: 1.6320 | Learning Rate: 0.000208 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4702/12542 | Batch Loss: 1.3815 | Learning Rate: 0.000208 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4703/12542 | Batch Loss: 0.8455 | Learning Rate: 0.000208 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4704/12542 | Batch Loss: 1.2168 | Learning Rate: 0.000208 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4705/12542 | Batch Loss: 1.1074 | Learning Rate: 0.000208 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4706/12542 | Batch Loss: 1.4747 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4707/12542 | Batch Loss: 2.2272 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4708/12542 | Batch Loss: 1.3329 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4709/12542 | Batch Loss: 1.7587 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4710/12542 | Batch Loss: 1.2168 | Learning Rate: 0.000208 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4711/12542 | Batch Loss: 1.6344 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4712/12542 | Batch Loss: 0.8020 | Learning Rate: 0.000208 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4713/12542 | Batch Loss: 1.3195 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4714/12542 | Batch Loss: 0.9436 | Learning Rate: 0.000208 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4715/12542 | Batch Loss: 1.5383 | Learning Rate: 0.000208 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4716/12542 | Batch Loss: 1.6694 | Learning Rate: 0.000208 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4717/12542 | Batch Loss: 0.9848 | Learning Rate: 0.000208 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4718/12542 | Batch Loss: 1.0781 | Learning Rate: 0.000208 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4719/12542 | Batch Loss: 0.6939 | Learning Rate: 0.000208 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4720/12542 | Batch Loss: 0.9245 | Learning Rate: 0.000208 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4721/12542 | Batch Loss: 1.5705 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4722/12542 | Batch Loss: 1.1988 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4723/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4724/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4725/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4726/12542 | Batch Loss: 1.1841 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4727/12542 | Batch Loss: 1.5588 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4728/12542 | Batch Loss: 1.2765 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4729/12542 | Batch Loss: 0.7893 | Learning Rate: 0.000208 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4730/12542 | Batch Loss: 0.6421 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4731/12542 | Batch Loss: 1.9241 | Learning Rate: 0.000208 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4732/12542 | Batch Loss: 1.0144 | Learning Rate: 0.000208 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4733/12542 | Batch Loss: 1.1408 | Learning Rate: 0.000208 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4734/12542 | Batch Loss: 1.2022 | Learning Rate: 0.000208 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4735/12542 | Batch Loss: 1.6287 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4736/12542 | Batch Loss: 1.7749 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4737/12542 | Batch Loss: 1.0513 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4738/12542 | Batch Loss: 0.6756 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4739/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000207 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4740/12542 | Batch Loss: 0.5695 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4741/12542 | Batch Loss: 1.2322 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4742/12542 | Batch Loss: 0.6819 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4743/12542 | Batch Loss: 1.9125 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4744/12542 | Batch Loss: 0.8824 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4745/12542 | Batch Loss: 0.5246 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4746/12542 | Batch Loss: 1.4663 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4747/12542 | Batch Loss: 1.6492 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4748/12542 | Batch Loss: 0.7245 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4749/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4750/12542 | Batch Loss: 1.5208 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4751/12542 | Batch Loss: 0.5654 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4752/12542 | Batch Loss: 1.4345 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4753/12542 | Batch Loss: 1.3112 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4754/12542 | Batch Loss: 0.7033 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4755/12542 | Batch Loss: 1.6651 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4756/12542 | Batch Loss: 1.7223 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4757/12542 | Batch Loss: 1.3243 | Learning Rate: 0.000207 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4758/12542 | Batch Loss: 0.6027 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4759/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4760/12542 | Batch Loss: 0.9995 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4761/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4762/12542 | Batch Loss: 1.0895 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4763/12542 | Batch Loss: 1.8533 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4764/12542 | Batch Loss: 1.0175 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4765/12542 | Batch Loss: 2.1387 | Learning Rate: 0.000207 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4766/12542 | Batch Loss: 2.3269 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4767/12542 | Batch Loss: 1.1764 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4768/12542 | Batch Loss: 0.9567 | Learning Rate: 0.000207 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4769/12542 | Batch Loss: 0.4865 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4770/12542 | Batch Loss: 1.4069 | Learning Rate: 0.000207 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4771/12542 | Batch Loss: 1.0588 | Learning Rate: 0.000207 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4772/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000207 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4773/12542 | Batch Loss: 2.4409 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4774/12542 | Batch Loss: 1.2973 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4775/12542 | Batch Loss: 2.0169 | Learning Rate: 0.000206 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4776/12542 | Batch Loss: 1.3899 | Learning Rate: 0.000206 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4777/12542 | Batch Loss: 2.3954 | Learning Rate: 0.000206 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4778/12542 | Batch Loss: 0.9807 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4779/12542 | Batch Loss: 1.3395 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4780/12542 | Batch Loss: 0.4580 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4781/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4782/12542 | Batch Loss: 1.4957 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4783/12542 | Batch Loss: 1.0263 | Learning Rate: 0.000206 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4784/12542 | Batch Loss: 2.0386 | Learning Rate: 0.000206 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4785/12542 | Batch Loss: 1.0192 | Learning Rate: 0.000206 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4786/12542 | Batch Loss: 0.6406 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4787/12542 | Batch Loss: 1.6272 | Learning Rate: 0.000206 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4788/12542 | Batch Loss: 1.9770 | Learning Rate: 0.000206 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4789/12542 | Batch Loss: 1.6832 | Learning Rate: 0.000206 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4790/12542 | Batch Loss: 1.3625 | Learning Rate: 0.000206 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4791/12542 | Batch Loss: 0.8197 | Learning Rate: 0.000206 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4792/12542 | Batch Loss: 1.2116 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4793/12542 | Batch Loss: 1.5514 | Learning Rate: 0.000206 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4794/12542 | Batch Loss: 0.9955 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4795/12542 | Batch Loss: 1.8743 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4796/12542 | Batch Loss: 1.1168 | Learning Rate: 0.000206 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4797/12542 | Batch Loss: 1.7352 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4798/12542 | Batch Loss: 0.5759 | Learning Rate: 0.000206 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4799/12542 | Batch Loss: 1.5155 | Learning Rate: 0.000206 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4800/12542 | Batch Loss: 1.3221 | Learning Rate: 0.000206 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4801/12542 | Batch Loss: 2.1344 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4802/12542 | Batch Loss: 2.6838 | Learning Rate: 0.000206 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4803/12542 | Batch Loss: 0.4871 | Learning Rate: 0.000206 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4804/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000206 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4805/12542 | Batch Loss: 1.8144 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4806/12542 | Batch Loss: 1.2924 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4807/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000206 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4808/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000206 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4809/12542 | Batch Loss: 0.3175 | Learning Rate: 0.000206 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4810/12542 | Batch Loss: 2.1340 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4811/12542 | Batch Loss: 1.7092 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4812/12542 | Batch Loss: 2.2490 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4813/12542 | Batch Loss: 2.4454 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4814/12542 | Batch Loss: 1.3826 | Learning Rate: 0.000205 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4815/12542 | Batch Loss: 0.8591 | Learning Rate: 0.000205 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 4816/12542 | Batch Loss: 0.4964 | Learning Rate: 0.000205 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4817/12542 | Batch Loss: 1.3054 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4818/12542 | Batch Loss: 2.2458 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4819/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4820/12542 | Batch Loss: 1.6869 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4821/12542 | Batch Loss: 2.0026 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4822/12542 | Batch Loss: 1.0785 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4823/12542 | Batch Loss: 0.4475 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4824/12542 | Batch Loss: 2.4099 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4825/12542 | Batch Loss: 0.5394 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4826/12542 | Batch Loss: 0.8122 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4827/12542 | Batch Loss: 0.5943 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4828/12542 | Batch Loss: 1.4746 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4829/12542 | Batch Loss: 1.3293 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4830/12542 | Batch Loss: 0.6314 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4831/12542 | Batch Loss: 1.5032 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4832/12542 | Batch Loss: 0.7118 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4833/12542 | Batch Loss: 1.6696 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4834/12542 | Batch Loss: 1.3576 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4835/12542 | Batch Loss: 1.9240 | Learning Rate: 0.000205 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4836/12542 | Batch Loss: 1.1253 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4837/12542 | Batch Loss: 0.5682 | Learning Rate: 0.000205 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4838/12542 | Batch Loss: 1.5472 | Learning Rate: 0.000205 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4839/12542 | Batch Loss: 1.0224 | Learning Rate: 0.000205 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4840/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4841/12542 | Batch Loss: 1.4427 | Learning Rate: 0.000205 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4842/12542 | Batch Loss: 0.9685 | Learning Rate: 0.000205 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4843/12542 | Batch Loss: 0.9663 | Learning Rate: 0.000205 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4844/12542 | Batch Loss: 1.1030 | Learning Rate: 0.000205 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4845/12542 | Batch Loss: 0.6756 | Learning Rate: 0.000205 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4846/12542 | Batch Loss: 1.2719 | Learning Rate: 0.000205 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4847/12542 | Batch Loss: 1.2024 | Learning Rate: 0.000205 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4848/12542 | Batch Loss: 0.4869 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4849/12542 | Batch Loss: 0.5695 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4850/12542 | Batch Loss: 1.3854 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4851/12542 | Batch Loss: 1.2376 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4852/12542 | Batch Loss: 1.0811 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4853/12542 | Batch Loss: 2.4691 | Learning Rate: 0.000204 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4854/12542 | Batch Loss: 0.8058 | Learning Rate: 0.000204 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4855/12542 | Batch Loss: 2.3271 | Learning Rate: 0.000204 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4856/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000204 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4857/12542 | Batch Loss: 0.6838 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4858/12542 | Batch Loss: 0.5734 | Learning Rate: 0.000204 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4859/12542 | Batch Loss: 1.7454 | Learning Rate: 0.000204 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4860/12542 | Batch Loss: 1.0184 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4861/12542 | Batch Loss: 1.8261 | Learning Rate: 0.000204 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4862/12542 | Batch Loss: 1.9993 | Learning Rate: 0.000204 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4863/12542 | Batch Loss: 0.7024 | Learning Rate: 0.000204 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4864/12542 | Batch Loss: 1.1184 | Learning Rate: 0.000204 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4865/12542 | Batch Loss: 1.9606 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4866/12542 | Batch Loss: 0.5715 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4867/12542 | Batch Loss: 0.9030 | Learning Rate: 0.000204 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4868/12542 | Batch Loss: 2.5694 | Learning Rate: 0.000204 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4869/12542 | Batch Loss: 0.8319 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4870/12542 | Batch Loss: 1.3950 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4871/12542 | Batch Loss: 0.9824 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4872/12542 | Batch Loss: 1.3184 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4873/12542 | Batch Loss: 0.9486 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4874/12542 | Batch Loss: 2.5521 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4875/12542 | Batch Loss: 1.8675 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4876/12542 | Batch Loss: 1.5460 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4877/12542 | Batch Loss: 1.7251 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4878/12542 | Batch Loss: 1.8700 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4879/12542 | Batch Loss: 0.8796 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4880/12542 | Batch Loss: 1.0807 | Learning Rate: 0.000204 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4881/12542 | Batch Loss: 1.4596 | Learning Rate: 0.000204 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4882/12542 | Batch Loss: 0.5430 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4883/12542 | Batch Loss: 1.2991 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4884/12542 | Batch Loss: 1.2017 | Learning Rate: 0.000204 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4885/12542 | Batch Loss: 0.5532 | Learning Rate: 0.000204 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4886/12542 | Batch Loss: 0.9832 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4887/12542 | Batch Loss: 1.2067 | Learning Rate: 0.000203 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4888/12542 | Batch Loss: 1.0191 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4889/12542 | Batch Loss: 1.6089 | Learning Rate: 0.000203 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4890/12542 | Batch Loss: 0.5592 | Learning Rate: 0.000203 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4891/12542 | Batch Loss: 1.6103 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4892/12542 | Batch Loss: 1.2189 | Learning Rate: 0.000203 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4893/12542 | Batch Loss: 2.2229 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4894/12542 | Batch Loss: 1.3965 | Learning Rate: 0.000203 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4895/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4896/12542 | Batch Loss: 1.8670 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4897/12542 | Batch Loss: 2.6994 | Learning Rate: 0.000203 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4898/12542 | Batch Loss: 1.5795 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4899/12542 | Batch Loss: 1.2383 | Learning Rate: 0.000203 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4900/12542 | Batch Loss: 0.6153 | Learning Rate: 0.000203 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4901/12542 | Batch Loss: 0.5581 | Learning Rate: 0.000203 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4902/12542 | Batch Loss: 1.0750 | Learning Rate: 0.000203 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4903/12542 | Batch Loss: 1.6235 | Learning Rate: 0.000203 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 4904/12542 | Batch Loss: 0.8822 | Learning Rate: 0.000203 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4905/12542 | Batch Loss: 1.8425 | Learning Rate: 0.000203 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4906/12542 | Batch Loss: 0.6002 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4907/12542 | Batch Loss: 1.6351 | Learning Rate: 0.000203 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4908/12542 | Batch Loss: 1.4327 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4909/12542 | Batch Loss: 1.1343 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4910/12542 | Batch Loss: 1.6991 | Learning Rate: 0.000203 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4911/12542 | Batch Loss: 1.1800 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4912/12542 | Batch Loss: 0.3279 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4913/12542 | Batch Loss: 2.3921 | Learning Rate: 0.000203 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4914/12542 | Batch Loss: 0.9929 | Learning Rate: 0.000203 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4915/12542 | Batch Loss: 1.1798 | Learning Rate: 0.000203 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4916/12542 | Batch Loss: 1.7562 | Learning Rate: 0.000203 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4917/12542 | Batch Loss: 1.7625 | Learning Rate: 0.000203 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4918/12542 | Batch Loss: 1.8212 | Learning Rate: 0.000203 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4919/12542 | Batch Loss: 1.6310 | Learning Rate: 0.000203 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4920/12542 | Batch Loss: 1.3720 | Learning Rate: 0.000203 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4921/12542 | Batch Loss: 0.9239 | Learning Rate: 0.000203 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 4922/12542 | Batch Loss: 0.9976 | Learning Rate: 0.000203 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4923/12542 | Batch Loss: 1.3513 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4924/12542 | Batch Loss: 0.7873 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4925/12542 | Batch Loss: 0.7927 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4926/12542 | Batch Loss: 1.5492 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4927/12542 | Batch Loss: 0.9101 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4928/12542 | Batch Loss: 1.6703 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4929/12542 | Batch Loss: 1.4862 | Learning Rate: 0.000202 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4930/12542 | Batch Loss: 1.1191 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4931/12542 | Batch Loss: 1.0128 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4932/12542 | Batch Loss: 1.1683 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4933/12542 | Batch Loss: 1.7359 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4934/12542 | Batch Loss: 1.5586 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4935/12542 | Batch Loss: 1.3793 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4936/12542 | Batch Loss: 2.1142 | Learning Rate: 0.000202 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4937/12542 | Batch Loss: 1.3343 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4938/12542 | Batch Loss: 1.5809 | Learning Rate: 0.000202 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4939/12542 | Batch Loss: 1.2413 | Learning Rate: 0.000202 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4940/12542 | Batch Loss: 0.9650 | Learning Rate: 0.000202 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4941/12542 | Batch Loss: 0.9937 | Learning Rate: 0.000202 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4942/12542 | Batch Loss: 1.6871 | Learning Rate: 0.000202 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4943/12542 | Batch Loss: 0.9129 | Learning Rate: 0.000202 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 4944/12542 | Batch Loss: 0.8787 | Learning Rate: 0.000202 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 4945/12542 | Batch Loss: 1.2136 | Learning Rate: 0.000202 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4946/12542 | Batch Loss: 0.8786 | Learning Rate: 0.000202 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4947/12542 | Batch Loss: 1.2123 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4948/12542 | Batch Loss: 1.5437 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4949/12542 | Batch Loss: 1.0152 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4950/12542 | Batch Loss: 1.9087 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4951/12542 | Batch Loss: 2.3984 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4952/12542 | Batch Loss: 0.8866 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4953/12542 | Batch Loss: 1.2081 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4954/12542 | Batch Loss: 2.3882 | Learning Rate: 0.000202 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4955/12542 | Batch Loss: 1.5280 | Learning Rate: 0.000202 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4956/12542 | Batch Loss: 0.7138 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4957/12542 | Batch Loss: 1.9227 | Learning Rate: 0.000202 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4958/12542 | Batch Loss: 1.2728 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4959/12542 | Batch Loss: 1.1505 | Learning Rate: 0.000202 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4960/12542 | Batch Loss: 1.2722 | Learning Rate: 0.000202 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4961/12542 | Batch Loss: 1.2896 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4962/12542 | Batch Loss: 1.3585 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4963/12542 | Batch Loss: 1.4580 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4964/12542 | Batch Loss: 1.2882 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4965/12542 | Batch Loss: 0.8383 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4966/12542 | Batch Loss: 2.7567 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4967/12542 | Batch Loss: 0.9165 | Learning Rate: 0.000201 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4968/12542 | Batch Loss: 1.1979 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4969/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000201 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4970/12542 | Batch Loss: 1.9105 | Learning Rate: 0.000201 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 4971/12542 | Batch Loss: 2.1700 | Learning Rate: 0.000201 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 4972/12542 | Batch Loss: 1.0930 | Learning Rate: 0.000201 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4973/12542 | Batch Loss: 1.0420 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4974/12542 | Batch Loss: 2.6992 | Learning Rate: 0.000201 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4975/12542 | Batch Loss: 0.7496 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4976/12542 | Batch Loss: 1.6315 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4977/12542 | Batch Loss: 1.2838 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4978/12542 | Batch Loss: 1.1081 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4979/12542 | Batch Loss: 1.5197 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4980/12542 | Batch Loss: 1.1914 | Learning Rate: 0.000201 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4981/12542 | Batch Loss: 0.6039 | Learning Rate: 0.000201 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 4982/12542 | Batch Loss: 0.8946 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4983/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4984/12542 | Batch Loss: 1.5883 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4985/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4986/12542 | Batch Loss: 1.3675 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4987/12542 | Batch Loss: 1.4255 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4988/12542 | Batch Loss: 1.1345 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4989/12542 | Batch Loss: 2.7944 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4990/12542 | Batch Loss: 1.6919 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4991/12542 | Batch Loss: 0.5444 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4992/12542 | Batch Loss: 1.7723 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4993/12542 | Batch Loss: 0.5052 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4994/12542 | Batch Loss: 1.9375 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4995/12542 | Batch Loss: 2.7598 | Learning Rate: 0.000201 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 4996/12542 | Batch Loss: 1.3268 | Learning Rate: 0.000201 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 4997/12542 | Batch Loss: 0.8942 | Learning Rate: 0.000201 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 4998/12542 | Batch Loss: 1.1111 | Learning Rate: 0.000200 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 4999/12542 | Batch Loss: 2.1488 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5000/12542 | Batch Loss: 1.4535 | Learning Rate: 0.000200 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5001/12542 | Batch Loss: 1.3854 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5002/12542 | Batch Loss: 0.8231 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5003/12542 | Batch Loss: 0.9911 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5004/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5005/12542 | Batch Loss: 1.3807 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5006/12542 | Batch Loss: 1.1357 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5007/12542 | Batch Loss: 2.4193 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5008/12542 | Batch Loss: 1.6771 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5009/12542 | Batch Loss: 1.7197 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5010/12542 | Batch Loss: 0.8014 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5011/12542 | Batch Loss: 2.0034 | Learning Rate: 0.000200 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5012/12542 | Batch Loss: 0.8937 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5013/12542 | Batch Loss: 0.6890 | Learning Rate: 0.000200 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5014/12542 | Batch Loss: 0.4378 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5015/12542 | Batch Loss: 1.8424 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5016/12542 | Batch Loss: 0.7130 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5017/12542 | Batch Loss: 1.6386 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5018/12542 | Batch Loss: 2.6014 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5019/12542 | Batch Loss: 0.8662 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5020/12542 | Batch Loss: 2.3764 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5021/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000200 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5022/12542 | Batch Loss: 0.8111 | Learning Rate: 0.000200 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5023/12542 | Batch Loss: 0.4446 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5024/12542 | Batch Loss: 1.4690 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5025/12542 | Batch Loss: 0.9896 | Learning Rate: 0.000200 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5026/12542 | Batch Loss: 0.9612 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5027/12542 | Batch Loss: 2.0495 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5028/12542 | Batch Loss: 1.3091 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5029/12542 | Batch Loss: 1.5403 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5030/12542 | Batch Loss: 0.5799 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5031/12542 | Batch Loss: 1.3276 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5032/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5033/12542 | Batch Loss: 1.0664 | Learning Rate: 0.000200 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5034/12542 | Batch Loss: 0.9886 | Learning Rate: 0.000200 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5035/12542 | Batch Loss: 1.3037 | Learning Rate: 0.000200 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5036/12542 | Batch Loss: 1.3561 | Learning Rate: 0.000199 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5037/12542 | Batch Loss: 1.4630 | Learning Rate: 0.000199 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5038/12542 | Batch Loss: 2.2675 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5039/12542 | Batch Loss: 2.0501 | Learning Rate: 0.000199 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5040/12542 | Batch Loss: 1.3726 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5041/12542 | Batch Loss: 1.7475 | Learning Rate: 0.000199 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5042/12542 | Batch Loss: 0.9062 | Learning Rate: 0.000199 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5043/12542 | Batch Loss: 1.6017 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5044/12542 | Batch Loss: 2.2756 | Learning Rate: 0.000199 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5045/12542 | Batch Loss: 1.5513 | Learning Rate: 0.000199 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5046/12542 | Batch Loss: 1.7001 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5047/12542 | Batch Loss: 0.7891 | Learning Rate: 0.000199 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5048/12542 | Batch Loss: 1.5167 | Learning Rate: 0.000199 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5049/12542 | Batch Loss: 0.7550 | Learning Rate: 0.000199 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5050/12542 | Batch Loss: 0.7999 | Learning Rate: 0.000199 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5051/12542 | Batch Loss: 1.4091 | Learning Rate: 0.000199 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5052/12542 | Batch Loss: 2.0016 | Learning Rate: 0.000199 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5053/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5054/12542 | Batch Loss: 0.7202 | Learning Rate: 0.000199 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5055/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000199 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5056/12542 | Batch Loss: 1.1600 | Learning Rate: 0.000199 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5057/12542 | Batch Loss: 2.3021 | Learning Rate: 0.000199 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5058/12542 | Batch Loss: 1.8916 | Learning Rate: 0.000199 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5059/12542 | Batch Loss: 1.7654 | Learning Rate: 0.000199 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5060/12542 | Batch Loss: 1.2606 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5061/12542 | Batch Loss: 0.9756 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5062/12542 | Batch Loss: 0.6475 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5063/12542 | Batch Loss: 2.3269 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5064/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000199 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5065/12542 | Batch Loss: 1.1809 | Learning Rate: 0.000199 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5066/12542 | Batch Loss: 2.1571 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5067/12542 | Batch Loss: 1.1398 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5068/12542 | Batch Loss: 1.8065 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5069/12542 | Batch Loss: 0.5268 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5070/12542 | Batch Loss: 1.7942 | Learning Rate: 0.000199 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5071/12542 | Batch Loss: 0.7574 | Learning Rate: 0.000199 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5072/12542 | Batch Loss: 1.4481 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5073/12542 | Batch Loss: 1.8897 | Learning Rate: 0.000199 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5074/12542 | Batch Loss: 0.8261 | Learning Rate: 0.000198 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5075/12542 | Batch Loss: 1.4369 | Learning Rate: 0.000198 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5076/12542 | Batch Loss: 1.4482 | Learning Rate: 0.000198 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5077/12542 | Batch Loss: 1.7443 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5078/12542 | Batch Loss: 1.8143 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5079/12542 | Batch Loss: 0.9417 | Learning Rate: 0.000198 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5080/12542 | Batch Loss: 0.8714 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5081/12542 | Batch Loss: 0.7700 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5082/12542 | Batch Loss: 0.7299 | Learning Rate: 0.000198 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5083/12542 | Batch Loss: 1.6376 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5084/12542 | Batch Loss: 0.6808 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5085/12542 | Batch Loss: 0.5470 | Learning Rate: 0.000198 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5086/12542 | Batch Loss: 0.8334 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5087/12542 | Batch Loss: 2.1050 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5088/12542 | Batch Loss: 1.6588 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5089/12542 | Batch Loss: 0.6821 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5090/12542 | Batch Loss: 2.0549 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5091/12542 | Batch Loss: 1.7434 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5092/12542 | Batch Loss: 0.8924 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5093/12542 | Batch Loss: 0.6222 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5094/12542 | Batch Loss: 0.6284 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5095/12542 | Batch Loss: 1.2812 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5096/12542 | Batch Loss: 0.8271 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5097/12542 | Batch Loss: 0.5701 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5098/12542 | Batch Loss: 1.2615 | Learning Rate: 0.000198 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5099/12542 | Batch Loss: 0.7279 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5100/12542 | Batch Loss: 1.3930 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5101/12542 | Batch Loss: 0.6091 | Learning Rate: 0.000198 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5102/12542 | Batch Loss: 1.2610 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5103/12542 | Batch Loss: 0.6465 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5104/12542 | Batch Loss: 1.4979 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5105/12542 | Batch Loss: 0.8039 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5106/12542 | Batch Loss: 1.2431 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5107/12542 | Batch Loss: 0.7817 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5108/12542 | Batch Loss: 0.7344 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5109/12542 | Batch Loss: 1.6325 | Learning Rate: 0.000198 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5110/12542 | Batch Loss: 1.1368 | Learning Rate: 0.000198 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5111/12542 | Batch Loss: 0.9696 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5112/12542 | Batch Loss: 1.2422 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5113/12542 | Batch Loss: 1.1437 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5114/12542 | Batch Loss: 1.0414 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5115/12542 | Batch Loss: 1.5463 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5116/12542 | Batch Loss: 1.3116 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5117/12542 | Batch Loss: 0.8414 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5118/12542 | Batch Loss: 1.4739 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5119/12542 | Batch Loss: 1.8665 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5120/12542 | Batch Loss: 0.5779 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5121/12542 | Batch Loss: 0.8397 | Learning Rate: 0.000197 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5122/12542 | Batch Loss: 1.6751 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5123/12542 | Batch Loss: 1.9639 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5124/12542 | Batch Loss: 0.6294 | Learning Rate: 0.000197 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5125/12542 | Batch Loss: 1.0068 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5126/12542 | Batch Loss: 0.6391 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5127/12542 | Batch Loss: 1.3174 | Learning Rate: 0.000197 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5128/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5129/12542 | Batch Loss: 1.5922 | Learning Rate: 0.000197 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5130/12542 | Batch Loss: 1.0150 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5131/12542 | Batch Loss: 1.4391 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5132/12542 | Batch Loss: 0.5083 | Learning Rate: 0.000197 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5133/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000197 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5134/12542 | Batch Loss: 1.2276 | Learning Rate: 0.000197 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5135/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000197 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5136/12542 | Batch Loss: 1.2442 | Learning Rate: 0.000197 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5137/12542 | Batch Loss: 2.0184 | Learning Rate: 0.000197 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5138/12542 | Batch Loss: 0.7938 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5139/12542 | Batch Loss: 1.2091 | Learning Rate: 0.000197 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5140/12542 | Batch Loss: 1.6318 | Learning Rate: 0.000197 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5141/12542 | Batch Loss: 0.5113 | Learning Rate: 0.000197 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5142/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000197 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5143/12542 | Batch Loss: 1.0434 | Learning Rate: 0.000197 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5144/12542 | Batch Loss: 0.4135 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5145/12542 | Batch Loss: 0.5484 | Learning Rate: 0.000197 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5146/12542 | Batch Loss: 0.8664 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5147/12542 | Batch Loss: 0.6920 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5148/12542 | Batch Loss: 1.9008 | Learning Rate: 0.000197 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5149/12542 | Batch Loss: 0.7641 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5150/12542 | Batch Loss: 0.6722 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5151/12542 | Batch Loss: 1.0073 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5152/12542 | Batch Loss: 1.3902 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5153/12542 | Batch Loss: 0.6180 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5154/12542 | Batch Loss: 1.8595 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5155/12542 | Batch Loss: 1.1070 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5156/12542 | Batch Loss: 1.8744 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5157/12542 | Batch Loss: 1.4388 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5158/12542 | Batch Loss: 1.2062 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5159/12542 | Batch Loss: 1.3887 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5160/12542 | Batch Loss: 1.4433 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5161/12542 | Batch Loss: 1.6098 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5162/12542 | Batch Loss: 1.9433 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5163/12542 | Batch Loss: 2.0125 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5164/12542 | Batch Loss: 0.9980 | Learning Rate: 0.000196 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5165/12542 | Batch Loss: 0.4633 | Learning Rate: 0.000196 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5166/12542 | Batch Loss: 1.1378 | Learning Rate: 0.000196 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5167/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5168/12542 | Batch Loss: 0.4866 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5169/12542 | Batch Loss: 0.7960 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5170/12542 | Batch Loss: 1.8523 | Learning Rate: 0.000196 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5171/12542 | Batch Loss: 1.5803 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5172/12542 | Batch Loss: 1.2166 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5173/12542 | Batch Loss: 0.5070 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5174/12542 | Batch Loss: 1.1341 | Learning Rate: 0.000196 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5175/12542 | Batch Loss: 0.5728 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5176/12542 | Batch Loss: 0.6824 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5177/12542 | Batch Loss: 0.8387 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5178/12542 | Batch Loss: 0.6514 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5179/12542 | Batch Loss: 0.8689 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5180/12542 | Batch Loss: 2.3494 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5181/12542 | Batch Loss: 0.8471 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5182/12542 | Batch Loss: 1.9049 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5183/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5184/12542 | Batch Loss: 1.3490 | Learning Rate: 0.000196 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5185/12542 | Batch Loss: 1.1017 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5186/12542 | Batch Loss: 1.3898 | Learning Rate: 0.000196 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5187/12542 | Batch Loss: 1.6462 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5188/12542 | Batch Loss: 0.8791 | Learning Rate: 0.000195 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5189/12542 | Batch Loss: 1.7655 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5190/12542 | Batch Loss: 1.6003 | Learning Rate: 0.000195 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5191/12542 | Batch Loss: 1.0098 | Learning Rate: 0.000195 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5192/12542 | Batch Loss: 1.6262 | Learning Rate: 0.000195 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5193/12542 | Batch Loss: 3.2314 | Learning Rate: 0.000195 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5194/12542 | Batch Loss: 1.4105 | Learning Rate: 0.000195 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5195/12542 | Batch Loss: 1.0615 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5196/12542 | Batch Loss: 1.3431 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5197/12542 | Batch Loss: 0.6799 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5198/12542 | Batch Loss: 0.7078 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5199/12542 | Batch Loss: 1.7073 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5200/12542 | Batch Loss: 1.9414 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5201/12542 | Batch Loss: 3.5868 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5202/12542 | Batch Loss: 1.1869 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5203/12542 | Batch Loss: 1.6122 | Learning Rate: 0.000195 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5204/12542 | Batch Loss: 0.9669 | Learning Rate: 0.000195 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5205/12542 | Batch Loss: 0.7770 | Learning Rate: 0.000195 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5206/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5207/12542 | Batch Loss: 1.6503 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5208/12542 | Batch Loss: 1.8127 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5209/12542 | Batch Loss: 2.1167 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5210/12542 | Batch Loss: 0.8409 | Learning Rate: 0.000195 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5211/12542 | Batch Loss: 1.7487 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5212/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5213/12542 | Batch Loss: 0.9101 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5214/12542 | Batch Loss: 0.6843 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5215/12542 | Batch Loss: 1.7411 | Learning Rate: 0.000195 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5216/12542 | Batch Loss: 1.3527 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5217/12542 | Batch Loss: 0.9948 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5218/12542 | Batch Loss: 1.2055 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5219/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000195 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 5220/12542 | Batch Loss: 0.8612 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5221/12542 | Batch Loss: 1.1826 | Learning Rate: 0.000195 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5222/12542 | Batch Loss: 0.9567 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5223/12542 | Batch Loss: 1.3084 | Learning Rate: 0.000195 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5224/12542 | Batch Loss: 1.2044 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5225/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5226/12542 | Batch Loss: 0.6531 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5227/12542 | Batch Loss: 1.4688 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5228/12542 | Batch Loss: 0.7953 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5229/12542 | Batch Loss: 2.3659 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5230/12542 | Batch Loss: 1.2043 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5231/12542 | Batch Loss: 2.1252 | Learning Rate: 0.000194 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5232/12542 | Batch Loss: 1.3844 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5233/12542 | Batch Loss: 1.3845 | Learning Rate: 0.000194 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5234/12542 | Batch Loss: 1.1524 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5235/12542 | Batch Loss: 1.2324 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5236/12542 | Batch Loss: 0.6721 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5237/12542 | Batch Loss: 0.8216 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5238/12542 | Batch Loss: 3.8275 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5239/12542 | Batch Loss: 1.8133 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5240/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5241/12542 | Batch Loss: 0.9835 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5242/12542 | Batch Loss: 1.2068 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5243/12542 | Batch Loss: 0.9712 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5244/12542 | Batch Loss: 2.2721 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5245/12542 | Batch Loss: 1.6218 | Learning Rate: 0.000194 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5246/12542 | Batch Loss: 0.7573 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5247/12542 | Batch Loss: 0.7285 | Learning Rate: 0.000194 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5248/12542 | Batch Loss: 1.0810 | Learning Rate: 0.000194 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5249/12542 | Batch Loss: 1.5074 | Learning Rate: 0.000194 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5250/12542 | Batch Loss: 1.0977 | Learning Rate: 0.000194 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5251/12542 | Batch Loss: 1.0698 | Learning Rate: 0.000194 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5252/12542 | Batch Loss: 2.5014 | Learning Rate: 0.000194 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5253/12542 | Batch Loss: 0.9546 | Learning Rate: 0.000194 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5254/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000194 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5255/12542 | Batch Loss: 1.6032 | Learning Rate: 0.000194 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5256/12542 | Batch Loss: 1.8094 | Learning Rate: 0.000194 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5257/12542 | Batch Loss: 0.9928 | Learning Rate: 0.000194 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5258/12542 | Batch Loss: 0.5264 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5259/12542 | Batch Loss: 0.9161 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5260/12542 | Batch Loss: 1.6898 | Learning Rate: 0.000194 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5261/12542 | Batch Loss: 0.9299 | Learning Rate: 0.000194 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5262/12542 | Batch Loss: 1.2290 | Learning Rate: 0.000193 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5263/12542 | Batch Loss: 0.8670 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5264/12542 | Batch Loss: 5.4749 | Learning Rate: 0.000193 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5265/12542 | Batch Loss: 1.9444 | Learning Rate: 0.000193 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5266/12542 | Batch Loss: 1.7806 | Learning Rate: 0.000193 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5267/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000193 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5268/12542 | Batch Loss: 1.4845 | Learning Rate: 0.000193 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5269/12542 | Batch Loss: 1.2940 | Learning Rate: 0.000193 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5270/12542 | Batch Loss: 1.0778 | Learning Rate: 0.000193 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5271/12542 | Batch Loss: 0.8375 | Learning Rate: 0.000193 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5272/12542 | Batch Loss: 1.7581 | Learning Rate: 0.000193 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5273/12542 | Batch Loss: 2.8082 | Learning Rate: 0.000193 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5274/12542 | Batch Loss: 1.3433 | Learning Rate: 0.000193 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5275/12542 | Batch Loss: 1.2325 | Learning Rate: 0.000193 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5276/12542 | Batch Loss: 1.0747 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5277/12542 | Batch Loss: 0.6930 | Learning Rate: 0.000193 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5278/12542 | Batch Loss: 0.9957 | Learning Rate: 0.000193 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5279/12542 | Batch Loss: 0.6737 | Learning Rate: 0.000193 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5280/12542 | Batch Loss: 0.8917 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5281/12542 | Batch Loss: 1.2825 | Learning Rate: 0.000193 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5282/12542 | Batch Loss: 1.5002 | Learning Rate: 0.000193 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5283/12542 | Batch Loss: 1.1526 | Learning Rate: 0.000193 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5284/12542 | Batch Loss: 1.3669 | Learning Rate: 0.000193 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5285/12542 | Batch Loss: 0.7590 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5286/12542 | Batch Loss: 1.2197 | Learning Rate: 0.000193 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5287/12542 | Batch Loss: 1.1892 | Learning Rate: 0.000193 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5288/12542 | Batch Loss: 1.4098 | Learning Rate: 0.000193 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5289/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000193 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5290/12542 | Batch Loss: 1.0599 | Learning Rate: 0.000193 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5291/12542 | Batch Loss: 1.3336 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5292/12542 | Batch Loss: 0.5930 | Learning Rate: 0.000193 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5293/12542 | Batch Loss: 2.0077 | Learning Rate: 0.000193 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5294/12542 | Batch Loss: 1.7199 | Learning Rate: 0.000193 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5295/12542 | Batch Loss: 0.7784 | Learning Rate: 0.000193 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5296/12542 | Batch Loss: 1.5570 | Learning Rate: 0.000193 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5297/12542 | Batch Loss: 1.2364 | Learning Rate: 0.000193 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5298/12542 | Batch Loss: 1.4475 | Learning Rate: 0.000193 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5299/12542 | Batch Loss: 2.2928 | Learning Rate: 0.000192 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5300/12542 | Batch Loss: 1.0193 | Learning Rate: 0.000192 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5301/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5302/12542 | Batch Loss: 1.0610 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5303/12542 | Batch Loss: 1.1269 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5304/12542 | Batch Loss: 0.8609 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5305/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5306/12542 | Batch Loss: 1.5647 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5307/12542 | Batch Loss: 1.4300 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5308/12542 | Batch Loss: 1.2001 | Learning Rate: 0.000192 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5309/12542 | Batch Loss: 2.2915 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5310/12542 | Batch Loss: 1.2911 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5311/12542 | Batch Loss: 1.4653 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5312/12542 | Batch Loss: 0.8347 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5313/12542 | Batch Loss: 1.8511 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5314/12542 | Batch Loss: 3.9124 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5315/12542 | Batch Loss: 0.6556 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5316/12542 | Batch Loss: 0.9740 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5317/12542 | Batch Loss: 1.3723 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5318/12542 | Batch Loss: 3.0818 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5319/12542 | Batch Loss: 1.0309 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5320/12542 | Batch Loss: 0.5704 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5321/12542 | Batch Loss: 1.4460 | Learning Rate: 0.000192 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5322/12542 | Batch Loss: 1.4128 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5323/12542 | Batch Loss: 1.8229 | Learning Rate: 0.000192 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5324/12542 | Batch Loss: 0.8866 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5325/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5326/12542 | Batch Loss: 1.8568 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5327/12542 | Batch Loss: 0.7301 | Learning Rate: 0.000192 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5328/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5329/12542 | Batch Loss: 1.0991 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5330/12542 | Batch Loss: 1.5461 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5331/12542 | Batch Loss: 1.0731 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5332/12542 | Batch Loss: 1.2959 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5333/12542 | Batch Loss: 1.4891 | Learning Rate: 0.000192 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5334/12542 | Batch Loss: 1.8769 | Learning Rate: 0.000192 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5335/12542 | Batch Loss: 2.1608 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5336/12542 | Batch Loss: 1.0264 | Learning Rate: 0.000192 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5337/12542 | Batch Loss: 1.3285 | Learning Rate: 0.000191 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5338/12542 | Batch Loss: 0.9319 | Learning Rate: 0.000191 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5339/12542 | Batch Loss: 1.4569 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5340/12542 | Batch Loss: 1.1735 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5341/12542 | Batch Loss: 1.3835 | Learning Rate: 0.000191 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5342/12542 | Batch Loss: 1.2554 | Learning Rate: 0.000191 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5343/12542 | Batch Loss: 1.0426 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5344/12542 | Batch Loss: 0.7425 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5345/12542 | Batch Loss: 1.1757 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5346/12542 | Batch Loss: 1.3072 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5347/12542 | Batch Loss: 1.3962 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5348/12542 | Batch Loss: 1.0326 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5349/12542 | Batch Loss: 2.0936 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5350/12542 | Batch Loss: 3.4220 | Learning Rate: 0.000191 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5351/12542 | Batch Loss: 2.2644 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5352/12542 | Batch Loss: 1.8267 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5353/12542 | Batch Loss: 1.3772 | Learning Rate: 0.000191 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5354/12542 | Batch Loss: 1.6025 | Learning Rate: 0.000191 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5355/12542 | Batch Loss: 0.8901 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5356/12542 | Batch Loss: 1.1049 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5357/12542 | Batch Loss: 0.8617 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5358/12542 | Batch Loss: 0.4945 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5359/12542 | Batch Loss: 0.8365 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5360/12542 | Batch Loss: 0.9176 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5361/12542 | Batch Loss: 1.9318 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5362/12542 | Batch Loss: 0.9038 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5363/12542 | Batch Loss: 0.6640 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5364/12542 | Batch Loss: 3.2891 | Learning Rate: 0.000191 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5365/12542 | Batch Loss: 1.0997 | Learning Rate: 0.000191 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5366/12542 | Batch Loss: 0.7688 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5367/12542 | Batch Loss: 1.7729 | Learning Rate: 0.000191 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5368/12542 | Batch Loss: 1.8335 | Learning Rate: 0.000191 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5369/12542 | Batch Loss: 1.4865 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5370/12542 | Batch Loss: 1.2203 | Learning Rate: 0.000191 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5371/12542 | Batch Loss: 0.8984 | Learning Rate: 0.000191 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5372/12542 | Batch Loss: 0.6901 | Learning Rate: 0.000191 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5373/12542 | Batch Loss: 2.6112 | Learning Rate: 0.000191 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5374/12542 | Batch Loss: 2.2527 | Learning Rate: 0.000191 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5375/12542 | Batch Loss: 1.5889 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5376/12542 | Batch Loss: 0.4156 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5377/12542 | Batch Loss: 1.8332 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5378/12542 | Batch Loss: 0.6748 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5379/12542 | Batch Loss: 0.6665 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5380/12542 | Batch Loss: 4.5480 | Learning Rate: 0.000190 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5381/12542 | Batch Loss: 1.6460 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5382/12542 | Batch Loss: 0.5739 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5383/12542 | Batch Loss: 1.3458 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5384/12542 | Batch Loss: 1.0168 | Learning Rate: 0.000190 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5385/12542 | Batch Loss: 1.1248 | Learning Rate: 0.000190 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5386/12542 | Batch Loss: 3.4563 | Learning Rate: 0.000190 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5387/12542 | Batch Loss: 0.6858 | Learning Rate: 0.000190 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5388/12542 | Batch Loss: 1.6887 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5389/12542 | Batch Loss: 1.8372 | Learning Rate: 0.000190 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5390/12542 | Batch Loss: 0.9007 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5391/12542 | Batch Loss: 2.4880 | Learning Rate: 0.000190 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5392/12542 | Batch Loss: 2.3785 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5393/12542 | Batch Loss: 1.1669 | Learning Rate: 0.000190 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5394/12542 | Batch Loss: 2.0576 | Learning Rate: 0.000190 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5395/12542 | Batch Loss: 1.6175 | Learning Rate: 0.000190 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5396/12542 | Batch Loss: 1.7411 | Learning Rate: 0.000190 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5397/12542 | Batch Loss: 0.9932 | Learning Rate: 0.000190 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5398/12542 | Batch Loss: 0.6331 | Learning Rate: 0.000190 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5399/12542 | Batch Loss: 0.6669 | Learning Rate: 0.000190 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5400/12542 | Batch Loss: 0.4341 | Learning Rate: 0.000190 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5401/12542 | Batch Loss: 1.6346 | Learning Rate: 0.000190 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5402/12542 | Batch Loss: 1.5706 | Learning Rate: 0.000190 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5403/12542 | Batch Loss: 1.3766 | Learning Rate: 0.000190 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5404/12542 | Batch Loss: 2.5025 | Learning Rate: 0.000190 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5405/12542 | Batch Loss: 0.9343 | Learning Rate: 0.000190 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5406/12542 | Batch Loss: 1.1646 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5407/12542 | Batch Loss: 0.6296 | Learning Rate: 0.000190 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5408/12542 | Batch Loss: 1.1906 | Learning Rate: 0.000190 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5409/12542 | Batch Loss: 0.6176 | Learning Rate: 0.000190 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5410/12542 | Batch Loss: 0.8321 | Learning Rate: 0.000190 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5411/12542 | Batch Loss: 1.4404 | Learning Rate: 0.000190 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5412/12542 | Batch Loss: 1.3045 | Learning Rate: 0.000189 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5413/12542 | Batch Loss: 1.1865 | Learning Rate: 0.000189 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5414/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000189 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5415/12542 | Batch Loss: 1.0734 | Learning Rate: 0.000189 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5416/12542 | Batch Loss: 1.7416 | Learning Rate: 0.000189 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5417/12542 | Batch Loss: 1.8027 | Learning Rate: 0.000189 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5418/12542 | Batch Loss: 1.6770 | Learning Rate: 0.000189 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5419/12542 | Batch Loss: 1.3953 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5420/12542 | Batch Loss: 0.6733 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5421/12542 | Batch Loss: 1.9392 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5422/12542 | Batch Loss: 2.4912 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5423/12542 | Batch Loss: 1.9215 | Learning Rate: 0.000189 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5424/12542 | Batch Loss: 1.1976 | Learning Rate: 0.000189 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5425/12542 | Batch Loss: 1.6800 | Learning Rate: 0.000189 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5426/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5427/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5428/12542 | Batch Loss: 1.3622 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5429/12542 | Batch Loss: 0.6494 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5430/12542 | Batch Loss: 0.3002 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5431/12542 | Batch Loss: 1.9103 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5432/12542 | Batch Loss: 0.7328 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5433/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5434/12542 | Batch Loss: 0.6668 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5435/12542 | Batch Loss: 0.8799 | Learning Rate: 0.000189 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5436/12542 | Batch Loss: 3.2672 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5437/12542 | Batch Loss: 1.2108 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5438/12542 | Batch Loss: 0.5567 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5439/12542 | Batch Loss: 1.3007 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5440/12542 | Batch Loss: 1.2956 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5441/12542 | Batch Loss: 0.6482 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5442/12542 | Batch Loss: 1.7408 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5443/12542 | Batch Loss: 0.9233 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5444/12542 | Batch Loss: 1.6299 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5445/12542 | Batch Loss: 1.6559 | Learning Rate: 0.000189 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5446/12542 | Batch Loss: 1.3567 | Learning Rate: 0.000189 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5447/12542 | Batch Loss: 2.1033 | Learning Rate: 0.000189 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5448/12542 | Batch Loss: 1.1309 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5449/12542 | Batch Loss: 2.5299 | Learning Rate: 0.000189 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5450/12542 | Batch Loss: 2.1092 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5451/12542 | Batch Loss: 1.0249 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5452/12542 | Batch Loss: 1.2151 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5453/12542 | Batch Loss: 0.8525 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5454/12542 | Batch Loss: 0.6579 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5455/12542 | Batch Loss: 0.6474 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5456/12542 | Batch Loss: 0.4105 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5457/12542 | Batch Loss: 1.0047 | Learning Rate: 0.000188 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5458/12542 | Batch Loss: 0.7803 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5459/12542 | Batch Loss: 1.3080 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5460/12542 | Batch Loss: 2.6285 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5461/12542 | Batch Loss: 1.9465 | Learning Rate: 0.000188 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5462/12542 | Batch Loss: 0.5244 | Learning Rate: 0.000188 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5463/12542 | Batch Loss: 1.4577 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5464/12542 | Batch Loss: 1.3531 | Learning Rate: 0.000188 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5465/12542 | Batch Loss: 0.6207 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5466/12542 | Batch Loss: 1.0437 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5467/12542 | Batch Loss: 0.9502 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5468/12542 | Batch Loss: 1.9388 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5469/12542 | Batch Loss: 0.6511 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5470/12542 | Batch Loss: 2.6441 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5471/12542 | Batch Loss: 0.9582 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5472/12542 | Batch Loss: 1.7608 | Learning Rate: 0.000188 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5473/12542 | Batch Loss: 1.2556 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5474/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5475/12542 | Batch Loss: 1.1595 | Learning Rate: 0.000188 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5476/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5477/12542 | Batch Loss: 1.8282 | Learning Rate: 0.000188 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5478/12542 | Batch Loss: 0.7358 | Learning Rate: 0.000188 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5479/12542 | Batch Loss: 1.2769 | Learning Rate: 0.000188 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5480/12542 | Batch Loss: 0.7073 | Learning Rate: 0.000188 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5481/12542 | Batch Loss: 0.7608 | Learning Rate: 0.000188 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5482/12542 | Batch Loss: 0.6782 | Learning Rate: 0.000188 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5483/12542 | Batch Loss: 0.5333 | Learning Rate: 0.000188 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5484/12542 | Batch Loss: 1.3884 | Learning Rate: 0.000188 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5485/12542 | Batch Loss: 0.7908 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5486/12542 | Batch Loss: 0.9882 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5487/12542 | Batch Loss: 1.4169 | Learning Rate: 0.000188 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5488/12542 | Batch Loss: 1.3018 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5489/12542 | Batch Loss: 1.4089 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5490/12542 | Batch Loss: 1.5829 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5491/12542 | Batch Loss: 1.0042 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5492/12542 | Batch Loss: 0.8238 | Learning Rate: 0.000187 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5493/12542 | Batch Loss: 5.0125 | Learning Rate: 0.000187 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5494/12542 | Batch Loss: 1.0990 | Learning Rate: 0.000187 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5495/12542 | Batch Loss: 0.7801 | Learning Rate: 0.000187 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5496/12542 | Batch Loss: 1.7313 | Learning Rate: 0.000187 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5497/12542 | Batch Loss: 1.8580 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5498/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5499/12542 | Batch Loss: 0.7842 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5500/12542 | Batch Loss: 0.8071 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5501/12542 | Batch Loss: 0.8131 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5502/12542 | Batch Loss: 2.9020 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5503/12542 | Batch Loss: 2.0562 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5504/12542 | Batch Loss: 0.9651 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5505/12542 | Batch Loss: 1.2193 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5506/12542 | Batch Loss: 0.9427 | Learning Rate: 0.000187 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5507/12542 | Batch Loss: 0.7083 | Learning Rate: 0.000187 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5508/12542 | Batch Loss: 1.3614 | Learning Rate: 0.000187 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5509/12542 | Batch Loss: 0.6270 | Learning Rate: 0.000187 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5510/12542 | Batch Loss: 1.1821 | Learning Rate: 0.000187 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5511/12542 | Batch Loss: 0.8102 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5512/12542 | Batch Loss: 1.7849 | Learning Rate: 0.000187 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5513/12542 | Batch Loss: 1.2373 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5514/12542 | Batch Loss: 1.2597 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5515/12542 | Batch Loss: 2.0052 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5516/12542 | Batch Loss: 1.3085 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5517/12542 | Batch Loss: 1.0176 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5518/12542 | Batch Loss: 0.9142 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5519/12542 | Batch Loss: 1.2901 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5520/12542 | Batch Loss: 1.7055 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5521/12542 | Batch Loss: 1.0727 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5522/12542 | Batch Loss: 0.5547 | Learning Rate: 0.000187 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5523/12542 | Batch Loss: 0.6752 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5524/12542 | Batch Loss: 0.9838 | Learning Rate: 0.000187 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5525/12542 | Batch Loss: 1.4737 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5526/12542 | Batch Loss: 1.4534 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5527/12542 | Batch Loss: 1.0865 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5528/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5529/12542 | Batch Loss: 2.5820 | Learning Rate: 0.000186 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5530/12542 | Batch Loss: 1.1748 | Learning Rate: 0.000186 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5531/12542 | Batch Loss: 2.0887 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5532/12542 | Batch Loss: 1.6344 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5533/12542 | Batch Loss: 3.1115 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5534/12542 | Batch Loss: 0.6407 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5535/12542 | Batch Loss: 2.2442 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5536/12542 | Batch Loss: 1.4184 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5537/12542 | Batch Loss: 0.9195 | Learning Rate: 0.000186 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5538/12542 | Batch Loss: 1.5684 | Learning Rate: 0.000186 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5539/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000186 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5540/12542 | Batch Loss: 1.0817 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5541/12542 | Batch Loss: 1.2756 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5542/12542 | Batch Loss: 1.8014 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5543/12542 | Batch Loss: 1.5141 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5544/12542 | Batch Loss: 0.8590 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5545/12542 | Batch Loss: 1.3275 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5546/12542 | Batch Loss: 0.9034 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5547/12542 | Batch Loss: 0.6019 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5548/12542 | Batch Loss: 3.6409 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5549/12542 | Batch Loss: 0.8955 | Learning Rate: 0.000186 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5550/12542 | Batch Loss: 2.3198 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5551/12542 | Batch Loss: 2.6509 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5552/12542 | Batch Loss: 1.9525 | Learning Rate: 0.000186 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5553/12542 | Batch Loss: 1.6116 | Learning Rate: 0.000186 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5554/12542 | Batch Loss: 0.9780 | Learning Rate: 0.000186 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5555/12542 | Batch Loss: 2.6270 | Learning Rate: 0.000186 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5556/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000186 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5557/12542 | Batch Loss: 2.1789 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5558/12542 | Batch Loss: 2.4256 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5559/12542 | Batch Loss: 1.4803 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5560/12542 | Batch Loss: 0.9545 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5561/12542 | Batch Loss: 0.6717 | Learning Rate: 0.000186 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5562/12542 | Batch Loss: 1.7463 | Learning Rate: 0.000186 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5563/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000185 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5564/12542 | Batch Loss: 0.7002 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5565/12542 | Batch Loss: 1.7440 | Learning Rate: 0.000185 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5566/12542 | Batch Loss: 1.6214 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5567/12542 | Batch Loss: 1.2447 | Learning Rate: 0.000185 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5568/12542 | Batch Loss: 0.7436 | Learning Rate: 0.000185 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5569/12542 | Batch Loss: 1.8378 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5570/12542 | Batch Loss: 1.7999 | Learning Rate: 0.000185 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5571/12542 | Batch Loss: 1.4017 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5572/12542 | Batch Loss: 1.0820 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5573/12542 | Batch Loss: 0.6663 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5574/12542 | Batch Loss: 0.9364 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5575/12542 | Batch Loss: 1.3748 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5576/12542 | Batch Loss: 0.4999 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5577/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5578/12542 | Batch Loss: 2.0141 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5579/12542 | Batch Loss: 0.8887 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5580/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5581/12542 | Batch Loss: 1.0838 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5582/12542 | Batch Loss: 2.0438 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5583/12542 | Batch Loss: 1.1292 | Learning Rate: 0.000185 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5584/12542 | Batch Loss: 1.4658 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5585/12542 | Batch Loss: 1.5267 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5586/12542 | Batch Loss: 1.5798 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5587/12542 | Batch Loss: 0.3520 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5588/12542 | Batch Loss: 1.1746 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5589/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5590/12542 | Batch Loss: 1.2341 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5591/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5592/12542 | Batch Loss: 0.7943 | Learning Rate: 0.000185 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5593/12542 | Batch Loss: 1.4299 | Learning Rate: 0.000185 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5594/12542 | Batch Loss: 1.6303 | Learning Rate: 0.000185 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5595/12542 | Batch Loss: 1.3170 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5596/12542 | Batch Loss: 2.3942 | Learning Rate: 0.000185 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5597/12542 | Batch Loss: 3.3787 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5598/12542 | Batch Loss: 2.2906 | Learning Rate: 0.000185 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5599/12542 | Batch Loss: 0.9887 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5600/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000185 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5601/12542 | Batch Loss: 1.0093 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5602/12542 | Batch Loss: 0.8566 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5603/12542 | Batch Loss: 1.7111 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5604/12542 | Batch Loss: 1.1883 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5605/12542 | Batch Loss: 0.8815 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5606/12542 | Batch Loss: 1.6313 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5607/12542 | Batch Loss: 0.9700 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5608/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000184 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5609/12542 | Batch Loss: 1.1331 | Learning Rate: 0.000184 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5610/12542 | Batch Loss: 0.9865 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5611/12542 | Batch Loss: 1.4953 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5612/12542 | Batch Loss: 0.8182 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5613/12542 | Batch Loss: 0.8313 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5614/12542 | Batch Loss: 1.2977 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5615/12542 | Batch Loss: 2.1244 | Learning Rate: 0.000184 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5616/12542 | Batch Loss: 0.2340 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5617/12542 | Batch Loss: 0.6089 | Learning Rate: 0.000184 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5618/12542 | Batch Loss: 1.6190 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5619/12542 | Batch Loss: 2.6336 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5620/12542 | Batch Loss: 2.1390 | Learning Rate: 0.000184 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5621/12542 | Batch Loss: 1.8251 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5622/12542 | Batch Loss: 2.2410 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5623/12542 | Batch Loss: 1.9281 | Learning Rate: 0.000184 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5624/12542 | Batch Loss: 1.1013 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5625/12542 | Batch Loss: 2.3796 | Learning Rate: 0.000184 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5626/12542 | Batch Loss: 1.5750 | Learning Rate: 0.000184 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5627/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000184 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5628/12542 | Batch Loss: 1.3850 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5629/12542 | Batch Loss: 1.3474 | Learning Rate: 0.000184 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5630/12542 | Batch Loss: 2.9816 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5631/12542 | Batch Loss: 1.4846 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5632/12542 | Batch Loss: 0.6022 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5633/12542 | Batch Loss: 0.8245 | Learning Rate: 0.000184 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5634/12542 | Batch Loss: 1.1127 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5635/12542 | Batch Loss: 0.9398 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5636/12542 | Batch Loss: 1.5172 | Learning Rate: 0.000184 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5637/12542 | Batch Loss: 0.5383 | Learning Rate: 0.000184 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5638/12542 | Batch Loss: 0.9291 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5639/12542 | Batch Loss: 1.2918 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5640/12542 | Batch Loss: 0.6803 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5641/12542 | Batch Loss: 1.6715 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5642/12542 | Batch Loss: 0.6436 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5643/12542 | Batch Loss: 4.2152 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5644/12542 | Batch Loss: 1.4070 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5645/12542 | Batch Loss: 0.6408 | Learning Rate: 0.000183 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5646/12542 | Batch Loss: 0.7116 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5647/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000183 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5648/12542 | Batch Loss: 1.7881 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5649/12542 | Batch Loss: 1.1148 | Learning Rate: 0.000183 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5650/12542 | Batch Loss: 1.9620 | Learning Rate: 0.000183 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5651/12542 | Batch Loss: 0.5525 | Learning Rate: 0.000183 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5652/12542 | Batch Loss: 0.4665 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5653/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000183 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5654/12542 | Batch Loss: 2.5460 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5655/12542 | Batch Loss: 1.2652 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5656/12542 | Batch Loss: 0.8506 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5657/12542 | Batch Loss: 2.0519 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5658/12542 | Batch Loss: 1.5555 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5659/12542 | Batch Loss: 1.1191 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5660/12542 | Batch Loss: 0.7324 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5661/12542 | Batch Loss: 1.0807 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5662/12542 | Batch Loss: 1.0373 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5663/12542 | Batch Loss: 2.9102 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5664/12542 | Batch Loss: 1.0709 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5665/12542 | Batch Loss: 0.9813 | Learning Rate: 0.000183 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5666/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000183 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5667/12542 | Batch Loss: 1.1944 | Learning Rate: 0.000183 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5668/12542 | Batch Loss: 1.1060 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5669/12542 | Batch Loss: 1.9050 | Learning Rate: 0.000183 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5670/12542 | Batch Loss: 2.4764 | Learning Rate: 0.000183 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5671/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000183 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5672/12542 | Batch Loss: 1.6069 | Learning Rate: 0.000183 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5673/12542 | Batch Loss: 1.9304 | Learning Rate: 0.000183 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5674/12542 | Batch Loss: 1.6610 | Learning Rate: 0.000183 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5675/12542 | Batch Loss: 2.0137 | Learning Rate: 0.000183 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5676/12542 | Batch Loss: 1.0196 | Learning Rate: 0.000182 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5677/12542 | Batch Loss: 0.9955 | Learning Rate: 0.000182 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5678/12542 | Batch Loss: 1.1252 | Learning Rate: 0.000182 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5679/12542 | Batch Loss: 1.7382 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5680/12542 | Batch Loss: 0.6530 | Learning Rate: 0.000182 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5681/12542 | Batch Loss: 1.1222 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5682/12542 | Batch Loss: 0.8836 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5683/12542 | Batch Loss: 2.5999 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5684/12542 | Batch Loss: 0.8155 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5685/12542 | Batch Loss: 1.1130 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5686/12542 | Batch Loss: 1.7256 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5687/12542 | Batch Loss: 0.5863 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5688/12542 | Batch Loss: 1.2616 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5689/12542 | Batch Loss: 0.6598 | Learning Rate: 0.000182 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5690/12542 | Batch Loss: 2.0598 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5691/12542 | Batch Loss: 2.1187 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5692/12542 | Batch Loss: 2.4442 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5693/12542 | Batch Loss: 2.6453 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5694/12542 | Batch Loss: 1.1664 | Learning Rate: 0.000182 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5695/12542 | Batch Loss: 1.9762 | Learning Rate: 0.000182 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5696/12542 | Batch Loss: 2.1949 | Learning Rate: 0.000182 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5697/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000182 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5698/12542 | Batch Loss: 1.1696 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5699/12542 | Batch Loss: 1.1746 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5700/12542 | Batch Loss: 0.7341 | Learning Rate: 0.000182 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5701/12542 | Batch Loss: 1.5337 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5702/12542 | Batch Loss: 0.8359 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5703/12542 | Batch Loss: 1.3969 | Learning Rate: 0.000182 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5704/12542 | Batch Loss: 1.0114 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5705/12542 | Batch Loss: 0.8912 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5706/12542 | Batch Loss: 1.4290 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5707/12542 | Batch Loss: 1.3932 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5708/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000182 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5709/12542 | Batch Loss: 2.2094 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5710/12542 | Batch Loss: 1.1866 | Learning Rate: 0.000182 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5711/12542 | Batch Loss: 1.1017 | Learning Rate: 0.000182 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5712/12542 | Batch Loss: 1.0137 | Learning Rate: 0.000182 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5713/12542 | Batch Loss: 1.8982 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5714/12542 | Batch Loss: 1.2233 | Learning Rate: 0.000181 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5715/12542 | Batch Loss: 2.1309 | Learning Rate: 0.000181 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5716/12542 | Batch Loss: 0.5254 | Learning Rate: 0.000181 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5717/12542 | Batch Loss: 1.3685 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5718/12542 | Batch Loss: 0.8898 | Learning Rate: 0.000181 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5719/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5720/12542 | Batch Loss: 1.9182 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5721/12542 | Batch Loss: 3.0049 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5722/12542 | Batch Loss: 0.4605 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5723/12542 | Batch Loss: 0.6934 | Learning Rate: 0.000181 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5724/12542 | Batch Loss: 1.1319 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5725/12542 | Batch Loss: 1.0007 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5726/12542 | Batch Loss: 1.3869 | Learning Rate: 0.000181 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5727/12542 | Batch Loss: 1.3959 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5728/12542 | Batch Loss: 0.8967 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5729/12542 | Batch Loss: 0.7037 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5730/12542 | Batch Loss: 1.9753 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5731/12542 | Batch Loss: 0.5664 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5732/12542 | Batch Loss: 0.9973 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5733/12542 | Batch Loss: 2.0756 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5734/12542 | Batch Loss: 1.4709 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5735/12542 | Batch Loss: 1.9076 | Learning Rate: 0.000181 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5736/12542 | Batch Loss: 1.3243 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5737/12542 | Batch Loss: 1.6444 | Learning Rate: 0.000181 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5738/12542 | Batch Loss: 1.1830 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5739/12542 | Batch Loss: 0.9228 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5740/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5741/12542 | Batch Loss: 1.3098 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5742/12542 | Batch Loss: 1.4260 | Learning Rate: 0.000181 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5743/12542 | Batch Loss: 1.0214 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5744/12542 | Batch Loss: 3.1630 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5745/12542 | Batch Loss: 1.0800 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5746/12542 | Batch Loss: 1.0761 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5747/12542 | Batch Loss: 0.6366 | Learning Rate: 0.000181 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5748/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000181 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5749/12542 | Batch Loss: 0.8675 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5750/12542 | Batch Loss: 2.6597 | Learning Rate: 0.000181 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5751/12542 | Batch Loss: 2.2041 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5752/12542 | Batch Loss: 0.7247 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5753/12542 | Batch Loss: 1.1794 | Learning Rate: 0.000180 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5754/12542 | Batch Loss: 2.0297 | Learning Rate: 0.000180 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5755/12542 | Batch Loss: 0.5513 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5756/12542 | Batch Loss: 0.6435 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5757/12542 | Batch Loss: 0.8117 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5758/12542 | Batch Loss: 1.1508 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5759/12542 | Batch Loss: 1.6111 | Learning Rate: 0.000180 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5760/12542 | Batch Loss: 1.5640 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5761/12542 | Batch Loss: 0.7320 | Learning Rate: 0.000180 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5762/12542 | Batch Loss: 1.1852 | Learning Rate: 0.000180 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5763/12542 | Batch Loss: 1.0994 | Learning Rate: 0.000180 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5764/12542 | Batch Loss: 0.6315 | Learning Rate: 0.000180 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5765/12542 | Batch Loss: 1.2780 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5766/12542 | Batch Loss: 0.5810 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5767/12542 | Batch Loss: 1.2435 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5768/12542 | Batch Loss: 1.5051 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5769/12542 | Batch Loss: 2.1351 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5770/12542 | Batch Loss: 1.0910 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5771/12542 | Batch Loss: 1.4158 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5772/12542 | Batch Loss: 1.7854 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5773/12542 | Batch Loss: 1.1300 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5774/12542 | Batch Loss: 0.6367 | Learning Rate: 0.000180 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5775/12542 | Batch Loss: 0.9517 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5776/12542 | Batch Loss: 0.6288 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5777/12542 | Batch Loss: 1.0491 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5778/12542 | Batch Loss: 1.2130 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5779/12542 | Batch Loss: 1.3821 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5780/12542 | Batch Loss: 2.3275 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5781/12542 | Batch Loss: 1.9753 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5782/12542 | Batch Loss: 3.5508 | Learning Rate: 0.000180 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5783/12542 | Batch Loss: 0.9904 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5784/12542 | Batch Loss: 1.1568 | Learning Rate: 0.000180 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5785/12542 | Batch Loss: 1.2871 | Learning Rate: 0.000180 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5786/12542 | Batch Loss: 1.4865 | Learning Rate: 0.000180 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5787/12542 | Batch Loss: 0.4402 | Learning Rate: 0.000180 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5788/12542 | Batch Loss: 1.1462 | Learning Rate: 0.000180 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5789/12542 | Batch Loss: 1.6767 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5790/12542 | Batch Loss: 3.1738 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5791/12542 | Batch Loss: 2.4458 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5792/12542 | Batch Loss: 1.1745 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5793/12542 | Batch Loss: 0.8982 | Learning Rate: 0.000179 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5794/12542 | Batch Loss: 1.1489 | Learning Rate: 0.000179 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5795/12542 | Batch Loss: 0.8185 | Learning Rate: 0.000179 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5796/12542 | Batch Loss: 1.8144 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5797/12542 | Batch Loss: 1.7229 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5798/12542 | Batch Loss: 2.1401 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5799/12542 | Batch Loss: 0.8417 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5800/12542 | Batch Loss: 1.6310 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5801/12542 | Batch Loss: 1.6570 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5802/12542 | Batch Loss: 1.3054 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5803/12542 | Batch Loss: 0.6064 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5804/12542 | Batch Loss: 0.6771 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5805/12542 | Batch Loss: 1.3755 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5806/12542 | Batch Loss: 0.7451 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5807/12542 | Batch Loss: 0.9872 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5808/12542 | Batch Loss: 1.6749 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5809/12542 | Batch Loss: 0.5890 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5810/12542 | Batch Loss: 1.8290 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5811/12542 | Batch Loss: 1.4233 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5812/12542 | Batch Loss: 1.3294 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5813/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5814/12542 | Batch Loss: 0.8521 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5815/12542 | Batch Loss: 0.4692 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5816/12542 | Batch Loss: 0.8757 | Learning Rate: 0.000179 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5817/12542 | Batch Loss: 1.4603 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5818/12542 | Batch Loss: 0.8263 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5819/12542 | Batch Loss: 1.2152 | Learning Rate: 0.000179 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5820/12542 | Batch Loss: 0.7958 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5821/12542 | Batch Loss: 0.5100 | Learning Rate: 0.000179 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5822/12542 | Batch Loss: 1.4210 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5823/12542 | Batch Loss: 2.3052 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5824/12542 | Batch Loss: 0.7416 | Learning Rate: 0.000179 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5825/12542 | Batch Loss: 1.5697 | Learning Rate: 0.000179 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5826/12542 | Batch Loss: 0.6969 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5827/12542 | Batch Loss: 0.9780 | Learning Rate: 0.000178 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5828/12542 | Batch Loss: 0.9649 | Learning Rate: 0.000178 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5829/12542 | Batch Loss: 2.3330 | Learning Rate: 0.000178 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5830/12542 | Batch Loss: 1.2391 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5831/12542 | Batch Loss: 0.9337 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5832/12542 | Batch Loss: 1.8056 | Learning Rate: 0.000178 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5833/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000178 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5834/12542 | Batch Loss: 0.5636 | Learning Rate: 0.000178 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 5835/12542 | Batch Loss: 0.9945 | Learning Rate: 0.000178 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5836/12542 | Batch Loss: 1.3743 | Learning Rate: 0.000178 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 5837/12542 | Batch Loss: 0.6733 | Learning Rate: 0.000178 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5838/12542 | Batch Loss: 2.2611 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5839/12542 | Batch Loss: 1.6396 | Learning Rate: 0.000178 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5840/12542 | Batch Loss: 1.4689 | Learning Rate: 0.000178 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5841/12542 | Batch Loss: 1.2701 | Learning Rate: 0.000178 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5842/12542 | Batch Loss: 1.1915 | Learning Rate: 0.000178 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5843/12542 | Batch Loss: 1.1219 | Learning Rate: 0.000178 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5844/12542 | Batch Loss: 0.6137 | Learning Rate: 0.000178 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5845/12542 | Batch Loss: 0.7755 | Learning Rate: 0.000178 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5846/12542 | Batch Loss: 2.0702 | Learning Rate: 0.000178 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5847/12542 | Batch Loss: 1.5173 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5848/12542 | Batch Loss: 0.6369 | Learning Rate: 0.000178 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5849/12542 | Batch Loss: 0.6918 | Learning Rate: 0.000178 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5850/12542 | Batch Loss: 1.0963 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5851/12542 | Batch Loss: 0.8515 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5852/12542 | Batch Loss: 0.8861 | Learning Rate: 0.000178 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5853/12542 | Batch Loss: 0.6968 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5854/12542 | Batch Loss: 1.8334 | Learning Rate: 0.000178 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5855/12542 | Batch Loss: 1.9721 | Learning Rate: 0.000178 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5856/12542 | Batch Loss: 1.1302 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5857/12542 | Batch Loss: 1.5495 | Learning Rate: 0.000178 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5858/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000178 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5859/12542 | Batch Loss: 2.1035 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5860/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000178 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5861/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000178 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5862/12542 | Batch Loss: 0.6390 | Learning Rate: 0.000178 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5863/12542 | Batch Loss: 1.5143 | Learning Rate: 0.000178 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5864/12542 | Batch Loss: 3.0257 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5865/12542 | Batch Loss: 0.6964 | Learning Rate: 0.000177 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5866/12542 | Batch Loss: 1.6738 | Learning Rate: 0.000177 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 5867/12542 | Batch Loss: 0.7003 | Learning Rate: 0.000177 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 5868/12542 | Batch Loss: 1.5110 | Learning Rate: 0.000177 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5869/12542 | Batch Loss: 0.6886 | Learning Rate: 0.000177 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5870/12542 | Batch Loss: 1.2380 | Learning Rate: 0.000177 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5871/12542 | Batch Loss: 1.0045 | Learning Rate: 0.000177 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5872/12542 | Batch Loss: 1.1087 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5873/12542 | Batch Loss: 0.8917 | Learning Rate: 0.000177 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5874/12542 | Batch Loss: 1.4311 | Learning Rate: 0.000177 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5875/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5876/12542 | Batch Loss: 1.7239 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5877/12542 | Batch Loss: 0.4496 | Learning Rate: 0.000177 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5878/12542 | Batch Loss: 2.1145 | Learning Rate: 0.000177 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5879/12542 | Batch Loss: 0.8938 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5880/12542 | Batch Loss: 0.6919 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5881/12542 | Batch Loss: 2.0357 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5882/12542 | Batch Loss: 1.3035 | Learning Rate: 0.000177 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5883/12542 | Batch Loss: 0.9915 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5884/12542 | Batch Loss: 1.4769 | Learning Rate: 0.000177 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 5885/12542 | Batch Loss: 1.1186 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5886/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5887/12542 | Batch Loss: 2.1675 | Learning Rate: 0.000177 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5888/12542 | Batch Loss: 1.0638 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5889/12542 | Batch Loss: 0.9354 | Learning Rate: 0.000177 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5890/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000177 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5891/12542 | Batch Loss: 0.8566 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5892/12542 | Batch Loss: 1.1729 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5893/12542 | Batch Loss: 1.0379 | Learning Rate: 0.000177 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5894/12542 | Batch Loss: 0.4807 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5895/12542 | Batch Loss: 0.4624 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5896/12542 | Batch Loss: 0.7511 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5897/12542 | Batch Loss: 1.7785 | Learning Rate: 0.000177 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5898/12542 | Batch Loss: 1.4421 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5899/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5900/12542 | Batch Loss: 1.0495 | Learning Rate: 0.000177 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5901/12542 | Batch Loss: 1.1360 | Learning Rate: 0.000177 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5902/12542 | Batch Loss: 2.1841 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5903/12542 | Batch Loss: 1.8243 | Learning Rate: 0.000176 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5904/12542 | Batch Loss: 1.6782 | Learning Rate: 0.000176 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5905/12542 | Batch Loss: 1.4319 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5906/12542 | Batch Loss: 0.9020 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5907/12542 | Batch Loss: 3.1133 | Learning Rate: 0.000176 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5908/12542 | Batch Loss: 1.4633 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5909/12542 | Batch Loss: 0.7875 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5910/12542 | Batch Loss: 2.0812 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5911/12542 | Batch Loss: 1.6026 | Learning Rate: 0.000176 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5912/12542 | Batch Loss: 1.2613 | Learning Rate: 0.000176 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 5913/12542 | Batch Loss: 2.4421 | Learning Rate: 0.000176 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5914/12542 | Batch Loss: 1.1264 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5915/12542 | Batch Loss: 1.5975 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5916/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5917/12542 | Batch Loss: 2.6993 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5918/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000176 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5919/12542 | Batch Loss: 1.3700 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5920/12542 | Batch Loss: 0.9453 | Learning Rate: 0.000176 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5921/12542 | Batch Loss: 0.7740 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5922/12542 | Batch Loss: 1.8619 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5923/12542 | Batch Loss: 1.6170 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5924/12542 | Batch Loss: 3.5072 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5925/12542 | Batch Loss: 1.0651 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5926/12542 | Batch Loss: 1.5907 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5927/12542 | Batch Loss: 0.7273 | Learning Rate: 0.000176 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5928/12542 | Batch Loss: 1.6688 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5929/12542 | Batch Loss: 1.0463 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5930/12542 | Batch Loss: 1.7394 | Learning Rate: 0.000176 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5931/12542 | Batch Loss: 1.7757 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5932/12542 | Batch Loss: 1.1545 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5933/12542 | Batch Loss: 0.9093 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5934/12542 | Batch Loss: 1.2724 | Learning Rate: 0.000176 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5935/12542 | Batch Loss: 3.3184 | Learning Rate: 0.000176 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5936/12542 | Batch Loss: 0.9953 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5937/12542 | Batch Loss: 2.1741 | Learning Rate: 0.000176 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5938/12542 | Batch Loss: 1.0590 | Learning Rate: 0.000176 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5939/12542 | Batch Loss: 3.1958 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5940/12542 | Batch Loss: 3.1537 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5941/12542 | Batch Loss: 1.3823 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5942/12542 | Batch Loss: 0.8610 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5943/12542 | Batch Loss: 1.3279 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5944/12542 | Batch Loss: 1.4892 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5945/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000175 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5946/12542 | Batch Loss: 1.5723 | Learning Rate: 0.000175 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 5947/12542 | Batch Loss: 0.5323 | Learning Rate: 0.000175 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5948/12542 | Batch Loss: 1.0874 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5949/12542 | Batch Loss: 1.0971 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5950/12542 | Batch Loss: 0.8270 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5951/12542 | Batch Loss: 1.3407 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5952/12542 | Batch Loss: 1.7294 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5953/12542 | Batch Loss: 1.6912 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5954/12542 | Batch Loss: 0.8466 | Learning Rate: 0.000175 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 5955/12542 | Batch Loss: 2.3339 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5956/12542 | Batch Loss: 0.6521 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5957/12542 | Batch Loss: 1.0222 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5958/12542 | Batch Loss: 0.6699 | Learning Rate: 0.000175 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5959/12542 | Batch Loss: 1.0885 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5960/12542 | Batch Loss: 1.2027 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5961/12542 | Batch Loss: 1.5349 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5962/12542 | Batch Loss: 0.6404 | Learning Rate: 0.000175 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5963/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000175 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5964/12542 | Batch Loss: 2.1773 | Learning Rate: 0.000175 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5965/12542 | Batch Loss: 0.9083 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5966/12542 | Batch Loss: 1.7191 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5967/12542 | Batch Loss: 1.1014 | Learning Rate: 0.000175 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5968/12542 | Batch Loss: 2.0375 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5969/12542 | Batch Loss: 1.3314 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5970/12542 | Batch Loss: 0.5735 | Learning Rate: 0.000175 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5971/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5972/12542 | Batch Loss: 1.4288 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5973/12542 | Batch Loss: 0.6614 | Learning Rate: 0.000175 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 5974/12542 | Batch Loss: 1.2089 | Learning Rate: 0.000175 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5975/12542 | Batch Loss: 1.3477 | Learning Rate: 0.000175 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5976/12542 | Batch Loss: 1.9983 | Learning Rate: 0.000175 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5977/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5978/12542 | Batch Loss: 0.9159 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5979/12542 | Batch Loss: 0.9992 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5980/12542 | Batch Loss: 1.1089 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5981/12542 | Batch Loss: 0.6872 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5982/12542 | Batch Loss: 0.8073 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5983/12542 | Batch Loss: 0.6368 | Learning Rate: 0.000174 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 5984/12542 | Batch Loss: 1.2689 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5985/12542 | Batch Loss: 1.8223 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5986/12542 | Batch Loss: 0.6211 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5987/12542 | Batch Loss: 0.8988 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5988/12542 | Batch Loss: 0.8070 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5989/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5990/12542 | Batch Loss: 1.1713 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5991/12542 | Batch Loss: 1.2804 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5992/12542 | Batch Loss: 0.4577 | Learning Rate: 0.000174 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 5993/12542 | Batch Loss: 1.9639 | Learning Rate: 0.000174 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5994/12542 | Batch Loss: 2.3464 | Learning Rate: 0.000174 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 5995/12542 | Batch Loss: 0.6354 | Learning Rate: 0.000174 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 5996/12542 | Batch Loss: 1.3935 | Learning Rate: 0.000174 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 5997/12542 | Batch Loss: 0.9888 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 5998/12542 | Batch Loss: 1.0784 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 5999/12542 | Batch Loss: 0.4869 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6000/12542 | Batch Loss: 0.5627 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6001/12542 | Batch Loss: 1.6741 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6002/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000174 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6003/12542 | Batch Loss: 2.0881 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6004/12542 | Batch Loss: 0.8028 | Learning Rate: 0.000174 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6005/12542 | Batch Loss: 1.8718 | Learning Rate: 0.000174 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6006/12542 | Batch Loss: 0.5835 | Learning Rate: 0.000174 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6007/12542 | Batch Loss: 0.7444 | Learning Rate: 0.000174 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6008/12542 | Batch Loss: 0.7969 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6009/12542 | Batch Loss: 0.6561 | Learning Rate: 0.000174 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6010/12542 | Batch Loss: 3.0698 | Learning Rate: 0.000174 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6011/12542 | Batch Loss: 0.8075 | Learning Rate: 0.000174 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6012/12542 | Batch Loss: 0.6584 | Learning Rate: 0.000174 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6013/12542 | Batch Loss: 2.9534 | Learning Rate: 0.000174 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6014/12542 | Batch Loss: 2.4530 | Learning Rate: 0.000173 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6015/12542 | Batch Loss: 4.3011 | Learning Rate: 0.000173 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6016/12542 | Batch Loss: 0.7231 | Learning Rate: 0.000173 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6017/12542 | Batch Loss: 1.6218 | Learning Rate: 0.000173 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6018/12542 | Batch Loss: 0.5632 | Learning Rate: 0.000173 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6019/12542 | Batch Loss: 0.7057 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6020/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6021/12542 | Batch Loss: 1.7466 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6022/12542 | Batch Loss: 0.7038 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6023/12542 | Batch Loss: 0.7673 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6024/12542 | Batch Loss: 0.7349 | Learning Rate: 0.000173 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6025/12542 | Batch Loss: 0.7959 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6026/12542 | Batch Loss: 1.2712 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6027/12542 | Batch Loss: 1.1511 | Learning Rate: 0.000173 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6028/12542 | Batch Loss: 0.3658 | Learning Rate: 0.000173 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6029/12542 | Batch Loss: 0.4848 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6030/12542 | Batch Loss: 0.8475 | Learning Rate: 0.000173 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6031/12542 | Batch Loss: 0.9146 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6032/12542 | Batch Loss: 0.9104 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6033/12542 | Batch Loss: 1.6465 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6034/12542 | Batch Loss: 1.6749 | Learning Rate: 0.000173 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6035/12542 | Batch Loss: 1.1740 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6036/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000173 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6037/12542 | Batch Loss: 1.5917 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6038/12542 | Batch Loss: 1.0088 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6039/12542 | Batch Loss: 0.6427 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6040/12542 | Batch Loss: 2.5618 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6041/12542 | Batch Loss: 1.3823 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6042/12542 | Batch Loss: 1.7196 | Learning Rate: 0.000173 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6043/12542 | Batch Loss: 1.6580 | Learning Rate: 0.000173 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6044/12542 | Batch Loss: 2.1604 | Learning Rate: 0.000173 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6045/12542 | Batch Loss: 2.8394 | Learning Rate: 0.000173 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6046/12542 | Batch Loss: 1.7370 | Learning Rate: 0.000173 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6047/12542 | Batch Loss: 1.6148 | Learning Rate: 0.000173 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6048/12542 | Batch Loss: 0.4734 | Learning Rate: 0.000173 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6049/12542 | Batch Loss: 1.0987 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6050/12542 | Batch Loss: 1.3646 | Learning Rate: 0.000173 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6051/12542 | Batch Loss: 1.3781 | Learning Rate: 0.000173 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6052/12542 | Batch Loss: 1.4586 | Learning Rate: 0.000172 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6053/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000172 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6054/12542 | Batch Loss: 1.1566 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6055/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6056/12542 | Batch Loss: 1.6302 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6057/12542 | Batch Loss: 1.2908 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6058/12542 | Batch Loss: 2.1800 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6059/12542 | Batch Loss: 2.3288 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6060/12542 | Batch Loss: 0.9808 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6061/12542 | Batch Loss: 1.0272 | Learning Rate: 0.000172 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6062/12542 | Batch Loss: 0.5486 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6063/12542 | Batch Loss: 1.0767 | Learning Rate: 0.000172 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6064/12542 | Batch Loss: 1.3086 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6065/12542 | Batch Loss: 1.9270 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6066/12542 | Batch Loss: 0.8839 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6067/12542 | Batch Loss: 1.4321 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6068/12542 | Batch Loss: 1.3459 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6069/12542 | Batch Loss: 1.0198 | Learning Rate: 0.000172 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6070/12542 | Batch Loss: 1.3946 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6071/12542 | Batch Loss: 1.7715 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6072/12542 | Batch Loss: 1.7608 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6073/12542 | Batch Loss: 1.1937 | Learning Rate: 0.000172 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6074/12542 | Batch Loss: 1.8293 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6075/12542 | Batch Loss: 2.3822 | Learning Rate: 0.000172 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6076/12542 | Batch Loss: 2.2145 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6077/12542 | Batch Loss: 1.7108 | Learning Rate: 0.000172 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6078/12542 | Batch Loss: 0.6915 | Learning Rate: 0.000172 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6079/12542 | Batch Loss: 0.9913 | Learning Rate: 0.000172 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6080/12542 | Batch Loss: 0.7239 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6081/12542 | Batch Loss: 0.7993 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6082/12542 | Batch Loss: 2.5228 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6083/12542 | Batch Loss: 0.9707 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6084/12542 | Batch Loss: 0.6375 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6085/12542 | Batch Loss: 0.5932 | Learning Rate: 0.000172 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6086/12542 | Batch Loss: 1.7087 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6087/12542 | Batch Loss: 1.0949 | Learning Rate: 0.000172 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6088/12542 | Batch Loss: 0.8311 | Learning Rate: 0.000172 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6089/12542 | Batch Loss: 0.5053 | Learning Rate: 0.000172 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6090/12542 | Batch Loss: 2.0449 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6091/12542 | Batch Loss: 0.7027 | Learning Rate: 0.000171 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6092/12542 | Batch Loss: 1.2575 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6093/12542 | Batch Loss: 0.5974 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6094/12542 | Batch Loss: 1.8538 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6095/12542 | Batch Loss: 1.0402 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6096/12542 | Batch Loss: 1.0465 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6097/12542 | Batch Loss: 0.5357 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6098/12542 | Batch Loss: 1.2170 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6099/12542 | Batch Loss: 2.0591 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6100/12542 | Batch Loss: 2.2016 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6101/12542 | Batch Loss: 1.6639 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6102/12542 | Batch Loss: 1.2791 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6103/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6104/12542 | Batch Loss: 0.7960 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6105/12542 | Batch Loss: 0.8403 | Learning Rate: 0.000171 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6106/12542 | Batch Loss: 1.8190 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6107/12542 | Batch Loss: 1.1675 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6108/12542 | Batch Loss: 0.8198 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6109/12542 | Batch Loss: 1.5516 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6110/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6111/12542 | Batch Loss: 2.1032 | Learning Rate: 0.000171 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6112/12542 | Batch Loss: 0.8362 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6113/12542 | Batch Loss: 1.3558 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6114/12542 | Batch Loss: 1.4434 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6115/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000171 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6116/12542 | Batch Loss: 1.7580 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6117/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000171 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6118/12542 | Batch Loss: 1.4021 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6119/12542 | Batch Loss: 2.2341 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6120/12542 | Batch Loss: 2.0259 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6121/12542 | Batch Loss: 0.7193 | Learning Rate: 0.000171 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6122/12542 | Batch Loss: 0.8982 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6123/12542 | Batch Loss: 2.1515 | Learning Rate: 0.000171 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6124/12542 | Batch Loss: 1.1130 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6125/12542 | Batch Loss: 0.8246 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6126/12542 | Batch Loss: 1.8506 | Learning Rate: 0.000171 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6127/12542 | Batch Loss: 2.8477 | Learning Rate: 0.000170 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6128/12542 | Batch Loss: 0.8870 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6129/12542 | Batch Loss: 0.7172 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6130/12542 | Batch Loss: 2.1148 | Learning Rate: 0.000170 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6131/12542 | Batch Loss: 1.3189 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6132/12542 | Batch Loss: 1.3247 | Learning Rate: 0.000170 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6133/12542 | Batch Loss: 1.0549 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6134/12542 | Batch Loss: 1.5688 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6135/12542 | Batch Loss: 0.7776 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6136/12542 | Batch Loss: 1.0826 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6137/12542 | Batch Loss: 0.9045 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6138/12542 | Batch Loss: 1.5829 | Learning Rate: 0.000170 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6139/12542 | Batch Loss: 2.2663 | Learning Rate: 0.000170 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6140/12542 | Batch Loss: 1.4653 | Learning Rate: 0.000170 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6141/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000170 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6142/12542 | Batch Loss: 2.0582 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6143/12542 | Batch Loss: 0.6533 | Learning Rate: 0.000170 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6144/12542 | Batch Loss: 1.6987 | Learning Rate: 0.000170 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6145/12542 | Batch Loss: 1.3914 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6146/12542 | Batch Loss: 1.0077 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6147/12542 | Batch Loss: 1.0117 | Learning Rate: 0.000170 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6148/12542 | Batch Loss: 1.2778 | Learning Rate: 0.000170 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6149/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000170 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6150/12542 | Batch Loss: 0.6856 | Learning Rate: 0.000170 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6151/12542 | Batch Loss: 1.3385 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6152/12542 | Batch Loss: 0.6014 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6153/12542 | Batch Loss: 0.7467 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6154/12542 | Batch Loss: 1.0889 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6155/12542 | Batch Loss: 0.7151 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6156/12542 | Batch Loss: 1.7314 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6157/12542 | Batch Loss: 1.0592 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6158/12542 | Batch Loss: 0.5306 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6159/12542 | Batch Loss: 1.4159 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6160/12542 | Batch Loss: 0.7591 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6161/12542 | Batch Loss: 2.3198 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6162/12542 | Batch Loss: 0.8788 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6163/12542 | Batch Loss: 0.8821 | Learning Rate: 0.000170 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6164/12542 | Batch Loss: 0.8601 | Learning Rate: 0.000170 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6165/12542 | Batch Loss: 1.3050 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6166/12542 | Batch Loss: 0.7731 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6167/12542 | Batch Loss: 1.1816 | Learning Rate: 0.000169 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6168/12542 | Batch Loss: 1.1775 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6169/12542 | Batch Loss: 0.5361 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6170/12542 | Batch Loss: 1.3722 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6171/12542 | Batch Loss: 1.5096 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6172/12542 | Batch Loss: 0.8780 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6173/12542 | Batch Loss: 0.7839 | Learning Rate: 0.000169 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6174/12542 | Batch Loss: 1.6587 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6175/12542 | Batch Loss: 0.7476 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6176/12542 | Batch Loss: 1.1521 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6177/12542 | Batch Loss: 3.1655 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6178/12542 | Batch Loss: 2.2223 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6179/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6180/12542 | Batch Loss: 1.6105 | Learning Rate: 0.000169 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6181/12542 | Batch Loss: 2.0920 | Learning Rate: 0.000169 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6182/12542 | Batch Loss: 1.2852 | Learning Rate: 0.000169 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6183/12542 | Batch Loss: 1.2851 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6184/12542 | Batch Loss: 0.7083 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6185/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6186/12542 | Batch Loss: 2.2128 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6187/12542 | Batch Loss: 2.1348 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6188/12542 | Batch Loss: 1.3361 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6189/12542 | Batch Loss: 1.4971 | Learning Rate: 0.000169 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6190/12542 | Batch Loss: 0.6166 | Learning Rate: 0.000169 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6191/12542 | Batch Loss: 1.2113 | Learning Rate: 0.000169 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6192/12542 | Batch Loss: 0.7679 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6193/12542 | Batch Loss: 0.7263 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6194/12542 | Batch Loss: 1.5287 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6195/12542 | Batch Loss: 1.1665 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6196/12542 | Batch Loss: 1.6099 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6197/12542 | Batch Loss: 2.4632 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6198/12542 | Batch Loss: 0.6201 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6199/12542 | Batch Loss: 1.9855 | Learning Rate: 0.000169 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6200/12542 | Batch Loss: 1.1916 | Learning Rate: 0.000169 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6201/12542 | Batch Loss: 1.2811 | Learning Rate: 0.000169 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6202/12542 | Batch Loss: 2.0373 | Learning Rate: 0.000169 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6203/12542 | Batch Loss: 2.5301 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6204/12542 | Batch Loss: 0.8947 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6205/12542 | Batch Loss: 2.4006 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6206/12542 | Batch Loss: 1.0916 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6207/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6208/12542 | Batch Loss: 0.9377 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6209/12542 | Batch Loss: 1.0014 | Learning Rate: 0.000168 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6210/12542 | Batch Loss: 1.2884 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6211/12542 | Batch Loss: 1.1454 | Learning Rate: 0.000168 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6212/12542 | Batch Loss: 0.7540 | Learning Rate: 0.000168 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6213/12542 | Batch Loss: 0.9403 | Learning Rate: 0.000168 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6214/12542 | Batch Loss: 1.8082 | Learning Rate: 0.000168 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6215/12542 | Batch Loss: 0.5129 | Learning Rate: 0.000168 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6216/12542 | Batch Loss: 0.5416 | Learning Rate: 0.000168 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6217/12542 | Batch Loss: 0.7334 | Learning Rate: 0.000168 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6218/12542 | Batch Loss: 2.2539 | Learning Rate: 0.000168 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6219/12542 | Batch Loss: 1.4843 | Learning Rate: 0.000168 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6220/12542 | Batch Loss: 0.4809 | Learning Rate: 0.000168 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6221/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000168 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6222/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000168 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6223/12542 | Batch Loss: 0.6370 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6224/12542 | Batch Loss: 1.3142 | Learning Rate: 0.000168 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6225/12542 | Batch Loss: 0.5497 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6226/12542 | Batch Loss: 0.6160 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6227/12542 | Batch Loss: 1.9317 | Learning Rate: 0.000168 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6228/12542 | Batch Loss: 1.1835 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6229/12542 | Batch Loss: 0.9511 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6230/12542 | Batch Loss: 1.2298 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6231/12542 | Batch Loss: 2.1079 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6232/12542 | Batch Loss: 1.5887 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6233/12542 | Batch Loss: 1.1173 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6234/12542 | Batch Loss: 0.7280 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6235/12542 | Batch Loss: 1.0463 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6236/12542 | Batch Loss: 0.9014 | Learning Rate: 0.000168 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6237/12542 | Batch Loss: 1.8579 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6238/12542 | Batch Loss: 0.9284 | Learning Rate: 0.000168 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6239/12542 | Batch Loss: 1.5592 | Learning Rate: 0.000168 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6240/12542 | Batch Loss: 1.9772 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6241/12542 | Batch Loss: 0.8013 | Learning Rate: 0.000167 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6242/12542 | Batch Loss: 0.5838 | Learning Rate: 0.000167 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6243/12542 | Batch Loss: 1.5862 | Learning Rate: 0.000167 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6244/12542 | Batch Loss: 0.7849 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6245/12542 | Batch Loss: 1.7056 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6246/12542 | Batch Loss: 1.6859 | Learning Rate: 0.000167 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6247/12542 | Batch Loss: 1.3164 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6248/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000167 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6249/12542 | Batch Loss: 1.2068 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6250/12542 | Batch Loss: 1.7768 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6251/12542 | Batch Loss: 1.2437 | Learning Rate: 0.000167 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6252/12542 | Batch Loss: 1.2650 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6253/12542 | Batch Loss: 2.4199 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6254/12542 | Batch Loss: 1.5669 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6255/12542 | Batch Loss: 1.2971 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6256/12542 | Batch Loss: 0.6088 | Learning Rate: 0.000167 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6257/12542 | Batch Loss: 0.6690 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6258/12542 | Batch Loss: 1.5170 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6259/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6260/12542 | Batch Loss: 3.5195 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6261/12542 | Batch Loss: 2.9424 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6262/12542 | Batch Loss: 1.5097 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6263/12542 | Batch Loss: 1.9199 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6264/12542 | Batch Loss: 1.4934 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6265/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000167 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6266/12542 | Batch Loss: 1.5844 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6267/12542 | Batch Loss: 0.8079 | Learning Rate: 0.000167 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6268/12542 | Batch Loss: 1.2259 | Learning Rate: 0.000167 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6269/12542 | Batch Loss: 2.1575 | Learning Rate: 0.000167 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6270/12542 | Batch Loss: 0.4331 | Learning Rate: 0.000167 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6271/12542 | Batch Loss: 0.7961 | Learning Rate: 0.000167 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6272/12542 | Batch Loss: 1.3914 | Learning Rate: 0.000167 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6273/12542 | Batch Loss: 0.6496 | Learning Rate: 0.000167 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6274/12542 | Batch Loss: 1.2079 | Learning Rate: 0.000167 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6275/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000167 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6276/12542 | Batch Loss: 1.4431 | Learning Rate: 0.000167 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6277/12542 | Batch Loss: 0.6442 | Learning Rate: 0.000167 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6278/12542 | Batch Loss: 1.3645 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6279/12542 | Batch Loss: 1.2871 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6280/12542 | Batch Loss: 1.5963 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6281/12542 | Batch Loss: 1.8940 | Learning Rate: 0.000166 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6282/12542 | Batch Loss: 2.5505 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6283/12542 | Batch Loss: 1.2246 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6284/12542 | Batch Loss: 1.6212 | Learning Rate: 0.000166 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6285/12542 | Batch Loss: 1.1451 | Learning Rate: 0.000166 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6286/12542 | Batch Loss: 0.8751 | Learning Rate: 0.000166 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6287/12542 | Batch Loss: 0.7470 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6288/12542 | Batch Loss: 0.6737 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6289/12542 | Batch Loss: 0.5813 | Learning Rate: 0.000166 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6290/12542 | Batch Loss: 0.8799 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6291/12542 | Batch Loss: 0.6054 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6292/12542 | Batch Loss: 1.0147 | Learning Rate: 0.000166 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6293/12542 | Batch Loss: 1.5722 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6294/12542 | Batch Loss: 0.9860 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6295/12542 | Batch Loss: 0.9829 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6296/12542 | Batch Loss: 0.7857 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6297/12542 | Batch Loss: 0.8284 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6298/12542 | Batch Loss: 1.6971 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6299/12542 | Batch Loss: 0.6619 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6300/12542 | Batch Loss: 2.3415 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6301/12542 | Batch Loss: 0.9778 | Learning Rate: 0.000166 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6302/12542 | Batch Loss: 1.9063 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6303/12542 | Batch Loss: 0.5063 | Learning Rate: 0.000166 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6304/12542 | Batch Loss: 1.4623 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6305/12542 | Batch Loss: 1.1810 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6306/12542 | Batch Loss: 1.3274 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6307/12542 | Batch Loss: 1.1727 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6308/12542 | Batch Loss: 1.3934 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6309/12542 | Batch Loss: 0.6517 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6310/12542 | Batch Loss: 3.3780 | Learning Rate: 0.000166 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6311/12542 | Batch Loss: 0.5339 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6312/12542 | Batch Loss: 1.5045 | Learning Rate: 0.000166 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6313/12542 | Batch Loss: 3.5173 | Learning Rate: 0.000166 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6314/12542 | Batch Loss: 1.4354 | Learning Rate: 0.000166 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6315/12542 | Batch Loss: 1.6883 | Learning Rate: 0.000165 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6316/12542 | Batch Loss: 1.1672 | Learning Rate: 0.000165 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6317/12542 | Batch Loss: 1.0539 | Learning Rate: 0.000165 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6318/12542 | Batch Loss: 1.1279 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6319/12542 | Batch Loss: 1.3569 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6320/12542 | Batch Loss: 2.3987 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6321/12542 | Batch Loss: 2.6017 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6322/12542 | Batch Loss: 1.3813 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6323/12542 | Batch Loss: 2.0105 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6324/12542 | Batch Loss: 1.2821 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6325/12542 | Batch Loss: 1.0220 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6326/12542 | Batch Loss: 0.9544 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6327/12542 | Batch Loss: 1.1470 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6328/12542 | Batch Loss: 1.7670 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6329/12542 | Batch Loss: 2.0704 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6330/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6331/12542 | Batch Loss: 1.3602 | Learning Rate: 0.000165 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 6332/12542 | Batch Loss: 1.2823 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6333/12542 | Batch Loss: 1.0214 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6334/12542 | Batch Loss: 2.6817 | Learning Rate: 0.000165 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6335/12542 | Batch Loss: 1.5219 | Learning Rate: 0.000165 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6336/12542 | Batch Loss: 3.7779 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6337/12542 | Batch Loss: 0.7222 | Learning Rate: 0.000165 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6338/12542 | Batch Loss: 2.0204 | Learning Rate: 0.000165 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6339/12542 | Batch Loss: 0.6239 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6340/12542 | Batch Loss: 0.6272 | Learning Rate: 0.000165 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6341/12542 | Batch Loss: 1.3208 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6342/12542 | Batch Loss: 0.6888 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6343/12542 | Batch Loss: 1.3584 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6344/12542 | Batch Loss: 0.3920 | Learning Rate: 0.000165 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6345/12542 | Batch Loss: 2.6533 | Learning Rate: 0.000165 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6346/12542 | Batch Loss: 1.2850 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6347/12542 | Batch Loss: 1.4703 | Learning Rate: 0.000165 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6348/12542 | Batch Loss: 1.0512 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6349/12542 | Batch Loss: 1.6693 | Learning Rate: 0.000165 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6350/12542 | Batch Loss: 1.2318 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6351/12542 | Batch Loss: 1.7411 | Learning Rate: 0.000165 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6352/12542 | Batch Loss: 1.0062 | Learning Rate: 0.000165 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6353/12542 | Batch Loss: 0.8677 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6354/12542 | Batch Loss: 2.0620 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6355/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6356/12542 | Batch Loss: 1.6914 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6357/12542 | Batch Loss: 0.7436 | Learning Rate: 0.000164 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6358/12542 | Batch Loss: 0.9524 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6359/12542 | Batch Loss: 2.3581 | Learning Rate: 0.000164 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6360/12542 | Batch Loss: 3.3237 | Learning Rate: 0.000164 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6361/12542 | Batch Loss: 1.5794 | Learning Rate: 0.000164 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6362/12542 | Batch Loss: 1.0447 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6363/12542 | Batch Loss: 1.3729 | Learning Rate: 0.000164 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6364/12542 | Batch Loss: 0.9236 | Learning Rate: 0.000164 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6365/12542 | Batch Loss: 1.4954 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6366/12542 | Batch Loss: 0.8481 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6367/12542 | Batch Loss: 0.6483 | Learning Rate: 0.000164 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6368/12542 | Batch Loss: 1.1528 | Learning Rate: 0.000164 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6369/12542 | Batch Loss: 0.9364 | Learning Rate: 0.000164 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6370/12542 | Batch Loss: 2.0130 | Learning Rate: 0.000164 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6371/12542 | Batch Loss: 1.7286 | Learning Rate: 0.000164 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6372/12542 | Batch Loss: 1.3961 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6373/12542 | Batch Loss: 2.2331 | Learning Rate: 0.000164 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6374/12542 | Batch Loss: 1.2717 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6375/12542 | Batch Loss: 2.5041 | Learning Rate: 0.000164 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6376/12542 | Batch Loss: 0.7883 | Learning Rate: 0.000164 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6377/12542 | Batch Loss: 1.0053 | Learning Rate: 0.000164 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6378/12542 | Batch Loss: 1.9694 | Learning Rate: 0.000164 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6379/12542 | Batch Loss: 0.9674 | Learning Rate: 0.000164 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6380/12542 | Batch Loss: 1.9204 | Learning Rate: 0.000164 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6381/12542 | Batch Loss: 0.8262 | Learning Rate: 0.000164 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6382/12542 | Batch Loss: 0.6475 | Learning Rate: 0.000164 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6383/12542 | Batch Loss: 1.4156 | Learning Rate: 0.000164 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6384/12542 | Batch Loss: 2.5960 | Learning Rate: 0.000164 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6385/12542 | Batch Loss: 1.8157 | Learning Rate: 0.000164 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6386/12542 | Batch Loss: 1.3426 | Learning Rate: 0.000164 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6387/12542 | Batch Loss: 1.2722 | Learning Rate: 0.000164 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6388/12542 | Batch Loss: 0.5851 | Learning Rate: 0.000164 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6389/12542 | Batch Loss: 1.5971 | Learning Rate: 0.000164 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6390/12542 | Batch Loss: 0.4529 | Learning Rate: 0.000164 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6391/12542 | Batch Loss: 1.4601 | Learning Rate: 0.000163 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6392/12542 | Batch Loss: 2.2220 | Learning Rate: 0.000163 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6393/12542 | Batch Loss: 1.1943 | Learning Rate: 0.000163 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6394/12542 | Batch Loss: 0.4636 | Learning Rate: 0.000163 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6395/12542 | Batch Loss: 0.8593 | Learning Rate: 0.000163 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6396/12542 | Batch Loss: 0.7746 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6397/12542 | Batch Loss: 1.4276 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6398/12542 | Batch Loss: 0.9782 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6399/12542 | Batch Loss: 1.3370 | Learning Rate: 0.000163 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6400/12542 | Batch Loss: 1.2829 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6401/12542 | Batch Loss: 1.5184 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6402/12542 | Batch Loss: 0.5969 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6403/12542 | Batch Loss: 2.3556 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6404/12542 | Batch Loss: 1.0107 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6405/12542 | Batch Loss: 0.5670 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6406/12542 | Batch Loss: 0.5475 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6407/12542 | Batch Loss: 0.5043 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6408/12542 | Batch Loss: 1.4288 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6409/12542 | Batch Loss: 0.6851 | Learning Rate: 0.000163 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6410/12542 | Batch Loss: 1.6514 | Learning Rate: 0.000163 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6411/12542 | Batch Loss: 1.9374 | Learning Rate: 0.000163 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6412/12542 | Batch Loss: 1.4531 | Learning Rate: 0.000163 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6413/12542 | Batch Loss: 0.8294 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6414/12542 | Batch Loss: 2.0128 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6415/12542 | Batch Loss: 2.0006 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6416/12542 | Batch Loss: 1.4072 | Learning Rate: 0.000163 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6417/12542 | Batch Loss: 1.8235 | Learning Rate: 0.000163 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6418/12542 | Batch Loss: 2.0985 | Learning Rate: 0.000163 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6419/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000163 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6420/12542 | Batch Loss: 1.1848 | Learning Rate: 0.000163 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 6421/12542 | Batch Loss: 0.8589 | Learning Rate: 0.000163 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6422/12542 | Batch Loss: 0.7545 | Learning Rate: 0.000163 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6423/12542 | Batch Loss: 3.5641 | Learning Rate: 0.000163 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6424/12542 | Batch Loss: 1.2280 | Learning Rate: 0.000163 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6425/12542 | Batch Loss: 1.1006 | Learning Rate: 0.000163 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6426/12542 | Batch Loss: 1.6786 | Learning Rate: 0.000163 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6427/12542 | Batch Loss: 0.6753 | Learning Rate: 0.000163 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6428/12542 | Batch Loss: 0.9810 | Learning Rate: 0.000162 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6429/12542 | Batch Loss: 0.9108 | Learning Rate: 0.000162 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6430/12542 | Batch Loss: 1.9901 | Learning Rate: 0.000162 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6431/12542 | Batch Loss: 0.7417 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6432/12542 | Batch Loss: 0.7545 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6433/12542 | Batch Loss: 0.3639 | Learning Rate: 0.000162 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6434/12542 | Batch Loss: 1.0348 | Learning Rate: 0.000162 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6435/12542 | Batch Loss: 1.3176 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6436/12542 | Batch Loss: 1.5972 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6437/12542 | Batch Loss: 0.7114 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6438/12542 | Batch Loss: 1.0011 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6439/12542 | Batch Loss: 1.2947 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6440/12542 | Batch Loss: 1.5669 | Learning Rate: 0.000162 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6441/12542 | Batch Loss: 0.8721 | Learning Rate: 0.000162 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6442/12542 | Batch Loss: 1.6776 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6443/12542 | Batch Loss: 1.5230 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6444/12542 | Batch Loss: 0.8951 | Learning Rate: 0.000162 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6445/12542 | Batch Loss: 1.2229 | Learning Rate: 0.000162 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6446/12542 | Batch Loss: 2.5081 | Learning Rate: 0.000162 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6447/12542 | Batch Loss: 2.1549 | Learning Rate: 0.000162 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6448/12542 | Batch Loss: 2.1959 | Learning Rate: 0.000162 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6449/12542 | Batch Loss: 1.1810 | Learning Rate: 0.000162 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6450/12542 | Batch Loss: 1.1092 | Learning Rate: 0.000162 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6451/12542 | Batch Loss: 2.3328 | Learning Rate: 0.000162 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6452/12542 | Batch Loss: 1.4100 | Learning Rate: 0.000162 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6453/12542 | Batch Loss: 0.9886 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6454/12542 | Batch Loss: 0.7937 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6455/12542 | Batch Loss: 1.5497 | Learning Rate: 0.000162 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6456/12542 | Batch Loss: 1.0887 | Learning Rate: 0.000162 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6457/12542 | Batch Loss: 1.9823 | Learning Rate: 0.000162 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6458/12542 | Batch Loss: 0.6017 | Learning Rate: 0.000162 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6459/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000162 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6460/12542 | Batch Loss: 0.9828 | Learning Rate: 0.000162 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6461/12542 | Batch Loss: 1.0376 | Learning Rate: 0.000162 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6462/12542 | Batch Loss: 3.5266 | Learning Rate: 0.000162 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6463/12542 | Batch Loss: 1.2235 | Learning Rate: 0.000162 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6464/12542 | Batch Loss: 1.7171 | Learning Rate: 0.000162 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6465/12542 | Batch Loss: 0.6346 | Learning Rate: 0.000162 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6466/12542 | Batch Loss: 1.5784 | Learning Rate: 0.000161 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6467/12542 | Batch Loss: 1.3615 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6468/12542 | Batch Loss: 1.1833 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6469/12542 | Batch Loss: 1.8650 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6470/12542 | Batch Loss: 1.1427 | Learning Rate: 0.000161 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6471/12542 | Batch Loss: 1.1169 | Learning Rate: 0.000161 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6472/12542 | Batch Loss: 1.0121 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6473/12542 | Batch Loss: 1.1623 | Learning Rate: 0.000161 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6474/12542 | Batch Loss: 0.9183 | Learning Rate: 0.000161 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6475/12542 | Batch Loss: 1.5612 | Learning Rate: 0.000161 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6476/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000161 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6477/12542 | Batch Loss: 0.8956 | Learning Rate: 0.000161 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6478/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000161 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6479/12542 | Batch Loss: 1.9202 | Learning Rate: 0.000161 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6480/12542 | Batch Loss: 1.2781 | Learning Rate: 0.000161 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6481/12542 | Batch Loss: 0.9688 | Learning Rate: 0.000161 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6482/12542 | Batch Loss: 0.9451 | Learning Rate: 0.000161 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6483/12542 | Batch Loss: 1.1461 | Learning Rate: 0.000161 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6484/12542 | Batch Loss: 2.6621 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6485/12542 | Batch Loss: 1.6234 | Learning Rate: 0.000161 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6486/12542 | Batch Loss: 2.2049 | Learning Rate: 0.000161 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6487/12542 | Batch Loss: 1.5814 | Learning Rate: 0.000161 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6488/12542 | Batch Loss: 3.6949 | Learning Rate: 0.000161 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6489/12542 | Batch Loss: 1.2681 | Learning Rate: 0.000161 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6490/12542 | Batch Loss: 1.5054 | Learning Rate: 0.000161 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6491/12542 | Batch Loss: 2.0101 | Learning Rate: 0.000161 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6492/12542 | Batch Loss: 0.6233 | Learning Rate: 0.000161 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6493/12542 | Batch Loss: 1.1415 | Learning Rate: 0.000161 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6494/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000161 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6495/12542 | Batch Loss: 2.9140 | Learning Rate: 0.000161 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6496/12542 | Batch Loss: 0.6681 | Learning Rate: 0.000161 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6497/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000161 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6498/12542 | Batch Loss: 1.6808 | Learning Rate: 0.000161 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6499/12542 | Batch Loss: 1.0868 | Learning Rate: 0.000161 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6500/12542 | Batch Loss: 0.8743 | Learning Rate: 0.000161 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6501/12542 | Batch Loss: 1.1304 | Learning Rate: 0.000161 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6502/12542 | Batch Loss: 1.0705 | Learning Rate: 0.000161 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6503/12542 | Batch Loss: 1.4646 | Learning Rate: 0.000161 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6504/12542 | Batch Loss: 1.7506 | Learning Rate: 0.000160 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6505/12542 | Batch Loss: 1.6210 | Learning Rate: 0.000160 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6506/12542 | Batch Loss: 1.2752 | Learning Rate: 0.000160 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6507/12542 | Batch Loss: 1.0680 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6508/12542 | Batch Loss: 0.2897 | Learning Rate: 0.000160 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6509/12542 | Batch Loss: 2.0062 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6510/12542 | Batch Loss: 0.5942 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6511/12542 | Batch Loss: 1.7744 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6512/12542 | Batch Loss: 1.1258 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6513/12542 | Batch Loss: 2.0256 | Learning Rate: 0.000160 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6514/12542 | Batch Loss: 1.1585 | Learning Rate: 0.000160 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6515/12542 | Batch Loss: 1.6191 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6516/12542 | Batch Loss: 1.5327 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6517/12542 | Batch Loss: 1.2771 | Learning Rate: 0.000160 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6518/12542 | Batch Loss: 0.7675 | Learning Rate: 0.000160 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6519/12542 | Batch Loss: 1.7147 | Learning Rate: 0.000160 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6520/12542 | Batch Loss: 1.2490 | Learning Rate: 0.000160 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6521/12542 | Batch Loss: 0.7431 | Learning Rate: 0.000160 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6522/12542 | Batch Loss: 2.2830 | Learning Rate: 0.000160 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6523/12542 | Batch Loss: 1.8318 | Learning Rate: 0.000160 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6524/12542 | Batch Loss: 0.8932 | Learning Rate: 0.000160 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6525/12542 | Batch Loss: 1.4281 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6526/12542 | Batch Loss: 1.2750 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6527/12542 | Batch Loss: 1.1069 | Learning Rate: 0.000160 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6528/12542 | Batch Loss: 0.6047 | Learning Rate: 0.000160 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6529/12542 | Batch Loss: 1.8547 | Learning Rate: 0.000160 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6530/12542 | Batch Loss: 0.6439 | Learning Rate: 0.000160 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6531/12542 | Batch Loss: 0.7369 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6532/12542 | Batch Loss: 1.1273 | Learning Rate: 0.000160 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6533/12542 | Batch Loss: 1.4701 | Learning Rate: 0.000160 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6534/12542 | Batch Loss: 1.8675 | Learning Rate: 0.000160 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6535/12542 | Batch Loss: 2.1783 | Learning Rate: 0.000160 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6536/12542 | Batch Loss: 2.2447 | Learning Rate: 0.000160 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6537/12542 | Batch Loss: 0.8589 | Learning Rate: 0.000160 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6538/12542 | Batch Loss: 1.5588 | Learning Rate: 0.000160 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6539/12542 | Batch Loss: 1.5777 | Learning Rate: 0.000160 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6540/12542 | Batch Loss: 0.5928 | Learning Rate: 0.000160 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6541/12542 | Batch Loss: 1.7481 | Learning Rate: 0.000159 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6542/12542 | Batch Loss: 0.8113 | Learning Rate: 0.000159 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6543/12542 | Batch Loss: 0.4358 | Learning Rate: 0.000159 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6544/12542 | Batch Loss: 1.7376 | Learning Rate: 0.000159 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6545/12542 | Batch Loss: 1.5303 | Learning Rate: 0.000159 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6546/12542 | Batch Loss: 2.5211 | Learning Rate: 0.000159 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6547/12542 | Batch Loss: 1.7693 | Learning Rate: 0.000159 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6548/12542 | Batch Loss: 1.7362 | Learning Rate: 0.000159 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6549/12542 | Batch Loss: 0.9719 | Learning Rate: 0.000159 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6550/12542 | Batch Loss: 1.6165 | Learning Rate: 0.000159 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6551/12542 | Batch Loss: 0.6818 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6552/12542 | Batch Loss: 1.2063 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6553/12542 | Batch Loss: 0.8337 | Learning Rate: 0.000159 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6554/12542 | Batch Loss: 2.1615 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6555/12542 | Batch Loss: 1.2734 | Learning Rate: 0.000159 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6556/12542 | Batch Loss: 1.0993 | Learning Rate: 0.000159 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6557/12542 | Batch Loss: 1.4711 | Learning Rate: 0.000159 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6558/12542 | Batch Loss: 2.0335 | Learning Rate: 0.000159 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6559/12542 | Batch Loss: 2.2918 | Learning Rate: 0.000159 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6560/12542 | Batch Loss: 1.5573 | Learning Rate: 0.000159 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6561/12542 | Batch Loss: 1.2431 | Learning Rate: 0.000159 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6562/12542 | Batch Loss: 0.6232 | Learning Rate: 0.000159 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6563/12542 | Batch Loss: 1.3976 | Learning Rate: 0.000159 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6564/12542 | Batch Loss: 0.5195 | Learning Rate: 0.000159 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6565/12542 | Batch Loss: 1.1142 | Learning Rate: 0.000159 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6566/12542 | Batch Loss: 2.0224 | Learning Rate: 0.000159 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6567/12542 | Batch Loss: 1.7244 | Learning Rate: 0.000159 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6568/12542 | Batch Loss: 1.0592 | Learning Rate: 0.000159 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6569/12542 | Batch Loss: 2.3477 | Learning Rate: 0.000159 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6570/12542 | Batch Loss: 1.0858 | Learning Rate: 0.000159 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6571/12542 | Batch Loss: 1.5101 | Learning Rate: 0.000159 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6572/12542 | Batch Loss: 0.9450 | Learning Rate: 0.000159 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6573/12542 | Batch Loss: 2.0915 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6574/12542 | Batch Loss: 1.6840 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6575/12542 | Batch Loss: 1.1770 | Learning Rate: 0.000159 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6576/12542 | Batch Loss: 0.7918 | Learning Rate: 0.000159 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6577/12542 | Batch Loss: 1.2327 | Learning Rate: 0.000159 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6578/12542 | Batch Loss: 1.1584 | Learning Rate: 0.000159 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6579/12542 | Batch Loss: 0.7455 | Learning Rate: 0.000158 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6580/12542 | Batch Loss: 1.2386 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6581/12542 | Batch Loss: 0.7775 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6582/12542 | Batch Loss: 0.7025 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6583/12542 | Batch Loss: 1.3891 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6584/12542 | Batch Loss: 0.8194 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6585/12542 | Batch Loss: 1.4458 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6586/12542 | Batch Loss: 0.8737 | Learning Rate: 0.000158 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6587/12542 | Batch Loss: 1.9569 | Learning Rate: 0.000158 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6588/12542 | Batch Loss: 1.7771 | Learning Rate: 0.000158 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6589/12542 | Batch Loss: 1.3568 | Learning Rate: 0.000158 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6590/12542 | Batch Loss: 2.0094 | Learning Rate: 0.000158 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6591/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000158 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6592/12542 | Batch Loss: 1.8896 | Learning Rate: 0.000158 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6593/12542 | Batch Loss: 0.7537 | Learning Rate: 0.000158 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6594/12542 | Batch Loss: 1.2092 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6595/12542 | Batch Loss: 2.2401 | Learning Rate: 0.000158 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6596/12542 | Batch Loss: 1.3523 | Learning Rate: 0.000158 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6597/12542 | Batch Loss: 1.4538 | Learning Rate: 0.000158 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6598/12542 | Batch Loss: 0.9278 | Learning Rate: 0.000158 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6599/12542 | Batch Loss: 0.7786 | Learning Rate: 0.000158 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6600/12542 | Batch Loss: 3.1439 | Learning Rate: 0.000158 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6601/12542 | Batch Loss: 1.9217 | Learning Rate: 0.000158 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6602/12542 | Batch Loss: 1.9130 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6603/12542 | Batch Loss: 0.9191 | Learning Rate: 0.000158 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6604/12542 | Batch Loss: 0.5240 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6605/12542 | Batch Loss: 0.7528 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6606/12542 | Batch Loss: 1.5613 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6607/12542 | Batch Loss: 1.1357 | Learning Rate: 0.000158 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6608/12542 | Batch Loss: 0.8936 | Learning Rate: 0.000158 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6609/12542 | Batch Loss: 1.5023 | Learning Rate: 0.000158 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6610/12542 | Batch Loss: 2.9728 | Learning Rate: 0.000158 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6611/12542 | Batch Loss: 1.7632 | Learning Rate: 0.000158 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6612/12542 | Batch Loss: 1.5655 | Learning Rate: 0.000158 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6613/12542 | Batch Loss: 2.5842 | Learning Rate: 0.000158 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6614/12542 | Batch Loss: 1.5974 | Learning Rate: 0.000158 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6615/12542 | Batch Loss: 0.4965 | Learning Rate: 0.000158 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6616/12542 | Batch Loss: 2.0058 | Learning Rate: 0.000157 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6617/12542 | Batch Loss: 0.8053 | Learning Rate: 0.000157 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6618/12542 | Batch Loss: 2.2252 | Learning Rate: 0.000157 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6619/12542 | Batch Loss: 0.8469 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6620/12542 | Batch Loss: 1.3372 | Learning Rate: 0.000157 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6621/12542 | Batch Loss: 1.0586 | Learning Rate: 0.000157 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6622/12542 | Batch Loss: 1.4182 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6623/12542 | Batch Loss: 0.9009 | Learning Rate: 0.000157 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6624/12542 | Batch Loss: 2.3309 | Learning Rate: 0.000157 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6625/12542 | Batch Loss: 0.9504 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6626/12542 | Batch Loss: 1.2172 | Learning Rate: 0.000157 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6627/12542 | Batch Loss: 1.4708 | Learning Rate: 0.000157 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6628/12542 | Batch Loss: 1.3992 | Learning Rate: 0.000157 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6629/12542 | Batch Loss: 0.9234 | Learning Rate: 0.000157 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6630/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000157 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6631/12542 | Batch Loss: 0.8624 | Learning Rate: 0.000157 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6632/12542 | Batch Loss: 0.8116 | Learning Rate: 0.000157 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6633/12542 | Batch Loss: 0.6532 | Learning Rate: 0.000157 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6634/12542 | Batch Loss: 1.3498 | Learning Rate: 0.000157 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6635/12542 | Batch Loss: 1.3049 | Learning Rate: 0.000157 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6636/12542 | Batch Loss: 2.4883 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6637/12542 | Batch Loss: 0.7856 | Learning Rate: 0.000157 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6638/12542 | Batch Loss: 0.9164 | Learning Rate: 0.000157 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6639/12542 | Batch Loss: 1.8028 | Learning Rate: 0.000157 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6640/12542 | Batch Loss: 1.2318 | Learning Rate: 0.000157 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6641/12542 | Batch Loss: 1.9593 | Learning Rate: 0.000157 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6642/12542 | Batch Loss: 1.3787 | Learning Rate: 0.000157 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6643/12542 | Batch Loss: 0.9391 | Learning Rate: 0.000157 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6644/12542 | Batch Loss: 2.0838 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6645/12542 | Batch Loss: 1.2574 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6646/12542 | Batch Loss: 0.8473 | Learning Rate: 0.000157 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6647/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6648/12542 | Batch Loss: 1.0091 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6649/12542 | Batch Loss: 1.3354 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6650/12542 | Batch Loss: 2.4078 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6651/12542 | Batch Loss: 1.6182 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6652/12542 | Batch Loss: 1.3340 | Learning Rate: 0.000157 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6653/12542 | Batch Loss: 1.2333 | Learning Rate: 0.000157 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6654/12542 | Batch Loss: 1.5212 | Learning Rate: 0.000156 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6655/12542 | Batch Loss: 2.3304 | Learning Rate: 0.000156 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6656/12542 | Batch Loss: 1.5297 | Learning Rate: 0.000156 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6657/12542 | Batch Loss: 1.8568 | Learning Rate: 0.000156 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6658/12542 | Batch Loss: 0.8023 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6659/12542 | Batch Loss: 2.2644 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6660/12542 | Batch Loss: 0.8173 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6661/12542 | Batch Loss: 0.4995 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6662/12542 | Batch Loss: 1.7986 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6663/12542 | Batch Loss: 1.5554 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6664/12542 | Batch Loss: 2.4468 | Learning Rate: 0.000156 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6665/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000156 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6666/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000156 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6667/12542 | Batch Loss: 0.9221 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6668/12542 | Batch Loss: 0.9762 | Learning Rate: 0.000156 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6669/12542 | Batch Loss: 0.7172 | Learning Rate: 0.000156 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6670/12542 | Batch Loss: 0.5563 | Learning Rate: 0.000156 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6671/12542 | Batch Loss: 1.3317 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6672/12542 | Batch Loss: 0.8211 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6673/12542 | Batch Loss: 0.9678 | Learning Rate: 0.000156 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6674/12542 | Batch Loss: 0.5888 | Learning Rate: 0.000156 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6675/12542 | Batch Loss: 1.0226 | Learning Rate: 0.000156 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6676/12542 | Batch Loss: 0.9759 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6677/12542 | Batch Loss: 1.5582 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6678/12542 | Batch Loss: 1.9244 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6679/12542 | Batch Loss: 1.8250 | Learning Rate: 0.000156 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6680/12542 | Batch Loss: 1.7960 | Learning Rate: 0.000156 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6681/12542 | Batch Loss: 1.8244 | Learning Rate: 0.000156 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6682/12542 | Batch Loss: 0.9011 | Learning Rate: 0.000156 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6683/12542 | Batch Loss: 1.6288 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6684/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6685/12542 | Batch Loss: 1.3622 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6686/12542 | Batch Loss: 0.7134 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6687/12542 | Batch Loss: 0.6110 | Learning Rate: 0.000156 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6688/12542 | Batch Loss: 0.9308 | Learning Rate: 0.000156 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6689/12542 | Batch Loss: 0.7451 | Learning Rate: 0.000156 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6690/12542 | Batch Loss: 1.3517 | Learning Rate: 0.000156 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6691/12542 | Batch Loss: 1.8533 | Learning Rate: 0.000156 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6692/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000155 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6693/12542 | Batch Loss: 1.1450 | Learning Rate: 0.000155 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6694/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6695/12542 | Batch Loss: 2.1320 | Learning Rate: 0.000155 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6696/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000155 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6697/12542 | Batch Loss: 1.8425 | Learning Rate: 0.000155 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6698/12542 | Batch Loss: 0.9172 | Learning Rate: 0.000155 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6699/12542 | Batch Loss: 0.9378 | Learning Rate: 0.000155 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6700/12542 | Batch Loss: 1.4863 | Learning Rate: 0.000155 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 6701/12542 | Batch Loss: 0.5257 | Learning Rate: 0.000155 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6702/12542 | Batch Loss: 0.8916 | Learning Rate: 0.000155 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6703/12542 | Batch Loss: 1.0611 | Learning Rate: 0.000155 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6704/12542 | Batch Loss: 1.2061 | Learning Rate: 0.000155 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6705/12542 | Batch Loss: 1.4368 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6706/12542 | Batch Loss: 1.7096 | Learning Rate: 0.000155 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6707/12542 | Batch Loss: 1.8214 | Learning Rate: 0.000155 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6708/12542 | Batch Loss: 0.7170 | Learning Rate: 0.000155 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6709/12542 | Batch Loss: 1.9025 | Learning Rate: 0.000155 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6710/12542 | Batch Loss: 0.9372 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6711/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000155 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6712/12542 | Batch Loss: 2.9043 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6713/12542 | Batch Loss: 0.9082 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6714/12542 | Batch Loss: 1.1020 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6715/12542 | Batch Loss: 1.3505 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6716/12542 | Batch Loss: 0.3160 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6717/12542 | Batch Loss: 0.4057 | Learning Rate: 0.000155 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6718/12542 | Batch Loss: 1.9340 | Learning Rate: 0.000155 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6719/12542 | Batch Loss: 0.6138 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6720/12542 | Batch Loss: 1.6298 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6721/12542 | Batch Loss: 1.6819 | Learning Rate: 0.000155 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6722/12542 | Batch Loss: 0.8108 | Learning Rate: 0.000155 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6723/12542 | Batch Loss: 1.3918 | Learning Rate: 0.000155 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6724/12542 | Batch Loss: 0.9977 | Learning Rate: 0.000155 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6725/12542 | Batch Loss: 1.6580 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6726/12542 | Batch Loss: 1.6248 | Learning Rate: 0.000155 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6727/12542 | Batch Loss: 1.6405 | Learning Rate: 0.000155 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6728/12542 | Batch Loss: 1.5905 | Learning Rate: 0.000155 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6729/12542 | Batch Loss: 1.7785 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6730/12542 | Batch Loss: 0.9431 | Learning Rate: 0.000154 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6731/12542 | Batch Loss: 0.7360 | Learning Rate: 0.000154 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6732/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000154 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6733/12542 | Batch Loss: 0.7824 | Learning Rate: 0.000154 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6734/12542 | Batch Loss: 1.0695 | Learning Rate: 0.000154 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6735/12542 | Batch Loss: 0.9980 | Learning Rate: 0.000154 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6736/12542 | Batch Loss: 1.3909 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6737/12542 | Batch Loss: 0.8790 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6738/12542 | Batch Loss: 0.9543 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6739/12542 | Batch Loss: 0.9795 | Learning Rate: 0.000154 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6740/12542 | Batch Loss: 2.1408 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6741/12542 | Batch Loss: 1.8890 | Learning Rate: 0.000154 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6742/12542 | Batch Loss: 1.7120 | Learning Rate: 0.000154 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6743/12542 | Batch Loss: 0.9853 | Learning Rate: 0.000154 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6744/12542 | Batch Loss: 0.5891 | Learning Rate: 0.000154 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6745/12542 | Batch Loss: 0.5816 | Learning Rate: 0.000154 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6746/12542 | Batch Loss: 1.6723 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6747/12542 | Batch Loss: 1.3365 | Learning Rate: 0.000154 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6748/12542 | Batch Loss: 1.0606 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6749/12542 | Batch Loss: 1.1492 | Learning Rate: 0.000154 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6750/12542 | Batch Loss: 2.1692 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6751/12542 | Batch Loss: 2.1559 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6752/12542 | Batch Loss: 0.8800 | Learning Rate: 0.000154 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6753/12542 | Batch Loss: 0.6191 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6754/12542 | Batch Loss: 0.7366 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6755/12542 | Batch Loss: 0.9337 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6756/12542 | Batch Loss: 1.0700 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6757/12542 | Batch Loss: 1.3090 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6758/12542 | Batch Loss: 0.7217 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6759/12542 | Batch Loss: 1.1967 | Learning Rate: 0.000154 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6760/12542 | Batch Loss: 1.6768 | Learning Rate: 0.000154 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6761/12542 | Batch Loss: 1.8320 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6762/12542 | Batch Loss: 0.9065 | Learning Rate: 0.000154 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6763/12542 | Batch Loss: 1.9849 | Learning Rate: 0.000154 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6764/12542 | Batch Loss: 1.9635 | Learning Rate: 0.000154 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6765/12542 | Batch Loss: 1.5946 | Learning Rate: 0.000154 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6766/12542 | Batch Loss: 1.5626 | Learning Rate: 0.000154 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6767/12542 | Batch Loss: 1.7004 | Learning Rate: 0.000153 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6768/12542 | Batch Loss: 1.7480 | Learning Rate: 0.000153 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6769/12542 | Batch Loss: 0.4549 | Learning Rate: 0.000153 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6770/12542 | Batch Loss: 0.9144 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6771/12542 | Batch Loss: 1.0979 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6772/12542 | Batch Loss: 0.7587 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6773/12542 | Batch Loss: 2.1515 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6774/12542 | Batch Loss: 1.7219 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6775/12542 | Batch Loss: 1.4973 | Learning Rate: 0.000153 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6776/12542 | Batch Loss: 1.0747 | Learning Rate: 0.000153 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6777/12542 | Batch Loss: 2.7444 | Learning Rate: 0.000153 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6778/12542 | Batch Loss: 0.6281 | Learning Rate: 0.000153 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6779/12542 | Batch Loss: 1.7202 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6780/12542 | Batch Loss: 2.2544 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6781/12542 | Batch Loss: 1.1843 | Learning Rate: 0.000153 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6782/12542 | Batch Loss: 1.0541 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6783/12542 | Batch Loss: 3.1105 | Learning Rate: 0.000153 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6784/12542 | Batch Loss: 1.0076 | Learning Rate: 0.000153 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6785/12542 | Batch Loss: 0.9198 | Learning Rate: 0.000153 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6786/12542 | Batch Loss: 2.1241 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6787/12542 | Batch Loss: 0.7340 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6788/12542 | Batch Loss: 0.4953 | Learning Rate: 0.000153 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6789/12542 | Batch Loss: 0.9424 | Learning Rate: 0.000153 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6790/12542 | Batch Loss: 0.6103 | Learning Rate: 0.000153 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6791/12542 | Batch Loss: 1.3033 | Learning Rate: 0.000153 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6792/12542 | Batch Loss: 0.8370 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6793/12542 | Batch Loss: 1.2067 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6794/12542 | Batch Loss: 1.4031 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6795/12542 | Batch Loss: 1.1930 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6796/12542 | Batch Loss: 0.8685 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6797/12542 | Batch Loss: 1.2495 | Learning Rate: 0.000153 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6798/12542 | Batch Loss: 1.3654 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6799/12542 | Batch Loss: 1.8407 | Learning Rate: 0.000153 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6800/12542 | Batch Loss: 1.5060 | Learning Rate: 0.000153 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6801/12542 | Batch Loss: 1.2284 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6802/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000153 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6803/12542 | Batch Loss: 1.1613 | Learning Rate: 0.000153 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6804/12542 | Batch Loss: 1.1284 | Learning Rate: 0.000153 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6805/12542 | Batch Loss: 0.6639 | Learning Rate: 0.000152 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6806/12542 | Batch Loss: 1.1756 | Learning Rate: 0.000152 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6807/12542 | Batch Loss: 1.5363 | Learning Rate: 0.000152 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6808/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000152 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6809/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000152 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6810/12542 | Batch Loss: 1.0089 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6811/12542 | Batch Loss: 0.8741 | Learning Rate: 0.000152 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 6812/12542 | Batch Loss: 0.4625 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6813/12542 | Batch Loss: 0.7443 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6814/12542 | Batch Loss: 2.0594 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6815/12542 | Batch Loss: 1.1542 | Learning Rate: 0.000152 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6816/12542 | Batch Loss: 1.6996 | Learning Rate: 0.000152 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6817/12542 | Batch Loss: 1.0681 | Learning Rate: 0.000152 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6818/12542 | Batch Loss: 0.6514 | Learning Rate: 0.000152 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6819/12542 | Batch Loss: 1.7890 | Learning Rate: 0.000152 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6820/12542 | Batch Loss: 0.8944 | Learning Rate: 0.000152 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6821/12542 | Batch Loss: 1.8882 | Learning Rate: 0.000152 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6822/12542 | Batch Loss: 1.4091 | Learning Rate: 0.000152 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6823/12542 | Batch Loss: 1.2126 | Learning Rate: 0.000152 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6824/12542 | Batch Loss: 1.6403 | Learning Rate: 0.000152 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6825/12542 | Batch Loss: 0.8877 | Learning Rate: 0.000152 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6826/12542 | Batch Loss: 1.3964 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6827/12542 | Batch Loss: 0.5182 | Learning Rate: 0.000152 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6828/12542 | Batch Loss: 1.3118 | Learning Rate: 0.000152 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 6829/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6830/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6831/12542 | Batch Loss: 0.7602 | Learning Rate: 0.000152 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6832/12542 | Batch Loss: 1.3877 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6833/12542 | Batch Loss: 0.7521 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6834/12542 | Batch Loss: 0.9829 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6835/12542 | Batch Loss: 1.1809 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6836/12542 | Batch Loss: 1.9170 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6837/12542 | Batch Loss: 0.7921 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6838/12542 | Batch Loss: 1.0625 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6839/12542 | Batch Loss: 1.0613 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6840/12542 | Batch Loss: 0.7507 | Learning Rate: 0.000152 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6841/12542 | Batch Loss: 0.6116 | Learning Rate: 0.000152 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6842/12542 | Batch Loss: 1.2683 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6843/12542 | Batch Loss: 1.0686 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6844/12542 | Batch Loss: 2.2280 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6845/12542 | Batch Loss: 1.5491 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6846/12542 | Batch Loss: 0.4453 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6847/12542 | Batch Loss: 1.0627 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6848/12542 | Batch Loss: 1.4838 | Learning Rate: 0.000151 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6849/12542 | Batch Loss: 0.8512 | Learning Rate: 0.000151 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6850/12542 | Batch Loss: 0.8181 | Learning Rate: 0.000151 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6851/12542 | Batch Loss: 1.2998 | Learning Rate: 0.000151 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6852/12542 | Batch Loss: 0.7998 | Learning Rate: 0.000151 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6853/12542 | Batch Loss: 1.3515 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6854/12542 | Batch Loss: 3.2461 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6855/12542 | Batch Loss: 0.8051 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6856/12542 | Batch Loss: 1.3960 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6857/12542 | Batch Loss: 1.2811 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6858/12542 | Batch Loss: 2.1441 | Learning Rate: 0.000151 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6859/12542 | Batch Loss: 0.4672 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6860/12542 | Batch Loss: 0.9232 | Learning Rate: 0.000151 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6861/12542 | Batch Loss: 0.5082 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6862/12542 | Batch Loss: 1.4735 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6863/12542 | Batch Loss: 0.8501 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6864/12542 | Batch Loss: 1.0145 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6865/12542 | Batch Loss: 0.9472 | Learning Rate: 0.000151 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6866/12542 | Batch Loss: 2.0483 | Learning Rate: 0.000151 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6867/12542 | Batch Loss: 0.9607 | Learning Rate: 0.000151 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6868/12542 | Batch Loss: 3.2376 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6869/12542 | Batch Loss: 2.8122 | Learning Rate: 0.000151 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6870/12542 | Batch Loss: 1.5444 | Learning Rate: 0.000151 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6871/12542 | Batch Loss: 1.4783 | Learning Rate: 0.000151 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6872/12542 | Batch Loss: 0.6488 | Learning Rate: 0.000151 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 6873/12542 | Batch Loss: 0.6111 | Learning Rate: 0.000151 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6874/12542 | Batch Loss: 1.1246 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6875/12542 | Batch Loss: 1.6817 | Learning Rate: 0.000151 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6876/12542 | Batch Loss: 0.8534 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6877/12542 | Batch Loss: 1.0363 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6878/12542 | Batch Loss: 2.0354 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6879/12542 | Batch Loss: 1.1041 | Learning Rate: 0.000151 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6880/12542 | Batch Loss: 0.8713 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6881/12542 | Batch Loss: 1.9386 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6882/12542 | Batch Loss: 1.0443 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6883/12542 | Batch Loss: 1.8156 | Learning Rate: 0.000150 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6884/12542 | Batch Loss: 1.7272 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6885/12542 | Batch Loss: 1.0349 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6886/12542 | Batch Loss: 1.4302 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6887/12542 | Batch Loss: 1.8760 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6888/12542 | Batch Loss: 1.3338 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6889/12542 | Batch Loss: 2.2449 | Learning Rate: 0.000150 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6890/12542 | Batch Loss: 1.0462 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6891/12542 | Batch Loss: 0.6763 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6892/12542 | Batch Loss: 1.4846 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6893/12542 | Batch Loss: 0.5150 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6894/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6895/12542 | Batch Loss: 1.1861 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6896/12542 | Batch Loss: 2.1629 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6897/12542 | Batch Loss: 0.8617 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6898/12542 | Batch Loss: 2.2596 | Learning Rate: 0.000150 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6899/12542 | Batch Loss: 1.0647 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6900/12542 | Batch Loss: 1.5322 | Learning Rate: 0.000150 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6901/12542 | Batch Loss: 0.9723 | Learning Rate: 0.000150 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6902/12542 | Batch Loss: 1.4392 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6903/12542 | Batch Loss: 0.9186 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6904/12542 | Batch Loss: 0.6113 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6905/12542 | Batch Loss: 1.0384 | Learning Rate: 0.000150 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6906/12542 | Batch Loss: 2.5074 | Learning Rate: 0.000150 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6907/12542 | Batch Loss: 2.5704 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6908/12542 | Batch Loss: 2.6923 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6909/12542 | Batch Loss: 0.6962 | Learning Rate: 0.000150 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6910/12542 | Batch Loss: 1.4743 | Learning Rate: 0.000150 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6911/12542 | Batch Loss: 1.6884 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6912/12542 | Batch Loss: 1.0471 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6913/12542 | Batch Loss: 1.7459 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6914/12542 | Batch Loss: 1.4807 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6915/12542 | Batch Loss: 0.5998 | Learning Rate: 0.000150 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6916/12542 | Batch Loss: 0.6658 | Learning Rate: 0.000150 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6917/12542 | Batch Loss: 0.7155 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6918/12542 | Batch Loss: 0.9649 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6919/12542 | Batch Loss: 1.0270 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6920/12542 | Batch Loss: 0.6385 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6921/12542 | Batch Loss: 1.2347 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6922/12542 | Batch Loss: 1.7249 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6923/12542 | Batch Loss: 1.2015 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6924/12542 | Batch Loss: 1.2005 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6925/12542 | Batch Loss: 1.4064 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6926/12542 | Batch Loss: 0.7215 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6927/12542 | Batch Loss: 1.6204 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6928/12542 | Batch Loss: 2.1845 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6929/12542 | Batch Loss: 0.4953 | Learning Rate: 0.000149 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6930/12542 | Batch Loss: 0.9078 | Learning Rate: 0.000149 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6931/12542 | Batch Loss: 0.9165 | Learning Rate: 0.000149 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6932/12542 | Batch Loss: 3.0249 | Learning Rate: 0.000149 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6933/12542 | Batch Loss: 2.4340 | Learning Rate: 0.000149 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6934/12542 | Batch Loss: 2.0610 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6935/12542 | Batch Loss: 1.3882 | Learning Rate: 0.000149 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6936/12542 | Batch Loss: 0.7672 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6937/12542 | Batch Loss: 1.6297 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6938/12542 | Batch Loss: 2.0777 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6939/12542 | Batch Loss: 1.0693 | Learning Rate: 0.000149 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6940/12542 | Batch Loss: 1.2054 | Learning Rate: 0.000149 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6941/12542 | Batch Loss: 1.1356 | Learning Rate: 0.000149 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6942/12542 | Batch Loss: 2.6998 | Learning Rate: 0.000149 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6943/12542 | Batch Loss: 1.1992 | Learning Rate: 0.000149 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6944/12542 | Batch Loss: 0.7903 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6945/12542 | Batch Loss: 1.5454 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6946/12542 | Batch Loss: 1.2912 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6947/12542 | Batch Loss: 1.0414 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6948/12542 | Batch Loss: 1.8715 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6949/12542 | Batch Loss: 1.1410 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6950/12542 | Batch Loss: 1.2079 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6951/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6952/12542 | Batch Loss: 1.6057 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6953/12542 | Batch Loss: 1.6849 | Learning Rate: 0.000149 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6954/12542 | Batch Loss: 0.7915 | Learning Rate: 0.000149 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6955/12542 | Batch Loss: 0.8879 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6956/12542 | Batch Loss: 3.2725 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6957/12542 | Batch Loss: 1.6092 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6958/12542 | Batch Loss: 1.2511 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6959/12542 | Batch Loss: 1.4353 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6960/12542 | Batch Loss: 1.3557 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6961/12542 | Batch Loss: 2.1855 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6962/12542 | Batch Loss: 0.7650 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6963/12542 | Batch Loss: 1.0149 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6964/12542 | Batch Loss: 1.2728 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6965/12542 | Batch Loss: 0.8876 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6966/12542 | Batch Loss: 1.6308 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6967/12542 | Batch Loss: 2.4122 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6968/12542 | Batch Loss: 0.9711 | Learning Rate: 0.000148 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6969/12542 | Batch Loss: 1.1392 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6970/12542 | Batch Loss: 0.8861 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6971/12542 | Batch Loss: 1.7915 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6972/12542 | Batch Loss: 1.6191 | Learning Rate: 0.000148 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6973/12542 | Batch Loss: 1.0959 | Learning Rate: 0.000148 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6974/12542 | Batch Loss: 1.7002 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6975/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6976/12542 | Batch Loss: 0.8091 | Learning Rate: 0.000148 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6977/12542 | Batch Loss: 2.3942 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6978/12542 | Batch Loss: 1.2924 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6979/12542 | Batch Loss: 0.7754 | Learning Rate: 0.000148 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 6980/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000148 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6981/12542 | Batch Loss: 1.9730 | Learning Rate: 0.000148 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6982/12542 | Batch Loss: 1.7545 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6983/12542 | Batch Loss: 2.3133 | Learning Rate: 0.000148 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6984/12542 | Batch Loss: 1.5799 | Learning Rate: 0.000148 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6985/12542 | Batch Loss: 1.3335 | Learning Rate: 0.000148 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6986/12542 | Batch Loss: 0.6763 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6987/12542 | Batch Loss: 0.8016 | Learning Rate: 0.000148 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 6988/12542 | Batch Loss: 0.9250 | Learning Rate: 0.000148 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6989/12542 | Batch Loss: 0.2837 | Learning Rate: 0.000148 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 6990/12542 | Batch Loss: 1.7637 | Learning Rate: 0.000148 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6991/12542 | Batch Loss: 1.3286 | Learning Rate: 0.000148 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 6992/12542 | Batch Loss: 1.9584 | Learning Rate: 0.000148 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 6993/12542 | Batch Loss: 0.7254 | Learning Rate: 0.000147 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6994/12542 | Batch Loss: 0.8166 | Learning Rate: 0.000147 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 6995/12542 | Batch Loss: 1.8055 | Learning Rate: 0.000147 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 6996/12542 | Batch Loss: 0.8729 | Learning Rate: 0.000147 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 6997/12542 | Batch Loss: 1.7815 | Learning Rate: 0.000147 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 6998/12542 | Batch Loss: 1.1474 | Learning Rate: 0.000147 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 6999/12542 | Batch Loss: 1.6541 | Learning Rate: 0.000147 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7000/12542 | Batch Loss: 1.6890 | Learning Rate: 0.000147 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7001/12542 | Batch Loss: 1.1231 | Learning Rate: 0.000147 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7002/12542 | Batch Loss: 1.2770 | Learning Rate: 0.000147 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7003/12542 | Batch Loss: 0.6387 | Learning Rate: 0.000147 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7004/12542 | Batch Loss: 1.1719 | Learning Rate: 0.000147 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7005/12542 | Batch Loss: 0.5488 | Learning Rate: 0.000147 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7006/12542 | Batch Loss: 0.7122 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7007/12542 | Batch Loss: 2.0180 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7008/12542 | Batch Loss: 0.8203 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7009/12542 | Batch Loss: 0.7116 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7010/12542 | Batch Loss: 0.3276 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7011/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7012/12542 | Batch Loss: 1.8526 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7013/12542 | Batch Loss: 0.9780 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7014/12542 | Batch Loss: 0.9951 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7015/12542 | Batch Loss: 1.7317 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7016/12542 | Batch Loss: 0.7547 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7017/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7018/12542 | Batch Loss: 1.1542 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7019/12542 | Batch Loss: 1.5649 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7020/12542 | Batch Loss: 1.6769 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7021/12542 | Batch Loss: 1.0753 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7022/12542 | Batch Loss: 0.8717 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7023/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7024/12542 | Batch Loss: 1.6074 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7025/12542 | Batch Loss: 0.6599 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7026/12542 | Batch Loss: 0.5151 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7027/12542 | Batch Loss: 1.4309 | Learning Rate: 0.000147 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7028/12542 | Batch Loss: 1.8749 | Learning Rate: 0.000147 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7029/12542 | Batch Loss: 1.1566 | Learning Rate: 0.000147 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7030/12542 | Batch Loss: 2.3405 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7031/12542 | Batch Loss: 1.8742 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7032/12542 | Batch Loss: 0.8777 | Learning Rate: 0.000146 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7033/12542 | Batch Loss: 1.4406 | Learning Rate: 0.000146 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7034/12542 | Batch Loss: 1.2241 | Learning Rate: 0.000146 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7035/12542 | Batch Loss: 0.8009 | Learning Rate: 0.000146 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7036/12542 | Batch Loss: 1.9337 | Learning Rate: 0.000146 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7037/12542 | Batch Loss: 1.5018 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7038/12542 | Batch Loss: 0.9907 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7039/12542 | Batch Loss: 1.3850 | Learning Rate: 0.000146 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7040/12542 | Batch Loss: 1.0724 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7041/12542 | Batch Loss: 1.6753 | Learning Rate: 0.000146 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7042/12542 | Batch Loss: 0.7275 | Learning Rate: 0.000146 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7043/12542 | Batch Loss: 1.2093 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7044/12542 | Batch Loss: 1.0233 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7045/12542 | Batch Loss: 1.4630 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7046/12542 | Batch Loss: 1.3840 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7047/12542 | Batch Loss: 1.1248 | Learning Rate: 0.000146 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7048/12542 | Batch Loss: 0.9934 | Learning Rate: 0.000146 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7049/12542 | Batch Loss: 1.3643 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7050/12542 | Batch Loss: 1.3859 | Learning Rate: 0.000146 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7051/12542 | Batch Loss: 1.3969 | Learning Rate: 0.000146 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7052/12542 | Batch Loss: 1.2445 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7053/12542 | Batch Loss: 1.0462 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7054/12542 | Batch Loss: 0.8767 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7055/12542 | Batch Loss: 0.8063 | Learning Rate: 0.000146 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7056/12542 | Batch Loss: 0.4770 | Learning Rate: 0.000146 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7057/12542 | Batch Loss: 1.4719 | Learning Rate: 0.000146 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7058/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7059/12542 | Batch Loss: 1.2645 | Learning Rate: 0.000146 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7060/12542 | Batch Loss: 2.0660 | Learning Rate: 0.000146 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7061/12542 | Batch Loss: 1.3972 | Learning Rate: 0.000146 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7062/12542 | Batch Loss: 1.2050 | Learning Rate: 0.000146 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7063/12542 | Batch Loss: 2.7080 | Learning Rate: 0.000146 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7064/12542 | Batch Loss: 0.6286 | Learning Rate: 0.000146 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7065/12542 | Batch Loss: 0.8924 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7066/12542 | Batch Loss: 2.1098 | Learning Rate: 0.000146 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7067/12542 | Batch Loss: 1.6554 | Learning Rate: 0.000146 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7068/12542 | Batch Loss: 0.6099 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7069/12542 | Batch Loss: 0.9350 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7070/12542 | Batch Loss: 1.8204 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7071/12542 | Batch Loss: 1.7238 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7072/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7073/12542 | Batch Loss: 1.7202 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7074/12542 | Batch Loss: 0.6627 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7075/12542 | Batch Loss: 0.7353 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7076/12542 | Batch Loss: 1.4960 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7077/12542 | Batch Loss: 1.8020 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7078/12542 | Batch Loss: 1.1857 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7079/12542 | Batch Loss: 1.5156 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7080/12542 | Batch Loss: 0.7381 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7081/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000145 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7082/12542 | Batch Loss: 1.2141 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7083/12542 | Batch Loss: 1.3127 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7084/12542 | Batch Loss: 0.8996 | Learning Rate: 0.000145 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7085/12542 | Batch Loss: 0.4846 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7086/12542 | Batch Loss: 2.5011 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7087/12542 | Batch Loss: 0.7089 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7088/12542 | Batch Loss: 2.4348 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7089/12542 | Batch Loss: 0.4399 | Learning Rate: 0.000145 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7090/12542 | Batch Loss: 1.5375 | Learning Rate: 0.000145 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7091/12542 | Batch Loss: 0.6600 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7092/12542 | Batch Loss: 1.1880 | Learning Rate: 0.000145 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7093/12542 | Batch Loss: 0.8522 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7094/12542 | Batch Loss: 0.5920 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7095/12542 | Batch Loss: 2.4163 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7096/12542 | Batch Loss: 1.9680 | Learning Rate: 0.000145 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7097/12542 | Batch Loss: 1.4176 | Learning Rate: 0.000145 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7098/12542 | Batch Loss: 1.0308 | Learning Rate: 0.000145 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7099/12542 | Batch Loss: 2.1468 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7100/12542 | Batch Loss: 1.5631 | Learning Rate: 0.000145 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7101/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7102/12542 | Batch Loss: 1.5740 | Learning Rate: 0.000145 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7103/12542 | Batch Loss: 1.3388 | Learning Rate: 0.000145 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7104/12542 | Batch Loss: 1.3368 | Learning Rate: 0.000145 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7105/12542 | Batch Loss: 0.9788 | Learning Rate: 0.000145 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7106/12542 | Batch Loss: 1.6697 | Learning Rate: 0.000144 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7107/12542 | Batch Loss: 1.3376 | Learning Rate: 0.000144 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7108/12542 | Batch Loss: 1.4043 | Learning Rate: 0.000144 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7109/12542 | Batch Loss: 0.4095 | Learning Rate: 0.000144 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7110/12542 | Batch Loss: 1.4563 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7111/12542 | Batch Loss: 1.4050 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7112/12542 | Batch Loss: 1.6344 | Learning Rate: 0.000144 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7113/12542 | Batch Loss: 1.8945 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7114/12542 | Batch Loss: 1.1170 | Learning Rate: 0.000144 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7115/12542 | Batch Loss: 1.9782 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7116/12542 | Batch Loss: 1.8001 | Learning Rate: 0.000144 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7117/12542 | Batch Loss: 0.9363 | Learning Rate: 0.000144 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7118/12542 | Batch Loss: 1.5408 | Learning Rate: 0.000144 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7119/12542 | Batch Loss: 0.7944 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7120/12542 | Batch Loss: 1.0430 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7121/12542 | Batch Loss: 0.7053 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7122/12542 | Batch Loss: 0.8402 | Learning Rate: 0.000144 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7123/12542 | Batch Loss: 0.7056 | Learning Rate: 0.000144 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7124/12542 | Batch Loss: 0.7275 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7125/12542 | Batch Loss: 1.7449 | Learning Rate: 0.000144 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7126/12542 | Batch Loss: 0.7494 | Learning Rate: 0.000144 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7127/12542 | Batch Loss: 0.5806 | Learning Rate: 0.000144 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7128/12542 | Batch Loss: 1.6723 | Learning Rate: 0.000144 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7129/12542 | Batch Loss: 1.4151 | Learning Rate: 0.000144 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7130/12542 | Batch Loss: 1.3502 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7131/12542 | Batch Loss: 1.3633 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7132/12542 | Batch Loss: 1.8900 | Learning Rate: 0.000144 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7133/12542 | Batch Loss: 1.0471 | Learning Rate: 0.000144 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7134/12542 | Batch Loss: 1.2597 | Learning Rate: 0.000144 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7135/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7136/12542 | Batch Loss: 1.6026 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7137/12542 | Batch Loss: 5.0848 | Learning Rate: 0.000144 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7138/12542 | Batch Loss: 1.7292 | Learning Rate: 0.000144 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7139/12542 | Batch Loss: 1.3991 | Learning Rate: 0.000144 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7140/12542 | Batch Loss: 1.4699 | Learning Rate: 0.000144 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7141/12542 | Batch Loss: 0.8438 | Learning Rate: 0.000144 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7142/12542 | Batch Loss: 2.2616 | Learning Rate: 0.000144 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7143/12542 | Batch Loss: 2.1070 | Learning Rate: 0.000143 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 7144/12542 | Batch Loss: 1.6192 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7145/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000143 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7146/12542 | Batch Loss: 0.5878 | Learning Rate: 0.000143 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7147/12542 | Batch Loss: 1.9200 | Learning Rate: 0.000143 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7148/12542 | Batch Loss: 1.6317 | Learning Rate: 0.000143 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7149/12542 | Batch Loss: 1.1567 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7150/12542 | Batch Loss: 1.2209 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7151/12542 | Batch Loss: 1.4238 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7152/12542 | Batch Loss: 1.2364 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7153/12542 | Batch Loss: 2.2549 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7154/12542 | Batch Loss: 1.2430 | Learning Rate: 0.000143 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7155/12542 | Batch Loss: 1.0369 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7156/12542 | Batch Loss: 2.1556 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7157/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000143 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7158/12542 | Batch Loss: 1.4621 | Learning Rate: 0.000143 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7159/12542 | Batch Loss: 1.6959 | Learning Rate: 0.000143 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7160/12542 | Batch Loss: 0.9610 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7161/12542 | Batch Loss: 1.7061 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7162/12542 | Batch Loss: 0.8441 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7163/12542 | Batch Loss: 1.7663 | Learning Rate: 0.000143 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7164/12542 | Batch Loss: 0.8909 | Learning Rate: 0.000143 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7165/12542 | Batch Loss: 1.0559 | Learning Rate: 0.000143 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7166/12542 | Batch Loss: 1.0154 | Learning Rate: 0.000143 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7167/12542 | Batch Loss: 0.9473 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7168/12542 | Batch Loss: 1.8386 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7169/12542 | Batch Loss: 0.8833 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7170/12542 | Batch Loss: 1.3873 | Learning Rate: 0.000143 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7171/12542 | Batch Loss: 2.6620 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7172/12542 | Batch Loss: 0.9540 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7173/12542 | Batch Loss: 1.7152 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7174/12542 | Batch Loss: 0.9364 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7175/12542 | Batch Loss: 0.5139 | Learning Rate: 0.000143 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7176/12542 | Batch Loss: 0.6727 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7177/12542 | Batch Loss: 2.0428 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7178/12542 | Batch Loss: 1.9140 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7179/12542 | Batch Loss: 0.7052 | Learning Rate: 0.000143 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7180/12542 | Batch Loss: 0.6548 | Learning Rate: 0.000143 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7181/12542 | Batch Loss: 2.0146 | Learning Rate: 0.000142 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7182/12542 | Batch Loss: 2.1023 | Learning Rate: 0.000142 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7183/12542 | Batch Loss: 0.8931 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7184/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7185/12542 | Batch Loss: 1.0558 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7186/12542 | Batch Loss: 1.2755 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7187/12542 | Batch Loss: 3.0957 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7188/12542 | Batch Loss: 1.5495 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7189/12542 | Batch Loss: 1.5186 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7190/12542 | Batch Loss: 1.5697 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7191/12542 | Batch Loss: 1.4134 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7192/12542 | Batch Loss: 0.9070 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7193/12542 | Batch Loss: 0.6570 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7194/12542 | Batch Loss: 0.6732 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7195/12542 | Batch Loss: 0.9126 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7196/12542 | Batch Loss: 1.5150 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7197/12542 | Batch Loss: 2.7015 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7198/12542 | Batch Loss: 2.9004 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7199/12542 | Batch Loss: 0.7926 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7200/12542 | Batch Loss: 1.2850 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7201/12542 | Batch Loss: 0.8217 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7202/12542 | Batch Loss: 1.7778 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7203/12542 | Batch Loss: 0.6702 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7204/12542 | Batch Loss: 1.6307 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7205/12542 | Batch Loss: 1.7910 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7206/12542 | Batch Loss: 1.3992 | Learning Rate: 0.000142 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7207/12542 | Batch Loss: 0.4339 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7208/12542 | Batch Loss: 2.8151 | Learning Rate: 0.000142 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7209/12542 | Batch Loss: 1.1229 | Learning Rate: 0.000142 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7210/12542 | Batch Loss: 1.5622 | Learning Rate: 0.000142 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7211/12542 | Batch Loss: 0.9310 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7212/12542 | Batch Loss: 2.1509 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7213/12542 | Batch Loss: 2.0111 | Learning Rate: 0.000142 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7214/12542 | Batch Loss: 0.8317 | Learning Rate: 0.000142 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7215/12542 | Batch Loss: 1.2688 | Learning Rate: 0.000142 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7216/12542 | Batch Loss: 0.7827 | Learning Rate: 0.000142 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7217/12542 | Batch Loss: 3.6561 | Learning Rate: 0.000142 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7218/12542 | Batch Loss: 1.5510 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7219/12542 | Batch Loss: 1.8792 | Learning Rate: 0.000141 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7220/12542 | Batch Loss: 2.3343 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7221/12542 | Batch Loss: 0.7566 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7222/12542 | Batch Loss: 0.9357 | Learning Rate: 0.000141 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7223/12542 | Batch Loss: 1.5837 | Learning Rate: 0.000141 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7224/12542 | Batch Loss: 1.3824 | Learning Rate: 0.000141 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7225/12542 | Batch Loss: 1.7765 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7226/12542 | Batch Loss: 1.0444 | Learning Rate: 0.000141 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7227/12542 | Batch Loss: 1.1470 | Learning Rate: 0.000141 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7228/12542 | Batch Loss: 1.1720 | Learning Rate: 0.000141 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7229/12542 | Batch Loss: 0.5072 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7230/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7231/12542 | Batch Loss: 2.9914 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7232/12542 | Batch Loss: 1.1653 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7233/12542 | Batch Loss: 1.1506 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7234/12542 | Batch Loss: 1.5775 | Learning Rate: 0.000141 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7235/12542 | Batch Loss: 2.1242 | Learning Rate: 0.000141 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7236/12542 | Batch Loss: 2.7693 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7237/12542 | Batch Loss: 1.1544 | Learning Rate: 0.000141 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7238/12542 | Batch Loss: 1.3820 | Learning Rate: 0.000141 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7239/12542 | Batch Loss: 0.7999 | Learning Rate: 0.000141 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7240/12542 | Batch Loss: 1.3912 | Learning Rate: 0.000141 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7241/12542 | Batch Loss: 1.2979 | Learning Rate: 0.000141 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7242/12542 | Batch Loss: 1.5386 | Learning Rate: 0.000141 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7243/12542 | Batch Loss: 1.8182 | Learning Rate: 0.000141 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7244/12542 | Batch Loss: 0.8621 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7245/12542 | Batch Loss: 1.7930 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7246/12542 | Batch Loss: 1.4388 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7247/12542 | Batch Loss: 0.8391 | Learning Rate: 0.000141 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7248/12542 | Batch Loss: 0.5821 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7249/12542 | Batch Loss: 1.2263 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7250/12542 | Batch Loss: 0.6357 | Learning Rate: 0.000141 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7251/12542 | Batch Loss: 1.7200 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7252/12542 | Batch Loss: 0.6788 | Learning Rate: 0.000141 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7253/12542 | Batch Loss: 1.9892 | Learning Rate: 0.000141 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7254/12542 | Batch Loss: 1.3108 | Learning Rate: 0.000141 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7255/12542 | Batch Loss: 1.4416 | Learning Rate: 0.000141 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7256/12542 | Batch Loss: 0.6611 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7257/12542 | Batch Loss: 1.4569 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7258/12542 | Batch Loss: 1.7005 | Learning Rate: 0.000140 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7259/12542 | Batch Loss: 1.1459 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7260/12542 | Batch Loss: 1.5540 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7261/12542 | Batch Loss: 0.7923 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7262/12542 | Batch Loss: 1.3599 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7263/12542 | Batch Loss: 1.3296 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7264/12542 | Batch Loss: 2.8622 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7265/12542 | Batch Loss: 0.6103 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7266/12542 | Batch Loss: 2.1352 | Learning Rate: 0.000140 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7267/12542 | Batch Loss: 3.1137 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7268/12542 | Batch Loss: 0.6596 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7269/12542 | Batch Loss: 1.0757 | Learning Rate: 0.000140 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7270/12542 | Batch Loss: 0.6914 | Learning Rate: 0.000140 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7271/12542 | Batch Loss: 1.8041 | Learning Rate: 0.000140 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7272/12542 | Batch Loss: 1.3439 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7273/12542 | Batch Loss: 2.6247 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7274/12542 | Batch Loss: 1.1400 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7275/12542 | Batch Loss: 1.2933 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7276/12542 | Batch Loss: 2.0984 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7277/12542 | Batch Loss: 0.9694 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7278/12542 | Batch Loss: 0.6232 | Learning Rate: 0.000140 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7279/12542 | Batch Loss: 1.4360 | Learning Rate: 0.000140 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7280/12542 | Batch Loss: 1.0967 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7281/12542 | Batch Loss: 1.0123 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7282/12542 | Batch Loss: 2.6054 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7283/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000140 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7284/12542 | Batch Loss: 1.8799 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7285/12542 | Batch Loss: 2.7222 | Learning Rate: 0.000140 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7286/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000140 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7287/12542 | Batch Loss: 1.1312 | Learning Rate: 0.000140 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7288/12542 | Batch Loss: 1.5697 | Learning Rate: 0.000140 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7289/12542 | Batch Loss: 2.6595 | Learning Rate: 0.000140 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7290/12542 | Batch Loss: 1.6874 | Learning Rate: 0.000140 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7291/12542 | Batch Loss: 1.6028 | Learning Rate: 0.000140 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7292/12542 | Batch Loss: 2.6807 | Learning Rate: 0.000140 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7293/12542 | Batch Loss: 0.6688 | Learning Rate: 0.000140 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7294/12542 | Batch Loss: 0.9561 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7295/12542 | Batch Loss: 1.0110 | Learning Rate: 0.000139 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7296/12542 | Batch Loss: 2.2234 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7297/12542 | Batch Loss: 1.8026 | Learning Rate: 0.000139 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7298/12542 | Batch Loss: 2.0790 | Learning Rate: 0.000139 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7299/12542 | Batch Loss: 1.3438 | Learning Rate: 0.000139 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7300/12542 | Batch Loss: 0.7693 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7301/12542 | Batch Loss: 1.0086 | Learning Rate: 0.000139 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7302/12542 | Batch Loss: 3.5479 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7303/12542 | Batch Loss: 0.4270 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7304/12542 | Batch Loss: 1.0248 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7305/12542 | Batch Loss: 1.1054 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7306/12542 | Batch Loss: 2.0989 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7307/12542 | Batch Loss: 0.9138 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7308/12542 | Batch Loss: 1.6873 | Learning Rate: 0.000139 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7309/12542 | Batch Loss: 3.3089 | Learning Rate: 0.000139 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7310/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000139 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7311/12542 | Batch Loss: 1.1390 | Learning Rate: 0.000139 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7312/12542 | Batch Loss: 1.2809 | Learning Rate: 0.000139 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7313/12542 | Batch Loss: 1.7098 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7314/12542 | Batch Loss: 1.4911 | Learning Rate: 0.000139 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7315/12542 | Batch Loss: 1.5219 | Learning Rate: 0.000139 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7316/12542 | Batch Loss: 1.1644 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7317/12542 | Batch Loss: 1.0069 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7318/12542 | Batch Loss: 0.8809 | Learning Rate: 0.000139 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7319/12542 | Batch Loss: 1.0309 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7320/12542 | Batch Loss: 0.8830 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7321/12542 | Batch Loss: 1.5321 | Learning Rate: 0.000139 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7322/12542 | Batch Loss: 2.3735 | Learning Rate: 0.000139 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7323/12542 | Batch Loss: 0.5979 | Learning Rate: 0.000139 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7324/12542 | Batch Loss: 1.2110 | Learning Rate: 0.000139 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7325/12542 | Batch Loss: 1.3080 | Learning Rate: 0.000139 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7326/12542 | Batch Loss: 2.0692 | Learning Rate: 0.000139 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7327/12542 | Batch Loss: 0.5736 | Learning Rate: 0.000139 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7328/12542 | Batch Loss: 0.8007 | Learning Rate: 0.000139 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7329/12542 | Batch Loss: 0.5684 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7330/12542 | Batch Loss: 1.7878 | Learning Rate: 0.000139 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7331/12542 | Batch Loss: 0.6458 | Learning Rate: 0.000138 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7332/12542 | Batch Loss: 2.5192 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7333/12542 | Batch Loss: 1.8068 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7334/12542 | Batch Loss: 1.2848 | Learning Rate: 0.000138 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7335/12542 | Batch Loss: 0.7778 | Learning Rate: 0.000138 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7336/12542 | Batch Loss: 1.0307 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7337/12542 | Batch Loss: 0.9972 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7338/12542 | Batch Loss: 0.6974 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7339/12542 | Batch Loss: 1.2620 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7340/12542 | Batch Loss: 0.7957 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7341/12542 | Batch Loss: 1.3316 | Learning Rate: 0.000138 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7342/12542 | Batch Loss: 1.3585 | Learning Rate: 0.000138 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7343/12542 | Batch Loss: 0.6373 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7344/12542 | Batch Loss: 1.3316 | Learning Rate: 0.000138 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7345/12542 | Batch Loss: 1.2998 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7346/12542 | Batch Loss: 1.3261 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7347/12542 | Batch Loss: 1.5983 | Learning Rate: 0.000138 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7348/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000138 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7349/12542 | Batch Loss: 2.1549 | Learning Rate: 0.000138 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7350/12542 | Batch Loss: 0.9599 | Learning Rate: 0.000138 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7351/12542 | Batch Loss: 0.9871 | Learning Rate: 0.000138 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7352/12542 | Batch Loss: 0.5199 | Learning Rate: 0.000138 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7353/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000138 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7354/12542 | Batch Loss: 0.9058 | Learning Rate: 0.000138 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7355/12542 | Batch Loss: 0.7907 | Learning Rate: 0.000138 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7356/12542 | Batch Loss: 0.8367 | Learning Rate: 0.000138 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7357/12542 | Batch Loss: 1.4976 | Learning Rate: 0.000138 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7358/12542 | Batch Loss: 0.8856 | Learning Rate: 0.000138 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7359/12542 | Batch Loss: 1.7451 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7360/12542 | Batch Loss: 1.1185 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7361/12542 | Batch Loss: 1.6073 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7362/12542 | Batch Loss: 3.1182 | Learning Rate: 0.000138 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7363/12542 | Batch Loss: 1.0894 | Learning Rate: 0.000138 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7364/12542 | Batch Loss: 2.3275 | Learning Rate: 0.000138 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7365/12542 | Batch Loss: 2.2136 | Learning Rate: 0.000138 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7366/12542 | Batch Loss: 1.8093 | Learning Rate: 0.000138 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7367/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000138 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7368/12542 | Batch Loss: 1.4938 | Learning Rate: 0.000138 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7369/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7370/12542 | Batch Loss: 0.7390 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7371/12542 | Batch Loss: 1.0467 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7372/12542 | Batch Loss: 1.0581 | Learning Rate: 0.000137 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7373/12542 | Batch Loss: 0.9275 | Learning Rate: 0.000137 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7374/12542 | Batch Loss: 2.0556 | Learning Rate: 0.000137 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7375/12542 | Batch Loss: 1.4657 | Learning Rate: 0.000137 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7376/12542 | Batch Loss: 0.7401 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7377/12542 | Batch Loss: 0.5088 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7378/12542 | Batch Loss: 1.4715 | Learning Rate: 0.000137 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7379/12542 | Batch Loss: 1.5445 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7380/12542 | Batch Loss: 1.3433 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7381/12542 | Batch Loss: 2.5455 | Learning Rate: 0.000137 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7382/12542 | Batch Loss: 0.5156 | Learning Rate: 0.000137 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7383/12542 | Batch Loss: 1.3277 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7384/12542 | Batch Loss: 1.2558 | Learning Rate: 0.000137 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7385/12542 | Batch Loss: 1.2286 | Learning Rate: 0.000137 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7386/12542 | Batch Loss: 2.3874 | Learning Rate: 0.000137 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7387/12542 | Batch Loss: 1.9837 | Learning Rate: 0.000137 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7388/12542 | Batch Loss: 1.3687 | Learning Rate: 0.000137 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7389/12542 | Batch Loss: 2.0337 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7390/12542 | Batch Loss: 1.4896 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7391/12542 | Batch Loss: 0.8155 | Learning Rate: 0.000137 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7392/12542 | Batch Loss: 3.4985 | Learning Rate: 0.000137 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7393/12542 | Batch Loss: 2.1977 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7394/12542 | Batch Loss: 1.4748 | Learning Rate: 0.000137 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7395/12542 | Batch Loss: 0.9634 | Learning Rate: 0.000137 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7396/12542 | Batch Loss: 1.3408 | Learning Rate: 0.000137 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7397/12542 | Batch Loss: 0.5653 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7398/12542 | Batch Loss: 0.9982 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7399/12542 | Batch Loss: 1.0874 | Learning Rate: 0.000137 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7400/12542 | Batch Loss: 1.3090 | Learning Rate: 0.000137 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7401/12542 | Batch Loss: 0.7965 | Learning Rate: 0.000137 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7402/12542 | Batch Loss: 0.9080 | Learning Rate: 0.000137 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7403/12542 | Batch Loss: 1.5704 | Learning Rate: 0.000137 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7404/12542 | Batch Loss: 0.9764 | Learning Rate: 0.000137 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7405/12542 | Batch Loss: 0.7276 | Learning Rate: 0.000137 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7406/12542 | Batch Loss: 1.5735 | Learning Rate: 0.000137 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7407/12542 | Batch Loss: 1.5721 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7408/12542 | Batch Loss: 1.0201 | Learning Rate: 0.000136 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7409/12542 | Batch Loss: 3.2376 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7410/12542 | Batch Loss: 0.8156 | Learning Rate: 0.000136 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7411/12542 | Batch Loss: 2.3101 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7412/12542 | Batch Loss: 1.0614 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7413/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7414/12542 | Batch Loss: 0.5437 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7415/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000136 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7416/12542 | Batch Loss: 1.4490 | Learning Rate: 0.000136 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7417/12542 | Batch Loss: 1.8467 | Learning Rate: 0.000136 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7418/12542 | Batch Loss: 1.0625 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7419/12542 | Batch Loss: 4.1701 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7420/12542 | Batch Loss: 1.5792 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7421/12542 | Batch Loss: 0.8869 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7422/12542 | Batch Loss: 1.2149 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7423/12542 | Batch Loss: 1.6359 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7424/12542 | Batch Loss: 1.5604 | Learning Rate: 0.000136 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7425/12542 | Batch Loss: 2.3395 | Learning Rate: 0.000136 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7426/12542 | Batch Loss: 0.9585 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7427/12542 | Batch Loss: 1.5777 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7428/12542 | Batch Loss: 2.1398 | Learning Rate: 0.000136 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7429/12542 | Batch Loss: 1.0026 | Learning Rate: 0.000136 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7430/12542 | Batch Loss: 1.2272 | Learning Rate: 0.000136 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7431/12542 | Batch Loss: 1.6109 | Learning Rate: 0.000136 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7432/12542 | Batch Loss: 1.4860 | Learning Rate: 0.000136 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7433/12542 | Batch Loss: 1.6964 | Learning Rate: 0.000136 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7434/12542 | Batch Loss: 0.6029 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7435/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7436/12542 | Batch Loss: 1.0797 | Learning Rate: 0.000136 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7437/12542 | Batch Loss: 0.8834 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7438/12542 | Batch Loss: 0.5076 | Learning Rate: 0.000136 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7439/12542 | Batch Loss: 2.7407 | Learning Rate: 0.000136 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7440/12542 | Batch Loss: 2.1735 | Learning Rate: 0.000136 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7441/12542 | Batch Loss: 1.5867 | Learning Rate: 0.000136 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7442/12542 | Batch Loss: 0.8660 | Learning Rate: 0.000136 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7443/12542 | Batch Loss: 0.5592 | Learning Rate: 0.000136 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7444/12542 | Batch Loss: 1.8612 | Learning Rate: 0.000135 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7445/12542 | Batch Loss: 1.4851 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7446/12542 | Batch Loss: 1.4170 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7447/12542 | Batch Loss: 0.4584 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7448/12542 | Batch Loss: 1.8752 | Learning Rate: 0.000135 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7449/12542 | Batch Loss: 2.4275 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7450/12542 | Batch Loss: 1.3561 | Learning Rate: 0.000135 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7451/12542 | Batch Loss: 0.6137 | Learning Rate: 0.000135 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7452/12542 | Batch Loss: 1.0030 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7453/12542 | Batch Loss: 0.8262 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7454/12542 | Batch Loss: 1.4177 | Learning Rate: 0.000135 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7455/12542 | Batch Loss: 2.4326 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7456/12542 | Batch Loss: 2.0110 | Learning Rate: 0.000135 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7457/12542 | Batch Loss: 1.8780 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7458/12542 | Batch Loss: 0.8287 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7459/12542 | Batch Loss: 0.5931 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7460/12542 | Batch Loss: 1.6219 | Learning Rate: 0.000135 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7461/12542 | Batch Loss: 0.5598 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7462/12542 | Batch Loss: 0.6669 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7463/12542 | Batch Loss: 1.5673 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7464/12542 | Batch Loss: 3.2088 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7465/12542 | Batch Loss: 1.4113 | Learning Rate: 0.000135 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7466/12542 | Batch Loss: 1.1788 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7467/12542 | Batch Loss: 0.8627 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7468/12542 | Batch Loss: 2.0354 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7469/12542 | Batch Loss: 2.4212 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7470/12542 | Batch Loss: 1.2776 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7471/12542 | Batch Loss: 2.0115 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7472/12542 | Batch Loss: 0.9890 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7473/12542 | Batch Loss: 0.5016 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7474/12542 | Batch Loss: 0.8735 | Learning Rate: 0.000135 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7475/12542 | Batch Loss: 1.9768 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7476/12542 | Batch Loss: 1.2441 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7477/12542 | Batch Loss: 1.5549 | Learning Rate: 0.000135 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7478/12542 | Batch Loss: 0.6948 | Learning Rate: 0.000135 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7479/12542 | Batch Loss: 0.4947 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7480/12542 | Batch Loss: 0.8315 | Learning Rate: 0.000135 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7481/12542 | Batch Loss: 0.9248 | Learning Rate: 0.000135 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7482/12542 | Batch Loss: 1.0119 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7483/12542 | Batch Loss: 0.8977 | Learning Rate: 0.000134 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7484/12542 | Batch Loss: 1.2499 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7485/12542 | Batch Loss: 2.0418 | Learning Rate: 0.000134 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7486/12542 | Batch Loss: 1.3923 | Learning Rate: 0.000134 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7487/12542 | Batch Loss: 0.7215 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7488/12542 | Batch Loss: 1.1033 | Learning Rate: 0.000134 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7489/12542 | Batch Loss: 0.3895 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7490/12542 | Batch Loss: 0.9024 | Learning Rate: 0.000134 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7491/12542 | Batch Loss: 1.7125 | Learning Rate: 0.000134 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7492/12542 | Batch Loss: 1.5819 | Learning Rate: 0.000134 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7493/12542 | Batch Loss: 0.9779 | Learning Rate: 0.000134 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7494/12542 | Batch Loss: 1.2609 | Learning Rate: 0.000134 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7495/12542 | Batch Loss: 1.3567 | Learning Rate: 0.000134 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7496/12542 | Batch Loss: 1.0365 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7497/12542 | Batch Loss: 1.7993 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7498/12542 | Batch Loss: 0.7042 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7499/12542 | Batch Loss: 1.1176 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7500/12542 | Batch Loss: 1.1552 | Learning Rate: 0.000134 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7501/12542 | Batch Loss: 1.9027 | Learning Rate: 0.000134 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7502/12542 | Batch Loss: 1.6039 | Learning Rate: 0.000134 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7503/12542 | Batch Loss: 3.2373 | Learning Rate: 0.000134 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7504/12542 | Batch Loss: 0.7565 | Learning Rate: 0.000134 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7505/12542 | Batch Loss: 1.3510 | Learning Rate: 0.000134 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7506/12542 | Batch Loss: 1.7018 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7507/12542 | Batch Loss: 1.2665 | Learning Rate: 0.000134 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7508/12542 | Batch Loss: 2.1714 | Learning Rate: 0.000134 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7509/12542 | Batch Loss: 1.9314 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7510/12542 | Batch Loss: 1.0484 | Learning Rate: 0.000134 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7511/12542 | Batch Loss: 1.8146 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7512/12542 | Batch Loss: 2.2052 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7513/12542 | Batch Loss: 1.0145 | Learning Rate: 0.000134 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7514/12542 | Batch Loss: 1.0534 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7515/12542 | Batch Loss: 1.4261 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7516/12542 | Batch Loss: 0.9678 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7517/12542 | Batch Loss: 2.8485 | Learning Rate: 0.000134 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7518/12542 | Batch Loss: 1.3154 | Learning Rate: 0.000134 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7519/12542 | Batch Loss: 1.1363 | Learning Rate: 0.000133 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7520/12542 | Batch Loss: 1.6530 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7521/12542 | Batch Loss: 1.4836 | Learning Rate: 0.000133 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7522/12542 | Batch Loss: 1.4065 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7523/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7524/12542 | Batch Loss: 0.9106 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7525/12542 | Batch Loss: 0.8013 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7526/12542 | Batch Loss: 1.3148 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7527/12542 | Batch Loss: 0.6139 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7528/12542 | Batch Loss: 2.7203 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7529/12542 | Batch Loss: 1.6949 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7530/12542 | Batch Loss: 1.1271 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7531/12542 | Batch Loss: 2.3128 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7532/12542 | Batch Loss: 0.9095 | Learning Rate: 0.000133 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7533/12542 | Batch Loss: 0.5999 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7534/12542 | Batch Loss: 1.7866 | Learning Rate: 0.000133 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7535/12542 | Batch Loss: 1.1276 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7536/12542 | Batch Loss: 1.4375 | Learning Rate: 0.000133 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7537/12542 | Batch Loss: 0.9183 | Learning Rate: 0.000133 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7538/12542 | Batch Loss: 2.2653 | Learning Rate: 0.000133 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7539/12542 | Batch Loss: 0.9223 | Learning Rate: 0.000133 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7540/12542 | Batch Loss: 0.7501 | Learning Rate: 0.000133 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7541/12542 | Batch Loss: 1.3997 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7542/12542 | Batch Loss: 0.9846 | Learning Rate: 0.000133 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7543/12542 | Batch Loss: 0.7691 | Learning Rate: 0.000133 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7544/12542 | Batch Loss: 3.8478 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7545/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7546/12542 | Batch Loss: 0.8160 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7547/12542 | Batch Loss: 1.1257 | Learning Rate: 0.000133 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7548/12542 | Batch Loss: 0.8813 | Learning Rate: 0.000133 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7549/12542 | Batch Loss: 2.4652 | Learning Rate: 0.000133 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7550/12542 | Batch Loss: 1.5729 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7551/12542 | Batch Loss: 1.1016 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7552/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000133 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7553/12542 | Batch Loss: 1.9351 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7554/12542 | Batch Loss: 0.8719 | Learning Rate: 0.000133 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7555/12542 | Batch Loss: 1.7851 | Learning Rate: 0.000133 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7556/12542 | Batch Loss: 1.3586 | Learning Rate: 0.000133 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7557/12542 | Batch Loss: 0.7730 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7558/12542 | Batch Loss: 1.0697 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7559/12542 | Batch Loss: 0.8811 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7560/12542 | Batch Loss: 0.6244 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7561/12542 | Batch Loss: 0.5918 | Learning Rate: 0.000132 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7562/12542 | Batch Loss: 0.6436 | Learning Rate: 0.000132 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7563/12542 | Batch Loss: 0.8618 | Learning Rate: 0.000132 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7564/12542 | Batch Loss: 1.1084 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7565/12542 | Batch Loss: 0.5482 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7566/12542 | Batch Loss: 1.8925 | Learning Rate: 0.000132 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7567/12542 | Batch Loss: 1.7050 | Learning Rate: 0.000132 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7568/12542 | Batch Loss: 1.4256 | Learning Rate: 0.000132 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7569/12542 | Batch Loss: 0.7555 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7570/12542 | Batch Loss: 0.5996 | Learning Rate: 0.000132 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7571/12542 | Batch Loss: 1.0746 | Learning Rate: 0.000132 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7572/12542 | Batch Loss: 1.6547 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7573/12542 | Batch Loss: 0.9068 | Learning Rate: 0.000132 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7574/12542 | Batch Loss: 1.8262 | Learning Rate: 0.000132 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7575/12542 | Batch Loss: 1.6112 | Learning Rate: 0.000132 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7576/12542 | Batch Loss: 1.1433 | Learning Rate: 0.000132 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7577/12542 | Batch Loss: 1.1040 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7578/12542 | Batch Loss: 1.3680 | Learning Rate: 0.000132 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7579/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7580/12542 | Batch Loss: 1.8793 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7581/12542 | Batch Loss: 1.8246 | Learning Rate: 0.000132 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7582/12542 | Batch Loss: 1.4926 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7583/12542 | Batch Loss: 2.9132 | Learning Rate: 0.000132 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7584/12542 | Batch Loss: 1.7416 | Learning Rate: 0.000132 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7585/12542 | Batch Loss: 1.4308 | Learning Rate: 0.000132 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7586/12542 | Batch Loss: 1.7681 | Learning Rate: 0.000132 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7587/12542 | Batch Loss: 1.1852 | Learning Rate: 0.000132 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7588/12542 | Batch Loss: 0.5835 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7589/12542 | Batch Loss: 1.2515 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7590/12542 | Batch Loss: 1.0082 | Learning Rate: 0.000132 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7591/12542 | Batch Loss: 1.0312 | Learning Rate: 0.000132 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7592/12542 | Batch Loss: 1.7227 | Learning Rate: 0.000132 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7593/12542 | Batch Loss: 0.6767 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7594/12542 | Batch Loss: 2.0891 | Learning Rate: 0.000132 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7595/12542 | Batch Loss: 0.8819 | Learning Rate: 0.000131 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7596/12542 | Batch Loss: 1.0168 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7597/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7598/12542 | Batch Loss: 0.6034 | Learning Rate: 0.000131 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7599/12542 | Batch Loss: 1.1004 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7600/12542 | Batch Loss: 1.6883 | Learning Rate: 0.000131 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7601/12542 | Batch Loss: 1.3168 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7602/12542 | Batch Loss: 1.2566 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7603/12542 | Batch Loss: 1.5396 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7604/12542 | Batch Loss: 0.2973 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7605/12542 | Batch Loss: 1.8604 | Learning Rate: 0.000131 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7606/12542 | Batch Loss: 1.1545 | Learning Rate: 0.000131 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7607/12542 | Batch Loss: 1.0135 | Learning Rate: 0.000131 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7608/12542 | Batch Loss: 0.7324 | Learning Rate: 0.000131 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7609/12542 | Batch Loss: 1.1021 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7610/12542 | Batch Loss: 1.5679 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7611/12542 | Batch Loss: 1.7720 | Learning Rate: 0.000131 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7612/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000131 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7613/12542 | Batch Loss: 0.6366 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7614/12542 | Batch Loss: 0.7871 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7615/12542 | Batch Loss: 0.9798 | Learning Rate: 0.000131 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7616/12542 | Batch Loss: 0.9338 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7617/12542 | Batch Loss: 0.6856 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7618/12542 | Batch Loss: 0.6104 | Learning Rate: 0.000131 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7619/12542 | Batch Loss: 0.9937 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7620/12542 | Batch Loss: 1.3149 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7621/12542 | Batch Loss: 1.6918 | Learning Rate: 0.000131 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7622/12542 | Batch Loss: 1.5071 | Learning Rate: 0.000131 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7623/12542 | Batch Loss: 0.6902 | Learning Rate: 0.000131 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7624/12542 | Batch Loss: 0.7551 | Learning Rate: 0.000131 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7625/12542 | Batch Loss: 1.4810 | Learning Rate: 0.000131 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7626/12542 | Batch Loss: 1.0505 | Learning Rate: 0.000131 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7627/12542 | Batch Loss: 1.4675 | Learning Rate: 0.000131 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7628/12542 | Batch Loss: 1.1175 | Learning Rate: 0.000131 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7629/12542 | Batch Loss: 1.2156 | Learning Rate: 0.000131 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7630/12542 | Batch Loss: 3.1152 | Learning Rate: 0.000131 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7631/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000131 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7632/12542 | Batch Loss: 2.3597 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7633/12542 | Batch Loss: 1.9357 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7634/12542 | Batch Loss: 0.6654 | Learning Rate: 0.000130 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7635/12542 | Batch Loss: 1.1529 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7636/12542 | Batch Loss: 0.7268 | Learning Rate: 0.000130 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7637/12542 | Batch Loss: 0.8063 | Learning Rate: 0.000130 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7638/12542 | Batch Loss: 1.0902 | Learning Rate: 0.000130 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7639/12542 | Batch Loss: 1.0984 | Learning Rate: 0.000130 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7640/12542 | Batch Loss: 1.8563 | Learning Rate: 0.000130 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7641/12542 | Batch Loss: 0.7646 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7642/12542 | Batch Loss: 1.4210 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7643/12542 | Batch Loss: 2.7806 | Learning Rate: 0.000130 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7644/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000130 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7645/12542 | Batch Loss: 0.9725 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7646/12542 | Batch Loss: 1.6377 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7647/12542 | Batch Loss: 1.5079 | Learning Rate: 0.000130 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7648/12542 | Batch Loss: 1.0564 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7649/12542 | Batch Loss: 2.1263 | Learning Rate: 0.000130 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7650/12542 | Batch Loss: 1.2421 | Learning Rate: 0.000130 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7651/12542 | Batch Loss: 1.1936 | Learning Rate: 0.000130 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7652/12542 | Batch Loss: 0.7683 | Learning Rate: 0.000130 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7653/12542 | Batch Loss: 1.1586 | Learning Rate: 0.000130 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7654/12542 | Batch Loss: 1.2801 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7655/12542 | Batch Loss: 0.8009 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7656/12542 | Batch Loss: 2.6049 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7657/12542 | Batch Loss: 1.5793 | Learning Rate: 0.000130 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7658/12542 | Batch Loss: 1.3674 | Learning Rate: 0.000130 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7659/12542 | Batch Loss: 1.1575 | Learning Rate: 0.000130 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7660/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000130 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7661/12542 | Batch Loss: 0.7096 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7662/12542 | Batch Loss: 2.6836 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7663/12542 | Batch Loss: 0.4467 | Learning Rate: 0.000130 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7664/12542 | Batch Loss: 1.4266 | Learning Rate: 0.000130 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7665/12542 | Batch Loss: 2.0593 | Learning Rate: 0.000130 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7666/12542 | Batch Loss: 1.7654 | Learning Rate: 0.000130 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7667/12542 | Batch Loss: 2.3853 | Learning Rate: 0.000130 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7668/12542 | Batch Loss: 1.5494 | Learning Rate: 0.000130 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7669/12542 | Batch Loss: 1.3605 | Learning Rate: 0.000130 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7670/12542 | Batch Loss: 1.9097 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7671/12542 | Batch Loss: 1.6115 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7672/12542 | Batch Loss: 0.9535 | Learning Rate: 0.000129 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7673/12542 | Batch Loss: 1.9688 | Learning Rate: 0.000129 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7674/12542 | Batch Loss: 1.2890 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7675/12542 | Batch Loss: 3.0101 | Learning Rate: 0.000129 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7676/12542 | Batch Loss: 1.0298 | Learning Rate: 0.000129 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7677/12542 | Batch Loss: 0.3575 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7678/12542 | Batch Loss: 1.1346 | Learning Rate: 0.000129 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7679/12542 | Batch Loss: 0.6487 | Learning Rate: 0.000129 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7680/12542 | Batch Loss: 1.4895 | Learning Rate: 0.000129 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7681/12542 | Batch Loss: 1.2275 | Learning Rate: 0.000129 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7682/12542 | Batch Loss: 0.9140 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7683/12542 | Batch Loss: 1.0472 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7684/12542 | Batch Loss: 2.3057 | Learning Rate: 0.000129 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7685/12542 | Batch Loss: 1.3758 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7686/12542 | Batch Loss: 0.4431 | Learning Rate: 0.000129 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7687/12542 | Batch Loss: 2.3796 | Learning Rate: 0.000129 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7688/12542 | Batch Loss: 1.3417 | Learning Rate: 0.000129 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7689/12542 | Batch Loss: 0.9164 | Learning Rate: 0.000129 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7690/12542 | Batch Loss: 0.9597 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7691/12542 | Batch Loss: 1.0366 | Learning Rate: 0.000129 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7692/12542 | Batch Loss: 3.1090 | Learning Rate: 0.000129 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7693/12542 | Batch Loss: 2.6867 | Learning Rate: 0.000129 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7694/12542 | Batch Loss: 0.8864 | Learning Rate: 0.000129 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7695/12542 | Batch Loss: 1.9665 | Learning Rate: 0.000129 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7696/12542 | Batch Loss: 1.0542 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7697/12542 | Batch Loss: 0.7769 | Learning Rate: 0.000129 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7698/12542 | Batch Loss: 0.6346 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7699/12542 | Batch Loss: 0.6028 | Learning Rate: 0.000129 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7700/12542 | Batch Loss: 1.1048 | Learning Rate: 0.000129 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7701/12542 | Batch Loss: 0.8610 | Learning Rate: 0.000129 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7702/12542 | Batch Loss: 1.8082 | Learning Rate: 0.000129 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7703/12542 | Batch Loss: 0.7796 | Learning Rate: 0.000129 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7704/12542 | Batch Loss: 1.1218 | Learning Rate: 0.000129 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7705/12542 | Batch Loss: 1.3663 | Learning Rate: 0.000129 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7706/12542 | Batch Loss: 1.4190 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7707/12542 | Batch Loss: 2.5606 | Learning Rate: 0.000129 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7708/12542 | Batch Loss: 2.1893 | Learning Rate: 0.000128 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7709/12542 | Batch Loss: 1.2459 | Learning Rate: 0.000128 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7710/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7711/12542 | Batch Loss: 1.4396 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7712/12542 | Batch Loss: 2.0405 | Learning Rate: 0.000128 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7713/12542 | Batch Loss: 0.9521 | Learning Rate: 0.000128 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7714/12542 | Batch Loss: 1.3320 | Learning Rate: 0.000128 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7715/12542 | Batch Loss: 1.5321 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7716/12542 | Batch Loss: 0.7294 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7717/12542 | Batch Loss: 1.3993 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7718/12542 | Batch Loss: 1.1707 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7719/12542 | Batch Loss: 0.6735 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7720/12542 | Batch Loss: 1.0345 | Learning Rate: 0.000128 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7721/12542 | Batch Loss: 1.0224 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7722/12542 | Batch Loss: 0.9977 | Learning Rate: 0.000128 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7723/12542 | Batch Loss: 0.4751 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7724/12542 | Batch Loss: 0.9826 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7725/12542 | Batch Loss: 1.3818 | Learning Rate: 0.000128 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7726/12542 | Batch Loss: 0.9660 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7727/12542 | Batch Loss: 3.1943 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7728/12542 | Batch Loss: 1.3190 | Learning Rate: 0.000128 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7729/12542 | Batch Loss: 1.3501 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7730/12542 | Batch Loss: 0.4972 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7731/12542 | Batch Loss: 1.2677 | Learning Rate: 0.000128 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7732/12542 | Batch Loss: 1.2308 | Learning Rate: 0.000128 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7733/12542 | Batch Loss: 1.1783 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7734/12542 | Batch Loss: 1.0968 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7735/12542 | Batch Loss: 1.3059 | Learning Rate: 0.000128 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7736/12542 | Batch Loss: 1.3321 | Learning Rate: 0.000128 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7737/12542 | Batch Loss: 1.2107 | Learning Rate: 0.000128 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7738/12542 | Batch Loss: 0.7804 | Learning Rate: 0.000128 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7739/12542 | Batch Loss: 0.6902 | Learning Rate: 0.000128 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7740/12542 | Batch Loss: 1.2997 | Learning Rate: 0.000128 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7741/12542 | Batch Loss: 1.0883 | Learning Rate: 0.000128 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7742/12542 | Batch Loss: 0.7911 | Learning Rate: 0.000128 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7743/12542 | Batch Loss: 1.7378 | Learning Rate: 0.000128 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7744/12542 | Batch Loss: 0.9527 | Learning Rate: 0.000128 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7745/12542 | Batch Loss: 1.4874 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7746/12542 | Batch Loss: 0.5260 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7747/12542 | Batch Loss: 1.6548 | Learning Rate: 0.000127 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7748/12542 | Batch Loss: 0.5610 | Learning Rate: 0.000127 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7749/12542 | Batch Loss: 1.5851 | Learning Rate: 0.000127 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7750/12542 | Batch Loss: 1.3977 | Learning Rate: 0.000127 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7751/12542 | Batch Loss: 1.2571 | Learning Rate: 0.000127 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7752/12542 | Batch Loss: 0.8716 | Learning Rate: 0.000127 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7753/12542 | Batch Loss: 1.3035 | Learning Rate: 0.000127 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7754/12542 | Batch Loss: 1.4156 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7755/12542 | Batch Loss: 1.3555 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7756/12542 | Batch Loss: 1.0978 | Learning Rate: 0.000127 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7757/12542 | Batch Loss: 1.1301 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7758/12542 | Batch Loss: 0.8509 | Learning Rate: 0.000127 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7759/12542 | Batch Loss: 1.2671 | Learning Rate: 0.000127 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7760/12542 | Batch Loss: 0.5673 | Learning Rate: 0.000127 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7761/12542 | Batch Loss: 1.2005 | Learning Rate: 0.000127 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7762/12542 | Batch Loss: 1.7934 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7763/12542 | Batch Loss: 1.8916 | Learning Rate: 0.000127 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7764/12542 | Batch Loss: 1.6961 | Learning Rate: 0.000127 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7765/12542 | Batch Loss: 0.7169 | Learning Rate: 0.000127 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7766/12542 | Batch Loss: 0.6955 | Learning Rate: 0.000127 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7767/12542 | Batch Loss: 1.6018 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7768/12542 | Batch Loss: 1.2345 | Learning Rate: 0.000127 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7769/12542 | Batch Loss: 0.8110 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7770/12542 | Batch Loss: 1.0445 | Learning Rate: 0.000127 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7771/12542 | Batch Loss: 0.9334 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7772/12542 | Batch Loss: 0.8820 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7773/12542 | Batch Loss: 0.6429 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7774/12542 | Batch Loss: 0.5952 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7775/12542 | Batch Loss: 1.8025 | Learning Rate: 0.000127 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7776/12542 | Batch Loss: 2.0051 | Learning Rate: 0.000127 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7777/12542 | Batch Loss: 1.0928 | Learning Rate: 0.000127 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7778/12542 | Batch Loss: 1.4812 | Learning Rate: 0.000127 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7779/12542 | Batch Loss: 1.4260 | Learning Rate: 0.000127 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7780/12542 | Batch Loss: 0.8049 | Learning Rate: 0.000127 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7781/12542 | Batch Loss: 1.1123 | Learning Rate: 0.000127 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7782/12542 | Batch Loss: 2.1924 | Learning Rate: 0.000127 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7783/12542 | Batch Loss: 1.4943 | Learning Rate: 0.000126 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7784/12542 | Batch Loss: 0.5138 | Learning Rate: 0.000126 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7785/12542 | Batch Loss: 1.1241 | Learning Rate: 0.000126 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7786/12542 | Batch Loss: 1.4248 | Learning Rate: 0.000126 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7787/12542 | Batch Loss: 2.2820 | Learning Rate: 0.000126 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7788/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000126 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7789/12542 | Batch Loss: 0.7795 | Learning Rate: 0.000126 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7790/12542 | Batch Loss: 0.8276 | Learning Rate: 0.000126 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7791/12542 | Batch Loss: 1.9959 | Learning Rate: 0.000126 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7792/12542 | Batch Loss: 1.2887 | Learning Rate: 0.000126 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7793/12542 | Batch Loss: 0.6764 | Learning Rate: 0.000126 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7794/12542 | Batch Loss: 0.6329 | Learning Rate: 0.000126 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7795/12542 | Batch Loss: 1.5301 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7796/12542 | Batch Loss: 1.2773 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7797/12542 | Batch Loss: 1.6255 | Learning Rate: 0.000126 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7798/12542 | Batch Loss: 1.2217 | Learning Rate: 0.000126 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7799/12542 | Batch Loss: 1.2285 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7800/12542 | Batch Loss: 0.9622 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7801/12542 | Batch Loss: 0.7676 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7802/12542 | Batch Loss: 0.7415 | Learning Rate: 0.000126 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7803/12542 | Batch Loss: 3.9537 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7804/12542 | Batch Loss: 1.4125 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7805/12542 | Batch Loss: 0.4428 | Learning Rate: 0.000126 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7806/12542 | Batch Loss: 0.9772 | Learning Rate: 0.000126 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7807/12542 | Batch Loss: 0.8744 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7808/12542 | Batch Loss: 1.6148 | Learning Rate: 0.000126 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7809/12542 | Batch Loss: 2.4985 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7810/12542 | Batch Loss: 0.7703 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7811/12542 | Batch Loss: 0.7158 | Learning Rate: 0.000126 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7812/12542 | Batch Loss: 1.6249 | Learning Rate: 0.000126 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7813/12542 | Batch Loss: 2.1016 | Learning Rate: 0.000126 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7814/12542 | Batch Loss: 1.4210 | Learning Rate: 0.000126 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7815/12542 | Batch Loss: 1.4910 | Learning Rate: 0.000126 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7816/12542 | Batch Loss: 0.7919 | Learning Rate: 0.000126 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7817/12542 | Batch Loss: 1.2227 | Learning Rate: 0.000126 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7818/12542 | Batch Loss: 1.9816 | Learning Rate: 0.000126 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7819/12542 | Batch Loss: 1.2001 | Learning Rate: 0.000126 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7820/12542 | Batch Loss: 1.2603 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7821/12542 | Batch Loss: 1.0452 | Learning Rate: 0.000125 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7822/12542 | Batch Loss: 1.2399 | Learning Rate: 0.000125 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7823/12542 | Batch Loss: 0.6436 | Learning Rate: 0.000125 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7824/12542 | Batch Loss: 0.8231 | Learning Rate: 0.000125 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7825/12542 | Batch Loss: 1.5365 | Learning Rate: 0.000125 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7826/12542 | Batch Loss: 1.8926 | Learning Rate: 0.000125 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7827/12542 | Batch Loss: 1.0968 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7828/12542 | Batch Loss: 1.6399 | Learning Rate: 0.000125 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7829/12542 | Batch Loss: 1.2107 | Learning Rate: 0.000125 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7830/12542 | Batch Loss: 1.1557 | Learning Rate: 0.000125 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7831/12542 | Batch Loss: 0.9596 | Learning Rate: 0.000125 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7832/12542 | Batch Loss: 1.9908 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7833/12542 | Batch Loss: 2.5303 | Learning Rate: 0.000125 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7834/12542 | Batch Loss: 1.2177 | Learning Rate: 0.000125 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7835/12542 | Batch Loss: 1.9195 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7836/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7837/12542 | Batch Loss: 1.1802 | Learning Rate: 0.000125 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7838/12542 | Batch Loss: 2.7077 | Learning Rate: 0.000125 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7839/12542 | Batch Loss: 2.1724 | Learning Rate: 0.000125 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7840/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000125 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7841/12542 | Batch Loss: 1.2995 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7842/12542 | Batch Loss: 1.4169 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7843/12542 | Batch Loss: 1.4446 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7844/12542 | Batch Loss: 0.8097 | Learning Rate: 0.000125 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7845/12542 | Batch Loss: 1.4652 | Learning Rate: 0.000125 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7846/12542 | Batch Loss: 2.0458 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7847/12542 | Batch Loss: 1.4833 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7848/12542 | Batch Loss: 1.3871 | Learning Rate: 0.000125 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7849/12542 | Batch Loss: 0.8522 | Learning Rate: 0.000125 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7850/12542 | Batch Loss: 0.7959 | Learning Rate: 0.000125 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7851/12542 | Batch Loss: 1.3673 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7852/12542 | Batch Loss: 0.6917 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7853/12542 | Batch Loss: 3.0555 | Learning Rate: 0.000125 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7854/12542 | Batch Loss: 1.2756 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7855/12542 | Batch Loss: 1.6979 | Learning Rate: 0.000125 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7856/12542 | Batch Loss: 0.8919 | Learning Rate: 0.000125 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7857/12542 | Batch Loss: 1.0356 | Learning Rate: 0.000125 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7858/12542 | Batch Loss: 0.6429 | Learning Rate: 0.000124 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7859/12542 | Batch Loss: 2.7176 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7860/12542 | Batch Loss: 1.4559 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7861/12542 | Batch Loss: 1.6631 | Learning Rate: 0.000124 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7862/12542 | Batch Loss: 1.1532 | Learning Rate: 0.000124 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7863/12542 | Batch Loss: 2.2093 | Learning Rate: 0.000124 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7864/12542 | Batch Loss: 1.8032 | Learning Rate: 0.000124 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7865/12542 | Batch Loss: 1.0932 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7866/12542 | Batch Loss: 0.8107 | Learning Rate: 0.000124 | Batch Time: 0.71s\n",
      "Epoch 3 | Step 7867/12542 | Batch Loss: 0.9428 | Learning Rate: 0.000124 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7868/12542 | Batch Loss: 1.6849 | Learning Rate: 0.000124 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7869/12542 | Batch Loss: 1.7013 | Learning Rate: 0.000124 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7870/12542 | Batch Loss: 2.3130 | Learning Rate: 0.000124 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7871/12542 | Batch Loss: 2.1779 | Learning Rate: 0.000124 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7872/12542 | Batch Loss: 1.4713 | Learning Rate: 0.000124 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7873/12542 | Batch Loss: 0.7616 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7874/12542 | Batch Loss: 1.5228 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7875/12542 | Batch Loss: 1.4229 | Learning Rate: 0.000124 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7876/12542 | Batch Loss: 0.6354 | Learning Rate: 0.000124 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7877/12542 | Batch Loss: 1.0267 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7878/12542 | Batch Loss: 1.2832 | Learning Rate: 0.000124 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7879/12542 | Batch Loss: 0.5643 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7880/12542 | Batch Loss: 0.9118 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7881/12542 | Batch Loss: 0.4677 | Learning Rate: 0.000124 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7882/12542 | Batch Loss: 0.8649 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7883/12542 | Batch Loss: 0.4983 | Learning Rate: 0.000124 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7884/12542 | Batch Loss: 1.1854 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7885/12542 | Batch Loss: 0.8770 | Learning Rate: 0.000124 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7886/12542 | Batch Loss: 1.6834 | Learning Rate: 0.000124 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7887/12542 | Batch Loss: 1.7203 | Learning Rate: 0.000124 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7888/12542 | Batch Loss: 2.7665 | Learning Rate: 0.000124 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7889/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000124 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7890/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000124 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7891/12542 | Batch Loss: 1.2178 | Learning Rate: 0.000124 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7892/12542 | Batch Loss: 1.9441 | Learning Rate: 0.000124 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7893/12542 | Batch Loss: 0.6819 | Learning Rate: 0.000124 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7894/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000124 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 7895/12542 | Batch Loss: 0.5178 | Learning Rate: 0.000124 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7896/12542 | Batch Loss: 1.2505 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7897/12542 | Batch Loss: 1.7259 | Learning Rate: 0.000123 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 7898/12542 | Batch Loss: 1.3648 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7899/12542 | Batch Loss: 0.5984 | Learning Rate: 0.000123 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7900/12542 | Batch Loss: 2.8992 | Learning Rate: 0.000123 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7901/12542 | Batch Loss: 0.5443 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7902/12542 | Batch Loss: 1.4217 | Learning Rate: 0.000123 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7903/12542 | Batch Loss: 1.2740 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7904/12542 | Batch Loss: 0.7132 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7905/12542 | Batch Loss: 1.6284 | Learning Rate: 0.000123 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7906/12542 | Batch Loss: 1.4760 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7907/12542 | Batch Loss: 1.3548 | Learning Rate: 0.000123 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7908/12542 | Batch Loss: 1.8524 | Learning Rate: 0.000123 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 7909/12542 | Batch Loss: 0.7674 | Learning Rate: 0.000123 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7910/12542 | Batch Loss: 1.3512 | Learning Rate: 0.000123 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7911/12542 | Batch Loss: 0.8678 | Learning Rate: 0.000123 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7912/12542 | Batch Loss: 0.7365 | Learning Rate: 0.000123 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 7913/12542 | Batch Loss: 0.9105 | Learning Rate: 0.000123 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7914/12542 | Batch Loss: 1.5529 | Learning Rate: 0.000123 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7915/12542 | Batch Loss: 2.2815 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7916/12542 | Batch Loss: 0.4744 | Learning Rate: 0.000123 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7917/12542 | Batch Loss: 1.3225 | Learning Rate: 0.000123 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7918/12542 | Batch Loss: 0.6915 | Learning Rate: 0.000123 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7919/12542 | Batch Loss: 1.5653 | Learning Rate: 0.000123 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7920/12542 | Batch Loss: 1.1607 | Learning Rate: 0.000123 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7921/12542 | Batch Loss: 1.3473 | Learning Rate: 0.000123 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7922/12542 | Batch Loss: 0.6509 | Learning Rate: 0.000123 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7923/12542 | Batch Loss: 2.1207 | Learning Rate: 0.000123 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7924/12542 | Batch Loss: 1.2522 | Learning Rate: 0.000123 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7925/12542 | Batch Loss: 0.7620 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7926/12542 | Batch Loss: 1.2284 | Learning Rate: 0.000123 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7927/12542 | Batch Loss: 0.6324 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7928/12542 | Batch Loss: 0.6623 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7929/12542 | Batch Loss: 1.3609 | Learning Rate: 0.000123 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7930/12542 | Batch Loss: 1.0683 | Learning Rate: 0.000123 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7931/12542 | Batch Loss: 1.2813 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7932/12542 | Batch Loss: 0.8321 | Learning Rate: 0.000123 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7933/12542 | Batch Loss: 1.5758 | Learning Rate: 0.000122 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7934/12542 | Batch Loss: 1.1395 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7935/12542 | Batch Loss: 2.5372 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7936/12542 | Batch Loss: 1.1392 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7937/12542 | Batch Loss: 0.9191 | Learning Rate: 0.000122 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7938/12542 | Batch Loss: 1.7650 | Learning Rate: 0.000122 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7939/12542 | Batch Loss: 1.3812 | Learning Rate: 0.000122 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7940/12542 | Batch Loss: 2.4161 | Learning Rate: 0.000122 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7941/12542 | Batch Loss: 1.4278 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7942/12542 | Batch Loss: 1.8723 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7943/12542 | Batch Loss: 1.6744 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7944/12542 | Batch Loss: 0.7179 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7945/12542 | Batch Loss: 1.0877 | Learning Rate: 0.000122 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7946/12542 | Batch Loss: 1.1122 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7947/12542 | Batch Loss: 0.7443 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7948/12542 | Batch Loss: 1.3145 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7949/12542 | Batch Loss: 1.0707 | Learning Rate: 0.000122 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7950/12542 | Batch Loss: 1.1936 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7951/12542 | Batch Loss: 1.6191 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7952/12542 | Batch Loss: 1.7757 | Learning Rate: 0.000122 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7953/12542 | Batch Loss: 2.0105 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7954/12542 | Batch Loss: 2.3733 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7955/12542 | Batch Loss: 1.1733 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7956/12542 | Batch Loss: 1.3325 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7957/12542 | Batch Loss: 1.2536 | Learning Rate: 0.000122 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7958/12542 | Batch Loss: 1.1321 | Learning Rate: 0.000122 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 7959/12542 | Batch Loss: 0.5660 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7960/12542 | Batch Loss: 0.7713 | Learning Rate: 0.000122 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7961/12542 | Batch Loss: 1.6157 | Learning Rate: 0.000122 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7962/12542 | Batch Loss: 1.0846 | Learning Rate: 0.000122 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7963/12542 | Batch Loss: 2.0142 | Learning Rate: 0.000122 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7964/12542 | Batch Loss: 0.8182 | Learning Rate: 0.000122 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7965/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7966/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7967/12542 | Batch Loss: 1.6064 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7968/12542 | Batch Loss: 2.4297 | Learning Rate: 0.000122 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7969/12542 | Batch Loss: 0.9666 | Learning Rate: 0.000122 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7970/12542 | Batch Loss: 0.9033 | Learning Rate: 0.000122 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7971/12542 | Batch Loss: 1.2412 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7972/12542 | Batch Loss: 2.1119 | Learning Rate: 0.000121 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7973/12542 | Batch Loss: 0.8740 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7974/12542 | Batch Loss: 0.6166 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7975/12542 | Batch Loss: 1.6340 | Learning Rate: 0.000121 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7976/12542 | Batch Loss: 1.4576 | Learning Rate: 0.000121 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7977/12542 | Batch Loss: 0.4255 | Learning Rate: 0.000121 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7978/12542 | Batch Loss: 1.3396 | Learning Rate: 0.000121 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 7979/12542 | Batch Loss: 0.7702 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7980/12542 | Batch Loss: 1.1696 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7981/12542 | Batch Loss: 1.8357 | Learning Rate: 0.000121 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7982/12542 | Batch Loss: 0.9062 | Learning Rate: 0.000121 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 7983/12542 | Batch Loss: 1.2727 | Learning Rate: 0.000121 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 7984/12542 | Batch Loss: 1.1505 | Learning Rate: 0.000121 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 7985/12542 | Batch Loss: 0.5461 | Learning Rate: 0.000121 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7986/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7987/12542 | Batch Loss: 1.3094 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7988/12542 | Batch Loss: 2.3463 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7989/12542 | Batch Loss: 0.7735 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7990/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7991/12542 | Batch Loss: 0.8674 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7992/12542 | Batch Loss: 0.7191 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7993/12542 | Batch Loss: 0.6737 | Learning Rate: 0.000121 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 7994/12542 | Batch Loss: 1.3861 | Learning Rate: 0.000121 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 7995/12542 | Batch Loss: 2.9396 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 7996/12542 | Batch Loss: 2.1756 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 7997/12542 | Batch Loss: 0.9578 | Learning Rate: 0.000121 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 7998/12542 | Batch Loss: 1.7321 | Learning Rate: 0.000121 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 7999/12542 | Batch Loss: 1.1490 | Learning Rate: 0.000121 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8000/12542 | Batch Loss: 0.8161 | Learning Rate: 0.000121 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8001/12542 | Batch Loss: 1.8583 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8002/12542 | Batch Loss: 0.8946 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8003/12542 | Batch Loss: 1.5249 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8004/12542 | Batch Loss: 0.9571 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8005/12542 | Batch Loss: 0.8264 | Learning Rate: 0.000121 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8006/12542 | Batch Loss: 2.1549 | Learning Rate: 0.000121 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8007/12542 | Batch Loss: 1.0465 | Learning Rate: 0.000121 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8008/12542 | Batch Loss: 1.1931 | Learning Rate: 0.000121 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8009/12542 | Batch Loss: 1.2055 | Learning Rate: 0.000120 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8010/12542 | Batch Loss: 1.2161 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8011/12542 | Batch Loss: 2.9313 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8012/12542 | Batch Loss: 0.8808 | Learning Rate: 0.000120 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8013/12542 | Batch Loss: 2.2371 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8014/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8015/12542 | Batch Loss: 1.0463 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8016/12542 | Batch Loss: 1.1721 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8017/12542 | Batch Loss: 1.1528 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8018/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8019/12542 | Batch Loss: 1.5000 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8020/12542 | Batch Loss: 0.8215 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8021/12542 | Batch Loss: 1.3196 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8022/12542 | Batch Loss: 1.2273 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8023/12542 | Batch Loss: 0.8094 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8024/12542 | Batch Loss: 1.5341 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8025/12542 | Batch Loss: 0.9913 | Learning Rate: 0.000120 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8026/12542 | Batch Loss: 1.4598 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8027/12542 | Batch Loss: 0.5824 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8028/12542 | Batch Loss: 0.6385 | Learning Rate: 0.000120 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8029/12542 | Batch Loss: 1.2908 | Learning Rate: 0.000120 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8030/12542 | Batch Loss: 1.5437 | Learning Rate: 0.000120 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8031/12542 | Batch Loss: 0.6726 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8032/12542 | Batch Loss: 1.2279 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8033/12542 | Batch Loss: 1.8227 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8034/12542 | Batch Loss: 2.1911 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8035/12542 | Batch Loss: 1.0225 | Learning Rate: 0.000120 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8036/12542 | Batch Loss: 0.6059 | Learning Rate: 0.000120 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8037/12542 | Batch Loss: 3.0751 | Learning Rate: 0.000120 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8038/12542 | Batch Loss: 3.3978 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8039/12542 | Batch Loss: 0.9532 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8040/12542 | Batch Loss: 1.3864 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8041/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000120 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8042/12542 | Batch Loss: 1.1937 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8043/12542 | Batch Loss: 2.0434 | Learning Rate: 0.000120 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8044/12542 | Batch Loss: 1.7793 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8045/12542 | Batch Loss: 0.9608 | Learning Rate: 0.000120 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8046/12542 | Batch Loss: 1.0381 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8047/12542 | Batch Loss: 0.8711 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8048/12542 | Batch Loss: 1.3688 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8049/12542 | Batch Loss: 1.0240 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8050/12542 | Batch Loss: 0.8940 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8051/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000119 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8052/12542 | Batch Loss: 1.1535 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8053/12542 | Batch Loss: 1.3488 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8054/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8055/12542 | Batch Loss: 3.3259 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8056/12542 | Batch Loss: 1.1498 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8057/12542 | Batch Loss: 1.4526 | Learning Rate: 0.000119 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8058/12542 | Batch Loss: 1.7485 | Learning Rate: 0.000119 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8059/12542 | Batch Loss: 1.2258 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8060/12542 | Batch Loss: 1.8507 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8061/12542 | Batch Loss: 1.5134 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8062/12542 | Batch Loss: 1.7904 | Learning Rate: 0.000119 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8063/12542 | Batch Loss: 2.6935 | Learning Rate: 0.000119 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8064/12542 | Batch Loss: 1.5900 | Learning Rate: 0.000119 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8065/12542 | Batch Loss: 1.1462 | Learning Rate: 0.000119 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8066/12542 | Batch Loss: 2.0228 | Learning Rate: 0.000119 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8067/12542 | Batch Loss: 0.9229 | Learning Rate: 0.000119 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8068/12542 | Batch Loss: 0.9697 | Learning Rate: 0.000119 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8069/12542 | Batch Loss: 0.8072 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8070/12542 | Batch Loss: 1.5073 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8071/12542 | Batch Loss: 1.5613 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8072/12542 | Batch Loss: 1.0709 | Learning Rate: 0.000119 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 8073/12542 | Batch Loss: 0.6546 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8074/12542 | Batch Loss: 1.6576 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8075/12542 | Batch Loss: 1.0002 | Learning Rate: 0.000119 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8076/12542 | Batch Loss: 2.1796 | Learning Rate: 0.000119 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8077/12542 | Batch Loss: 1.0848 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8078/12542 | Batch Loss: 1.9977 | Learning Rate: 0.000119 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8079/12542 | Batch Loss: 0.7240 | Learning Rate: 0.000119 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8080/12542 | Batch Loss: 1.7390 | Learning Rate: 0.000119 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8081/12542 | Batch Loss: 0.9685 | Learning Rate: 0.000119 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8082/12542 | Batch Loss: 1.5677 | Learning Rate: 0.000119 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8083/12542 | Batch Loss: 1.1005 | Learning Rate: 0.000119 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8084/12542 | Batch Loss: 0.9486 | Learning Rate: 0.000118 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8085/12542 | Batch Loss: 0.4084 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8086/12542 | Batch Loss: 1.8532 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8087/12542 | Batch Loss: 1.9456 | Learning Rate: 0.000118 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8088/12542 | Batch Loss: 0.9729 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8089/12542 | Batch Loss: 1.5342 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8090/12542 | Batch Loss: 2.4272 | Learning Rate: 0.000118 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 8091/12542 | Batch Loss: 0.9098 | Learning Rate: 0.000118 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8092/12542 | Batch Loss: 1.5353 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8093/12542 | Batch Loss: 1.5732 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8094/12542 | Batch Loss: 0.6793 | Learning Rate: 0.000118 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8095/12542 | Batch Loss: 0.7946 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8096/12542 | Batch Loss: 0.6178 | Learning Rate: 0.000118 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8097/12542 | Batch Loss: 0.4627 | Learning Rate: 0.000118 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8098/12542 | Batch Loss: 1.1453 | Learning Rate: 0.000118 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8099/12542 | Batch Loss: 1.8164 | Learning Rate: 0.000118 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8100/12542 | Batch Loss: 0.6685 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8101/12542 | Batch Loss: 2.0996 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8102/12542 | Batch Loss: 0.4416 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8103/12542 | Batch Loss: 0.8088 | Learning Rate: 0.000118 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8104/12542 | Batch Loss: 1.0294 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8105/12542 | Batch Loss: 1.7378 | Learning Rate: 0.000118 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8106/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000118 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8107/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000118 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8108/12542 | Batch Loss: 0.4942 | Learning Rate: 0.000118 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8109/12542 | Batch Loss: 1.0017 | Learning Rate: 0.000118 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8110/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000118 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8111/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000118 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8112/12542 | Batch Loss: 0.8628 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8113/12542 | Batch Loss: 2.2750 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8114/12542 | Batch Loss: 1.6127 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8115/12542 | Batch Loss: 1.7889 | Learning Rate: 0.000118 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8116/12542 | Batch Loss: 0.8801 | Learning Rate: 0.000118 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8117/12542 | Batch Loss: 1.3275 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8118/12542 | Batch Loss: 1.0605 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8119/12542 | Batch Loss: 1.3089 | Learning Rate: 0.000118 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8120/12542 | Batch Loss: 1.8406 | Learning Rate: 0.000118 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8121/12542 | Batch Loss: 0.6320 | Learning Rate: 0.000117 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8122/12542 | Batch Loss: 1.0691 | Learning Rate: 0.000117 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8123/12542 | Batch Loss: 2.5341 | Learning Rate: 0.000117 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8124/12542 | Batch Loss: 0.9452 | Learning Rate: 0.000117 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8125/12542 | Batch Loss: 1.1819 | Learning Rate: 0.000117 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8126/12542 | Batch Loss: 1.2171 | Learning Rate: 0.000117 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8127/12542 | Batch Loss: 1.1118 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8128/12542 | Batch Loss: 1.4022 | Learning Rate: 0.000117 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8129/12542 | Batch Loss: 0.8169 | Learning Rate: 0.000117 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8130/12542 | Batch Loss: 1.9535 | Learning Rate: 0.000117 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8131/12542 | Batch Loss: 0.9142 | Learning Rate: 0.000117 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8132/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000117 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8133/12542 | Batch Loss: 1.4814 | Learning Rate: 0.000117 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8134/12542 | Batch Loss: 0.7686 | Learning Rate: 0.000117 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8135/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000117 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8136/12542 | Batch Loss: 1.2381 | Learning Rate: 0.000117 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8137/12542 | Batch Loss: 1.3218 | Learning Rate: 0.000117 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8138/12542 | Batch Loss: 1.6589 | Learning Rate: 0.000117 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8139/12542 | Batch Loss: 2.0317 | Learning Rate: 0.000117 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8140/12542 | Batch Loss: 0.8336 | Learning Rate: 0.000117 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8141/12542 | Batch Loss: 0.4973 | Learning Rate: 0.000117 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8142/12542 | Batch Loss: 1.1057 | Learning Rate: 0.000117 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8143/12542 | Batch Loss: 0.5916 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8144/12542 | Batch Loss: 1.1845 | Learning Rate: 0.000117 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8145/12542 | Batch Loss: 1.7774 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8146/12542 | Batch Loss: 1.0716 | Learning Rate: 0.000117 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8147/12542 | Batch Loss: 0.9522 | Learning Rate: 0.000117 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8148/12542 | Batch Loss: 0.8491 | Learning Rate: 0.000117 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8149/12542 | Batch Loss: 2.2323 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8150/12542 | Batch Loss: 1.5738 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8151/12542 | Batch Loss: 1.7093 | Learning Rate: 0.000117 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8152/12542 | Batch Loss: 1.5932 | Learning Rate: 0.000117 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8153/12542 | Batch Loss: 2.0190 | Learning Rate: 0.000117 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8154/12542 | Batch Loss: 0.6378 | Learning Rate: 0.000117 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8155/12542 | Batch Loss: 0.8138 | Learning Rate: 0.000117 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8156/12542 | Batch Loss: 2.5123 | Learning Rate: 0.000117 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8157/12542 | Batch Loss: 1.0745 | Learning Rate: 0.000117 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8158/12542 | Batch Loss: 0.4902 | Learning Rate: 0.000117 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8159/12542 | Batch Loss: 1.9988 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8160/12542 | Batch Loss: 1.2066 | Learning Rate: 0.000116 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8161/12542 | Batch Loss: 0.9461 | Learning Rate: 0.000116 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8162/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000116 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8163/12542 | Batch Loss: 1.4627 | Learning Rate: 0.000116 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8164/12542 | Batch Loss: 1.2474 | Learning Rate: 0.000116 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8165/12542 | Batch Loss: 1.6627 | Learning Rate: 0.000116 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8166/12542 | Batch Loss: 2.2708 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8167/12542 | Batch Loss: 1.4052 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8168/12542 | Batch Loss: 1.7623 | Learning Rate: 0.000116 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8169/12542 | Batch Loss: 0.9595 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8170/12542 | Batch Loss: 0.7096 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8171/12542 | Batch Loss: 1.3610 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8172/12542 | Batch Loss: 0.8324 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8173/12542 | Batch Loss: 1.4682 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8174/12542 | Batch Loss: 1.2482 | Learning Rate: 0.000116 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8175/12542 | Batch Loss: 0.8393 | Learning Rate: 0.000116 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8176/12542 | Batch Loss: 1.4207 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8177/12542 | Batch Loss: 0.5409 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8178/12542 | Batch Loss: 0.7914 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8179/12542 | Batch Loss: 1.0347 | Learning Rate: 0.000116 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8180/12542 | Batch Loss: 1.4920 | Learning Rate: 0.000116 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8181/12542 | Batch Loss: 1.4900 | Learning Rate: 0.000116 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8182/12542 | Batch Loss: 0.8642 | Learning Rate: 0.000116 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8183/12542 | Batch Loss: 1.1751 | Learning Rate: 0.000116 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8184/12542 | Batch Loss: 0.8467 | Learning Rate: 0.000116 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8185/12542 | Batch Loss: 1.5011 | Learning Rate: 0.000116 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8186/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000116 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8187/12542 | Batch Loss: 1.4161 | Learning Rate: 0.000116 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8188/12542 | Batch Loss: 1.7598 | Learning Rate: 0.000116 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8189/12542 | Batch Loss: 1.0553 | Learning Rate: 0.000116 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8190/12542 | Batch Loss: 2.2328 | Learning Rate: 0.000116 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8191/12542 | Batch Loss: 1.2353 | Learning Rate: 0.000116 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8192/12542 | Batch Loss: 1.1345 | Learning Rate: 0.000116 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8193/12542 | Batch Loss: 1.5351 | Learning Rate: 0.000116 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8194/12542 | Batch Loss: 2.4374 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8195/12542 | Batch Loss: 3.1525 | Learning Rate: 0.000116 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8196/12542 | Batch Loss: 1.7939 | Learning Rate: 0.000116 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8197/12542 | Batch Loss: 1.5336 | Learning Rate: 0.000115 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8198/12542 | Batch Loss: 0.7644 | Learning Rate: 0.000115 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8199/12542 | Batch Loss: 1.4793 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8200/12542 | Batch Loss: 0.4137 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8201/12542 | Batch Loss: 1.2314 | Learning Rate: 0.000115 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8202/12542 | Batch Loss: 0.6023 | Learning Rate: 0.000115 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8203/12542 | Batch Loss: 0.7526 | Learning Rate: 0.000115 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8204/12542 | Batch Loss: 0.8988 | Learning Rate: 0.000115 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8205/12542 | Batch Loss: 1.0216 | Learning Rate: 0.000115 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8206/12542 | Batch Loss: 0.6078 | Learning Rate: 0.000115 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8207/12542 | Batch Loss: 1.2256 | Learning Rate: 0.000115 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8208/12542 | Batch Loss: 0.9485 | Learning Rate: 0.000115 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8209/12542 | Batch Loss: 1.3809 | Learning Rate: 0.000115 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8210/12542 | Batch Loss: 0.7788 | Learning Rate: 0.000115 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8211/12542 | Batch Loss: 2.2529 | Learning Rate: 0.000115 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8212/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000115 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8213/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000115 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8214/12542 | Batch Loss: 2.6738 | Learning Rate: 0.000115 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 8215/12542 | Batch Loss: 1.1093 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8216/12542 | Batch Loss: 0.6261 | Learning Rate: 0.000115 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8217/12542 | Batch Loss: 2.2143 | Learning Rate: 0.000115 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8218/12542 | Batch Loss: 0.3754 | Learning Rate: 0.000115 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8219/12542 | Batch Loss: 1.4059 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8220/12542 | Batch Loss: 1.1753 | Learning Rate: 0.000115 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8221/12542 | Batch Loss: 1.2404 | Learning Rate: 0.000115 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8222/12542 | Batch Loss: 0.6219 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8223/12542 | Batch Loss: 1.3901 | Learning Rate: 0.000115 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8224/12542 | Batch Loss: 1.2188 | Learning Rate: 0.000115 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8225/12542 | Batch Loss: 0.9320 | Learning Rate: 0.000115 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8226/12542 | Batch Loss: 0.7144 | Learning Rate: 0.000115 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8227/12542 | Batch Loss: 1.1755 | Learning Rate: 0.000115 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8228/12542 | Batch Loss: 0.6354 | Learning Rate: 0.000115 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8229/12542 | Batch Loss: 1.9378 | Learning Rate: 0.000115 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8230/12542 | Batch Loss: 0.7030 | Learning Rate: 0.000115 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8231/12542 | Batch Loss: 0.8130 | Learning Rate: 0.000115 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8232/12542 | Batch Loss: 1.2344 | Learning Rate: 0.000115 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8233/12542 | Batch Loss: 1.8546 | Learning Rate: 0.000115 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8234/12542 | Batch Loss: 0.5329 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8235/12542 | Batch Loss: 1.0029 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8236/12542 | Batch Loss: 0.8753 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8237/12542 | Batch Loss: 0.4460 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8238/12542 | Batch Loss: 1.2696 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8239/12542 | Batch Loss: 2.9879 | Learning Rate: 0.000114 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8240/12542 | Batch Loss: 1.2176 | Learning Rate: 0.000114 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8241/12542 | Batch Loss: 0.6552 | Learning Rate: 0.000114 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8242/12542 | Batch Loss: 0.8032 | Learning Rate: 0.000114 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8243/12542 | Batch Loss: 0.6251 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8244/12542 | Batch Loss: 1.3368 | Learning Rate: 0.000114 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8245/12542 | Batch Loss: 1.9149 | Learning Rate: 0.000114 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8246/12542 | Batch Loss: 1.4180 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8247/12542 | Batch Loss: 0.5843 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8248/12542 | Batch Loss: 3.0925 | Learning Rate: 0.000114 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8249/12542 | Batch Loss: 0.7865 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8250/12542 | Batch Loss: 0.7663 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8251/12542 | Batch Loss: 0.9473 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8252/12542 | Batch Loss: 1.5895 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8253/12542 | Batch Loss: 2.7418 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8254/12542 | Batch Loss: 0.4996 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8255/12542 | Batch Loss: 0.6937 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8256/12542 | Batch Loss: 1.6918 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8257/12542 | Batch Loss: 2.8016 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8258/12542 | Batch Loss: 0.7263 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8259/12542 | Batch Loss: 1.3562 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8260/12542 | Batch Loss: 0.8372 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8261/12542 | Batch Loss: 1.2461 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8262/12542 | Batch Loss: 1.0190 | Learning Rate: 0.000114 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8263/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8264/12542 | Batch Loss: 0.6487 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8265/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8266/12542 | Batch Loss: 0.9062 | Learning Rate: 0.000114 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8267/12542 | Batch Loss: 1.3334 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8268/12542 | Batch Loss: 0.5041 | Learning Rate: 0.000114 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8269/12542 | Batch Loss: 1.7984 | Learning Rate: 0.000114 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8270/12542 | Batch Loss: 1.5775 | Learning Rate: 0.000114 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8271/12542 | Batch Loss: 2.8289 | Learning Rate: 0.000114 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8272/12542 | Batch Loss: 2.0260 | Learning Rate: 0.000113 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8273/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000113 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8274/12542 | Batch Loss: 1.1184 | Learning Rate: 0.000113 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8275/12542 | Batch Loss: 1.3785 | Learning Rate: 0.000113 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8276/12542 | Batch Loss: 1.1623 | Learning Rate: 0.000113 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8277/12542 | Batch Loss: 1.0878 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8278/12542 | Batch Loss: 2.1379 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8279/12542 | Batch Loss: 0.5401 | Learning Rate: 0.000113 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8280/12542 | Batch Loss: 0.6528 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8281/12542 | Batch Loss: 0.6440 | Learning Rate: 0.000113 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8282/12542 | Batch Loss: 2.9761 | Learning Rate: 0.000113 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8283/12542 | Batch Loss: 0.4776 | Learning Rate: 0.000113 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8284/12542 | Batch Loss: 1.3253 | Learning Rate: 0.000113 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8285/12542 | Batch Loss: 1.3863 | Learning Rate: 0.000113 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8286/12542 | Batch Loss: 1.7482 | Learning Rate: 0.000113 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8287/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000113 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8288/12542 | Batch Loss: 1.4566 | Learning Rate: 0.000113 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8289/12542 | Batch Loss: 1.2288 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8290/12542 | Batch Loss: 0.4300 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8291/12542 | Batch Loss: 1.2401 | Learning Rate: 0.000113 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8292/12542 | Batch Loss: 1.8671 | Learning Rate: 0.000113 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8293/12542 | Batch Loss: 1.7146 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8294/12542 | Batch Loss: 0.7905 | Learning Rate: 0.000113 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8295/12542 | Batch Loss: 0.7210 | Learning Rate: 0.000113 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8296/12542 | Batch Loss: 2.1051 | Learning Rate: 0.000113 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8297/12542 | Batch Loss: 0.5841 | Learning Rate: 0.000113 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8298/12542 | Batch Loss: 1.6943 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8299/12542 | Batch Loss: 0.8491 | Learning Rate: 0.000113 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8300/12542 | Batch Loss: 1.7122 | Learning Rate: 0.000113 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8301/12542 | Batch Loss: 1.2940 | Learning Rate: 0.000113 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8302/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000113 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8303/12542 | Batch Loss: 1.0739 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8304/12542 | Batch Loss: 1.6449 | Learning Rate: 0.000113 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8305/12542 | Batch Loss: 1.7389 | Learning Rate: 0.000113 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8306/12542 | Batch Loss: 1.3709 | Learning Rate: 0.000113 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8307/12542 | Batch Loss: 2.3743 | Learning Rate: 0.000113 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8308/12542 | Batch Loss: 1.3851 | Learning Rate: 0.000113 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8309/12542 | Batch Loss: 2.7325 | Learning Rate: 0.000113 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8310/12542 | Batch Loss: 1.0135 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8311/12542 | Batch Loss: 2.3578 | Learning Rate: 0.000112 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8312/12542 | Batch Loss: 1.7525 | Learning Rate: 0.000112 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8313/12542 | Batch Loss: 1.0406 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8314/12542 | Batch Loss: 2.2501 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8315/12542 | Batch Loss: 1.0895 | Learning Rate: 0.000112 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8316/12542 | Batch Loss: 1.1769 | Learning Rate: 0.000112 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8317/12542 | Batch Loss: 0.5735 | Learning Rate: 0.000112 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8318/12542 | Batch Loss: 1.7198 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8319/12542 | Batch Loss: 0.6727 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8320/12542 | Batch Loss: 1.9766 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8321/12542 | Batch Loss: 0.6235 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8322/12542 | Batch Loss: 1.8504 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8323/12542 | Batch Loss: 0.7251 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8324/12542 | Batch Loss: 1.5098 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8325/12542 | Batch Loss: 1.0901 | Learning Rate: 0.000112 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8326/12542 | Batch Loss: 0.2497 | Learning Rate: 0.000112 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8327/12542 | Batch Loss: 2.2420 | Learning Rate: 0.000112 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8328/12542 | Batch Loss: 1.0518 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8329/12542 | Batch Loss: 0.7429 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8330/12542 | Batch Loss: 1.4824 | Learning Rate: 0.000112 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8331/12542 | Batch Loss: 1.3382 | Learning Rate: 0.000112 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8332/12542 | Batch Loss: 1.5657 | Learning Rate: 0.000112 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8333/12542 | Batch Loss: 1.4365 | Learning Rate: 0.000112 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8334/12542 | Batch Loss: 0.9893 | Learning Rate: 0.000112 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8335/12542 | Batch Loss: 0.8663 | Learning Rate: 0.000112 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8336/12542 | Batch Loss: 0.8299 | Learning Rate: 0.000112 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8337/12542 | Batch Loss: 0.4671 | Learning Rate: 0.000112 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8338/12542 | Batch Loss: 0.6765 | Learning Rate: 0.000112 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8339/12542 | Batch Loss: 1.5356 | Learning Rate: 0.000112 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8340/12542 | Batch Loss: 0.9169 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8341/12542 | Batch Loss: 1.3631 | Learning Rate: 0.000112 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8342/12542 | Batch Loss: 1.1492 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8343/12542 | Batch Loss: 1.4091 | Learning Rate: 0.000112 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8344/12542 | Batch Loss: 2.1967 | Learning Rate: 0.000112 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8345/12542 | Batch Loss: 1.1063 | Learning Rate: 0.000112 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8346/12542 | Batch Loss: 0.7213 | Learning Rate: 0.000112 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8347/12542 | Batch Loss: 1.2816 | Learning Rate: 0.000111 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8348/12542 | Batch Loss: 1.5713 | Learning Rate: 0.000111 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8349/12542 | Batch Loss: 1.0087 | Learning Rate: 0.000111 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8350/12542 | Batch Loss: 1.2865 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8351/12542 | Batch Loss: 0.9903 | Learning Rate: 0.000111 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8352/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8353/12542 | Batch Loss: 1.4279 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8354/12542 | Batch Loss: 0.5330 | Learning Rate: 0.000111 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8355/12542 | Batch Loss: 1.6749 | Learning Rate: 0.000111 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8356/12542 | Batch Loss: 2.0879 | Learning Rate: 0.000111 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8357/12542 | Batch Loss: 0.8865 | Learning Rate: 0.000111 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8358/12542 | Batch Loss: 1.0717 | Learning Rate: 0.000111 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8359/12542 | Batch Loss: 1.0175 | Learning Rate: 0.000111 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8360/12542 | Batch Loss: 0.9733 | Learning Rate: 0.000111 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8361/12542 | Batch Loss: 1.0779 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8362/12542 | Batch Loss: 1.2781 | Learning Rate: 0.000111 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8363/12542 | Batch Loss: 1.4823 | Learning Rate: 0.000111 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8364/12542 | Batch Loss: 1.4527 | Learning Rate: 0.000111 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8365/12542 | Batch Loss: 1.8474 | Learning Rate: 0.000111 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8366/12542 | Batch Loss: 2.1196 | Learning Rate: 0.000111 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8367/12542 | Batch Loss: 2.5721 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8368/12542 | Batch Loss: 0.5716 | Learning Rate: 0.000111 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8369/12542 | Batch Loss: 1.9768 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8370/12542 | Batch Loss: 0.7971 | Learning Rate: 0.000111 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8371/12542 | Batch Loss: 1.0049 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8372/12542 | Batch Loss: 1.0274 | Learning Rate: 0.000111 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8373/12542 | Batch Loss: 2.2304 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8374/12542 | Batch Loss: 1.6928 | Learning Rate: 0.000111 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8375/12542 | Batch Loss: 1.6943 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8376/12542 | Batch Loss: 1.1282 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8377/12542 | Batch Loss: 0.5844 | Learning Rate: 0.000111 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8378/12542 | Batch Loss: 1.5515 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8379/12542 | Batch Loss: 1.7555 | Learning Rate: 0.000111 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8380/12542 | Batch Loss: 1.3071 | Learning Rate: 0.000111 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8381/12542 | Batch Loss: 1.1287 | Learning Rate: 0.000111 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8382/12542 | Batch Loss: 0.7629 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8383/12542 | Batch Loss: 0.7068 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8384/12542 | Batch Loss: 1.5542 | Learning Rate: 0.000111 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8385/12542 | Batch Loss: 1.3756 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8386/12542 | Batch Loss: 0.5943 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8387/12542 | Batch Loss: 1.2893 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8388/12542 | Batch Loss: 0.6829 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8389/12542 | Batch Loss: 1.1258 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8390/12542 | Batch Loss: 1.2067 | Learning Rate: 0.000110 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8391/12542 | Batch Loss: 0.8750 | Learning Rate: 0.000110 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8392/12542 | Batch Loss: 2.3358 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8393/12542 | Batch Loss: 0.9796 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8394/12542 | Batch Loss: 1.8089 | Learning Rate: 0.000110 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8395/12542 | Batch Loss: 2.7132 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8396/12542 | Batch Loss: 2.5661 | Learning Rate: 0.000110 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8397/12542 | Batch Loss: 1.7729 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8398/12542 | Batch Loss: 1.0314 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8399/12542 | Batch Loss: 1.9864 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8400/12542 | Batch Loss: 1.5412 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8401/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8402/12542 | Batch Loss: 1.0644 | Learning Rate: 0.000110 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8403/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000110 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8404/12542 | Batch Loss: 0.6221 | Learning Rate: 0.000110 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8405/12542 | Batch Loss: 1.2786 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8406/12542 | Batch Loss: 1.7691 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8407/12542 | Batch Loss: 1.4292 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8408/12542 | Batch Loss: 1.6126 | Learning Rate: 0.000110 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8409/12542 | Batch Loss: 0.6466 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8410/12542 | Batch Loss: 0.9133 | Learning Rate: 0.000110 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8411/12542 | Batch Loss: 0.6965 | Learning Rate: 0.000110 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8412/12542 | Batch Loss: 0.6658 | Learning Rate: 0.000110 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8413/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8414/12542 | Batch Loss: 0.7910 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8415/12542 | Batch Loss: 0.7923 | Learning Rate: 0.000110 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8416/12542 | Batch Loss: 2.0438 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8417/12542 | Batch Loss: 0.6981 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8418/12542 | Batch Loss: 1.4351 | Learning Rate: 0.000110 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8419/12542 | Batch Loss: 0.7723 | Learning Rate: 0.000110 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8420/12542 | Batch Loss: 0.4997 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8421/12542 | Batch Loss: 1.9925 | Learning Rate: 0.000110 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8422/12542 | Batch Loss: 3.0127 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8423/12542 | Batch Loss: 0.5721 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8424/12542 | Batch Loss: 2.1233 | Learning Rate: 0.000109 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8425/12542 | Batch Loss: 1.3326 | Learning Rate: 0.000109 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8426/12542 | Batch Loss: 1.9196 | Learning Rate: 0.000109 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8427/12542 | Batch Loss: 0.4653 | Learning Rate: 0.000109 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8428/12542 | Batch Loss: 0.5833 | Learning Rate: 0.000109 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8429/12542 | Batch Loss: 2.1727 | Learning Rate: 0.000109 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8430/12542 | Batch Loss: 1.6524 | Learning Rate: 0.000109 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8431/12542 | Batch Loss: 2.6726 | Learning Rate: 0.000109 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8432/12542 | Batch Loss: 1.3066 | Learning Rate: 0.000109 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8433/12542 | Batch Loss: 0.9249 | Learning Rate: 0.000109 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8434/12542 | Batch Loss: 0.6672 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8435/12542 | Batch Loss: 2.0910 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8436/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000109 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8437/12542 | Batch Loss: 1.1845 | Learning Rate: 0.000109 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8438/12542 | Batch Loss: 0.7881 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8439/12542 | Batch Loss: 1.1549 | Learning Rate: 0.000109 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8440/12542 | Batch Loss: 0.8163 | Learning Rate: 0.000109 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8441/12542 | Batch Loss: 0.7259 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8442/12542 | Batch Loss: 0.4148 | Learning Rate: 0.000109 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8443/12542 | Batch Loss: 1.3814 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8444/12542 | Batch Loss: 2.0228 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8445/12542 | Batch Loss: 0.5367 | Learning Rate: 0.000109 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8446/12542 | Batch Loss: 1.4533 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8447/12542 | Batch Loss: 1.4478 | Learning Rate: 0.000109 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8448/12542 | Batch Loss: 1.3213 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8449/12542 | Batch Loss: 2.2048 | Learning Rate: 0.000109 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8450/12542 | Batch Loss: 1.0260 | Learning Rate: 0.000109 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8451/12542 | Batch Loss: 1.2629 | Learning Rate: 0.000109 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8452/12542 | Batch Loss: 0.5546 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8453/12542 | Batch Loss: 1.3503 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8454/12542 | Batch Loss: 1.2719 | Learning Rate: 0.000109 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8455/12542 | Batch Loss: 1.5541 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8456/12542 | Batch Loss: 1.8759 | Learning Rate: 0.000109 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8457/12542 | Batch Loss: 1.3274 | Learning Rate: 0.000109 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8458/12542 | Batch Loss: 0.4623 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8459/12542 | Batch Loss: 1.9842 | Learning Rate: 0.000109 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8460/12542 | Batch Loss: 0.8480 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8461/12542 | Batch Loss: 1.0127 | Learning Rate: 0.000108 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8462/12542 | Batch Loss: 2.0384 | Learning Rate: 0.000108 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8463/12542 | Batch Loss: 0.6322 | Learning Rate: 0.000108 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8464/12542 | Batch Loss: 1.5018 | Learning Rate: 0.000108 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8465/12542 | Batch Loss: 0.7656 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8466/12542 | Batch Loss: 0.7820 | Learning Rate: 0.000108 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8467/12542 | Batch Loss: 2.0052 | Learning Rate: 0.000108 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8468/12542 | Batch Loss: 1.1945 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8469/12542 | Batch Loss: 1.2993 | Learning Rate: 0.000108 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8470/12542 | Batch Loss: 2.2842 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8471/12542 | Batch Loss: 1.3081 | Learning Rate: 0.000108 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8472/12542 | Batch Loss: 1.4017 | Learning Rate: 0.000108 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8473/12542 | Batch Loss: 1.1516 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8474/12542 | Batch Loss: 0.9139 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8475/12542 | Batch Loss: 1.3644 | Learning Rate: 0.000108 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8476/12542 | Batch Loss: 2.1804 | Learning Rate: 0.000108 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8477/12542 | Batch Loss: 1.4757 | Learning Rate: 0.000108 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8478/12542 | Batch Loss: 1.6019 | Learning Rate: 0.000108 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8479/12542 | Batch Loss: 0.8153 | Learning Rate: 0.000108 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8480/12542 | Batch Loss: 0.8829 | Learning Rate: 0.000108 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8481/12542 | Batch Loss: 2.0407 | Learning Rate: 0.000108 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8482/12542 | Batch Loss: 0.9787 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8483/12542 | Batch Loss: 1.3948 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8484/12542 | Batch Loss: 0.8633 | Learning Rate: 0.000108 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8485/12542 | Batch Loss: 1.0924 | Learning Rate: 0.000108 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8486/12542 | Batch Loss: 1.7607 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8487/12542 | Batch Loss: 1.2579 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8488/12542 | Batch Loss: 0.6913 | Learning Rate: 0.000108 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8489/12542 | Batch Loss: 0.2913 | Learning Rate: 0.000108 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8490/12542 | Batch Loss: 0.8534 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8491/12542 | Batch Loss: 1.2211 | Learning Rate: 0.000108 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8492/12542 | Batch Loss: 1.2171 | Learning Rate: 0.000108 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8493/12542 | Batch Loss: 1.3817 | Learning Rate: 0.000108 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8494/12542 | Batch Loss: 1.4747 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8495/12542 | Batch Loss: 2.3636 | Learning Rate: 0.000108 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8496/12542 | Batch Loss: 2.0142 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8497/12542 | Batch Loss: 1.6200 | Learning Rate: 0.000108 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8498/12542 | Batch Loss: 0.7706 | Learning Rate: 0.000107 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8499/12542 | Batch Loss: 0.9194 | Learning Rate: 0.000107 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8500/12542 | Batch Loss: 0.9609 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8501/12542 | Batch Loss: 1.0955 | Learning Rate: 0.000107 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8502/12542 | Batch Loss: 2.0020 | Learning Rate: 0.000107 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8503/12542 | Batch Loss: 1.2322 | Learning Rate: 0.000107 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8504/12542 | Batch Loss: 1.2626 | Learning Rate: 0.000107 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8505/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8506/12542 | Batch Loss: 1.5495 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8507/12542 | Batch Loss: 0.5145 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8508/12542 | Batch Loss: 1.7190 | Learning Rate: 0.000107 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8509/12542 | Batch Loss: 1.4541 | Learning Rate: 0.000107 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8510/12542 | Batch Loss: 0.7055 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8511/12542 | Batch Loss: 0.4939 | Learning Rate: 0.000107 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8512/12542 | Batch Loss: 0.7742 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8513/12542 | Batch Loss: 1.3029 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8514/12542 | Batch Loss: 0.9532 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8515/12542 | Batch Loss: 1.3036 | Learning Rate: 0.000107 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8516/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8517/12542 | Batch Loss: 1.7213 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8518/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8519/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000107 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8520/12542 | Batch Loss: 1.1129 | Learning Rate: 0.000107 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8521/12542 | Batch Loss: 3.8706 | Learning Rate: 0.000107 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8522/12542 | Batch Loss: 1.4512 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8523/12542 | Batch Loss: 1.1997 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8524/12542 | Batch Loss: 0.7212 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8525/12542 | Batch Loss: 1.2857 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8526/12542 | Batch Loss: 1.1713 | Learning Rate: 0.000107 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8527/12542 | Batch Loss: 1.3152 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8528/12542 | Batch Loss: 1.5623 | Learning Rate: 0.000107 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8529/12542 | Batch Loss: 1.9204 | Learning Rate: 0.000107 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8530/12542 | Batch Loss: 0.7086 | Learning Rate: 0.000107 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8531/12542 | Batch Loss: 0.9689 | Learning Rate: 0.000107 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8532/12542 | Batch Loss: 2.5777 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8533/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000107 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8534/12542 | Batch Loss: 1.3483 | Learning Rate: 0.000107 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8535/12542 | Batch Loss: 1.1951 | Learning Rate: 0.000106 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8536/12542 | Batch Loss: 0.7916 | Learning Rate: 0.000106 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8537/12542 | Batch Loss: 2.3513 | Learning Rate: 0.000106 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8538/12542 | Batch Loss: 1.2617 | Learning Rate: 0.000106 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8539/12542 | Batch Loss: 1.4005 | Learning Rate: 0.000106 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8540/12542 | Batch Loss: 0.6712 | Learning Rate: 0.000106 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8541/12542 | Batch Loss: 2.5446 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8542/12542 | Batch Loss: 1.9991 | Learning Rate: 0.000106 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8543/12542 | Batch Loss: 3.0911 | Learning Rate: 0.000106 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8544/12542 | Batch Loss: 1.3253 | Learning Rate: 0.000106 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8545/12542 | Batch Loss: 0.7870 | Learning Rate: 0.000106 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8546/12542 | Batch Loss: 0.6668 | Learning Rate: 0.000106 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8547/12542 | Batch Loss: 1.2039 | Learning Rate: 0.000106 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8548/12542 | Batch Loss: 0.6249 | Learning Rate: 0.000106 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8549/12542 | Batch Loss: 1.1531 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8550/12542 | Batch Loss: 1.9390 | Learning Rate: 0.000106 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8551/12542 | Batch Loss: 1.3960 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8552/12542 | Batch Loss: 1.8331 | Learning Rate: 0.000106 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8553/12542 | Batch Loss: 1.1578 | Learning Rate: 0.000106 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8554/12542 | Batch Loss: 1.6006 | Learning Rate: 0.000106 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8555/12542 | Batch Loss: 1.7557 | Learning Rate: 0.000106 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8556/12542 | Batch Loss: 1.3083 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8557/12542 | Batch Loss: 2.5876 | Learning Rate: 0.000106 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8558/12542 | Batch Loss: 1.0581 | Learning Rate: 0.000106 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8559/12542 | Batch Loss: 0.6966 | Learning Rate: 0.000106 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8560/12542 | Batch Loss: 1.8920 | Learning Rate: 0.000106 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8561/12542 | Batch Loss: 0.3953 | Learning Rate: 0.000106 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8562/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000106 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8563/12542 | Batch Loss: 1.2333 | Learning Rate: 0.000106 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8564/12542 | Batch Loss: 1.3047 | Learning Rate: 0.000106 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8565/12542 | Batch Loss: 0.8541 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8566/12542 | Batch Loss: 0.7623 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8567/12542 | Batch Loss: 1.0276 | Learning Rate: 0.000106 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8568/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000106 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8569/12542 | Batch Loss: 1.5291 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8570/12542 | Batch Loss: 1.2173 | Learning Rate: 0.000106 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8571/12542 | Batch Loss: 3.2829 | Learning Rate: 0.000106 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8572/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000106 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8573/12542 | Batch Loss: 1.4325 | Learning Rate: 0.000105 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8574/12542 | Batch Loss: 1.6134 | Learning Rate: 0.000105 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8575/12542 | Batch Loss: 0.8727 | Learning Rate: 0.000105 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8576/12542 | Batch Loss: 0.8401 | Learning Rate: 0.000105 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8577/12542 | Batch Loss: 0.4651 | Learning Rate: 0.000105 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8578/12542 | Batch Loss: 0.8439 | Learning Rate: 0.000105 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8579/12542 | Batch Loss: 1.0949 | Learning Rate: 0.000105 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8580/12542 | Batch Loss: 1.6675 | Learning Rate: 0.000105 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8581/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000105 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8582/12542 | Batch Loss: 0.6272 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8583/12542 | Batch Loss: 1.8052 | Learning Rate: 0.000105 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 8584/12542 | Batch Loss: 3.1013 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8585/12542 | Batch Loss: 1.9882 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8586/12542 | Batch Loss: 0.6246 | Learning Rate: 0.000105 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8587/12542 | Batch Loss: 1.2570 | Learning Rate: 0.000105 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8588/12542 | Batch Loss: 0.6265 | Learning Rate: 0.000105 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8589/12542 | Batch Loss: 0.9985 | Learning Rate: 0.000105 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8590/12542 | Batch Loss: 0.6289 | Learning Rate: 0.000105 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8591/12542 | Batch Loss: 1.8531 | Learning Rate: 0.000105 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8592/12542 | Batch Loss: 0.8095 | Learning Rate: 0.000105 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8593/12542 | Batch Loss: 1.2070 | Learning Rate: 0.000105 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8594/12542 | Batch Loss: 1.8474 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8595/12542 | Batch Loss: 1.2936 | Learning Rate: 0.000105 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8596/12542 | Batch Loss: 0.6871 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8597/12542 | Batch Loss: 1.0780 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8598/12542 | Batch Loss: 0.8669 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8599/12542 | Batch Loss: 0.7253 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8600/12542 | Batch Loss: 0.9409 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8601/12542 | Batch Loss: 0.6016 | Learning Rate: 0.000105 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8602/12542 | Batch Loss: 1.0536 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8603/12542 | Batch Loss: 0.6161 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8604/12542 | Batch Loss: 0.6244 | Learning Rate: 0.000105 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8605/12542 | Batch Loss: 0.9136 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8606/12542 | Batch Loss: 2.7466 | Learning Rate: 0.000105 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8607/12542 | Batch Loss: 0.8832 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8608/12542 | Batch Loss: 1.7593 | Learning Rate: 0.000105 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8609/12542 | Batch Loss: 1.0419 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8610/12542 | Batch Loss: 1.4102 | Learning Rate: 0.000105 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8611/12542 | Batch Loss: 0.7033 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8612/12542 | Batch Loss: 0.9193 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8613/12542 | Batch Loss: 1.3427 | Learning Rate: 0.000104 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8614/12542 | Batch Loss: 0.6616 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8615/12542 | Batch Loss: 0.8250 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8616/12542 | Batch Loss: 1.0525 | Learning Rate: 0.000104 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8617/12542 | Batch Loss: 1.0665 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8618/12542 | Batch Loss: 1.1667 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8619/12542 | Batch Loss: 3.0250 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8620/12542 | Batch Loss: 1.2704 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8621/12542 | Batch Loss: 0.7766 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8622/12542 | Batch Loss: 0.9272 | Learning Rate: 0.000104 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8623/12542 | Batch Loss: 1.2856 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8624/12542 | Batch Loss: 0.4886 | Learning Rate: 0.000104 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8625/12542 | Batch Loss: 1.3275 | Learning Rate: 0.000104 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8626/12542 | Batch Loss: 0.7271 | Learning Rate: 0.000104 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8627/12542 | Batch Loss: 2.2254 | Learning Rate: 0.000104 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8628/12542 | Batch Loss: 1.4886 | Learning Rate: 0.000104 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8629/12542 | Batch Loss: 0.8665 | Learning Rate: 0.000104 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8630/12542 | Batch Loss: 2.5552 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8631/12542 | Batch Loss: 1.4586 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8632/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8633/12542 | Batch Loss: 0.8800 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8634/12542 | Batch Loss: 1.5708 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8635/12542 | Batch Loss: 1.0630 | Learning Rate: 0.000104 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8636/12542 | Batch Loss: 0.7479 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8637/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8638/12542 | Batch Loss: 3.2399 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8639/12542 | Batch Loss: 0.7425 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8640/12542 | Batch Loss: 2.2910 | Learning Rate: 0.000104 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8641/12542 | Batch Loss: 0.4642 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8642/12542 | Batch Loss: 0.8804 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8643/12542 | Batch Loss: 1.7128 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8644/12542 | Batch Loss: 0.9372 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8645/12542 | Batch Loss: 1.9834 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8646/12542 | Batch Loss: 0.5802 | Learning Rate: 0.000104 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8647/12542 | Batch Loss: 1.9761 | Learning Rate: 0.000104 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8648/12542 | Batch Loss: 1.2056 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8649/12542 | Batch Loss: 2.0367 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8650/12542 | Batch Loss: 0.4757 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8651/12542 | Batch Loss: 0.9379 | Learning Rate: 0.000103 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8652/12542 | Batch Loss: 0.6804 | Learning Rate: 0.000103 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8653/12542 | Batch Loss: 1.0615 | Learning Rate: 0.000103 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8654/12542 | Batch Loss: 0.5181 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8655/12542 | Batch Loss: 1.9042 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8656/12542 | Batch Loss: 0.4787 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8657/12542 | Batch Loss: 1.2398 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8658/12542 | Batch Loss: 1.0693 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8659/12542 | Batch Loss: 1.4695 | Learning Rate: 0.000103 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8660/12542 | Batch Loss: 1.3114 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8661/12542 | Batch Loss: 0.6424 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8662/12542 | Batch Loss: 0.8007 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8663/12542 | Batch Loss: 0.8216 | Learning Rate: 0.000103 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8664/12542 | Batch Loss: 1.3396 | Learning Rate: 0.000103 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8665/12542 | Batch Loss: 1.4229 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8666/12542 | Batch Loss: 0.7558 | Learning Rate: 0.000103 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8667/12542 | Batch Loss: 2.7636 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8668/12542 | Batch Loss: 3.4556 | Learning Rate: 0.000103 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8669/12542 | Batch Loss: 1.3125 | Learning Rate: 0.000103 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8670/12542 | Batch Loss: 1.5272 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8671/12542 | Batch Loss: 2.3806 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8672/12542 | Batch Loss: 1.5931 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8673/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000103 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8674/12542 | Batch Loss: 1.1784 | Learning Rate: 0.000103 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8675/12542 | Batch Loss: 0.8981 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8676/12542 | Batch Loss: 1.5134 | Learning Rate: 0.000103 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8677/12542 | Batch Loss: 1.3673 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8678/12542 | Batch Loss: 1.2730 | Learning Rate: 0.000103 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8679/12542 | Batch Loss: 2.4559 | Learning Rate: 0.000103 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8680/12542 | Batch Loss: 0.9390 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8681/12542 | Batch Loss: 2.2036 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8682/12542 | Batch Loss: 0.5235 | Learning Rate: 0.000103 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8683/12542 | Batch Loss: 2.0589 | Learning Rate: 0.000103 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8684/12542 | Batch Loss: 0.3645 | Learning Rate: 0.000103 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8685/12542 | Batch Loss: 1.5982 | Learning Rate: 0.000103 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8686/12542 | Batch Loss: 1.3844 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8687/12542 | Batch Loss: 1.5227 | Learning Rate: 0.000102 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8688/12542 | Batch Loss: 0.6036 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8689/12542 | Batch Loss: 1.1724 | Learning Rate: 0.000102 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8690/12542 | Batch Loss: 1.4153 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8691/12542 | Batch Loss: 1.4892 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8692/12542 | Batch Loss: 1.4780 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8693/12542 | Batch Loss: 1.2958 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8694/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000102 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8695/12542 | Batch Loss: 1.1958 | Learning Rate: 0.000102 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8696/12542 | Batch Loss: 1.1451 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8697/12542 | Batch Loss: 0.5671 | Learning Rate: 0.000102 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8698/12542 | Batch Loss: 1.4858 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8699/12542 | Batch Loss: 1.0660 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8700/12542 | Batch Loss: 1.6489 | Learning Rate: 0.000102 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8701/12542 | Batch Loss: 0.9038 | Learning Rate: 0.000102 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8702/12542 | Batch Loss: 1.0569 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8703/12542 | Batch Loss: 0.9546 | Learning Rate: 0.000102 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8704/12542 | Batch Loss: 1.1197 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8705/12542 | Batch Loss: 0.7335 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8706/12542 | Batch Loss: 0.8999 | Learning Rate: 0.000102 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8707/12542 | Batch Loss: 1.3559 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8708/12542 | Batch Loss: 1.2175 | Learning Rate: 0.000102 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8709/12542 | Batch Loss: 1.4241 | Learning Rate: 0.000102 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8710/12542 | Batch Loss: 1.4387 | Learning Rate: 0.000102 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8711/12542 | Batch Loss: 1.2968 | Learning Rate: 0.000102 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8712/12542 | Batch Loss: 1.2685 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8713/12542 | Batch Loss: 0.7933 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8714/12542 | Batch Loss: 1.1588 | Learning Rate: 0.000102 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8715/12542 | Batch Loss: 2.5123 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8716/12542 | Batch Loss: 1.1120 | Learning Rate: 0.000102 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8717/12542 | Batch Loss: 0.4469 | Learning Rate: 0.000102 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8718/12542 | Batch Loss: 1.5912 | Learning Rate: 0.000102 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8719/12542 | Batch Loss: 1.1920 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8720/12542 | Batch Loss: 1.5938 | Learning Rate: 0.000102 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8721/12542 | Batch Loss: 1.8833 | Learning Rate: 0.000102 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8722/12542 | Batch Loss: 1.1687 | Learning Rate: 0.000102 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8723/12542 | Batch Loss: 1.6064 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8724/12542 | Batch Loss: 0.4244 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8725/12542 | Batch Loss: 1.3787 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8726/12542 | Batch Loss: 0.6262 | Learning Rate: 0.000101 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8727/12542 | Batch Loss: 0.5625 | Learning Rate: 0.000101 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8728/12542 | Batch Loss: 2.4091 | Learning Rate: 0.000101 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8729/12542 | Batch Loss: 1.0703 | Learning Rate: 0.000101 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8730/12542 | Batch Loss: 1.0712 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8731/12542 | Batch Loss: 1.2543 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8732/12542 | Batch Loss: 1.0568 | Learning Rate: 0.000101 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8733/12542 | Batch Loss: 0.9667 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8734/12542 | Batch Loss: 0.6915 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8735/12542 | Batch Loss: 1.2934 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8736/12542 | Batch Loss: 0.5413 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8737/12542 | Batch Loss: 1.9671 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8738/12542 | Batch Loss: 1.3021 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8739/12542 | Batch Loss: 1.0897 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8740/12542 | Batch Loss: 0.6609 | Learning Rate: 0.000101 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8741/12542 | Batch Loss: 0.3397 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8742/12542 | Batch Loss: 1.0950 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8743/12542 | Batch Loss: 0.9655 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8744/12542 | Batch Loss: 1.0260 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8745/12542 | Batch Loss: 1.1298 | Learning Rate: 0.000101 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8746/12542 | Batch Loss: 0.8302 | Learning Rate: 0.000101 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8747/12542 | Batch Loss: 1.8148 | Learning Rate: 0.000101 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8748/12542 | Batch Loss: 1.0094 | Learning Rate: 0.000101 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8749/12542 | Batch Loss: 0.7706 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8750/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000101 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8751/12542 | Batch Loss: 1.4026 | Learning Rate: 0.000101 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8752/12542 | Batch Loss: 2.5281 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8753/12542 | Batch Loss: 3.0589 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8754/12542 | Batch Loss: 2.9096 | Learning Rate: 0.000101 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8755/12542 | Batch Loss: 1.7753 | Learning Rate: 0.000101 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8756/12542 | Batch Loss: 1.9206 | Learning Rate: 0.000101 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8757/12542 | Batch Loss: 1.2520 | Learning Rate: 0.000101 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8758/12542 | Batch Loss: 1.8042 | Learning Rate: 0.000101 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8759/12542 | Batch Loss: 1.0159 | Learning Rate: 0.000101 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8760/12542 | Batch Loss: 1.0761 | Learning Rate: 0.000101 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8761/12542 | Batch Loss: 0.9842 | Learning Rate: 0.000100 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8762/12542 | Batch Loss: 1.3298 | Learning Rate: 0.000100 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8763/12542 | Batch Loss: 3.3365 | Learning Rate: 0.000100 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8764/12542 | Batch Loss: 1.8644 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8765/12542 | Batch Loss: 0.6255 | Learning Rate: 0.000100 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 8766/12542 | Batch Loss: 2.2734 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8767/12542 | Batch Loss: 2.0998 | Learning Rate: 0.000100 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8768/12542 | Batch Loss: 1.5548 | Learning Rate: 0.000100 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8769/12542 | Batch Loss: 1.2148 | Learning Rate: 0.000100 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8770/12542 | Batch Loss: 1.4823 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8771/12542 | Batch Loss: 1.1936 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8772/12542 | Batch Loss: 2.4098 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8773/12542 | Batch Loss: 0.8629 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8774/12542 | Batch Loss: 1.1070 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8775/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000100 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8776/12542 | Batch Loss: 1.3274 | Learning Rate: 0.000100 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8777/12542 | Batch Loss: 0.7181 | Learning Rate: 0.000100 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8778/12542 | Batch Loss: 2.1557 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8779/12542 | Batch Loss: 1.9956 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8780/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8781/12542 | Batch Loss: 1.6640 | Learning Rate: 0.000100 | Batch Time: 0.71s\n",
      "Epoch 3 | Step 8782/12542 | Batch Loss: 0.3264 | Learning Rate: 0.000100 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8783/12542 | Batch Loss: 0.9735 | Learning Rate: 0.000100 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8784/12542 | Batch Loss: 1.3153 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8785/12542 | Batch Loss: 0.2720 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8786/12542 | Batch Loss: 0.9697 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8787/12542 | Batch Loss: 2.0622 | Learning Rate: 0.000100 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8788/12542 | Batch Loss: 0.7892 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8789/12542 | Batch Loss: 0.4203 | Learning Rate: 0.000100 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8790/12542 | Batch Loss: 0.4503 | Learning Rate: 0.000100 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8791/12542 | Batch Loss: 0.5588 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8792/12542 | Batch Loss: 0.8360 | Learning Rate: 0.000100 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8793/12542 | Batch Loss: 0.4674 | Learning Rate: 0.000100 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 8794/12542 | Batch Loss: 0.9967 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8795/12542 | Batch Loss: 1.1214 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8796/12542 | Batch Loss: 0.3982 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8797/12542 | Batch Loss: 1.4105 | Learning Rate: 0.000100 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8798/12542 | Batch Loss: 1.7285 | Learning Rate: 0.000100 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8799/12542 | Batch Loss: 0.6828 | Learning Rate: 0.000099 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8800/12542 | Batch Loss: 0.4752 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8801/12542 | Batch Loss: 0.9538 | Learning Rate: 0.000099 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8802/12542 | Batch Loss: 0.8973 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8803/12542 | Batch Loss: 0.6375 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8804/12542 | Batch Loss: 1.7618 | Learning Rate: 0.000099 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8805/12542 | Batch Loss: 0.4071 | Learning Rate: 0.000099 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 8806/12542 | Batch Loss: 2.1715 | Learning Rate: 0.000099 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8807/12542 | Batch Loss: 2.2131 | Learning Rate: 0.000099 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8808/12542 | Batch Loss: 0.9019 | Learning Rate: 0.000099 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8809/12542 | Batch Loss: 0.4958 | Learning Rate: 0.000099 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8810/12542 | Batch Loss: 1.1775 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8811/12542 | Batch Loss: 1.3480 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8812/12542 | Batch Loss: 2.0807 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8813/12542 | Batch Loss: 1.5223 | Learning Rate: 0.000099 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8814/12542 | Batch Loss: 0.7549 | Learning Rate: 0.000099 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8815/12542 | Batch Loss: 0.6332 | Learning Rate: 0.000099 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8816/12542 | Batch Loss: 0.8033 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8817/12542 | Batch Loss: 1.0591 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8818/12542 | Batch Loss: 1.7221 | Learning Rate: 0.000099 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8819/12542 | Batch Loss: 1.8396 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8820/12542 | Batch Loss: 0.7200 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8821/12542 | Batch Loss: 1.5537 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8822/12542 | Batch Loss: 1.6289 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8823/12542 | Batch Loss: 1.4577 | Learning Rate: 0.000099 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8824/12542 | Batch Loss: 1.4763 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8825/12542 | Batch Loss: 0.7789 | Learning Rate: 0.000099 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8826/12542 | Batch Loss: 1.5977 | Learning Rate: 0.000099 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8827/12542 | Batch Loss: 0.9377 | Learning Rate: 0.000099 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8828/12542 | Batch Loss: 0.7855 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8829/12542 | Batch Loss: 1.9022 | Learning Rate: 0.000099 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8830/12542 | Batch Loss: 0.9655 | Learning Rate: 0.000099 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8831/12542 | Batch Loss: 1.4803 | Learning Rate: 0.000099 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 8832/12542 | Batch Loss: 1.0143 | Learning Rate: 0.000099 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8833/12542 | Batch Loss: 1.5285 | Learning Rate: 0.000099 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8834/12542 | Batch Loss: 1.3872 | Learning Rate: 0.000099 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8835/12542 | Batch Loss: 0.5305 | Learning Rate: 0.000099 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8836/12542 | Batch Loss: 3.3826 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8837/12542 | Batch Loss: 0.5659 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8838/12542 | Batch Loss: 0.9630 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8839/12542 | Batch Loss: 1.2929 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8840/12542 | Batch Loss: 0.7754 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8841/12542 | Batch Loss: 1.6674 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8842/12542 | Batch Loss: 0.7864 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8843/12542 | Batch Loss: 1.6766 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8844/12542 | Batch Loss: 1.0705 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8845/12542 | Batch Loss: 0.4612 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8846/12542 | Batch Loss: 1.0661 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8847/12542 | Batch Loss: 1.5736 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8848/12542 | Batch Loss: 1.5204 | Learning Rate: 0.000098 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8849/12542 | Batch Loss: 1.8491 | Learning Rate: 0.000098 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8850/12542 | Batch Loss: 1.1076 | Learning Rate: 0.000098 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8851/12542 | Batch Loss: 2.1062 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8852/12542 | Batch Loss: 0.7501 | Learning Rate: 0.000098 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8853/12542 | Batch Loss: 0.7051 | Learning Rate: 0.000098 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8854/12542 | Batch Loss: 1.7564 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8855/12542 | Batch Loss: 0.7108 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8856/12542 | Batch Loss: 0.7449 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8857/12542 | Batch Loss: 3.6367 | Learning Rate: 0.000098 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8858/12542 | Batch Loss: 1.2598 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8859/12542 | Batch Loss: 1.4111 | Learning Rate: 0.000098 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8860/12542 | Batch Loss: 0.9467 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8861/12542 | Batch Loss: 1.1740 | Learning Rate: 0.000098 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8862/12542 | Batch Loss: 2.0598 | Learning Rate: 0.000098 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8863/12542 | Batch Loss: 1.4411 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8864/12542 | Batch Loss: 0.7044 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8865/12542 | Batch Loss: 1.4317 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8866/12542 | Batch Loss: 1.9056 | Learning Rate: 0.000098 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8867/12542 | Batch Loss: 2.2662 | Learning Rate: 0.000098 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8868/12542 | Batch Loss: 1.8821 | Learning Rate: 0.000098 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8869/12542 | Batch Loss: 1.8542 | Learning Rate: 0.000098 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8870/12542 | Batch Loss: 1.0838 | Learning Rate: 0.000098 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8871/12542 | Batch Loss: 1.8464 | Learning Rate: 0.000098 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8872/12542 | Batch Loss: 0.7317 | Learning Rate: 0.000098 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8873/12542 | Batch Loss: 0.9990 | Learning Rate: 0.000098 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8874/12542 | Batch Loss: 1.4880 | Learning Rate: 0.000097 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8875/12542 | Batch Loss: 0.6712 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8876/12542 | Batch Loss: 0.6253 | Learning Rate: 0.000097 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8877/12542 | Batch Loss: 1.9193 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8878/12542 | Batch Loss: 1.1417 | Learning Rate: 0.000097 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8879/12542 | Batch Loss: 1.1786 | Learning Rate: 0.000097 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8880/12542 | Batch Loss: 1.7952 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8881/12542 | Batch Loss: 0.6547 | Learning Rate: 0.000097 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8882/12542 | Batch Loss: 1.5971 | Learning Rate: 0.000097 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8883/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8884/12542 | Batch Loss: 1.7663 | Learning Rate: 0.000097 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8885/12542 | Batch Loss: 1.6501 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8886/12542 | Batch Loss: 1.0333 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8887/12542 | Batch Loss: 0.5787 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8888/12542 | Batch Loss: 1.1493 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8889/12542 | Batch Loss: 2.7191 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8890/12542 | Batch Loss: 1.2437 | Learning Rate: 0.000097 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8891/12542 | Batch Loss: 1.0139 | Learning Rate: 0.000097 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8892/12542 | Batch Loss: 1.0439 | Learning Rate: 0.000097 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8893/12542 | Batch Loss: 0.9323 | Learning Rate: 0.000097 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8894/12542 | Batch Loss: 1.6500 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8895/12542 | Batch Loss: 2.2800 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8896/12542 | Batch Loss: 1.3283 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8897/12542 | Batch Loss: 1.2453 | Learning Rate: 0.000097 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8898/12542 | Batch Loss: 2.3147 | Learning Rate: 0.000097 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8899/12542 | Batch Loss: 0.8281 | Learning Rate: 0.000097 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8900/12542 | Batch Loss: 1.1847 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8901/12542 | Batch Loss: 1.2988 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8902/12542 | Batch Loss: 1.7504 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8903/12542 | Batch Loss: 1.1716 | Learning Rate: 0.000097 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8904/12542 | Batch Loss: 1.1753 | Learning Rate: 0.000097 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8905/12542 | Batch Loss: 0.8337 | Learning Rate: 0.000097 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8906/12542 | Batch Loss: 0.7104 | Learning Rate: 0.000097 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8907/12542 | Batch Loss: 1.7134 | Learning Rate: 0.000097 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8908/12542 | Batch Loss: 0.8223 | Learning Rate: 0.000097 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8909/12542 | Batch Loss: 0.7195 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8910/12542 | Batch Loss: 1.1167 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8911/12542 | Batch Loss: 1.5569 | Learning Rate: 0.000097 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8912/12542 | Batch Loss: 0.7617 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8913/12542 | Batch Loss: 1.4193 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8914/12542 | Batch Loss: 1.6579 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8915/12542 | Batch Loss: 3.0148 | Learning Rate: 0.000096 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8916/12542 | Batch Loss: 1.8364 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8917/12542 | Batch Loss: 0.5593 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8918/12542 | Batch Loss: 1.2224 | Learning Rate: 0.000096 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8919/12542 | Batch Loss: 1.4446 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8920/12542 | Batch Loss: 1.5922 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8921/12542 | Batch Loss: 0.8446 | Learning Rate: 0.000096 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8922/12542 | Batch Loss: 1.0386 | Learning Rate: 0.000096 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8923/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000096 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8924/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000096 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8925/12542 | Batch Loss: 1.9691 | Learning Rate: 0.000096 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8926/12542 | Batch Loss: 1.4249 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8927/12542 | Batch Loss: 0.7759 | Learning Rate: 0.000096 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8928/12542 | Batch Loss: 0.9695 | Learning Rate: 0.000096 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8929/12542 | Batch Loss: 1.6129 | Learning Rate: 0.000096 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8930/12542 | Batch Loss: 0.9366 | Learning Rate: 0.000096 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8931/12542 | Batch Loss: 1.2611 | Learning Rate: 0.000096 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8932/12542 | Batch Loss: 1.7431 | Learning Rate: 0.000096 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8933/12542 | Batch Loss: 1.2348 | Learning Rate: 0.000096 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8934/12542 | Batch Loss: 1.6793 | Learning Rate: 0.000096 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8935/12542 | Batch Loss: 2.0705 | Learning Rate: 0.000096 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8936/12542 | Batch Loss: 1.1359 | Learning Rate: 0.000096 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8937/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000096 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8938/12542 | Batch Loss: 2.4477 | Learning Rate: 0.000096 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8939/12542 | Batch Loss: 0.5321 | Learning Rate: 0.000096 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8940/12542 | Batch Loss: 1.5983 | Learning Rate: 0.000096 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8941/12542 | Batch Loss: 0.8311 | Learning Rate: 0.000096 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8942/12542 | Batch Loss: 1.2136 | Learning Rate: 0.000096 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8943/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000096 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8944/12542 | Batch Loss: 1.2638 | Learning Rate: 0.000096 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 8945/12542 | Batch Loss: 1.4109 | Learning Rate: 0.000096 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 8946/12542 | Batch Loss: 1.0876 | Learning Rate: 0.000096 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8947/12542 | Batch Loss: 0.6304 | Learning Rate: 0.000096 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 8948/12542 | Batch Loss: 1.2877 | Learning Rate: 0.000096 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8949/12542 | Batch Loss: 1.3282 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8950/12542 | Batch Loss: 1.0120 | Learning Rate: 0.000095 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8951/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8952/12542 | Batch Loss: 1.6126 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8953/12542 | Batch Loss: 1.2581 | Learning Rate: 0.000095 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8954/12542 | Batch Loss: 1.7633 | Learning Rate: 0.000095 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8955/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000095 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8956/12542 | Batch Loss: 1.7319 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8957/12542 | Batch Loss: 1.3627 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8958/12542 | Batch Loss: 1.5562 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8959/12542 | Batch Loss: 1.6678 | Learning Rate: 0.000095 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8960/12542 | Batch Loss: 2.4754 | Learning Rate: 0.000095 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 8961/12542 | Batch Loss: 0.7467 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8962/12542 | Batch Loss: 0.6761 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8963/12542 | Batch Loss: 1.0331 | Learning Rate: 0.000095 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8964/12542 | Batch Loss: 1.4958 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8965/12542 | Batch Loss: 1.4606 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8966/12542 | Batch Loss: 0.7548 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8967/12542 | Batch Loss: 0.6361 | Learning Rate: 0.000095 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8968/12542 | Batch Loss: 1.4919 | Learning Rate: 0.000095 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8969/12542 | Batch Loss: 2.0739 | Learning Rate: 0.000095 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8970/12542 | Batch Loss: 1.7282 | Learning Rate: 0.000095 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8971/12542 | Batch Loss: 0.7092 | Learning Rate: 0.000095 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 8972/12542 | Batch Loss: 1.2713 | Learning Rate: 0.000095 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 8973/12542 | Batch Loss: 0.6053 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8974/12542 | Batch Loss: 0.8736 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8975/12542 | Batch Loss: 0.6237 | Learning Rate: 0.000095 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8976/12542 | Batch Loss: 1.5202 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8977/12542 | Batch Loss: 1.2384 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8978/12542 | Batch Loss: 0.9714 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8979/12542 | Batch Loss: 1.1300 | Learning Rate: 0.000095 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 8980/12542 | Batch Loss: 0.4925 | Learning Rate: 0.000095 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8981/12542 | Batch Loss: 0.4190 | Learning Rate: 0.000095 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8982/12542 | Batch Loss: 2.2580 | Learning Rate: 0.000095 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 8983/12542 | Batch Loss: 1.0981 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8984/12542 | Batch Loss: 0.5512 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8985/12542 | Batch Loss: 1.5927 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8986/12542 | Batch Loss: 1.7038 | Learning Rate: 0.000095 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8987/12542 | Batch Loss: 0.5228 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8988/12542 | Batch Loss: 1.2013 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8989/12542 | Batch Loss: 3.2703 | Learning Rate: 0.000094 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8990/12542 | Batch Loss: 0.5579 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 8991/12542 | Batch Loss: 1.0923 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8992/12542 | Batch Loss: 1.1948 | Learning Rate: 0.000094 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 8993/12542 | Batch Loss: 1.6861 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8994/12542 | Batch Loss: 1.1262 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8995/12542 | Batch Loss: 1.2372 | Learning Rate: 0.000094 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 8996/12542 | Batch Loss: 1.9004 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8997/12542 | Batch Loss: 0.7408 | Learning Rate: 0.000094 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 8998/12542 | Batch Loss: 0.5105 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 8999/12542 | Batch Loss: 1.3054 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9000/12542 | Batch Loss: 1.3391 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9001/12542 | Batch Loss: 0.9283 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9002/12542 | Batch Loss: 0.9116 | Learning Rate: 0.000094 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9003/12542 | Batch Loss: 1.3880 | Learning Rate: 0.000094 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9004/12542 | Batch Loss: 0.7492 | Learning Rate: 0.000094 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9005/12542 | Batch Loss: 1.8994 | Learning Rate: 0.000094 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9006/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000094 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9007/12542 | Batch Loss: 1.1241 | Learning Rate: 0.000094 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9008/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000094 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9009/12542 | Batch Loss: 1.5361 | Learning Rate: 0.000094 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9010/12542 | Batch Loss: 0.8407 | Learning Rate: 0.000094 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9011/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000094 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9012/12542 | Batch Loss: 2.6994 | Learning Rate: 0.000094 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9013/12542 | Batch Loss: 1.4464 | Learning Rate: 0.000094 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9014/12542 | Batch Loss: 1.6373 | Learning Rate: 0.000094 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9015/12542 | Batch Loss: 1.0051 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9016/12542 | Batch Loss: 2.0048 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9017/12542 | Batch Loss: 1.5060 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9018/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000094 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9019/12542 | Batch Loss: 1.0266 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9020/12542 | Batch Loss: 0.7164 | Learning Rate: 0.000094 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9021/12542 | Batch Loss: 1.4415 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9022/12542 | Batch Loss: 1.1749 | Learning Rate: 0.000094 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9023/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000094 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9024/12542 | Batch Loss: 0.9075 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9025/12542 | Batch Loss: 0.5879 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9026/12542 | Batch Loss: 1.1419 | Learning Rate: 0.000093 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9027/12542 | Batch Loss: 0.6994 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9028/12542 | Batch Loss: 0.4849 | Learning Rate: 0.000093 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9029/12542 | Batch Loss: 1.7468 | Learning Rate: 0.000093 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9030/12542 | Batch Loss: 1.0563 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9031/12542 | Batch Loss: 1.0063 | Learning Rate: 0.000093 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9032/12542 | Batch Loss: 1.9007 | Learning Rate: 0.000093 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9033/12542 | Batch Loss: 0.7008 | Learning Rate: 0.000093 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9034/12542 | Batch Loss: 0.6608 | Learning Rate: 0.000093 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9035/12542 | Batch Loss: 2.2126 | Learning Rate: 0.000093 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9036/12542 | Batch Loss: 1.1124 | Learning Rate: 0.000093 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9037/12542 | Batch Loss: 1.2647 | Learning Rate: 0.000093 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9038/12542 | Batch Loss: 1.2620 | Learning Rate: 0.000093 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9039/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000093 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9040/12542 | Batch Loss: 0.9360 | Learning Rate: 0.000093 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9041/12542 | Batch Loss: 1.5680 | Learning Rate: 0.000093 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9042/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000093 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9043/12542 | Batch Loss: 0.8295 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9044/12542 | Batch Loss: 1.1234 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9045/12542 | Batch Loss: 0.9441 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9046/12542 | Batch Loss: 1.4772 | Learning Rate: 0.000093 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9047/12542 | Batch Loss: 0.9611 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9048/12542 | Batch Loss: 1.3405 | Learning Rate: 0.000093 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9049/12542 | Batch Loss: 2.7060 | Learning Rate: 0.000093 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9050/12542 | Batch Loss: 0.8184 | Learning Rate: 0.000093 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9051/12542 | Batch Loss: 1.3948 | Learning Rate: 0.000093 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9052/12542 | Batch Loss: 1.2004 | Learning Rate: 0.000093 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9053/12542 | Batch Loss: 1.4019 | Learning Rate: 0.000093 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9054/12542 | Batch Loss: 1.8657 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9055/12542 | Batch Loss: 0.6090 | Learning Rate: 0.000093 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9056/12542 | Batch Loss: 0.6064 | Learning Rate: 0.000093 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9057/12542 | Batch Loss: 0.9179 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9058/12542 | Batch Loss: 0.8303 | Learning Rate: 0.000093 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9059/12542 | Batch Loss: 0.9215 | Learning Rate: 0.000093 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9060/12542 | Batch Loss: 0.9001 | Learning Rate: 0.000093 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 9061/12542 | Batch Loss: 0.8295 | Learning Rate: 0.000093 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9062/12542 | Batch Loss: 1.3254 | Learning Rate: 0.000092 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9063/12542 | Batch Loss: 0.3846 | Learning Rate: 0.000092 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9064/12542 | Batch Loss: 0.7920 | Learning Rate: 0.000092 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9065/12542 | Batch Loss: 1.4051 | Learning Rate: 0.000092 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9066/12542 | Batch Loss: 2.4498 | Learning Rate: 0.000092 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9067/12542 | Batch Loss: 0.6503 | Learning Rate: 0.000092 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9068/12542 | Batch Loss: 0.6808 | Learning Rate: 0.000092 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9069/12542 | Batch Loss: 0.7270 | Learning Rate: 0.000092 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9070/12542 | Batch Loss: 1.6887 | Learning Rate: 0.000092 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9071/12542 | Batch Loss: 0.7938 | Learning Rate: 0.000092 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9072/12542 | Batch Loss: 2.0557 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9073/12542 | Batch Loss: 1.7279 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9074/12542 | Batch Loss: 2.1158 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9075/12542 | Batch Loss: 0.6105 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9076/12542 | Batch Loss: 1.6744 | Learning Rate: 0.000092 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9077/12542 | Batch Loss: 1.4007 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9078/12542 | Batch Loss: 0.9065 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9079/12542 | Batch Loss: 1.7891 | Learning Rate: 0.000092 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9080/12542 | Batch Loss: 1.1921 | Learning Rate: 0.000092 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9081/12542 | Batch Loss: 1.1100 | Learning Rate: 0.000092 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9082/12542 | Batch Loss: 1.2623 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9083/12542 | Batch Loss: 1.2843 | Learning Rate: 0.000092 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9084/12542 | Batch Loss: 1.5935 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9085/12542 | Batch Loss: 1.0407 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9086/12542 | Batch Loss: 0.7542 | Learning Rate: 0.000092 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9087/12542 | Batch Loss: 0.4350 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9088/12542 | Batch Loss: 0.7503 | Learning Rate: 0.000092 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9089/12542 | Batch Loss: 1.6485 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9090/12542 | Batch Loss: 1.8503 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9091/12542 | Batch Loss: 1.6073 | Learning Rate: 0.000092 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9092/12542 | Batch Loss: 1.4511 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9093/12542 | Batch Loss: 1.7678 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9094/12542 | Batch Loss: 1.3239 | Learning Rate: 0.000092 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9095/12542 | Batch Loss: 0.9468 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9096/12542 | Batch Loss: 1.6832 | Learning Rate: 0.000092 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9097/12542 | Batch Loss: 2.1073 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9098/12542 | Batch Loss: 1.3564 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9099/12542 | Batch Loss: 0.7061 | Learning Rate: 0.000092 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9100/12542 | Batch Loss: 1.8816 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9101/12542 | Batch Loss: 1.2945 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9102/12542 | Batch Loss: 1.1164 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9103/12542 | Batch Loss: 1.9088 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9104/12542 | Batch Loss: 1.1496 | Learning Rate: 0.000091 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9105/12542 | Batch Loss: 1.5035 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9106/12542 | Batch Loss: 0.9348 | Learning Rate: 0.000091 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9107/12542 | Batch Loss: 0.9158 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9108/12542 | Batch Loss: 0.7895 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9109/12542 | Batch Loss: 1.3048 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9110/12542 | Batch Loss: 0.9861 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9111/12542 | Batch Loss: 1.1880 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9112/12542 | Batch Loss: 0.9873 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9113/12542 | Batch Loss: 1.0779 | Learning Rate: 0.000091 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9114/12542 | Batch Loss: 2.5926 | Learning Rate: 0.000091 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9115/12542 | Batch Loss: 0.8477 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9116/12542 | Batch Loss: 1.1112 | Learning Rate: 0.000091 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9117/12542 | Batch Loss: 1.8676 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9118/12542 | Batch Loss: 1.0538 | Learning Rate: 0.000091 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9119/12542 | Batch Loss: 0.3479 | Learning Rate: 0.000091 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9120/12542 | Batch Loss: 1.1925 | Learning Rate: 0.000091 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9121/12542 | Batch Loss: 1.6131 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9122/12542 | Batch Loss: 1.9393 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9123/12542 | Batch Loss: 0.7707 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9124/12542 | Batch Loss: 1.0001 | Learning Rate: 0.000091 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9125/12542 | Batch Loss: 1.7819 | Learning Rate: 0.000091 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9126/12542 | Batch Loss: 0.5994 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9127/12542 | Batch Loss: 0.8966 | Learning Rate: 0.000091 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9128/12542 | Batch Loss: 1.3258 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9129/12542 | Batch Loss: 0.6591 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9130/12542 | Batch Loss: 0.6558 | Learning Rate: 0.000091 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9131/12542 | Batch Loss: 1.0186 | Learning Rate: 0.000091 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9132/12542 | Batch Loss: 1.5064 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9133/12542 | Batch Loss: 1.9621 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9134/12542 | Batch Loss: 1.7002 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9135/12542 | Batch Loss: 1.2646 | Learning Rate: 0.000091 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9136/12542 | Batch Loss: 0.7866 | Learning Rate: 0.000091 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9137/12542 | Batch Loss: 1.1034 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9138/12542 | Batch Loss: 1.8614 | Learning Rate: 0.000090 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9139/12542 | Batch Loss: 0.6547 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9140/12542 | Batch Loss: 1.3386 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9141/12542 | Batch Loss: 0.6762 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9142/12542 | Batch Loss: 0.9924 | Learning Rate: 0.000090 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9143/12542 | Batch Loss: 0.6774 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9144/12542 | Batch Loss: 2.5066 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9145/12542 | Batch Loss: 0.5224 | Learning Rate: 0.000090 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9146/12542 | Batch Loss: 1.1456 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9147/12542 | Batch Loss: 0.9004 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9148/12542 | Batch Loss: 1.0291 | Learning Rate: 0.000090 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9149/12542 | Batch Loss: 0.9707 | Learning Rate: 0.000090 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9150/12542 | Batch Loss: 1.4709 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9151/12542 | Batch Loss: 1.6350 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9152/12542 | Batch Loss: 0.7414 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9153/12542 | Batch Loss: 0.9125 | Learning Rate: 0.000090 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9154/12542 | Batch Loss: 1.5210 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9155/12542 | Batch Loss: 1.4148 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9156/12542 | Batch Loss: 0.8563 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9157/12542 | Batch Loss: 2.4768 | Learning Rate: 0.000090 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9158/12542 | Batch Loss: 1.1494 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9159/12542 | Batch Loss: 1.2861 | Learning Rate: 0.000090 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9160/12542 | Batch Loss: 1.9909 | Learning Rate: 0.000090 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9161/12542 | Batch Loss: 0.7379 | Learning Rate: 0.000090 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9162/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000090 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9163/12542 | Batch Loss: 2.0373 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9164/12542 | Batch Loss: 0.4647 | Learning Rate: 0.000090 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9165/12542 | Batch Loss: 1.0829 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9166/12542 | Batch Loss: 0.3038 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9167/12542 | Batch Loss: 1.4165 | Learning Rate: 0.000090 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9168/12542 | Batch Loss: 2.2374 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9169/12542 | Batch Loss: 2.5983 | Learning Rate: 0.000090 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9170/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000090 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9171/12542 | Batch Loss: 1.1217 | Learning Rate: 0.000090 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9172/12542 | Batch Loss: 1.1891 | Learning Rate: 0.000090 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9173/12542 | Batch Loss: 0.6759 | Learning Rate: 0.000090 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9174/12542 | Batch Loss: 1.2691 | Learning Rate: 0.000090 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9175/12542 | Batch Loss: 0.6231 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9176/12542 | Batch Loss: 0.9620 | Learning Rate: 0.000089 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9177/12542 | Batch Loss: 1.4834 | Learning Rate: 0.000089 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9178/12542 | Batch Loss: 0.6457 | Learning Rate: 0.000089 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9179/12542 | Batch Loss: 1.0158 | Learning Rate: 0.000089 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9180/12542 | Batch Loss: 0.9664 | Learning Rate: 0.000089 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9181/12542 | Batch Loss: 0.6195 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9182/12542 | Batch Loss: 1.6697 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9183/12542 | Batch Loss: 2.2233 | Learning Rate: 0.000089 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9184/12542 | Batch Loss: 1.0528 | Learning Rate: 0.000089 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9185/12542 | Batch Loss: 1.3266 | Learning Rate: 0.000089 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9186/12542 | Batch Loss: 2.0557 | Learning Rate: 0.000089 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9187/12542 | Batch Loss: 2.4807 | Learning Rate: 0.000089 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9188/12542 | Batch Loss: 1.0755 | Learning Rate: 0.000089 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9189/12542 | Batch Loss: 0.8029 | Learning Rate: 0.000089 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9190/12542 | Batch Loss: 1.2761 | Learning Rate: 0.000089 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9191/12542 | Batch Loss: 0.6517 | Learning Rate: 0.000089 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9192/12542 | Batch Loss: 0.5766 | Learning Rate: 0.000089 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9193/12542 | Batch Loss: 1.2169 | Learning Rate: 0.000089 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9194/12542 | Batch Loss: 1.3296 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9195/12542 | Batch Loss: 0.3493 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9196/12542 | Batch Loss: 1.6421 | Learning Rate: 0.000089 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9197/12542 | Batch Loss: 1.1607 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9198/12542 | Batch Loss: 1.7885 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9199/12542 | Batch Loss: 1.1160 | Learning Rate: 0.000089 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9200/12542 | Batch Loss: 0.4592 | Learning Rate: 0.000089 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9201/12542 | Batch Loss: 0.6348 | Learning Rate: 0.000089 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9202/12542 | Batch Loss: 0.9284 | Learning Rate: 0.000089 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9203/12542 | Batch Loss: 1.2667 | Learning Rate: 0.000089 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9204/12542 | Batch Loss: 1.1847 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9205/12542 | Batch Loss: 2.8103 | Learning Rate: 0.000089 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9206/12542 | Batch Loss: 1.1325 | Learning Rate: 0.000089 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9207/12542 | Batch Loss: 1.3430 | Learning Rate: 0.000089 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9208/12542 | Batch Loss: 2.0063 | Learning Rate: 0.000089 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9209/12542 | Batch Loss: 2.0489 | Learning Rate: 0.000089 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9210/12542 | Batch Loss: 1.3246 | Learning Rate: 0.000089 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9211/12542 | Batch Loss: 2.8408 | Learning Rate: 0.000089 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9212/12542 | Batch Loss: 0.9193 | Learning Rate: 0.000089 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9213/12542 | Batch Loss: 1.4323 | Learning Rate: 0.000088 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9214/12542 | Batch Loss: 1.1096 | Learning Rate: 0.000088 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9215/12542 | Batch Loss: 0.8131 | Learning Rate: 0.000088 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9216/12542 | Batch Loss: 0.3875 | Learning Rate: 0.000088 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9217/12542 | Batch Loss: 2.2396 | Learning Rate: 0.000088 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9218/12542 | Batch Loss: 1.3853 | Learning Rate: 0.000088 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9219/12542 | Batch Loss: 0.9029 | Learning Rate: 0.000088 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9220/12542 | Batch Loss: 0.5308 | Learning Rate: 0.000088 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9221/12542 | Batch Loss: 1.3049 | Learning Rate: 0.000088 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9222/12542 | Batch Loss: 0.8220 | Learning Rate: 0.000088 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9223/12542 | Batch Loss: 1.1030 | Learning Rate: 0.000088 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9224/12542 | Batch Loss: 1.8318 | Learning Rate: 0.000088 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9225/12542 | Batch Loss: 1.4554 | Learning Rate: 0.000088 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9226/12542 | Batch Loss: 0.4046 | Learning Rate: 0.000088 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9227/12542 | Batch Loss: 1.4157 | Learning Rate: 0.000088 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9228/12542 | Batch Loss: 1.8440 | Learning Rate: 0.000088 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9229/12542 | Batch Loss: 0.7479 | Learning Rate: 0.000088 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9230/12542 | Batch Loss: 1.1548 | Learning Rate: 0.000088 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9231/12542 | Batch Loss: 1.8080 | Learning Rate: 0.000088 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9232/12542 | Batch Loss: 2.4221 | Learning Rate: 0.000088 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9233/12542 | Batch Loss: 0.9099 | Learning Rate: 0.000088 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9234/12542 | Batch Loss: 1.4412 | Learning Rate: 0.000088 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9235/12542 | Batch Loss: 1.3456 | Learning Rate: 0.000088 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9236/12542 | Batch Loss: 1.6362 | Learning Rate: 0.000088 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9237/12542 | Batch Loss: 1.4211 | Learning Rate: 0.000088 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9238/12542 | Batch Loss: 2.2619 | Learning Rate: 0.000088 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9239/12542 | Batch Loss: 1.1577 | Learning Rate: 0.000088 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9240/12542 | Batch Loss: 1.0788 | Learning Rate: 0.000088 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 9241/12542 | Batch Loss: 1.4600 | Learning Rate: 0.000088 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9242/12542 | Batch Loss: 1.4175 | Learning Rate: 0.000088 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9243/12542 | Batch Loss: 0.6996 | Learning Rate: 0.000088 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9244/12542 | Batch Loss: 1.1092 | Learning Rate: 0.000088 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9245/12542 | Batch Loss: 1.1874 | Learning Rate: 0.000088 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9246/12542 | Batch Loss: 1.2585 | Learning Rate: 0.000088 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9247/12542 | Batch Loss: 1.1390 | Learning Rate: 0.000088 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9248/12542 | Batch Loss: 0.7946 | Learning Rate: 0.000088 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9249/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000088 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9250/12542 | Batch Loss: 2.4889 | Learning Rate: 0.000087 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9251/12542 | Batch Loss: 1.1552 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9252/12542 | Batch Loss: 1.6523 | Learning Rate: 0.000087 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9253/12542 | Batch Loss: 2.4468 | Learning Rate: 0.000087 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9254/12542 | Batch Loss: 1.0718 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9255/12542 | Batch Loss: 1.7556 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9256/12542 | Batch Loss: 0.8494 | Learning Rate: 0.000087 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9257/12542 | Batch Loss: 0.8430 | Learning Rate: 0.000087 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9258/12542 | Batch Loss: 1.2605 | Learning Rate: 0.000087 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9259/12542 | Batch Loss: 1.0165 | Learning Rate: 0.000087 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9260/12542 | Batch Loss: 0.6133 | Learning Rate: 0.000087 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9261/12542 | Batch Loss: 1.5523 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9262/12542 | Batch Loss: 1.4285 | Learning Rate: 0.000087 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9263/12542 | Batch Loss: 0.4956 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9264/12542 | Batch Loss: 1.0262 | Learning Rate: 0.000087 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9265/12542 | Batch Loss: 0.5491 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9266/12542 | Batch Loss: 0.5120 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9267/12542 | Batch Loss: 1.1581 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9268/12542 | Batch Loss: 0.6741 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9269/12542 | Batch Loss: 0.5848 | Learning Rate: 0.000087 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9270/12542 | Batch Loss: 0.5688 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9271/12542 | Batch Loss: 2.1501 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9272/12542 | Batch Loss: 1.3787 | Learning Rate: 0.000087 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9273/12542 | Batch Loss: 0.5764 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9274/12542 | Batch Loss: 0.8410 | Learning Rate: 0.000087 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9275/12542 | Batch Loss: 1.4507 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9276/12542 | Batch Loss: 1.0860 | Learning Rate: 0.000087 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9277/12542 | Batch Loss: 1.4266 | Learning Rate: 0.000087 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9278/12542 | Batch Loss: 1.8100 | Learning Rate: 0.000087 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9279/12542 | Batch Loss: 0.9562 | Learning Rate: 0.000087 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9280/12542 | Batch Loss: 1.3374 | Learning Rate: 0.000087 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9281/12542 | Batch Loss: 2.5487 | Learning Rate: 0.000087 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9282/12542 | Batch Loss: 0.4657 | Learning Rate: 0.000087 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9283/12542 | Batch Loss: 0.9816 | Learning Rate: 0.000087 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9284/12542 | Batch Loss: 2.0061 | Learning Rate: 0.000087 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9285/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000087 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9286/12542 | Batch Loss: 1.9003 | Learning Rate: 0.000087 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9287/12542 | Batch Loss: 1.8318 | Learning Rate: 0.000087 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9288/12542 | Batch Loss: 2.0819 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9289/12542 | Batch Loss: 1.5005 | Learning Rate: 0.000086 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9290/12542 | Batch Loss: 0.6938 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9291/12542 | Batch Loss: 2.6090 | Learning Rate: 0.000086 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9292/12542 | Batch Loss: 1.8885 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9293/12542 | Batch Loss: 1.4988 | Learning Rate: 0.000086 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9294/12542 | Batch Loss: 1.2559 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9295/12542 | Batch Loss: 1.2364 | Learning Rate: 0.000086 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9296/12542 | Batch Loss: 1.4429 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9297/12542 | Batch Loss: 1.3857 | Learning Rate: 0.000086 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9298/12542 | Batch Loss: 1.2469 | Learning Rate: 0.000086 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9299/12542 | Batch Loss: 3.5524 | Learning Rate: 0.000086 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9300/12542 | Batch Loss: 2.0477 | Learning Rate: 0.000086 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9301/12542 | Batch Loss: 2.2918 | Learning Rate: 0.000086 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9302/12542 | Batch Loss: 1.2251 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9303/12542 | Batch Loss: 1.5711 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9304/12542 | Batch Loss: 1.6742 | Learning Rate: 0.000086 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9305/12542 | Batch Loss: 1.0502 | Learning Rate: 0.000086 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9306/12542 | Batch Loss: 1.6740 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9307/12542 | Batch Loss: 2.0923 | Learning Rate: 0.000086 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9308/12542 | Batch Loss: 3.0804 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9309/12542 | Batch Loss: 0.3792 | Learning Rate: 0.000086 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9310/12542 | Batch Loss: 1.9763 | Learning Rate: 0.000086 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9311/12542 | Batch Loss: 0.9449 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9312/12542 | Batch Loss: 2.0661 | Learning Rate: 0.000086 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9313/12542 | Batch Loss: 1.3610 | Learning Rate: 0.000086 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9314/12542 | Batch Loss: 1.4250 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9315/12542 | Batch Loss: 1.2303 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9316/12542 | Batch Loss: 1.0819 | Learning Rate: 0.000086 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9317/12542 | Batch Loss: 0.2516 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9318/12542 | Batch Loss: 0.9684 | Learning Rate: 0.000086 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9319/12542 | Batch Loss: 1.4614 | Learning Rate: 0.000086 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9320/12542 | Batch Loss: 2.2859 | Learning Rate: 0.000086 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9321/12542 | Batch Loss: 0.6360 | Learning Rate: 0.000086 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9322/12542 | Batch Loss: 1.0717 | Learning Rate: 0.000086 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9323/12542 | Batch Loss: 0.9598 | Learning Rate: 0.000086 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9324/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000086 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9325/12542 | Batch Loss: 1.1961 | Learning Rate: 0.000085 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9326/12542 | Batch Loss: 1.1068 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9327/12542 | Batch Loss: 2.0338 | Learning Rate: 0.000085 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9328/12542 | Batch Loss: 1.5156 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9329/12542 | Batch Loss: 0.7696 | Learning Rate: 0.000085 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9330/12542 | Batch Loss: 1.3470 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9331/12542 | Batch Loss: 0.8706 | Learning Rate: 0.000085 | Batch Time: 0.71s\n",
      "Epoch 3 | Step 9332/12542 | Batch Loss: 1.5557 | Learning Rate: 0.000085 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9333/12542 | Batch Loss: 1.0717 | Learning Rate: 0.000085 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9334/12542 | Batch Loss: 0.4908 | Learning Rate: 0.000085 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9335/12542 | Batch Loss: 1.2067 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9336/12542 | Batch Loss: 1.8823 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9337/12542 | Batch Loss: 1.9452 | Learning Rate: 0.000085 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9338/12542 | Batch Loss: 2.7673 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9339/12542 | Batch Loss: 0.7945 | Learning Rate: 0.000085 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9340/12542 | Batch Loss: 1.7338 | Learning Rate: 0.000085 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9341/12542 | Batch Loss: 2.1824 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9342/12542 | Batch Loss: 1.2325 | Learning Rate: 0.000085 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9343/12542 | Batch Loss: 1.0277 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9344/12542 | Batch Loss: 0.5014 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9345/12542 | Batch Loss: 0.6819 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9346/12542 | Batch Loss: 0.9384 | Learning Rate: 0.000085 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9347/12542 | Batch Loss: 3.0463 | Learning Rate: 0.000085 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9348/12542 | Batch Loss: 1.7949 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9349/12542 | Batch Loss: 2.7538 | Learning Rate: 0.000085 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9350/12542 | Batch Loss: 1.7102 | Learning Rate: 0.000085 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9351/12542 | Batch Loss: 0.7207 | Learning Rate: 0.000085 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9352/12542 | Batch Loss: 1.0469 | Learning Rate: 0.000085 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9353/12542 | Batch Loss: 1.8175 | Learning Rate: 0.000085 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9354/12542 | Batch Loss: 1.9051 | Learning Rate: 0.000085 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9355/12542 | Batch Loss: 1.6246 | Learning Rate: 0.000085 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9356/12542 | Batch Loss: 1.4537 | Learning Rate: 0.000085 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9357/12542 | Batch Loss: 1.3024 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9358/12542 | Batch Loss: 0.5332 | Learning Rate: 0.000085 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9359/12542 | Batch Loss: 3.0561 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9360/12542 | Batch Loss: 1.1015 | Learning Rate: 0.000085 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9361/12542 | Batch Loss: 1.8707 | Learning Rate: 0.000085 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9362/12542 | Batch Loss: 1.6102 | Learning Rate: 0.000085 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9363/12542 | Batch Loss: 0.9806 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9364/12542 | Batch Loss: 1.0367 | Learning Rate: 0.000084 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9365/12542 | Batch Loss: 0.6965 | Learning Rate: 0.000084 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9366/12542 | Batch Loss: 1.1418 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9367/12542 | Batch Loss: 1.5216 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9368/12542 | Batch Loss: 0.8023 | Learning Rate: 0.000084 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9369/12542 | Batch Loss: 1.7712 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9370/12542 | Batch Loss: 1.7095 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9371/12542 | Batch Loss: 2.2254 | Learning Rate: 0.000084 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9372/12542 | Batch Loss: 1.2941 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9373/12542 | Batch Loss: 1.4372 | Learning Rate: 0.000084 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9374/12542 | Batch Loss: 1.1456 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9375/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9376/12542 | Batch Loss: 1.5514 | Learning Rate: 0.000084 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9377/12542 | Batch Loss: 1.2250 | Learning Rate: 0.000084 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9378/12542 | Batch Loss: 1.2006 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9379/12542 | Batch Loss: 1.1177 | Learning Rate: 0.000084 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9380/12542 | Batch Loss: 0.7921 | Learning Rate: 0.000084 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9381/12542 | Batch Loss: 0.5188 | Learning Rate: 0.000084 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9382/12542 | Batch Loss: 0.8648 | Learning Rate: 0.000084 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9383/12542 | Batch Loss: 1.8146 | Learning Rate: 0.000084 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9384/12542 | Batch Loss: 1.4755 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9385/12542 | Batch Loss: 1.5403 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9386/12542 | Batch Loss: 2.6883 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9387/12542 | Batch Loss: 1.9116 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9388/12542 | Batch Loss: 1.7601 | Learning Rate: 0.000084 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9389/12542 | Batch Loss: 0.8670 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9390/12542 | Batch Loss: 1.6423 | Learning Rate: 0.000084 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9391/12542 | Batch Loss: 1.7193 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9392/12542 | Batch Loss: 2.8411 | Learning Rate: 0.000084 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9393/12542 | Batch Loss: 1.2614 | Learning Rate: 0.000084 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9394/12542 | Batch Loss: 4.2065 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9395/12542 | Batch Loss: 2.4246 | Learning Rate: 0.000084 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9396/12542 | Batch Loss: 0.7411 | Learning Rate: 0.000084 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9397/12542 | Batch Loss: 3.1317 | Learning Rate: 0.000084 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 9398/12542 | Batch Loss: 1.9371 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9399/12542 | Batch Loss: 1.1749 | Learning Rate: 0.000084 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9400/12542 | Batch Loss: 0.8822 | Learning Rate: 0.000084 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9401/12542 | Batch Loss: 1.2900 | Learning Rate: 0.000083 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9402/12542 | Batch Loss: 0.7694 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9403/12542 | Batch Loss: 1.4454 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9404/12542 | Batch Loss: 1.0140 | Learning Rate: 0.000083 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9405/12542 | Batch Loss: 0.4759 | Learning Rate: 0.000083 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9406/12542 | Batch Loss: 1.0965 | Learning Rate: 0.000083 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9407/12542 | Batch Loss: 0.6232 | Learning Rate: 0.000083 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9408/12542 | Batch Loss: 1.6984 | Learning Rate: 0.000083 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9409/12542 | Batch Loss: 3.0519 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9410/12542 | Batch Loss: 0.4852 | Learning Rate: 0.000083 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9411/12542 | Batch Loss: 1.0185 | Learning Rate: 0.000083 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9412/12542 | Batch Loss: 1.6641 | Learning Rate: 0.000083 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9413/12542 | Batch Loss: 2.0509 | Learning Rate: 0.000083 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9414/12542 | Batch Loss: 1.1638 | Learning Rate: 0.000083 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9415/12542 | Batch Loss: 1.7935 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9416/12542 | Batch Loss: 1.1420 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9417/12542 | Batch Loss: 1.5743 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9418/12542 | Batch Loss: 1.1747 | Learning Rate: 0.000083 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9419/12542 | Batch Loss: 0.7583 | Learning Rate: 0.000083 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9420/12542 | Batch Loss: 0.9250 | Learning Rate: 0.000083 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 9421/12542 | Batch Loss: 1.5644 | Learning Rate: 0.000083 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9422/12542 | Batch Loss: 1.4401 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9423/12542 | Batch Loss: 2.9453 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9424/12542 | Batch Loss: 1.7129 | Learning Rate: 0.000083 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9425/12542 | Batch Loss: 2.3957 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9426/12542 | Batch Loss: 1.3428 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9427/12542 | Batch Loss: 1.2512 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9428/12542 | Batch Loss: 1.0378 | Learning Rate: 0.000083 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9429/12542 | Batch Loss: 1.4088 | Learning Rate: 0.000083 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9430/12542 | Batch Loss: 0.8947 | Learning Rate: 0.000083 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9431/12542 | Batch Loss: 1.0382 | Learning Rate: 0.000083 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9432/12542 | Batch Loss: 0.9668 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9433/12542 | Batch Loss: 0.8179 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9434/12542 | Batch Loss: 0.9656 | Learning Rate: 0.000083 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9435/12542 | Batch Loss: 1.4296 | Learning Rate: 0.000083 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 9436/12542 | Batch Loss: 0.9090 | Learning Rate: 0.000083 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9437/12542 | Batch Loss: 0.9870 | Learning Rate: 0.000083 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9438/12542 | Batch Loss: 1.1927 | Learning Rate: 0.000082 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9439/12542 | Batch Loss: 1.9608 | Learning Rate: 0.000082 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9440/12542 | Batch Loss: 2.3718 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9441/12542 | Batch Loss: 0.8510 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9442/12542 | Batch Loss: 0.4937 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9443/12542 | Batch Loss: 1.7920 | Learning Rate: 0.000082 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9444/12542 | Batch Loss: 1.5320 | Learning Rate: 0.000082 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9445/12542 | Batch Loss: 1.2676 | Learning Rate: 0.000082 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9446/12542 | Batch Loss: 0.7736 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9447/12542 | Batch Loss: 0.8474 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9448/12542 | Batch Loss: 1.8064 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9449/12542 | Batch Loss: 1.9248 | Learning Rate: 0.000082 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9450/12542 | Batch Loss: 0.9971 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9451/12542 | Batch Loss: 0.6480 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9452/12542 | Batch Loss: 0.9553 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9453/12542 | Batch Loss: 1.4037 | Learning Rate: 0.000082 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 9454/12542 | Batch Loss: 2.7492 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9455/12542 | Batch Loss: 1.4592 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9456/12542 | Batch Loss: 0.5406 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9457/12542 | Batch Loss: 1.7319 | Learning Rate: 0.000082 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9458/12542 | Batch Loss: 1.6156 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9459/12542 | Batch Loss: 0.8274 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9460/12542 | Batch Loss: 1.2106 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9461/12542 | Batch Loss: 2.1771 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9462/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9463/12542 | Batch Loss: 0.8797 | Learning Rate: 0.000082 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9464/12542 | Batch Loss: 1.1603 | Learning Rate: 0.000082 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9465/12542 | Batch Loss: 1.7422 | Learning Rate: 0.000082 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9466/12542 | Batch Loss: 0.6605 | Learning Rate: 0.000082 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9467/12542 | Batch Loss: 1.0859 | Learning Rate: 0.000082 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9468/12542 | Batch Loss: 1.3214 | Learning Rate: 0.000082 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9469/12542 | Batch Loss: 1.5544 | Learning Rate: 0.000082 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9470/12542 | Batch Loss: 0.4201 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9471/12542 | Batch Loss: 1.6289 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9472/12542 | Batch Loss: 0.7697 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9473/12542 | Batch Loss: 1.6099 | Learning Rate: 0.000082 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9474/12542 | Batch Loss: 0.8871 | Learning Rate: 0.000082 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9475/12542 | Batch Loss: 0.9916 | Learning Rate: 0.000082 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9476/12542 | Batch Loss: 0.4287 | Learning Rate: 0.000081 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9477/12542 | Batch Loss: 0.7871 | Learning Rate: 0.000081 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9478/12542 | Batch Loss: 2.5796 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9479/12542 | Batch Loss: 1.5911 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9480/12542 | Batch Loss: 0.7675 | Learning Rate: 0.000081 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9481/12542 | Batch Loss: 0.4385 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9482/12542 | Batch Loss: 0.8262 | Learning Rate: 0.000081 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9483/12542 | Batch Loss: 0.9532 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9484/12542 | Batch Loss: 2.8684 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9485/12542 | Batch Loss: 2.1359 | Learning Rate: 0.000081 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9486/12542 | Batch Loss: 1.2277 | Learning Rate: 0.000081 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9487/12542 | Batch Loss: 1.2553 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9488/12542 | Batch Loss: 1.5308 | Learning Rate: 0.000081 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9489/12542 | Batch Loss: 0.7582 | Learning Rate: 0.000081 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9490/12542 | Batch Loss: 0.7866 | Learning Rate: 0.000081 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9491/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000081 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9492/12542 | Batch Loss: 0.9560 | Learning Rate: 0.000081 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9493/12542 | Batch Loss: 1.6705 | Learning Rate: 0.000081 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9494/12542 | Batch Loss: 1.0295 | Learning Rate: 0.000081 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9495/12542 | Batch Loss: 0.8248 | Learning Rate: 0.000081 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9496/12542 | Batch Loss: 3.9042 | Learning Rate: 0.000081 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9497/12542 | Batch Loss: 2.6932 | Learning Rate: 0.000081 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9498/12542 | Batch Loss: 1.7376 | Learning Rate: 0.000081 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9499/12542 | Batch Loss: 0.9522 | Learning Rate: 0.000081 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9500/12542 | Batch Loss: 0.8475 | Learning Rate: 0.000081 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9501/12542 | Batch Loss: 2.1753 | Learning Rate: 0.000081 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9502/12542 | Batch Loss: 0.6801 | Learning Rate: 0.000081 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9503/12542 | Batch Loss: 1.0438 | Learning Rate: 0.000081 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9504/12542 | Batch Loss: 0.7768 | Learning Rate: 0.000081 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9505/12542 | Batch Loss: 1.3066 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9506/12542 | Batch Loss: 0.9056 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9507/12542 | Batch Loss: 1.4952 | Learning Rate: 0.000081 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9508/12542 | Batch Loss: 2.1998 | Learning Rate: 0.000081 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9509/12542 | Batch Loss: 0.5768 | Learning Rate: 0.000081 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9510/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000081 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9511/12542 | Batch Loss: 1.0488 | Learning Rate: 0.000081 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9512/12542 | Batch Loss: 0.6117 | Learning Rate: 0.000081 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9513/12542 | Batch Loss: 1.0048 | Learning Rate: 0.000081 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9514/12542 | Batch Loss: 1.1585 | Learning Rate: 0.000080 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9515/12542 | Batch Loss: 1.6257 | Learning Rate: 0.000080 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9516/12542 | Batch Loss: 1.0284 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9517/12542 | Batch Loss: 2.6499 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9518/12542 | Batch Loss: 0.9490 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9519/12542 | Batch Loss: 1.2248 | Learning Rate: 0.000080 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9520/12542 | Batch Loss: 0.8168 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9521/12542 | Batch Loss: 2.0850 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9522/12542 | Batch Loss: 1.5409 | Learning Rate: 0.000080 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9523/12542 | Batch Loss: 1.4330 | Learning Rate: 0.000080 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9524/12542 | Batch Loss: 1.2793 | Learning Rate: 0.000080 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9525/12542 | Batch Loss: 1.2399 | Learning Rate: 0.000080 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9526/12542 | Batch Loss: 2.6404 | Learning Rate: 0.000080 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9527/12542 | Batch Loss: 1.0310 | Learning Rate: 0.000080 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9528/12542 | Batch Loss: 1.6228 | Learning Rate: 0.000080 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9529/12542 | Batch Loss: 1.3674 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9530/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000080 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9531/12542 | Batch Loss: 1.4493 | Learning Rate: 0.000080 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9532/12542 | Batch Loss: 1.0040 | Learning Rate: 0.000080 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9533/12542 | Batch Loss: 1.4865 | Learning Rate: 0.000080 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9534/12542 | Batch Loss: 1.5335 | Learning Rate: 0.000080 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9535/12542 | Batch Loss: 1.6780 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9536/12542 | Batch Loss: 1.3697 | Learning Rate: 0.000080 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9537/12542 | Batch Loss: 1.2127 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9538/12542 | Batch Loss: 1.2535 | Learning Rate: 0.000080 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9539/12542 | Batch Loss: 0.5806 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9540/12542 | Batch Loss: 1.0379 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9541/12542 | Batch Loss: 1.6200 | Learning Rate: 0.000080 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9542/12542 | Batch Loss: 0.9884 | Learning Rate: 0.000080 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9543/12542 | Batch Loss: 0.9360 | Learning Rate: 0.000080 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9544/12542 | Batch Loss: 1.4503 | Learning Rate: 0.000080 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9545/12542 | Batch Loss: 0.4837 | Learning Rate: 0.000080 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 9546/12542 | Batch Loss: 1.2896 | Learning Rate: 0.000080 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9547/12542 | Batch Loss: 2.0573 | Learning Rate: 0.000080 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9548/12542 | Batch Loss: 0.9746 | Learning Rate: 0.000080 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9549/12542 | Batch Loss: 0.9154 | Learning Rate: 0.000080 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9550/12542 | Batch Loss: 1.7358 | Learning Rate: 0.000080 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9551/12542 | Batch Loss: 0.9021 | Learning Rate: 0.000079 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9552/12542 | Batch Loss: 0.6132 | Learning Rate: 0.000079 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9553/12542 | Batch Loss: 3.2149 | Learning Rate: 0.000079 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9554/12542 | Batch Loss: 0.7726 | Learning Rate: 0.000079 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9555/12542 | Batch Loss: 1.9323 | Learning Rate: 0.000079 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9556/12542 | Batch Loss: 1.1300 | Learning Rate: 0.000079 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9557/12542 | Batch Loss: 1.5571 | Learning Rate: 0.000079 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9558/12542 | Batch Loss: 0.5536 | Learning Rate: 0.000079 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9559/12542 | Batch Loss: 2.0545 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9560/12542 | Batch Loss: 0.9068 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9561/12542 | Batch Loss: 2.3723 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9562/12542 | Batch Loss: 1.5418 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9563/12542 | Batch Loss: 1.2186 | Learning Rate: 0.000079 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9564/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000079 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9565/12542 | Batch Loss: 1.3207 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9566/12542 | Batch Loss: 1.0704 | Learning Rate: 0.000079 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9567/12542 | Batch Loss: 0.8633 | Learning Rate: 0.000079 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9568/12542 | Batch Loss: 0.7186 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9569/12542 | Batch Loss: 1.8271 | Learning Rate: 0.000079 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9570/12542 | Batch Loss: 0.9033 | Learning Rate: 0.000079 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9571/12542 | Batch Loss: 1.4310 | Learning Rate: 0.000079 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9572/12542 | Batch Loss: 0.7271 | Learning Rate: 0.000079 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9573/12542 | Batch Loss: 2.2013 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9574/12542 | Batch Loss: 1.5656 | Learning Rate: 0.000079 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9575/12542 | Batch Loss: 1.0736 | Learning Rate: 0.000079 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9576/12542 | Batch Loss: 1.8870 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9577/12542 | Batch Loss: 2.1078 | Learning Rate: 0.000079 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9578/12542 | Batch Loss: 2.7064 | Learning Rate: 0.000079 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9579/12542 | Batch Loss: 1.1476 | Learning Rate: 0.000079 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9580/12542 | Batch Loss: 0.5910 | Learning Rate: 0.000079 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9581/12542 | Batch Loss: 0.4148 | Learning Rate: 0.000079 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9582/12542 | Batch Loss: 1.1835 | Learning Rate: 0.000079 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9583/12542 | Batch Loss: 1.4847 | Learning Rate: 0.000079 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9584/12542 | Batch Loss: 0.6095 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9585/12542 | Batch Loss: 0.8067 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9586/12542 | Batch Loss: 1.0908 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9587/12542 | Batch Loss: 0.3326 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9588/12542 | Batch Loss: 0.9074 | Learning Rate: 0.000079 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9589/12542 | Batch Loss: 1.5125 | Learning Rate: 0.000078 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9590/12542 | Batch Loss: 0.7610 | Learning Rate: 0.000078 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9591/12542 | Batch Loss: 1.4452 | Learning Rate: 0.000078 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9592/12542 | Batch Loss: 1.5740 | Learning Rate: 0.000078 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9593/12542 | Batch Loss: 1.4946 | Learning Rate: 0.000078 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9594/12542 | Batch Loss: 0.7675 | Learning Rate: 0.000078 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9595/12542 | Batch Loss: 1.8239 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9596/12542 | Batch Loss: 1.2923 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9597/12542 | Batch Loss: 0.9052 | Learning Rate: 0.000078 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9598/12542 | Batch Loss: 0.9912 | Learning Rate: 0.000078 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9599/12542 | Batch Loss: 0.8305 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9600/12542 | Batch Loss: 1.1636 | Learning Rate: 0.000078 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9601/12542 | Batch Loss: 1.2917 | Learning Rate: 0.000078 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9602/12542 | Batch Loss: 1.4302 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9603/12542 | Batch Loss: 0.5958 | Learning Rate: 0.000078 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9604/12542 | Batch Loss: 0.8295 | Learning Rate: 0.000078 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9605/12542 | Batch Loss: 1.1891 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9606/12542 | Batch Loss: 1.1696 | Learning Rate: 0.000078 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9607/12542 | Batch Loss: 1.0023 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9608/12542 | Batch Loss: 1.7177 | Learning Rate: 0.000078 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9609/12542 | Batch Loss: 0.8057 | Learning Rate: 0.000078 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9610/12542 | Batch Loss: 2.6385 | Learning Rate: 0.000078 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9611/12542 | Batch Loss: 2.1144 | Learning Rate: 0.000078 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9612/12542 | Batch Loss: 0.6293 | Learning Rate: 0.000078 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9613/12542 | Batch Loss: 0.5995 | Learning Rate: 0.000078 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9614/12542 | Batch Loss: 1.5819 | Learning Rate: 0.000078 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9615/12542 | Batch Loss: 0.8929 | Learning Rate: 0.000078 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9616/12542 | Batch Loss: 1.6908 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9617/12542 | Batch Loss: 0.9692 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9618/12542 | Batch Loss: 0.4806 | Learning Rate: 0.000078 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9619/12542 | Batch Loss: 0.8682 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9620/12542 | Batch Loss: 1.0441 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9621/12542 | Batch Loss: 1.1480 | Learning Rate: 0.000078 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9622/12542 | Batch Loss: 1.6052 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9623/12542 | Batch Loss: 2.6323 | Learning Rate: 0.000078 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9624/12542 | Batch Loss: 1.4386 | Learning Rate: 0.000078 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9625/12542 | Batch Loss: 1.6412 | Learning Rate: 0.000078 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9626/12542 | Batch Loss: 2.0028 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9627/12542 | Batch Loss: 2.1769 | Learning Rate: 0.000077 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9628/12542 | Batch Loss: 1.0507 | Learning Rate: 0.000077 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9629/12542 | Batch Loss: 0.9622 | Learning Rate: 0.000077 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9630/12542 | Batch Loss: 0.8938 | Learning Rate: 0.000077 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9631/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000077 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9632/12542 | Batch Loss: 1.7635 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9633/12542 | Batch Loss: 1.6843 | Learning Rate: 0.000077 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9634/12542 | Batch Loss: 2.1781 | Learning Rate: 0.000077 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9635/12542 | Batch Loss: 2.4719 | Learning Rate: 0.000077 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9636/12542 | Batch Loss: 0.9288 | Learning Rate: 0.000077 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9637/12542 | Batch Loss: 0.9549 | Learning Rate: 0.000077 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9638/12542 | Batch Loss: 1.5241 | Learning Rate: 0.000077 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9639/12542 | Batch Loss: 0.5379 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9640/12542 | Batch Loss: 1.0846 | Learning Rate: 0.000077 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9641/12542 | Batch Loss: 2.4880 | Learning Rate: 0.000077 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9642/12542 | Batch Loss: 0.8015 | Learning Rate: 0.000077 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9643/12542 | Batch Loss: 0.9195 | Learning Rate: 0.000077 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9644/12542 | Batch Loss: 1.4626 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9645/12542 | Batch Loss: 1.0445 | Learning Rate: 0.000077 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9646/12542 | Batch Loss: 1.7689 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9647/12542 | Batch Loss: 1.3323 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9648/12542 | Batch Loss: 1.0619 | Learning Rate: 0.000077 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9649/12542 | Batch Loss: 0.8797 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9650/12542 | Batch Loss: 1.5590 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9651/12542 | Batch Loss: 0.9852 | Learning Rate: 0.000077 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9652/12542 | Batch Loss: 0.8007 | Learning Rate: 0.000077 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9653/12542 | Batch Loss: 2.5496 | Learning Rate: 0.000077 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9654/12542 | Batch Loss: 0.4381 | Learning Rate: 0.000077 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9655/12542 | Batch Loss: 0.7724 | Learning Rate: 0.000077 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9656/12542 | Batch Loss: 1.6205 | Learning Rate: 0.000077 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9657/12542 | Batch Loss: 0.7107 | Learning Rate: 0.000077 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9658/12542 | Batch Loss: 1.2875 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9659/12542 | Batch Loss: 1.9845 | Learning Rate: 0.000077 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9660/12542 | Batch Loss: 0.7093 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9661/12542 | Batch Loss: 0.7770 | Learning Rate: 0.000077 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9662/12542 | Batch Loss: 0.9324 | Learning Rate: 0.000077 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9663/12542 | Batch Loss: 1.4688 | Learning Rate: 0.000077 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9664/12542 | Batch Loss: 1.0341 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9665/12542 | Batch Loss: 1.5782 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9666/12542 | Batch Loss: 0.6701 | Learning Rate: 0.000076 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9667/12542 | Batch Loss: 1.3666 | Learning Rate: 0.000076 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9668/12542 | Batch Loss: 1.7870 | Learning Rate: 0.000076 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9669/12542 | Batch Loss: 0.8412 | Learning Rate: 0.000076 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9670/12542 | Batch Loss: 1.5545 | Learning Rate: 0.000076 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9671/12542 | Batch Loss: 1.2011 | Learning Rate: 0.000076 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9672/12542 | Batch Loss: 1.6598 | Learning Rate: 0.000076 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9673/12542 | Batch Loss: 0.9650 | Learning Rate: 0.000076 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9674/12542 | Batch Loss: 1.5767 | Learning Rate: 0.000076 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9675/12542 | Batch Loss: 1.4195 | Learning Rate: 0.000076 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9676/12542 | Batch Loss: 1.5169 | Learning Rate: 0.000076 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9677/12542 | Batch Loss: 3.1909 | Learning Rate: 0.000076 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9678/12542 | Batch Loss: 0.7741 | Learning Rate: 0.000076 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9679/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000076 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9680/12542 | Batch Loss: 0.8934 | Learning Rate: 0.000076 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9681/12542 | Batch Loss: 0.8103 | Learning Rate: 0.000076 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9682/12542 | Batch Loss: 0.9031 | Learning Rate: 0.000076 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9683/12542 | Batch Loss: 1.4822 | Learning Rate: 0.000076 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9684/12542 | Batch Loss: 1.3986 | Learning Rate: 0.000076 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9685/12542 | Batch Loss: 0.5563 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9686/12542 | Batch Loss: 1.7103 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9687/12542 | Batch Loss: 3.0425 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9688/12542 | Batch Loss: 1.2803 | Learning Rate: 0.000076 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9689/12542 | Batch Loss: 0.4850 | Learning Rate: 0.000076 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9690/12542 | Batch Loss: 1.5856 | Learning Rate: 0.000076 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9691/12542 | Batch Loss: 0.8399 | Learning Rate: 0.000076 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9692/12542 | Batch Loss: 1.0335 | Learning Rate: 0.000076 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9693/12542 | Batch Loss: 2.4469 | Learning Rate: 0.000076 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9694/12542 | Batch Loss: 0.8612 | Learning Rate: 0.000076 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9695/12542 | Batch Loss: 0.5356 | Learning Rate: 0.000076 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9696/12542 | Batch Loss: 1.7443 | Learning Rate: 0.000076 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9697/12542 | Batch Loss: 1.0896 | Learning Rate: 0.000076 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9698/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000076 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9699/12542 | Batch Loss: 0.7102 | Learning Rate: 0.000076 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9700/12542 | Batch Loss: 1.5550 | Learning Rate: 0.000076 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9701/12542 | Batch Loss: 0.6833 | Learning Rate: 0.000076 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9702/12542 | Batch Loss: 1.3485 | Learning Rate: 0.000075 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9703/12542 | Batch Loss: 0.4250 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9704/12542 | Batch Loss: 0.5321 | Learning Rate: 0.000075 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9705/12542 | Batch Loss: 2.8395 | Learning Rate: 0.000075 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9706/12542 | Batch Loss: 1.8279 | Learning Rate: 0.000075 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9707/12542 | Batch Loss: 1.0357 | Learning Rate: 0.000075 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9708/12542 | Batch Loss: 1.3081 | Learning Rate: 0.000075 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9709/12542 | Batch Loss: 0.9757 | Learning Rate: 0.000075 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9710/12542 | Batch Loss: 0.9969 | Learning Rate: 0.000075 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9711/12542 | Batch Loss: 0.8117 | Learning Rate: 0.000075 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9712/12542 | Batch Loss: 1.7654 | Learning Rate: 0.000075 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9713/12542 | Batch Loss: 1.1484 | Learning Rate: 0.000075 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9714/12542 | Batch Loss: 0.7614 | Learning Rate: 0.000075 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9715/12542 | Batch Loss: 1.5081 | Learning Rate: 0.000075 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9716/12542 | Batch Loss: 1.1808 | Learning Rate: 0.000075 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9717/12542 | Batch Loss: 0.6717 | Learning Rate: 0.000075 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9718/12542 | Batch Loss: 1.9727 | Learning Rate: 0.000075 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9719/12542 | Batch Loss: 1.2446 | Learning Rate: 0.000075 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9720/12542 | Batch Loss: 2.1167 | Learning Rate: 0.000075 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9721/12542 | Batch Loss: 1.9754 | Learning Rate: 0.000075 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9722/12542 | Batch Loss: 1.3468 | Learning Rate: 0.000075 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9723/12542 | Batch Loss: 2.6856 | Learning Rate: 0.000075 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9724/12542 | Batch Loss: 0.9185 | Learning Rate: 0.000075 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9725/12542 | Batch Loss: 1.0569 | Learning Rate: 0.000075 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9726/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000075 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9727/12542 | Batch Loss: 1.4095 | Learning Rate: 0.000075 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9728/12542 | Batch Loss: 0.9013 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9729/12542 | Batch Loss: 1.4226 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9730/12542 | Batch Loss: 0.8525 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9731/12542 | Batch Loss: 1.2445 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9732/12542 | Batch Loss: 0.8409 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9733/12542 | Batch Loss: 0.4589 | Learning Rate: 0.000075 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9734/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000075 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9735/12542 | Batch Loss: 0.9862 | Learning Rate: 0.000075 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9736/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000075 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9737/12542 | Batch Loss: 0.9356 | Learning Rate: 0.000075 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9738/12542 | Batch Loss: 0.6748 | Learning Rate: 0.000075 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9739/12542 | Batch Loss: 1.6439 | Learning Rate: 0.000074 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9740/12542 | Batch Loss: 1.9925 | Learning Rate: 0.000074 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 9741/12542 | Batch Loss: 1.5219 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9742/12542 | Batch Loss: 3.1237 | Learning Rate: 0.000074 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9743/12542 | Batch Loss: 3.5244 | Learning Rate: 0.000074 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9744/12542 | Batch Loss: 0.5105 | Learning Rate: 0.000074 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9745/12542 | Batch Loss: 0.7355 | Learning Rate: 0.000074 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9746/12542 | Batch Loss: 1.0426 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9747/12542 | Batch Loss: 1.6587 | Learning Rate: 0.000074 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9748/12542 | Batch Loss: 2.1852 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9749/12542 | Batch Loss: 3.4334 | Learning Rate: 0.000074 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9750/12542 | Batch Loss: 1.3703 | Learning Rate: 0.000074 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9751/12542 | Batch Loss: 3.3436 | Learning Rate: 0.000074 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9752/12542 | Batch Loss: 0.8834 | Learning Rate: 0.000074 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9753/12542 | Batch Loss: 0.5910 | Learning Rate: 0.000074 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9754/12542 | Batch Loss: 1.2531 | Learning Rate: 0.000074 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9755/12542 | Batch Loss: 0.7983 | Learning Rate: 0.000074 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9756/12542 | Batch Loss: 1.1794 | Learning Rate: 0.000074 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9757/12542 | Batch Loss: 1.2335 | Learning Rate: 0.000074 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9758/12542 | Batch Loss: 0.8956 | Learning Rate: 0.000074 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9759/12542 | Batch Loss: 2.4566 | Learning Rate: 0.000074 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9760/12542 | Batch Loss: 1.5503 | Learning Rate: 0.000074 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9761/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000074 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9762/12542 | Batch Loss: 2.8999 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9763/12542 | Batch Loss: 2.2883 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9764/12542 | Batch Loss: 0.9448 | Learning Rate: 0.000074 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9765/12542 | Batch Loss: 0.7812 | Learning Rate: 0.000074 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9766/12542 | Batch Loss: 1.6856 | Learning Rate: 0.000074 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9767/12542 | Batch Loss: 1.9419 | Learning Rate: 0.000074 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9768/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000074 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9769/12542 | Batch Loss: 0.9935 | Learning Rate: 0.000074 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9770/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000074 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9771/12542 | Batch Loss: 1.6651 | Learning Rate: 0.000074 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9772/12542 | Batch Loss: 1.4470 | Learning Rate: 0.000074 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9773/12542 | Batch Loss: 1.0082 | Learning Rate: 0.000074 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9774/12542 | Batch Loss: 1.3094 | Learning Rate: 0.000074 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9775/12542 | Batch Loss: 1.5272 | Learning Rate: 0.000074 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9776/12542 | Batch Loss: 0.8456 | Learning Rate: 0.000074 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9777/12542 | Batch Loss: 1.1654 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9778/12542 | Batch Loss: 1.4292 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9779/12542 | Batch Loss: 1.1207 | Learning Rate: 0.000073 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9780/12542 | Batch Loss: 1.6370 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9781/12542 | Batch Loss: 1.3021 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9782/12542 | Batch Loss: 0.6771 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9783/12542 | Batch Loss: 1.3948 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9784/12542 | Batch Loss: 2.2368 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9785/12542 | Batch Loss: 1.6440 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9786/12542 | Batch Loss: 2.2448 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9787/12542 | Batch Loss: 1.5287 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9788/12542 | Batch Loss: 2.5044 | Learning Rate: 0.000073 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9789/12542 | Batch Loss: 0.7836 | Learning Rate: 0.000073 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9790/12542 | Batch Loss: 0.6531 | Learning Rate: 0.000073 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9791/12542 | Batch Loss: 2.4025 | Learning Rate: 0.000073 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9792/12542 | Batch Loss: 0.5784 | Learning Rate: 0.000073 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9793/12542 | Batch Loss: 1.1603 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9794/12542 | Batch Loss: 0.4695 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9795/12542 | Batch Loss: 1.0127 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9796/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9797/12542 | Batch Loss: 1.5663 | Learning Rate: 0.000073 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9798/12542 | Batch Loss: 1.5752 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9799/12542 | Batch Loss: 2.8106 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9800/12542 | Batch Loss: 1.0345 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9801/12542 | Batch Loss: 0.6903 | Learning Rate: 0.000073 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9802/12542 | Batch Loss: 1.0399 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9803/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000073 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9804/12542 | Batch Loss: 1.4840 | Learning Rate: 0.000073 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9805/12542 | Batch Loss: 1.2554 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9806/12542 | Batch Loss: 2.7987 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9807/12542 | Batch Loss: 2.0526 | Learning Rate: 0.000073 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9808/12542 | Batch Loss: 2.2090 | Learning Rate: 0.000073 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9809/12542 | Batch Loss: 1.2413 | Learning Rate: 0.000073 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9810/12542 | Batch Loss: 0.8429 | Learning Rate: 0.000073 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9811/12542 | Batch Loss: 0.9249 | Learning Rate: 0.000073 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9812/12542 | Batch Loss: 1.6201 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9813/12542 | Batch Loss: 1.7005 | Learning Rate: 0.000073 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9814/12542 | Batch Loss: 1.1714 | Learning Rate: 0.000073 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9815/12542 | Batch Loss: 1.3123 | Learning Rate: 0.000072 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9816/12542 | Batch Loss: 1.0658 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9817/12542 | Batch Loss: 1.6699 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9818/12542 | Batch Loss: 0.9994 | Learning Rate: 0.000072 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9819/12542 | Batch Loss: 2.0803 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9820/12542 | Batch Loss: 1.5905 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9821/12542 | Batch Loss: 1.6335 | Learning Rate: 0.000072 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9822/12542 | Batch Loss: 0.8297 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9823/12542 | Batch Loss: 0.5848 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9824/12542 | Batch Loss: 0.5260 | Learning Rate: 0.000072 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9825/12542 | Batch Loss: 0.7477 | Learning Rate: 0.000072 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9826/12542 | Batch Loss: 1.1159 | Learning Rate: 0.000072 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9827/12542 | Batch Loss: 0.6203 | Learning Rate: 0.000072 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9828/12542 | Batch Loss: 0.8606 | Learning Rate: 0.000072 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9829/12542 | Batch Loss: 1.3517 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9830/12542 | Batch Loss: 0.6865 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9831/12542 | Batch Loss: 1.2707 | Learning Rate: 0.000072 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9832/12542 | Batch Loss: 1.1318 | Learning Rate: 0.000072 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9833/12542 | Batch Loss: 0.8810 | Learning Rate: 0.000072 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9834/12542 | Batch Loss: 0.6365 | Learning Rate: 0.000072 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9835/12542 | Batch Loss: 0.6767 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9836/12542 | Batch Loss: 1.1454 | Learning Rate: 0.000072 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9837/12542 | Batch Loss: 1.7897 | Learning Rate: 0.000072 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9838/12542 | Batch Loss: 1.5316 | Learning Rate: 0.000072 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9839/12542 | Batch Loss: 1.9165 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9840/12542 | Batch Loss: 0.4105 | Learning Rate: 0.000072 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9841/12542 | Batch Loss: 0.9101 | Learning Rate: 0.000072 | Batch Time: 0.70s\n",
      "Epoch 3 | Step 9842/12542 | Batch Loss: 0.8399 | Learning Rate: 0.000072 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9843/12542 | Batch Loss: 0.7853 | Learning Rate: 0.000072 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9844/12542 | Batch Loss: 1.3563 | Learning Rate: 0.000072 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9845/12542 | Batch Loss: 1.1792 | Learning Rate: 0.000072 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9846/12542 | Batch Loss: 1.6290 | Learning Rate: 0.000072 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9847/12542 | Batch Loss: 1.3396 | Learning Rate: 0.000072 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9848/12542 | Batch Loss: 2.7159 | Learning Rate: 0.000072 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9849/12542 | Batch Loss: 1.0509 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9850/12542 | Batch Loss: 1.3429 | Learning Rate: 0.000072 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9851/12542 | Batch Loss: 0.6266 | Learning Rate: 0.000072 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9852/12542 | Batch Loss: 1.0304 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9853/12542 | Batch Loss: 1.2844 | Learning Rate: 0.000071 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9854/12542 | Batch Loss: 1.3670 | Learning Rate: 0.000071 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9855/12542 | Batch Loss: 1.4661 | Learning Rate: 0.000071 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9856/12542 | Batch Loss: 2.5168 | Learning Rate: 0.000071 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9857/12542 | Batch Loss: 1.4944 | Learning Rate: 0.000071 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9858/12542 | Batch Loss: 0.7376 | Learning Rate: 0.000071 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9859/12542 | Batch Loss: 1.8385 | Learning Rate: 0.000071 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9860/12542 | Batch Loss: 3.3059 | Learning Rate: 0.000071 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9861/12542 | Batch Loss: 0.7330 | Learning Rate: 0.000071 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9862/12542 | Batch Loss: 1.6211 | Learning Rate: 0.000071 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9863/12542 | Batch Loss: 1.4931 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9864/12542 | Batch Loss: 0.8077 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9865/12542 | Batch Loss: 1.1527 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9866/12542 | Batch Loss: 0.9115 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9867/12542 | Batch Loss: 0.8422 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9868/12542 | Batch Loss: 0.4993 | Learning Rate: 0.000071 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9869/12542 | Batch Loss: 1.3779 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9870/12542 | Batch Loss: 1.0494 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9871/12542 | Batch Loss: 1.1379 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9872/12542 | Batch Loss: 0.6035 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9873/12542 | Batch Loss: 1.8988 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9874/12542 | Batch Loss: 2.4859 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9875/12542 | Batch Loss: 1.2227 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9876/12542 | Batch Loss: 1.5041 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9877/12542 | Batch Loss: 2.2375 | Learning Rate: 0.000071 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9878/12542 | Batch Loss: 0.9690 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9879/12542 | Batch Loss: 0.8453 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9880/12542 | Batch Loss: 0.6579 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9881/12542 | Batch Loss: 0.9515 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9882/12542 | Batch Loss: 1.3549 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9883/12542 | Batch Loss: 1.5125 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9884/12542 | Batch Loss: 1.9784 | Learning Rate: 0.000071 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9885/12542 | Batch Loss: 1.2952 | Learning Rate: 0.000071 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9886/12542 | Batch Loss: 1.3557 | Learning Rate: 0.000071 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9887/12542 | Batch Loss: 1.0020 | Learning Rate: 0.000071 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9888/12542 | Batch Loss: 1.1487 | Learning Rate: 0.000071 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9889/12542 | Batch Loss: 0.8666 | Learning Rate: 0.000071 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9890/12542 | Batch Loss: 0.5263 | Learning Rate: 0.000070 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9891/12542 | Batch Loss: 1.2648 | Learning Rate: 0.000070 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9892/12542 | Batch Loss: 0.6979 | Learning Rate: 0.000070 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9893/12542 | Batch Loss: 1.6729 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9894/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9895/12542 | Batch Loss: 0.9811 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9896/12542 | Batch Loss: 1.2910 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9897/12542 | Batch Loss: 1.5748 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9898/12542 | Batch Loss: 1.5891 | Learning Rate: 0.000070 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9899/12542 | Batch Loss: 1.3340 | Learning Rate: 0.000070 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9900/12542 | Batch Loss: 2.7991 | Learning Rate: 0.000070 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9901/12542 | Batch Loss: 1.3289 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9902/12542 | Batch Loss: 1.4483 | Learning Rate: 0.000070 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9903/12542 | Batch Loss: 1.9355 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9904/12542 | Batch Loss: 1.1567 | Learning Rate: 0.000070 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9905/12542 | Batch Loss: 0.7921 | Learning Rate: 0.000070 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9906/12542 | Batch Loss: 1.3342 | Learning Rate: 0.000070 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9907/12542 | Batch Loss: 2.3764 | Learning Rate: 0.000070 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9908/12542 | Batch Loss: 0.4336 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9909/12542 | Batch Loss: 2.2525 | Learning Rate: 0.000070 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9910/12542 | Batch Loss: 1.1538 | Learning Rate: 0.000070 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9911/12542 | Batch Loss: 1.4666 | Learning Rate: 0.000070 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9912/12542 | Batch Loss: 1.2253 | Learning Rate: 0.000070 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9913/12542 | Batch Loss: 1.8409 | Learning Rate: 0.000070 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9914/12542 | Batch Loss: 1.2192 | Learning Rate: 0.000070 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9915/12542 | Batch Loss: 2.8975 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9916/12542 | Batch Loss: 1.1625 | Learning Rate: 0.000070 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9917/12542 | Batch Loss: 2.4717 | Learning Rate: 0.000070 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 9918/12542 | Batch Loss: 1.5511 | Learning Rate: 0.000070 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9919/12542 | Batch Loss: 1.8980 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9920/12542 | Batch Loss: 0.5907 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9921/12542 | Batch Loss: 0.8056 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9922/12542 | Batch Loss: 2.1115 | Learning Rate: 0.000070 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9923/12542 | Batch Loss: 1.0898 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9924/12542 | Batch Loss: 2.1150 | Learning Rate: 0.000070 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9925/12542 | Batch Loss: 0.4959 | Learning Rate: 0.000070 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9926/12542 | Batch Loss: 1.1864 | Learning Rate: 0.000070 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 9927/12542 | Batch Loss: 1.8540 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9928/12542 | Batch Loss: 2.2399 | Learning Rate: 0.000069 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9929/12542 | Batch Loss: 1.0037 | Learning Rate: 0.000069 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9930/12542 | Batch Loss: 1.7167 | Learning Rate: 0.000069 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9931/12542 | Batch Loss: 1.3929 | Learning Rate: 0.000069 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9932/12542 | Batch Loss: 0.6809 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9933/12542 | Batch Loss: 1.5238 | Learning Rate: 0.000069 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9934/12542 | Batch Loss: 1.1136 | Learning Rate: 0.000069 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9935/12542 | Batch Loss: 1.8955 | Learning Rate: 0.000069 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9936/12542 | Batch Loss: 0.8745 | Learning Rate: 0.000069 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9937/12542 | Batch Loss: 0.7361 | Learning Rate: 0.000069 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9938/12542 | Batch Loss: 1.6444 | Learning Rate: 0.000069 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9939/12542 | Batch Loss: 0.8132 | Learning Rate: 0.000069 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9940/12542 | Batch Loss: 0.7281 | Learning Rate: 0.000069 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9941/12542 | Batch Loss: 2.0687 | Learning Rate: 0.000069 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9942/12542 | Batch Loss: 0.9743 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9943/12542 | Batch Loss: 1.8923 | Learning Rate: 0.000069 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 9944/12542 | Batch Loss: 0.8918 | Learning Rate: 0.000069 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9945/12542 | Batch Loss: 0.9894 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9946/12542 | Batch Loss: 2.0761 | Learning Rate: 0.000069 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9947/12542 | Batch Loss: 3.7916 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9948/12542 | Batch Loss: 1.3231 | Learning Rate: 0.000069 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9949/12542 | Batch Loss: 1.2874 | Learning Rate: 0.000069 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9950/12542 | Batch Loss: 0.9736 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9951/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000069 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 9952/12542 | Batch Loss: 1.6209 | Learning Rate: 0.000069 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9953/12542 | Batch Loss: 1.7366 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9954/12542 | Batch Loss: 0.9687 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9955/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9956/12542 | Batch Loss: 1.1602 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9957/12542 | Batch Loss: 1.4276 | Learning Rate: 0.000069 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 9958/12542 | Batch Loss: 1.0470 | Learning Rate: 0.000069 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9959/12542 | Batch Loss: 1.6211 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9960/12542 | Batch Loss: 1.4983 | Learning Rate: 0.000069 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9961/12542 | Batch Loss: 1.4787 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9962/12542 | Batch Loss: 0.6476 | Learning Rate: 0.000069 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9963/12542 | Batch Loss: 1.0980 | Learning Rate: 0.000069 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 9964/12542 | Batch Loss: 1.3250 | Learning Rate: 0.000069 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9965/12542 | Batch Loss: 2.6971 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9966/12542 | Batch Loss: 0.9653 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9967/12542 | Batch Loss: 0.9760 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9968/12542 | Batch Loss: 1.6530 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9969/12542 | Batch Loss: 1.0741 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9970/12542 | Batch Loss: 0.5960 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9971/12542 | Batch Loss: 0.8490 | Learning Rate: 0.000068 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9972/12542 | Batch Loss: 0.7163 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9973/12542 | Batch Loss: 2.4223 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9974/12542 | Batch Loss: 1.5746 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9975/12542 | Batch Loss: 1.3703 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9976/12542 | Batch Loss: 1.3577 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9977/12542 | Batch Loss: 1.0178 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9978/12542 | Batch Loss: 1.8752 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9979/12542 | Batch Loss: 2.1416 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9980/12542 | Batch Loss: 2.4571 | Learning Rate: 0.000068 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9981/12542 | Batch Loss: 0.9229 | Learning Rate: 0.000068 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 9982/12542 | Batch Loss: 1.1062 | Learning Rate: 0.000068 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9983/12542 | Batch Loss: 1.5706 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9984/12542 | Batch Loss: 0.9092 | Learning Rate: 0.000068 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9985/12542 | Batch Loss: 0.5606 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9986/12542 | Batch Loss: 1.4374 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9987/12542 | Batch Loss: 0.9322 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 9988/12542 | Batch Loss: 0.7172 | Learning Rate: 0.000068 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 9989/12542 | Batch Loss: 1.2053 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9990/12542 | Batch Loss: 0.8241 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9991/12542 | Batch Loss: 1.5406 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9992/12542 | Batch Loss: 2.7280 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9993/12542 | Batch Loss: 1.9019 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9994/12542 | Batch Loss: 2.1862 | Learning Rate: 0.000068 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 9995/12542 | Batch Loss: 1.7309 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9996/12542 | Batch Loss: 1.4255 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9997/12542 | Batch Loss: 2.0424 | Learning Rate: 0.000068 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 9998/12542 | Batch Loss: 0.9089 | Learning Rate: 0.000068 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 9999/12542 | Batch Loss: 2.2842 | Learning Rate: 0.000068 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10000/12542 | Batch Loss: 1.0135 | Learning Rate: 0.000068 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10001/12542 | Batch Loss: 2.3926 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10002/12542 | Batch Loss: 1.1052 | Learning Rate: 0.000068 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10003/12542 | Batch Loss: 1.3194 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10004/12542 | Batch Loss: 1.1414 | Learning Rate: 0.000067 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10005/12542 | Batch Loss: 1.3425 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10006/12542 | Batch Loss: 1.8644 | Learning Rate: 0.000067 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10007/12542 | Batch Loss: 0.8326 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10008/12542 | Batch Loss: 0.9297 | Learning Rate: 0.000067 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10009/12542 | Batch Loss: 0.7282 | Learning Rate: 0.000067 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10010/12542 | Batch Loss: 0.9714 | Learning Rate: 0.000067 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10011/12542 | Batch Loss: 1.0464 | Learning Rate: 0.000067 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10012/12542 | Batch Loss: 0.8448 | Learning Rate: 0.000067 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10013/12542 | Batch Loss: 1.0684 | Learning Rate: 0.000067 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10014/12542 | Batch Loss: 1.1786 | Learning Rate: 0.000067 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10015/12542 | Batch Loss: 0.7151 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10016/12542 | Batch Loss: 2.7279 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10017/12542 | Batch Loss: 1.9262 | Learning Rate: 0.000067 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10018/12542 | Batch Loss: 0.4815 | Learning Rate: 0.000067 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10019/12542 | Batch Loss: 0.7250 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10020/12542 | Batch Loss: 0.9737 | Learning Rate: 0.000067 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10021/12542 | Batch Loss: 2.4908 | Learning Rate: 0.000067 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10022/12542 | Batch Loss: 1.4463 | Learning Rate: 0.000067 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10023/12542 | Batch Loss: 0.8577 | Learning Rate: 0.000067 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10024/12542 | Batch Loss: 1.0536 | Learning Rate: 0.000067 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10025/12542 | Batch Loss: 1.2669 | Learning Rate: 0.000067 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10026/12542 | Batch Loss: 1.9332 | Learning Rate: 0.000067 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10027/12542 | Batch Loss: 0.9426 | Learning Rate: 0.000067 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10028/12542 | Batch Loss: 0.8019 | Learning Rate: 0.000067 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10029/12542 | Batch Loss: 1.9200 | Learning Rate: 0.000067 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10030/12542 | Batch Loss: 1.3216 | Learning Rate: 0.000067 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10031/12542 | Batch Loss: 1.3830 | Learning Rate: 0.000067 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10032/12542 | Batch Loss: 1.0528 | Learning Rate: 0.000067 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10033/12542 | Batch Loss: 1.8440 | Learning Rate: 0.000067 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10034/12542 | Batch Loss: 1.6081 | Learning Rate: 0.000067 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10035/12542 | Batch Loss: 1.5500 | Learning Rate: 0.000067 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10036/12542 | Batch Loss: 1.6357 | Learning Rate: 0.000067 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10037/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000067 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10038/12542 | Batch Loss: 1.3126 | Learning Rate: 0.000067 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10039/12542 | Batch Loss: 1.8137 | Learning Rate: 0.000067 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10040/12542 | Batch Loss: 1.7970 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10041/12542 | Batch Loss: 2.4453 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10042/12542 | Batch Loss: 2.6955 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10043/12542 | Batch Loss: 1.4796 | Learning Rate: 0.000066 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10044/12542 | Batch Loss: 1.2184 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10045/12542 | Batch Loss: 1.0799 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10046/12542 | Batch Loss: 2.0194 | Learning Rate: 0.000066 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10047/12542 | Batch Loss: 1.7530 | Learning Rate: 0.000066 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10048/12542 | Batch Loss: 1.1073 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10049/12542 | Batch Loss: 0.9670 | Learning Rate: 0.000066 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10050/12542 | Batch Loss: 0.9441 | Learning Rate: 0.000066 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10051/12542 | Batch Loss: 1.3194 | Learning Rate: 0.000066 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10052/12542 | Batch Loss: 1.7365 | Learning Rate: 0.000066 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10053/12542 | Batch Loss: 0.8896 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10054/12542 | Batch Loss: 0.6152 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10055/12542 | Batch Loss: 0.7944 | Learning Rate: 0.000066 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10056/12542 | Batch Loss: 0.6168 | Learning Rate: 0.000066 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10057/12542 | Batch Loss: 0.8425 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10058/12542 | Batch Loss: 1.5139 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10059/12542 | Batch Loss: 1.0153 | Learning Rate: 0.000066 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10060/12542 | Batch Loss: 1.3980 | Learning Rate: 0.000066 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10061/12542 | Batch Loss: 2.1535 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10062/12542 | Batch Loss: 2.0767 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10063/12542 | Batch Loss: 1.1910 | Learning Rate: 0.000066 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10064/12542 | Batch Loss: 1.7230 | Learning Rate: 0.000066 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10065/12542 | Batch Loss: 1.3493 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10066/12542 | Batch Loss: 0.6493 | Learning Rate: 0.000066 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10067/12542 | Batch Loss: 1.0988 | Learning Rate: 0.000066 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10068/12542 | Batch Loss: 1.5767 | Learning Rate: 0.000066 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10069/12542 | Batch Loss: 1.1297 | Learning Rate: 0.000066 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10070/12542 | Batch Loss: 0.4198 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10071/12542 | Batch Loss: 1.5016 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10072/12542 | Batch Loss: 1.4871 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10073/12542 | Batch Loss: 0.9744 | Learning Rate: 0.000066 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10074/12542 | Batch Loss: 0.5128 | Learning Rate: 0.000066 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10075/12542 | Batch Loss: 1.2905 | Learning Rate: 0.000066 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10076/12542 | Batch Loss: 0.8219 | Learning Rate: 0.000066 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10077/12542 | Batch Loss: 1.4784 | Learning Rate: 0.000066 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10078/12542 | Batch Loss: 0.9836 | Learning Rate: 0.000065 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10079/12542 | Batch Loss: 1.5415 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10080/12542 | Batch Loss: 1.5106 | Learning Rate: 0.000065 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10081/12542 | Batch Loss: 0.9966 | Learning Rate: 0.000065 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10082/12542 | Batch Loss: 0.8738 | Learning Rate: 0.000065 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10083/12542 | Batch Loss: 2.2257 | Learning Rate: 0.000065 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10084/12542 | Batch Loss: 1.7736 | Learning Rate: 0.000065 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10085/12542 | Batch Loss: 2.1851 | Learning Rate: 0.000065 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10086/12542 | Batch Loss: 0.7183 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10087/12542 | Batch Loss: 0.7567 | Learning Rate: 0.000065 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10088/12542 | Batch Loss: 1.9345 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10089/12542 | Batch Loss: 0.7139 | Learning Rate: 0.000065 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10090/12542 | Batch Loss: 2.2050 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10091/12542 | Batch Loss: 0.5418 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10092/12542 | Batch Loss: 2.9607 | Learning Rate: 0.000065 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10093/12542 | Batch Loss: 0.8500 | Learning Rate: 0.000065 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10094/12542 | Batch Loss: 0.9380 | Learning Rate: 0.000065 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10095/12542 | Batch Loss: 1.3414 | Learning Rate: 0.000065 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10096/12542 | Batch Loss: 0.9552 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10097/12542 | Batch Loss: 0.5742 | Learning Rate: 0.000065 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10098/12542 | Batch Loss: 1.3728 | Learning Rate: 0.000065 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10099/12542 | Batch Loss: 0.7456 | Learning Rate: 0.000065 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10100/12542 | Batch Loss: 1.6347 | Learning Rate: 0.000065 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10101/12542 | Batch Loss: 1.4345 | Learning Rate: 0.000065 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10102/12542 | Batch Loss: 0.7677 | Learning Rate: 0.000065 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10103/12542 | Batch Loss: 0.8312 | Learning Rate: 0.000065 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10104/12542 | Batch Loss: 0.6046 | Learning Rate: 0.000065 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10105/12542 | Batch Loss: 1.6331 | Learning Rate: 0.000065 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10106/12542 | Batch Loss: 2.2301 | Learning Rate: 0.000065 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10107/12542 | Batch Loss: 1.6110 | Learning Rate: 0.000065 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10108/12542 | Batch Loss: 1.6941 | Learning Rate: 0.000065 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10109/12542 | Batch Loss: 1.7328 | Learning Rate: 0.000065 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10110/12542 | Batch Loss: 1.0293 | Learning Rate: 0.000065 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10111/12542 | Batch Loss: 0.9009 | Learning Rate: 0.000065 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10112/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000065 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10113/12542 | Batch Loss: 1.3645 | Learning Rate: 0.000065 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10114/12542 | Batch Loss: 0.9162 | Learning Rate: 0.000065 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10115/12542 | Batch Loss: 1.6581 | Learning Rate: 0.000065 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10116/12542 | Batch Loss: 1.5576 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10117/12542 | Batch Loss: 0.7584 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10118/12542 | Batch Loss: 0.5144 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10119/12542 | Batch Loss: 1.2901 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10120/12542 | Batch Loss: 0.8074 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10121/12542 | Batch Loss: 1.8829 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10122/12542 | Batch Loss: 1.4820 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10123/12542 | Batch Loss: 1.7677 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10124/12542 | Batch Loss: 1.2965 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10125/12542 | Batch Loss: 2.1910 | Learning Rate: 0.000064 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10126/12542 | Batch Loss: 1.9661 | Learning Rate: 0.000064 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10127/12542 | Batch Loss: 1.5928 | Learning Rate: 0.000064 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10128/12542 | Batch Loss: 0.7366 | Learning Rate: 0.000064 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10129/12542 | Batch Loss: 1.1000 | Learning Rate: 0.000064 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10130/12542 | Batch Loss: 1.5967 | Learning Rate: 0.000064 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10131/12542 | Batch Loss: 1.2281 | Learning Rate: 0.000064 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10132/12542 | Batch Loss: 0.5300 | Learning Rate: 0.000064 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10133/12542 | Batch Loss: 1.6385 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10134/12542 | Batch Loss: 0.8623 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10135/12542 | Batch Loss: 1.6748 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10136/12542 | Batch Loss: 1.1539 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10137/12542 | Batch Loss: 1.1711 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10138/12542 | Batch Loss: 1.1944 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10139/12542 | Batch Loss: 0.4096 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10140/12542 | Batch Loss: 3.1778 | Learning Rate: 0.000064 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10141/12542 | Batch Loss: 1.6147 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10142/12542 | Batch Loss: 1.0326 | Learning Rate: 0.000064 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10143/12542 | Batch Loss: 5.4878 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10144/12542 | Batch Loss: 0.5464 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10145/12542 | Batch Loss: 1.4301 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10146/12542 | Batch Loss: 0.5048 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10147/12542 | Batch Loss: 1.1647 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10148/12542 | Batch Loss: 1.3004 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10149/12542 | Batch Loss: 0.7093 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10150/12542 | Batch Loss: 0.8846 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10151/12542 | Batch Loss: 0.8172 | Learning Rate: 0.000064 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10152/12542 | Batch Loss: 1.2683 | Learning Rate: 0.000064 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10153/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000063 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10154/12542 | Batch Loss: 1.5341 | Learning Rate: 0.000063 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10155/12542 | Batch Loss: 1.6466 | Learning Rate: 0.000063 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10156/12542 | Batch Loss: 1.3979 | Learning Rate: 0.000063 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10157/12542 | Batch Loss: 1.4464 | Learning Rate: 0.000063 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10158/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000063 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10159/12542 | Batch Loss: 2.0879 | Learning Rate: 0.000063 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10160/12542 | Batch Loss: 0.9508 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10161/12542 | Batch Loss: 2.0675 | Learning Rate: 0.000063 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10162/12542 | Batch Loss: 1.4774 | Learning Rate: 0.000063 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10163/12542 | Batch Loss: 0.8891 | Learning Rate: 0.000063 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10164/12542 | Batch Loss: 2.0665 | Learning Rate: 0.000063 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10165/12542 | Batch Loss: 1.4748 | Learning Rate: 0.000063 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10166/12542 | Batch Loss: 1.5534 | Learning Rate: 0.000063 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10167/12542 | Batch Loss: 1.9842 | Learning Rate: 0.000063 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10168/12542 | Batch Loss: 3.2654 | Learning Rate: 0.000063 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10169/12542 | Batch Loss: 0.8269 | Learning Rate: 0.000063 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10170/12542 | Batch Loss: 1.3425 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10171/12542 | Batch Loss: 1.5060 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10172/12542 | Batch Loss: 1.4832 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10173/12542 | Batch Loss: 1.3308 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10174/12542 | Batch Loss: 1.9348 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10175/12542 | Batch Loss: 2.9566 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10176/12542 | Batch Loss: 0.9933 | Learning Rate: 0.000063 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10177/12542 | Batch Loss: 1.2394 | Learning Rate: 0.000063 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10178/12542 | Batch Loss: 0.8025 | Learning Rate: 0.000063 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10179/12542 | Batch Loss: 1.2358 | Learning Rate: 0.000063 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10180/12542 | Batch Loss: 0.7460 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10181/12542 | Batch Loss: 0.8925 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10182/12542 | Batch Loss: 2.1242 | Learning Rate: 0.000063 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10183/12542 | Batch Loss: 1.2723 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10184/12542 | Batch Loss: 0.8265 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10185/12542 | Batch Loss: 1.6526 | Learning Rate: 0.000063 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10186/12542 | Batch Loss: 2.0716 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10187/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10188/12542 | Batch Loss: 1.5225 | Learning Rate: 0.000063 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10189/12542 | Batch Loss: 0.9758 | Learning Rate: 0.000063 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10190/12542 | Batch Loss: 1.3765 | Learning Rate: 0.000063 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10191/12542 | Batch Loss: 1.3614 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10192/12542 | Batch Loss: 1.1522 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10193/12542 | Batch Loss: 1.5060 | Learning Rate: 0.000062 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10194/12542 | Batch Loss: 1.3756 | Learning Rate: 0.000062 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10195/12542 | Batch Loss: 0.6181 | Learning Rate: 0.000062 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10196/12542 | Batch Loss: 2.1033 | Learning Rate: 0.000062 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10197/12542 | Batch Loss: 0.8374 | Learning Rate: 0.000062 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10198/12542 | Batch Loss: 0.8712 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10199/12542 | Batch Loss: 2.0606 | Learning Rate: 0.000062 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10200/12542 | Batch Loss: 0.9777 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10201/12542 | Batch Loss: 1.7448 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10202/12542 | Batch Loss: 0.7140 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10203/12542 | Batch Loss: 2.7801 | Learning Rate: 0.000062 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10204/12542 | Batch Loss: 0.6469 | Learning Rate: 0.000062 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10205/12542 | Batch Loss: 1.9700 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10206/12542 | Batch Loss: 0.9854 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10207/12542 | Batch Loss: 2.6540 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10208/12542 | Batch Loss: 1.3680 | Learning Rate: 0.000062 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10209/12542 | Batch Loss: 1.6494 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10210/12542 | Batch Loss: 2.3839 | Learning Rate: 0.000062 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10211/12542 | Batch Loss: 0.8625 | Learning Rate: 0.000062 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10212/12542 | Batch Loss: 2.0641 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10213/12542 | Batch Loss: 1.6894 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10214/12542 | Batch Loss: 1.4890 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10215/12542 | Batch Loss: 2.8595 | Learning Rate: 0.000062 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10216/12542 | Batch Loss: 1.4220 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10217/12542 | Batch Loss: 0.8245 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10218/12542 | Batch Loss: 2.1524 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10219/12542 | Batch Loss: 1.4954 | Learning Rate: 0.000062 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10220/12542 | Batch Loss: 0.6881 | Learning Rate: 0.000062 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10221/12542 | Batch Loss: 1.1214 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10222/12542 | Batch Loss: 1.2533 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10223/12542 | Batch Loss: 0.7877 | Learning Rate: 0.000062 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10224/12542 | Batch Loss: 3.8748 | Learning Rate: 0.000062 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10225/12542 | Batch Loss: 0.7181 | Learning Rate: 0.000062 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10226/12542 | Batch Loss: 0.8232 | Learning Rate: 0.000062 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10227/12542 | Batch Loss: 0.7753 | Learning Rate: 0.000062 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10228/12542 | Batch Loss: 0.9377 | Learning Rate: 0.000062 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10229/12542 | Batch Loss: 0.7901 | Learning Rate: 0.000061 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10230/12542 | Batch Loss: 1.5988 | Learning Rate: 0.000061 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10231/12542 | Batch Loss: 1.0630 | Learning Rate: 0.000061 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10232/12542 | Batch Loss: 1.0596 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10233/12542 | Batch Loss: 0.6897 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10234/12542 | Batch Loss: 1.9497 | Learning Rate: 0.000061 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10235/12542 | Batch Loss: 0.6110 | Learning Rate: 0.000061 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10236/12542 | Batch Loss: 1.5680 | Learning Rate: 0.000061 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10237/12542 | Batch Loss: 1.4412 | Learning Rate: 0.000061 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10238/12542 | Batch Loss: 2.8773 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10239/12542 | Batch Loss: 1.9816 | Learning Rate: 0.000061 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10240/12542 | Batch Loss: 2.5772 | Learning Rate: 0.000061 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10241/12542 | Batch Loss: 1.1964 | Learning Rate: 0.000061 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10242/12542 | Batch Loss: 1.2710 | Learning Rate: 0.000061 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10243/12542 | Batch Loss: 2.0145 | Learning Rate: 0.000061 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10244/12542 | Batch Loss: 1.8217 | Learning Rate: 0.000061 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10245/12542 | Batch Loss: 2.4181 | Learning Rate: 0.000061 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10246/12542 | Batch Loss: 1.3225 | Learning Rate: 0.000061 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10247/12542 | Batch Loss: 0.7522 | Learning Rate: 0.000061 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10248/12542 | Batch Loss: 2.1531 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10249/12542 | Batch Loss: 0.8677 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10250/12542 | Batch Loss: 0.5873 | Learning Rate: 0.000061 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10251/12542 | Batch Loss: 0.8487 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10252/12542 | Batch Loss: 0.9077 | Learning Rate: 0.000061 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 10253/12542 | Batch Loss: 2.3845 | Learning Rate: 0.000061 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10254/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000061 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10255/12542 | Batch Loss: 1.2664 | Learning Rate: 0.000061 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10256/12542 | Batch Loss: 1.0551 | Learning Rate: 0.000061 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10257/12542 | Batch Loss: 1.5922 | Learning Rate: 0.000061 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10258/12542 | Batch Loss: 1.3661 | Learning Rate: 0.000061 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10259/12542 | Batch Loss: 2.2860 | Learning Rate: 0.000061 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10260/12542 | Batch Loss: 1.0055 | Learning Rate: 0.000061 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10261/12542 | Batch Loss: 1.0689 | Learning Rate: 0.000061 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10262/12542 | Batch Loss: 1.5228 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10263/12542 | Batch Loss: 1.7934 | Learning Rate: 0.000061 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10264/12542 | Batch Loss: 0.6889 | Learning Rate: 0.000061 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10265/12542 | Batch Loss: 0.6582 | Learning Rate: 0.000061 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10266/12542 | Batch Loss: 0.8692 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10267/12542 | Batch Loss: 1.1151 | Learning Rate: 0.000060 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10268/12542 | Batch Loss: 1.3925 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10269/12542 | Batch Loss: 1.3771 | Learning Rate: 0.000060 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10270/12542 | Batch Loss: 1.0021 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10271/12542 | Batch Loss: 1.2515 | Learning Rate: 0.000060 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10272/12542 | Batch Loss: 1.1164 | Learning Rate: 0.000060 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10273/12542 | Batch Loss: 2.0180 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10274/12542 | Batch Loss: 1.4810 | Learning Rate: 0.000060 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10275/12542 | Batch Loss: 0.8691 | Learning Rate: 0.000060 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10276/12542 | Batch Loss: 2.1013 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10277/12542 | Batch Loss: 0.6027 | Learning Rate: 0.000060 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10278/12542 | Batch Loss: 2.0232 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10279/12542 | Batch Loss: 1.3558 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10280/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000060 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10281/12542 | Batch Loss: 0.8452 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10282/12542 | Batch Loss: 1.0364 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10283/12542 | Batch Loss: 0.1908 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10284/12542 | Batch Loss: 1.4919 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10285/12542 | Batch Loss: 1.0597 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10286/12542 | Batch Loss: 0.9499 | Learning Rate: 0.000060 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10287/12542 | Batch Loss: 0.6910 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10288/12542 | Batch Loss: 1.7843 | Learning Rate: 0.000060 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10289/12542 | Batch Loss: 2.2761 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10290/12542 | Batch Loss: 1.3032 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10291/12542 | Batch Loss: 2.2517 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10292/12542 | Batch Loss: 1.9827 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10293/12542 | Batch Loss: 0.4390 | Learning Rate: 0.000060 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10294/12542 | Batch Loss: 1.9290 | Learning Rate: 0.000060 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10295/12542 | Batch Loss: 0.9183 | Learning Rate: 0.000060 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10296/12542 | Batch Loss: 2.2914 | Learning Rate: 0.000060 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10297/12542 | Batch Loss: 0.6691 | Learning Rate: 0.000060 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10298/12542 | Batch Loss: 1.0679 | Learning Rate: 0.000060 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10299/12542 | Batch Loss: 1.7330 | Learning Rate: 0.000060 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10300/12542 | Batch Loss: 1.9277 | Learning Rate: 0.000060 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10301/12542 | Batch Loss: 2.3350 | Learning Rate: 0.000060 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10302/12542 | Batch Loss: 1.4571 | Learning Rate: 0.000060 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10303/12542 | Batch Loss: 1.2426 | Learning Rate: 0.000060 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10304/12542 | Batch Loss: 1.6709 | Learning Rate: 0.000059 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10305/12542 | Batch Loss: 1.2056 | Learning Rate: 0.000059 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10306/12542 | Batch Loss: 1.9548 | Learning Rate: 0.000059 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10307/12542 | Batch Loss: 2.4597 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10308/12542 | Batch Loss: 1.0424 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10309/12542 | Batch Loss: 0.8997 | Learning Rate: 0.000059 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10310/12542 | Batch Loss: 1.1406 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10311/12542 | Batch Loss: 1.4874 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10312/12542 | Batch Loss: 0.6686 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10313/12542 | Batch Loss: 2.2490 | Learning Rate: 0.000059 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10314/12542 | Batch Loss: 2.3589 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10315/12542 | Batch Loss: 0.5980 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10316/12542 | Batch Loss: 1.4307 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10317/12542 | Batch Loss: 0.8735 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10318/12542 | Batch Loss: 1.0587 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10319/12542 | Batch Loss: 0.7689 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10320/12542 | Batch Loss: 0.9454 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10321/12542 | Batch Loss: 1.1470 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10322/12542 | Batch Loss: 0.7633 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10323/12542 | Batch Loss: 1.2421 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10324/12542 | Batch Loss: 2.4939 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10325/12542 | Batch Loss: 2.1430 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10326/12542 | Batch Loss: 0.9692 | Learning Rate: 0.000059 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10327/12542 | Batch Loss: 1.3162 | Learning Rate: 0.000059 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10328/12542 | Batch Loss: 1.3260 | Learning Rate: 0.000059 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10329/12542 | Batch Loss: 0.4458 | Learning Rate: 0.000059 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10330/12542 | Batch Loss: 2.2492 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10331/12542 | Batch Loss: 1.7260 | Learning Rate: 0.000059 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10332/12542 | Batch Loss: 1.4594 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10333/12542 | Batch Loss: 2.4144 | Learning Rate: 0.000059 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10334/12542 | Batch Loss: 2.5026 | Learning Rate: 0.000059 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10335/12542 | Batch Loss: 1.7347 | Learning Rate: 0.000059 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10336/12542 | Batch Loss: 2.0321 | Learning Rate: 0.000059 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10337/12542 | Batch Loss: 1.3523 | Learning Rate: 0.000059 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10338/12542 | Batch Loss: 1.3594 | Learning Rate: 0.000059 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10339/12542 | Batch Loss: 0.8703 | Learning Rate: 0.000059 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10340/12542 | Batch Loss: 3.5611 | Learning Rate: 0.000059 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10341/12542 | Batch Loss: 2.0455 | Learning Rate: 0.000058 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10342/12542 | Batch Loss: 0.8092 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10343/12542 | Batch Loss: 0.8313 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10344/12542 | Batch Loss: 0.6527 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10345/12542 | Batch Loss: 2.1415 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10346/12542 | Batch Loss: 1.1411 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10347/12542 | Batch Loss: 1.3823 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10348/12542 | Batch Loss: 1.1104 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10349/12542 | Batch Loss: 0.6425 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10350/12542 | Batch Loss: 0.9532 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10351/12542 | Batch Loss: 1.6773 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10352/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000058 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10353/12542 | Batch Loss: 0.6485 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10354/12542 | Batch Loss: 1.5175 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10355/12542 | Batch Loss: 1.0931 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10356/12542 | Batch Loss: 0.4721 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10357/12542 | Batch Loss: 0.7130 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10358/12542 | Batch Loss: 0.9926 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10359/12542 | Batch Loss: 1.5460 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10360/12542 | Batch Loss: 2.8096 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10361/12542 | Batch Loss: 2.0549 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10362/12542 | Batch Loss: 3.2889 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10363/12542 | Batch Loss: 1.4688 | Learning Rate: 0.000058 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10364/12542 | Batch Loss: 1.1642 | Learning Rate: 0.000058 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10365/12542 | Batch Loss: 1.8177 | Learning Rate: 0.000058 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10366/12542 | Batch Loss: 0.6785 | Learning Rate: 0.000058 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10367/12542 | Batch Loss: 1.8852 | Learning Rate: 0.000058 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10368/12542 | Batch Loss: 1.8571 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10369/12542 | Batch Loss: 0.9706 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10370/12542 | Batch Loss: 0.9543 | Learning Rate: 0.000058 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10371/12542 | Batch Loss: 1.0594 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10372/12542 | Batch Loss: 1.3069 | Learning Rate: 0.000058 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10373/12542 | Batch Loss: 1.9212 | Learning Rate: 0.000058 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10374/12542 | Batch Loss: 0.7238 | Learning Rate: 0.000058 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10375/12542 | Batch Loss: 1.1540 | Learning Rate: 0.000058 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10376/12542 | Batch Loss: 1.1132 | Learning Rate: 0.000058 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10377/12542 | Batch Loss: 1.6728 | Learning Rate: 0.000058 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10378/12542 | Batch Loss: 0.9677 | Learning Rate: 0.000058 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10379/12542 | Batch Loss: 1.0792 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10380/12542 | Batch Loss: 0.4835 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10381/12542 | Batch Loss: 1.6147 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10382/12542 | Batch Loss: 1.8100 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10383/12542 | Batch Loss: 1.0147 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10384/12542 | Batch Loss: 0.9271 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10385/12542 | Batch Loss: 1.8086 | Learning Rate: 0.000057 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10386/12542 | Batch Loss: 0.5982 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10387/12542 | Batch Loss: 1.5701 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10388/12542 | Batch Loss: 1.6238 | Learning Rate: 0.000057 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10389/12542 | Batch Loss: 0.6363 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10390/12542 | Batch Loss: 0.8498 | Learning Rate: 0.000057 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10391/12542 | Batch Loss: 1.5835 | Learning Rate: 0.000057 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10392/12542 | Batch Loss: 1.6837 | Learning Rate: 0.000057 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10393/12542 | Batch Loss: 1.5812 | Learning Rate: 0.000057 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10394/12542 | Batch Loss: 1.5748 | Learning Rate: 0.000057 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10395/12542 | Batch Loss: 0.6303 | Learning Rate: 0.000057 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10396/12542 | Batch Loss: 2.6228 | Learning Rate: 0.000057 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10397/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000057 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10398/12542 | Batch Loss: 2.5635 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10399/12542 | Batch Loss: 0.6365 | Learning Rate: 0.000057 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10400/12542 | Batch Loss: 1.1490 | Learning Rate: 0.000057 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10401/12542 | Batch Loss: 0.9427 | Learning Rate: 0.000057 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10402/12542 | Batch Loss: 0.9191 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10403/12542 | Batch Loss: 1.5760 | Learning Rate: 0.000057 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10404/12542 | Batch Loss: 1.1163 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10405/12542 | Batch Loss: 0.8279 | Learning Rate: 0.000057 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10406/12542 | Batch Loss: 2.3363 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10407/12542 | Batch Loss: 1.2033 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10408/12542 | Batch Loss: 1.0763 | Learning Rate: 0.000057 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10409/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000057 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10410/12542 | Batch Loss: 1.5731 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10411/12542 | Batch Loss: 1.1906 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10412/12542 | Batch Loss: 1.0732 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10413/12542 | Batch Loss: 0.8446 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10414/12542 | Batch Loss: 0.7843 | Learning Rate: 0.000057 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10415/12542 | Batch Loss: 1.5454 | Learning Rate: 0.000057 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10416/12542 | Batch Loss: 0.9402 | Learning Rate: 0.000057 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10417/12542 | Batch Loss: 1.2942 | Learning Rate: 0.000056 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10418/12542 | Batch Loss: 1.8898 | Learning Rate: 0.000056 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10419/12542 | Batch Loss: 0.8073 | Learning Rate: 0.000056 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10420/12542 | Batch Loss: 0.8883 | Learning Rate: 0.000056 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10421/12542 | Batch Loss: 1.3472 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10422/12542 | Batch Loss: 0.6514 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10423/12542 | Batch Loss: 1.1888 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10424/12542 | Batch Loss: 1.5208 | Learning Rate: 0.000056 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10425/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10426/12542 | Batch Loss: 1.6006 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10427/12542 | Batch Loss: 0.5649 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10428/12542 | Batch Loss: 1.1987 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10429/12542 | Batch Loss: 1.0801 | Learning Rate: 0.000056 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10430/12542 | Batch Loss: 1.0680 | Learning Rate: 0.000056 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10431/12542 | Batch Loss: 0.2452 | Learning Rate: 0.000056 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10432/12542 | Batch Loss: 1.2920 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10433/12542 | Batch Loss: 1.9560 | Learning Rate: 0.000056 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10434/12542 | Batch Loss: 0.8023 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10435/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10436/12542 | Batch Loss: 0.7831 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10437/12542 | Batch Loss: 0.9168 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10438/12542 | Batch Loss: 0.9024 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10439/12542 | Batch Loss: 1.1273 | Learning Rate: 0.000056 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10440/12542 | Batch Loss: 1.4645 | Learning Rate: 0.000056 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10441/12542 | Batch Loss: 1.1028 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10442/12542 | Batch Loss: 3.0639 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10443/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10444/12542 | Batch Loss: 1.5073 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10445/12542 | Batch Loss: 1.7604 | Learning Rate: 0.000056 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10446/12542 | Batch Loss: 1.1593 | Learning Rate: 0.000056 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10447/12542 | Batch Loss: 3.2412 | Learning Rate: 0.000056 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10448/12542 | Batch Loss: 1.0507 | Learning Rate: 0.000056 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10449/12542 | Batch Loss: 0.9012 | Learning Rate: 0.000056 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10450/12542 | Batch Loss: 1.6686 | Learning Rate: 0.000056 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10451/12542 | Batch Loss: 1.1135 | Learning Rate: 0.000056 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10452/12542 | Batch Loss: 1.4813 | Learning Rate: 0.000056 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10453/12542 | Batch Loss: 1.7265 | Learning Rate: 0.000056 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10454/12542 | Batch Loss: 1.5244 | Learning Rate: 0.000055 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10455/12542 | Batch Loss: 0.9406 | Learning Rate: 0.000055 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10456/12542 | Batch Loss: 0.9214 | Learning Rate: 0.000055 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10457/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10458/12542 | Batch Loss: 1.4362 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10459/12542 | Batch Loss: 1.6920 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10460/12542 | Batch Loss: 1.4322 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10461/12542 | Batch Loss: 0.7978 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10462/12542 | Batch Loss: 0.7246 | Learning Rate: 0.000055 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10463/12542 | Batch Loss: 0.5585 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10464/12542 | Batch Loss: 1.8339 | Learning Rate: 0.000055 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10465/12542 | Batch Loss: 2.6060 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10466/12542 | Batch Loss: 3.4324 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10467/12542 | Batch Loss: 1.2864 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10468/12542 | Batch Loss: 1.7892 | Learning Rate: 0.000055 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10469/12542 | Batch Loss: 1.1034 | Learning Rate: 0.000055 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10470/12542 | Batch Loss: 1.5553 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10471/12542 | Batch Loss: 1.1987 | Learning Rate: 0.000055 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10472/12542 | Batch Loss: 2.6386 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10473/12542 | Batch Loss: 1.8594 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10474/12542 | Batch Loss: 1.6076 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10475/12542 | Batch Loss: 1.3670 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10476/12542 | Batch Loss: 1.0212 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10477/12542 | Batch Loss: 1.1057 | Learning Rate: 0.000055 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10478/12542 | Batch Loss: 0.9686 | Learning Rate: 0.000055 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10479/12542 | Batch Loss: 1.2313 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10480/12542 | Batch Loss: 0.9351 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10481/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10482/12542 | Batch Loss: 1.1705 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10483/12542 | Batch Loss: 1.0728 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10484/12542 | Batch Loss: 2.0391 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10485/12542 | Batch Loss: 0.6658 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10486/12542 | Batch Loss: 0.8467 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10487/12542 | Batch Loss: 1.3558 | Learning Rate: 0.000055 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10488/12542 | Batch Loss: 0.9248 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10489/12542 | Batch Loss: 1.1860 | Learning Rate: 0.000055 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10490/12542 | Batch Loss: 1.6139 | Learning Rate: 0.000055 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10491/12542 | Batch Loss: 2.0020 | Learning Rate: 0.000055 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10492/12542 | Batch Loss: 1.5583 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10493/12542 | Batch Loss: 1.0743 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10494/12542 | Batch Loss: 0.9613 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10495/12542 | Batch Loss: 0.6165 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10496/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000054 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10497/12542 | Batch Loss: 0.7783 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10498/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000054 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10499/12542 | Batch Loss: 0.6029 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10500/12542 | Batch Loss: 0.5954 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10501/12542 | Batch Loss: 1.9687 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10502/12542 | Batch Loss: 1.5137 | Learning Rate: 0.000054 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10503/12542 | Batch Loss: 0.7527 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10504/12542 | Batch Loss: 1.1884 | Learning Rate: 0.000054 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10505/12542 | Batch Loss: 0.7077 | Learning Rate: 0.000054 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10506/12542 | Batch Loss: 2.2222 | Learning Rate: 0.000054 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10507/12542 | Batch Loss: 1.9114 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10508/12542 | Batch Loss: 1.2767 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10509/12542 | Batch Loss: 1.2524 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10510/12542 | Batch Loss: 1.1390 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10511/12542 | Batch Loss: 0.7603 | Learning Rate: 0.000054 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10512/12542 | Batch Loss: 2.4175 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10513/12542 | Batch Loss: 0.8114 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10514/12542 | Batch Loss: 1.7034 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10515/12542 | Batch Loss: 1.1006 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10516/12542 | Batch Loss: 0.7493 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10517/12542 | Batch Loss: 0.7692 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10518/12542 | Batch Loss: 1.1866 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10519/12542 | Batch Loss: 0.8356 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10520/12542 | Batch Loss: 0.4099 | Learning Rate: 0.000054 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10521/12542 | Batch Loss: 1.2771 | Learning Rate: 0.000054 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10522/12542 | Batch Loss: 0.9353 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10523/12542 | Batch Loss: 0.4545 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10524/12542 | Batch Loss: 1.0749 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10525/12542 | Batch Loss: 1.3204 | Learning Rate: 0.000054 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10526/12542 | Batch Loss: 2.4914 | Learning Rate: 0.000054 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10527/12542 | Batch Loss: 1.5938 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10528/12542 | Batch Loss: 1.3119 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10529/12542 | Batch Loss: 1.7400 | Learning Rate: 0.000054 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10530/12542 | Batch Loss: 1.7617 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10531/12542 | Batch Loss: 2.5629 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10532/12542 | Batch Loss: 1.3984 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10533/12542 | Batch Loss: 1.6985 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10534/12542 | Batch Loss: 1.6504 | Learning Rate: 0.000053 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10535/12542 | Batch Loss: 0.6096 | Learning Rate: 0.000053 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10536/12542 | Batch Loss: 1.2670 | Learning Rate: 0.000053 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10537/12542 | Batch Loss: 1.4290 | Learning Rate: 0.000053 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10538/12542 | Batch Loss: 0.7024 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10539/12542 | Batch Loss: 1.4098 | Learning Rate: 0.000053 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10540/12542 | Batch Loss: 1.3063 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10541/12542 | Batch Loss: 1.9105 | Learning Rate: 0.000053 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10542/12542 | Batch Loss: 1.3109 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10543/12542 | Batch Loss: 2.2490 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10544/12542 | Batch Loss: 1.5227 | Learning Rate: 0.000053 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10545/12542 | Batch Loss: 1.2012 | Learning Rate: 0.000053 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10546/12542 | Batch Loss: 1.1219 | Learning Rate: 0.000053 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10547/12542 | Batch Loss: 0.7842 | Learning Rate: 0.000053 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10548/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10549/12542 | Batch Loss: 0.5628 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10550/12542 | Batch Loss: 0.3348 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10551/12542 | Batch Loss: 1.3140 | Learning Rate: 0.000053 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10552/12542 | Batch Loss: 1.9508 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10553/12542 | Batch Loss: 1.8888 | Learning Rate: 0.000053 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10554/12542 | Batch Loss: 1.0393 | Learning Rate: 0.000053 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10555/12542 | Batch Loss: 1.5706 | Learning Rate: 0.000053 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10556/12542 | Batch Loss: 0.3928 | Learning Rate: 0.000053 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10557/12542 | Batch Loss: 0.9139 | Learning Rate: 0.000053 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10558/12542 | Batch Loss: 1.5436 | Learning Rate: 0.000053 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10559/12542 | Batch Loss: 0.9873 | Learning Rate: 0.000053 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10560/12542 | Batch Loss: 0.7201 | Learning Rate: 0.000053 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10561/12542 | Batch Loss: 1.0315 | Learning Rate: 0.000053 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10562/12542 | Batch Loss: 1.0477 | Learning Rate: 0.000053 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10563/12542 | Batch Loss: 0.5145 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10564/12542 | Batch Loss: 0.9571 | Learning Rate: 0.000053 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10565/12542 | Batch Loss: 0.8798 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10566/12542 | Batch Loss: 2.1700 | Learning Rate: 0.000053 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10567/12542 | Batch Loss: 1.2693 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10568/12542 | Batch Loss: 0.8490 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10569/12542 | Batch Loss: 1.0344 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10570/12542 | Batch Loss: 0.5845 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10571/12542 | Batch Loss: 1.0964 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10572/12542 | Batch Loss: 3.4783 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10573/12542 | Batch Loss: 1.2918 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10574/12542 | Batch Loss: 1.5244 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10575/12542 | Batch Loss: 1.0695 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10576/12542 | Batch Loss: 0.8498 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10577/12542 | Batch Loss: 1.7483 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10578/12542 | Batch Loss: 1.4974 | Learning Rate: 0.000052 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10579/12542 | Batch Loss: 0.6665 | Learning Rate: 0.000052 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10580/12542 | Batch Loss: 0.9708 | Learning Rate: 0.000052 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10581/12542 | Batch Loss: 0.4782 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10582/12542 | Batch Loss: 0.9962 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10583/12542 | Batch Loss: 0.8239 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10584/12542 | Batch Loss: 1.3342 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10585/12542 | Batch Loss: 0.6456 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10586/12542 | Batch Loss: 0.5730 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10587/12542 | Batch Loss: 1.0312 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10588/12542 | Batch Loss: 1.1096 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10589/12542 | Batch Loss: 0.8422 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10590/12542 | Batch Loss: 2.0630 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10591/12542 | Batch Loss: 2.1384 | Learning Rate: 0.000052 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10592/12542 | Batch Loss: 1.5906 | Learning Rate: 0.000052 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10593/12542 | Batch Loss: 1.1342 | Learning Rate: 0.000052 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10594/12542 | Batch Loss: 0.7379 | Learning Rate: 0.000052 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10595/12542 | Batch Loss: 1.4261 | Learning Rate: 0.000052 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10596/12542 | Batch Loss: 0.9177 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10597/12542 | Batch Loss: 1.4746 | Learning Rate: 0.000052 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10598/12542 | Batch Loss: 0.4557 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10599/12542 | Batch Loss: 1.6148 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10600/12542 | Batch Loss: 1.0775 | Learning Rate: 0.000052 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10601/12542 | Batch Loss: 1.6567 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10602/12542 | Batch Loss: 3.2655 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10603/12542 | Batch Loss: 0.8188 | Learning Rate: 0.000052 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10604/12542 | Batch Loss: 0.7553 | Learning Rate: 0.000052 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10605/12542 | Batch Loss: 3.3406 | Learning Rate: 0.000051 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10606/12542 | Batch Loss: 0.9910 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10607/12542 | Batch Loss: 0.9534 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10608/12542 | Batch Loss: 1.8158 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10609/12542 | Batch Loss: 1.0630 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10610/12542 | Batch Loss: 1.5605 | Learning Rate: 0.000051 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10611/12542 | Batch Loss: 1.4133 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10612/12542 | Batch Loss: 1.0694 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10613/12542 | Batch Loss: 1.2839 | Learning Rate: 0.000051 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10614/12542 | Batch Loss: 1.4375 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10615/12542 | Batch Loss: 1.5416 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10616/12542 | Batch Loss: 1.1254 | Learning Rate: 0.000051 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10617/12542 | Batch Loss: 0.6573 | Learning Rate: 0.000051 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10618/12542 | Batch Loss: 0.6166 | Learning Rate: 0.000051 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10619/12542 | Batch Loss: 0.6841 | Learning Rate: 0.000051 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10620/12542 | Batch Loss: 1.3744 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10621/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10622/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10623/12542 | Batch Loss: 1.8145 | Learning Rate: 0.000051 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10624/12542 | Batch Loss: 0.8492 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10625/12542 | Batch Loss: 0.9753 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10626/12542 | Batch Loss: 0.9224 | Learning Rate: 0.000051 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10627/12542 | Batch Loss: 2.6607 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10628/12542 | Batch Loss: 1.5205 | Learning Rate: 0.000051 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10629/12542 | Batch Loss: 1.0853 | Learning Rate: 0.000051 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10630/12542 | Batch Loss: 1.7570 | Learning Rate: 0.000051 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10631/12542 | Batch Loss: 1.6468 | Learning Rate: 0.000051 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10632/12542 | Batch Loss: 0.8892 | Learning Rate: 0.000051 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10633/12542 | Batch Loss: 1.7495 | Learning Rate: 0.000051 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10634/12542 | Batch Loss: 1.1183 | Learning Rate: 0.000051 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10635/12542 | Batch Loss: 0.1535 | Learning Rate: 0.000051 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10636/12542 | Batch Loss: 1.7104 | Learning Rate: 0.000051 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10637/12542 | Batch Loss: 2.1790 | Learning Rate: 0.000051 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10638/12542 | Batch Loss: 0.6182 | Learning Rate: 0.000051 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10639/12542 | Batch Loss: 0.7791 | Learning Rate: 0.000051 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10640/12542 | Batch Loss: 1.2760 | Learning Rate: 0.000051 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10641/12542 | Batch Loss: 1.5222 | Learning Rate: 0.000051 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10642/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10643/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000050 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10644/12542 | Batch Loss: 0.5880 | Learning Rate: 0.000050 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10645/12542 | Batch Loss: 1.6933 | Learning Rate: 0.000050 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10646/12542 | Batch Loss: 2.4896 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10647/12542 | Batch Loss: 2.1833 | Learning Rate: 0.000050 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10648/12542 | Batch Loss: 0.9586 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10649/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000050 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10650/12542 | Batch Loss: 1.0174 | Learning Rate: 0.000050 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 10651/12542 | Batch Loss: 0.6094 | Learning Rate: 0.000050 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10652/12542 | Batch Loss: 0.4731 | Learning Rate: 0.000050 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10653/12542 | Batch Loss: 2.1546 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10654/12542 | Batch Loss: 0.6201 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10655/12542 | Batch Loss: 1.7282 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10656/12542 | Batch Loss: 1.8606 | Learning Rate: 0.000050 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10657/12542 | Batch Loss: 1.0629 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10658/12542 | Batch Loss: 1.5997 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10659/12542 | Batch Loss: 1.1328 | Learning Rate: 0.000050 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10660/12542 | Batch Loss: 2.1326 | Learning Rate: 0.000050 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10661/12542 | Batch Loss: 0.9505 | Learning Rate: 0.000050 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10662/12542 | Batch Loss: 1.3099 | Learning Rate: 0.000050 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10663/12542 | Batch Loss: 0.9438 | Learning Rate: 0.000050 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10664/12542 | Batch Loss: 0.9077 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10665/12542 | Batch Loss: 0.3855 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10666/12542 | Batch Loss: 0.5142 | Learning Rate: 0.000050 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10667/12542 | Batch Loss: 0.7899 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10668/12542 | Batch Loss: 1.0026 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10669/12542 | Batch Loss: 0.7452 | Learning Rate: 0.000050 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10670/12542 | Batch Loss: 1.3190 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10671/12542 | Batch Loss: 1.3851 | Learning Rate: 0.000050 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10672/12542 | Batch Loss: 0.3357 | Learning Rate: 0.000050 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10673/12542 | Batch Loss: 1.1740 | Learning Rate: 0.000050 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10674/12542 | Batch Loss: 0.5516 | Learning Rate: 0.000050 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10675/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10676/12542 | Batch Loss: 1.4096 | Learning Rate: 0.000050 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10677/12542 | Batch Loss: 0.9839 | Learning Rate: 0.000050 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10678/12542 | Batch Loss: 1.2394 | Learning Rate: 0.000050 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10679/12542 | Batch Loss: 1.1257 | Learning Rate: 0.000050 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10680/12542 | Batch Loss: 1.7348 | Learning Rate: 0.000049 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10681/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000049 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10682/12542 | Batch Loss: 0.9794 | Learning Rate: 0.000049 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10683/12542 | Batch Loss: 1.3183 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10684/12542 | Batch Loss: 2.6153 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10685/12542 | Batch Loss: 0.7562 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10686/12542 | Batch Loss: 1.2270 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10687/12542 | Batch Loss: 2.6457 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10688/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10689/12542 | Batch Loss: 0.6800 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10690/12542 | Batch Loss: 0.9788 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10691/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10692/12542 | Batch Loss: 2.2074 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10693/12542 | Batch Loss: 1.2089 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10694/12542 | Batch Loss: 1.4622 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10695/12542 | Batch Loss: 0.4657 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10696/12542 | Batch Loss: 0.9893 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10697/12542 | Batch Loss: 1.1584 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10698/12542 | Batch Loss: 1.5829 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10699/12542 | Batch Loss: 1.1161 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10700/12542 | Batch Loss: 0.5431 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10701/12542 | Batch Loss: 1.3446 | Learning Rate: 0.000049 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10702/12542 | Batch Loss: 2.4546 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10703/12542 | Batch Loss: 1.4717 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10704/12542 | Batch Loss: 1.6094 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10705/12542 | Batch Loss: 0.7256 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10706/12542 | Batch Loss: 0.8716 | Learning Rate: 0.000049 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10707/12542 | Batch Loss: 0.7570 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10708/12542 | Batch Loss: 2.1123 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10709/12542 | Batch Loss: 0.9476 | Learning Rate: 0.000049 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10710/12542 | Batch Loss: 1.4483 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10711/12542 | Batch Loss: 1.6871 | Learning Rate: 0.000049 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10712/12542 | Batch Loss: 2.1111 | Learning Rate: 0.000049 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10713/12542 | Batch Loss: 0.7985 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10714/12542 | Batch Loss: 0.7605 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10715/12542 | Batch Loss: 0.7181 | Learning Rate: 0.000049 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10716/12542 | Batch Loss: 2.4756 | Learning Rate: 0.000049 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10717/12542 | Batch Loss: 1.1943 | Learning Rate: 0.000049 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10718/12542 | Batch Loss: 0.7736 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10719/12542 | Batch Loss: 0.6032 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10720/12542 | Batch Loss: 0.3347 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10721/12542 | Batch Loss: 2.2443 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10722/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000048 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10723/12542 | Batch Loss: 1.0006 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10724/12542 | Batch Loss: 2.3240 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10725/12542 | Batch Loss: 0.6909 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10726/12542 | Batch Loss: 1.0631 | Learning Rate: 0.000048 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10727/12542 | Batch Loss: 2.0627 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10728/12542 | Batch Loss: 1.4221 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10729/12542 | Batch Loss: 1.8544 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10730/12542 | Batch Loss: 1.1141 | Learning Rate: 0.000048 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10731/12542 | Batch Loss: 0.5431 | Learning Rate: 0.000048 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10732/12542 | Batch Loss: 0.7678 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10733/12542 | Batch Loss: 1.6277 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10734/12542 | Batch Loss: 1.0493 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10735/12542 | Batch Loss: 1.1481 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10736/12542 | Batch Loss: 1.0029 | Learning Rate: 0.000048 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10737/12542 | Batch Loss: 1.6401 | Learning Rate: 0.000048 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10738/12542 | Batch Loss: 1.8799 | Learning Rate: 0.000048 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10739/12542 | Batch Loss: 1.0459 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10740/12542 | Batch Loss: 1.8793 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10741/12542 | Batch Loss: 1.1859 | Learning Rate: 0.000048 | Batch Time: 0.57s\n",
      "Epoch 3 | Step 10742/12542 | Batch Loss: 0.9461 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10743/12542 | Batch Loss: 0.6226 | Learning Rate: 0.000048 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10744/12542 | Batch Loss: 1.2964 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10745/12542 | Batch Loss: 1.3644 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10746/12542 | Batch Loss: 1.7843 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10747/12542 | Batch Loss: 1.4225 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10748/12542 | Batch Loss: 1.0232 | Learning Rate: 0.000048 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10749/12542 | Batch Loss: 1.9305 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10750/12542 | Batch Loss: 1.5226 | Learning Rate: 0.000048 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10751/12542 | Batch Loss: 0.8261 | Learning Rate: 0.000048 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10752/12542 | Batch Loss: 1.5840 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10753/12542 | Batch Loss: 0.9866 | Learning Rate: 0.000048 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10754/12542 | Batch Loss: 0.6995 | Learning Rate: 0.000048 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10755/12542 | Batch Loss: 1.5985 | Learning Rate: 0.000047 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10756/12542 | Batch Loss: 2.7429 | Learning Rate: 0.000047 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10757/12542 | Batch Loss: 2.2016 | Learning Rate: 0.000047 | Batch Time: 0.69s\n",
      "Epoch 3 | Step 10758/12542 | Batch Loss: 1.6569 | Learning Rate: 0.000047 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10759/12542 | Batch Loss: 0.5788 | Learning Rate: 0.000047 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10760/12542 | Batch Loss: 1.6516 | Learning Rate: 0.000047 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10761/12542 | Batch Loss: 0.9661 | Learning Rate: 0.000047 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10762/12542 | Batch Loss: 1.0165 | Learning Rate: 0.000047 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10763/12542 | Batch Loss: 1.5963 | Learning Rate: 0.000047 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10764/12542 | Batch Loss: 1.3774 | Learning Rate: 0.000047 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10765/12542 | Batch Loss: 1.2504 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10766/12542 | Batch Loss: 1.0721 | Learning Rate: 0.000047 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10767/12542 | Batch Loss: 1.0360 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10768/12542 | Batch Loss: 1.4035 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10769/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10770/12542 | Batch Loss: 1.0124 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10771/12542 | Batch Loss: 0.6002 | Learning Rate: 0.000047 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10772/12542 | Batch Loss: 0.6513 | Learning Rate: 0.000047 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10773/12542 | Batch Loss: 0.8330 | Learning Rate: 0.000047 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10774/12542 | Batch Loss: 0.8841 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10775/12542 | Batch Loss: 2.2036 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10776/12542 | Batch Loss: 1.2546 | Learning Rate: 0.000047 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10777/12542 | Batch Loss: 1.7145 | Learning Rate: 0.000047 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10778/12542 | Batch Loss: 1.1518 | Learning Rate: 0.000047 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10779/12542 | Batch Loss: 0.8853 | Learning Rate: 0.000047 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10780/12542 | Batch Loss: 0.8064 | Learning Rate: 0.000047 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10781/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000047 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10782/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000047 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10783/12542 | Batch Loss: 1.9984 | Learning Rate: 0.000047 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10784/12542 | Batch Loss: 1.3842 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10785/12542 | Batch Loss: 1.2704 | Learning Rate: 0.000047 | Batch Time: 0.62s\n",
      "Epoch 3 | Step 10786/12542 | Batch Loss: 2.3045 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10787/12542 | Batch Loss: 0.7221 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10788/12542 | Batch Loss: 1.8618 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10789/12542 | Batch Loss: 1.1026 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10790/12542 | Batch Loss: 3.4274 | Learning Rate: 0.000047 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10791/12542 | Batch Loss: 1.5226 | Learning Rate: 0.000047 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10792/12542 | Batch Loss: 1.5770 | Learning Rate: 0.000047 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10793/12542 | Batch Loss: 2.7531 | Learning Rate: 0.000046 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10794/12542 | Batch Loss: 0.7542 | Learning Rate: 0.000046 | Batch Time: 0.63s\n",
      "Epoch 3 | Step 10795/12542 | Batch Loss: 2.9306 | Learning Rate: 0.000046 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10796/12542 | Batch Loss: 1.4705 | Learning Rate: 0.000046 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10797/12542 | Batch Loss: 0.5511 | Learning Rate: 0.000046 | Batch Time: 0.65s\n",
      "Epoch 3 | Step 10798/12542 | Batch Loss: 1.7337 | Learning Rate: 0.000046 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10799/12542 | Batch Loss: 0.8224 | Learning Rate: 0.000046 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10800/12542 | Batch Loss: 0.8385 | Learning Rate: 0.000046 | Batch Time: 0.64s\n",
      "Epoch 3 | Step 10801/12542 | Batch Loss: 0.7914 | Learning Rate: 0.000046 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10802/12542 | Batch Loss: 0.4583 | Learning Rate: 0.000046 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10803/12542 | Batch Loss: 1.1049 | Learning Rate: 0.000046 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10804/12542 | Batch Loss: 1.2801 | Learning Rate: 0.000046 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10805/12542 | Batch Loss: 0.6363 | Learning Rate: 0.000046 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10806/12542 | Batch Loss: 1.4853 | Learning Rate: 0.000046 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10807/12542 | Batch Loss: 0.5601 | Learning Rate: 0.000046 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10808/12542 | Batch Loss: 0.8113 | Learning Rate: 0.000046 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10809/12542 | Batch Loss: 0.8190 | Learning Rate: 0.000046 | Batch Time: 0.61s\n",
      "Epoch 3 | Step 10810/12542 | Batch Loss: 2.1702 | Learning Rate: 0.000046 | Batch Time: 0.59s\n",
      "Epoch 3 | Step 10811/12542 | Batch Loss: 1.2726 | Learning Rate: 0.000046 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10812/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000046 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10813/12542 | Batch Loss: 2.4156 | Learning Rate: 0.000046 | Batch Time: 0.71s\n",
      "Epoch 3 | Step 10814/12542 | Batch Loss: 0.9398 | Learning Rate: 0.000046 | Batch Time: 0.66s\n",
      "Epoch 3 | Step 10815/12542 | Batch Loss: 0.9801 | Learning Rate: 0.000046 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10816/12542 | Batch Loss: 0.6109 | Learning Rate: 0.000046 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10817/12542 | Batch Loss: 2.6647 | Learning Rate: 0.000046 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10818/12542 | Batch Loss: 1.8939 | Learning Rate: 0.000046 | Batch Time: 0.60s\n",
      "Epoch 3 | Step 10819/12542 | Batch Loss: 2.0869 | Learning Rate: 0.000046 | Batch Time: 0.68s\n",
      "Epoch 3 | Step 10820/12542 | Batch Loss: 2.1495 | Learning Rate: 0.000046 | Batch Time: 0.67s\n",
      "Epoch 3 | Step 10821/12542 | Batch Loss: 1.4812 | Learning Rate: 0.000046 | Batch Time: 0.58s\n",
      "Epoch 3 | Step 10822/12542 | Batch Loss: 1.6760 | Learning Rate: 0.000046 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10823/12542 | Batch Loss: 1.7274 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10824/12542 | Batch Loss: 0.5291 | Learning Rate: 0.000046 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10825/12542 | Batch Loss: 1.1907 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10826/12542 | Batch Loss: 0.8196 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10827/12542 | Batch Loss: 0.4692 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10828/12542 | Batch Loss: 2.0353 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10829/12542 | Batch Loss: 0.5149 | Learning Rate: 0.000046 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10830/12542 | Batch Loss: 1.8387 | Learning Rate: 0.000046 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10831/12542 | Batch Loss: 1.1968 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10832/12542 | Batch Loss: 0.4368 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10833/12542 | Batch Loss: 0.8307 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10834/12542 | Batch Loss: 0.6535 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10835/12542 | Batch Loss: 0.3267 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10836/12542 | Batch Loss: 0.7594 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10837/12542 | Batch Loss: 2.0422 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10838/12542 | Batch Loss: 3.1053 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10839/12542 | Batch Loss: 0.7774 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10840/12542 | Batch Loss: 2.3677 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10841/12542 | Batch Loss: 1.1388 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10842/12542 | Batch Loss: 0.7352 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10843/12542 | Batch Loss: 1.3336 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10844/12542 | Batch Loss: 1.4923 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10845/12542 | Batch Loss: 1.1017 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10846/12542 | Batch Loss: 1.7743 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10847/12542 | Batch Loss: 1.8124 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10848/12542 | Batch Loss: 0.8369 | Learning Rate: 0.000045 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10849/12542 | Batch Loss: 0.9788 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10850/12542 | Batch Loss: 1.5030 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10851/12542 | Batch Loss: 1.3799 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10852/12542 | Batch Loss: 2.2210 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10853/12542 | Batch Loss: 0.7955 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10854/12542 | Batch Loss: 1.7658 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10855/12542 | Batch Loss: 0.9000 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10856/12542 | Batch Loss: 1.3253 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10857/12542 | Batch Loss: 0.9261 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10858/12542 | Batch Loss: 0.5998 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10859/12542 | Batch Loss: 0.6840 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10860/12542 | Batch Loss: 1.5152 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10861/12542 | Batch Loss: 1.8282 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10862/12542 | Batch Loss: 1.2657 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10863/12542 | Batch Loss: 0.7788 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10864/12542 | Batch Loss: 0.7807 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10865/12542 | Batch Loss: 1.9419 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10866/12542 | Batch Loss: 0.6493 | Learning Rate: 0.000045 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10867/12542 | Batch Loss: 0.7372 | Learning Rate: 0.000045 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10868/12542 | Batch Loss: 1.2243 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10869/12542 | Batch Loss: 0.9662 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10870/12542 | Batch Loss: 1.1930 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10871/12542 | Batch Loss: 1.2631 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10872/12542 | Batch Loss: 0.9659 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10873/12542 | Batch Loss: 1.2191 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10874/12542 | Batch Loss: 0.8147 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10875/12542 | Batch Loss: 1.1839 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10876/12542 | Batch Loss: 2.7374 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10877/12542 | Batch Loss: 1.3197 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10878/12542 | Batch Loss: 2.0986 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10879/12542 | Batch Loss: 1.2261 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10880/12542 | Batch Loss: 0.3911 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10881/12542 | Batch Loss: 0.8597 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10882/12542 | Batch Loss: 1.3799 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10883/12542 | Batch Loss: 2.0569 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10884/12542 | Batch Loss: 1.3786 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10885/12542 | Batch Loss: 0.8207 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10886/12542 | Batch Loss: 1.2276 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10887/12542 | Batch Loss: 0.9734 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10888/12542 | Batch Loss: 1.2643 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10889/12542 | Batch Loss: 1.4917 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10890/12542 | Batch Loss: 0.7909 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10891/12542 | Batch Loss: 0.9590 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10892/12542 | Batch Loss: 1.5579 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10893/12542 | Batch Loss: 1.6824 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10894/12542 | Batch Loss: 1.4602 | Learning Rate: 0.000044 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10895/12542 | Batch Loss: 1.3080 | Learning Rate: 0.000044 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10896/12542 | Batch Loss: 0.5822 | Learning Rate: 0.000044 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10897/12542 | Batch Loss: 1.3671 | Learning Rate: 0.000044 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10898/12542 | Batch Loss: 1.6253 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10899/12542 | Batch Loss: 0.9975 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10900/12542 | Batch Loss: 1.1140 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10901/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10902/12542 | Batch Loss: 0.6390 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10903/12542 | Batch Loss: 0.4422 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10904/12542 | Batch Loss: 1.8489 | Learning Rate: 0.000044 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10905/12542 | Batch Loss: 0.8123 | Learning Rate: 0.000044 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10906/12542 | Batch Loss: 0.8432 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10907/12542 | Batch Loss: 0.7458 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10908/12542 | Batch Loss: 0.7333 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10909/12542 | Batch Loss: 0.5573 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10910/12542 | Batch Loss: 1.1528 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10911/12542 | Batch Loss: 0.7538 | Learning Rate: 0.000043 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10912/12542 | Batch Loss: 0.5101 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10913/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10914/12542 | Batch Loss: 2.0320 | Learning Rate: 0.000043 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10915/12542 | Batch Loss: 1.1158 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10916/12542 | Batch Loss: 2.2365 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10917/12542 | Batch Loss: 1.0084 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10918/12542 | Batch Loss: 0.8961 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10919/12542 | Batch Loss: 1.1967 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10920/12542 | Batch Loss: 1.0338 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10921/12542 | Batch Loss: 2.1567 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10922/12542 | Batch Loss: 1.0152 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10923/12542 | Batch Loss: 1.3124 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10924/12542 | Batch Loss: 0.6402 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10925/12542 | Batch Loss: 0.5447 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10926/12542 | Batch Loss: 1.3075 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10927/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10928/12542 | Batch Loss: 2.2622 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10929/12542 | Batch Loss: 1.5751 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10930/12542 | Batch Loss: 0.7285 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10931/12542 | Batch Loss: 2.2001 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10932/12542 | Batch Loss: 0.7882 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10933/12542 | Batch Loss: 2.7779 | Learning Rate: 0.000043 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10934/12542 | Batch Loss: 1.7919 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10935/12542 | Batch Loss: 1.4432 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10936/12542 | Batch Loss: 2.7047 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10937/12542 | Batch Loss: 0.8183 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10938/12542 | Batch Loss: 0.7074 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10939/12542 | Batch Loss: 1.2365 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10940/12542 | Batch Loss: 1.8802 | Learning Rate: 0.000043 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10941/12542 | Batch Loss: 0.9498 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10942/12542 | Batch Loss: 1.7300 | Learning Rate: 0.000043 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10943/12542 | Batch Loss: 1.3860 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10944/12542 | Batch Loss: 2.2831 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10945/12542 | Batch Loss: 1.5997 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10946/12542 | Batch Loss: 1.1726 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10947/12542 | Batch Loss: 2.0255 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10948/12542 | Batch Loss: 1.2863 | Learning Rate: 0.000042 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10949/12542 | Batch Loss: 2.4969 | Learning Rate: 0.000042 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10950/12542 | Batch Loss: 0.5998 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10951/12542 | Batch Loss: 1.3018 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10952/12542 | Batch Loss: 1.6581 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10953/12542 | Batch Loss: 0.9147 | Learning Rate: 0.000042 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10954/12542 | Batch Loss: 1.3136 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10955/12542 | Batch Loss: 0.5554 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10956/12542 | Batch Loss: 0.8739 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10957/12542 | Batch Loss: 0.8243 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10958/12542 | Batch Loss: 1.8285 | Learning Rate: 0.000042 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10959/12542 | Batch Loss: 0.5677 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10960/12542 | Batch Loss: 0.7837 | Learning Rate: 0.000042 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10961/12542 | Batch Loss: 0.9869 | Learning Rate: 0.000042 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10962/12542 | Batch Loss: 0.8269 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10963/12542 | Batch Loss: 2.0093 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10964/12542 | Batch Loss: 0.8121 | Learning Rate: 0.000042 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10965/12542 | Batch Loss: 1.1778 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10966/12542 | Batch Loss: 1.2881 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10967/12542 | Batch Loss: 0.8587 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10968/12542 | Batch Loss: 0.6738 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10969/12542 | Batch Loss: 3.8525 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10970/12542 | Batch Loss: 2.4142 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10971/12542 | Batch Loss: 1.0214 | Learning Rate: 0.000042 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10972/12542 | Batch Loss: 1.6481 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10973/12542 | Batch Loss: 1.7718 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10974/12542 | Batch Loss: 0.6764 | Learning Rate: 0.000042 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10975/12542 | Batch Loss: 1.1388 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10976/12542 | Batch Loss: 0.9979 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10977/12542 | Batch Loss: 0.7410 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10978/12542 | Batch Loss: 1.3667 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10979/12542 | Batch Loss: 0.8759 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10980/12542 | Batch Loss: 0.4184 | Learning Rate: 0.000042 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10981/12542 | Batch Loss: 1.3684 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10982/12542 | Batch Loss: 1.3074 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10983/12542 | Batch Loss: 2.7136 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10984/12542 | Batch Loss: 1.4648 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10985/12542 | Batch Loss: 0.7944 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10986/12542 | Batch Loss: 1.0748 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10987/12542 | Batch Loss: 0.8981 | Learning Rate: 0.000041 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10988/12542 | Batch Loss: 0.6209 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10989/12542 | Batch Loss: 1.2327 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10990/12542 | Batch Loss: 1.2139 | Learning Rate: 0.000041 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 10991/12542 | Batch Loss: 2.2772 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10992/12542 | Batch Loss: 1.4129 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10993/12542 | Batch Loss: 1.3467 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 10994/12542 | Batch Loss: 1.0983 | Learning Rate: 0.000041 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10995/12542 | Batch Loss: 1.6094 | Learning Rate: 0.000041 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10996/12542 | Batch Loss: 1.2381 | Learning Rate: 0.000041 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 10997/12542 | Batch Loss: 1.0611 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10998/12542 | Batch Loss: 2.0217 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 10999/12542 | Batch Loss: 0.6416 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11000/12542 | Batch Loss: 1.0730 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11001/12542 | Batch Loss: 0.9598 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11002/12542 | Batch Loss: 0.6595 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11003/12542 | Batch Loss: 1.6537 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11004/12542 | Batch Loss: 0.6230 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11005/12542 | Batch Loss: 1.1901 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11006/12542 | Batch Loss: 1.1145 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11007/12542 | Batch Loss: 0.8267 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11008/12542 | Batch Loss: 1.2116 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11009/12542 | Batch Loss: 0.9097 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11010/12542 | Batch Loss: 3.1034 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11011/12542 | Batch Loss: 1.2627 | Learning Rate: 0.000041 | Batch Time: 0.45s\n",
      "Epoch 3 | Step 11012/12542 | Batch Loss: 0.5907 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11013/12542 | Batch Loss: 1.0935 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11014/12542 | Batch Loss: 0.6506 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11015/12542 | Batch Loss: 1.6099 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11016/12542 | Batch Loss: 1.1684 | Learning Rate: 0.000041 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11017/12542 | Batch Loss: 1.1413 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11018/12542 | Batch Loss: 2.4569 | Learning Rate: 0.000041 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11019/12542 | Batch Loss: 0.3226 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11020/12542 | Batch Loss: 1.1260 | Learning Rate: 0.000040 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11021/12542 | Batch Loss: 1.1692 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11022/12542 | Batch Loss: 0.6421 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11023/12542 | Batch Loss: 1.3137 | Learning Rate: 0.000040 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11024/12542 | Batch Loss: 1.9899 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11025/12542 | Batch Loss: 1.0969 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11026/12542 | Batch Loss: 0.4603 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11027/12542 | Batch Loss: 0.7564 | Learning Rate: 0.000040 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11028/12542 | Batch Loss: 0.9000 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11029/12542 | Batch Loss: 1.3710 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11030/12542 | Batch Loss: 0.9666 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11031/12542 | Batch Loss: 1.6211 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11032/12542 | Batch Loss: 0.9210 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11033/12542 | Batch Loss: 0.5454 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11034/12542 | Batch Loss: 0.8435 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11035/12542 | Batch Loss: 1.2230 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11036/12542 | Batch Loss: 1.0850 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11037/12542 | Batch Loss: 3.6136 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11038/12542 | Batch Loss: 1.9193 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11039/12542 | Batch Loss: 0.7395 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11040/12542 | Batch Loss: 1.6925 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11041/12542 | Batch Loss: 0.7598 | Learning Rate: 0.000040 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11042/12542 | Batch Loss: 1.5386 | Learning Rate: 0.000040 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11043/12542 | Batch Loss: 2.0355 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11044/12542 | Batch Loss: 0.6021 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11045/12542 | Batch Loss: 0.5177 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11046/12542 | Batch Loss: 0.6563 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11047/12542 | Batch Loss: 1.1959 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11048/12542 | Batch Loss: 0.5782 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11049/12542 | Batch Loss: 0.8633 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11050/12542 | Batch Loss: 1.0761 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11051/12542 | Batch Loss: 0.4299 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11052/12542 | Batch Loss: 0.7578 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11053/12542 | Batch Loss: 1.0808 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11054/12542 | Batch Loss: 1.0241 | Learning Rate: 0.000040 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11055/12542 | Batch Loss: 1.0615 | Learning Rate: 0.000040 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11056/12542 | Batch Loss: 0.5564 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11057/12542 | Batch Loss: 0.8760 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11058/12542 | Batch Loss: 1.3883 | Learning Rate: 0.000039 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11059/12542 | Batch Loss: 1.7380 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11060/12542 | Batch Loss: 1.3301 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11061/12542 | Batch Loss: 1.3529 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11062/12542 | Batch Loss: 1.1646 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11063/12542 | Batch Loss: 1.4172 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11064/12542 | Batch Loss: 0.8276 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11065/12542 | Batch Loss: 2.2868 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11066/12542 | Batch Loss: 0.8931 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11067/12542 | Batch Loss: 0.9526 | Learning Rate: 0.000039 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11068/12542 | Batch Loss: 0.7497 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11069/12542 | Batch Loss: 0.5256 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11070/12542 | Batch Loss: 1.0965 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11071/12542 | Batch Loss: 1.8694 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11072/12542 | Batch Loss: 1.0940 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11073/12542 | Batch Loss: 1.3307 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11074/12542 | Batch Loss: 3.7869 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11075/12542 | Batch Loss: 1.9332 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11076/12542 | Batch Loss: 1.2692 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11077/12542 | Batch Loss: 0.8700 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11078/12542 | Batch Loss: 1.0243 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11079/12542 | Batch Loss: 1.4634 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11080/12542 | Batch Loss: 1.2123 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11081/12542 | Batch Loss: 1.0583 | Learning Rate: 0.000039 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11082/12542 | Batch Loss: 1.5347 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11083/12542 | Batch Loss: 0.8973 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11084/12542 | Batch Loss: 0.8848 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11085/12542 | Batch Loss: 1.4126 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11086/12542 | Batch Loss: 0.9775 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11087/12542 | Batch Loss: 1.4747 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11088/12542 | Batch Loss: 1.0204 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11089/12542 | Batch Loss: 0.5062 | Learning Rate: 0.000039 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11090/12542 | Batch Loss: 1.1063 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11091/12542 | Batch Loss: 0.6537 | Learning Rate: 0.000039 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11092/12542 | Batch Loss: 0.5767 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11093/12542 | Batch Loss: 0.5649 | Learning Rate: 0.000039 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11094/12542 | Batch Loss: 1.1547 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11095/12542 | Batch Loss: 1.1326 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11096/12542 | Batch Loss: 0.6358 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11097/12542 | Batch Loss: 1.0434 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11098/12542 | Batch Loss: 3.1634 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11099/12542 | Batch Loss: 0.8466 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11100/12542 | Batch Loss: 0.5190 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11101/12542 | Batch Loss: 1.2619 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11102/12542 | Batch Loss: 3.6912 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11103/12542 | Batch Loss: 0.7155 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11104/12542 | Batch Loss: 0.8770 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11105/12542 | Batch Loss: 0.8164 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11106/12542 | Batch Loss: 0.9721 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11107/12542 | Batch Loss: 0.7636 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11108/12542 | Batch Loss: 0.8908 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11109/12542 | Batch Loss: 1.3182 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11110/12542 | Batch Loss: 1.6629 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11111/12542 | Batch Loss: 1.9338 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11112/12542 | Batch Loss: 1.1174 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11113/12542 | Batch Loss: 0.4683 | Learning Rate: 0.000038 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11114/12542 | Batch Loss: 1.9772 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11115/12542 | Batch Loss: 0.8584 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11116/12542 | Batch Loss: 3.5539 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11117/12542 | Batch Loss: 1.3527 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11118/12542 | Batch Loss: 1.7716 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11119/12542 | Batch Loss: 0.6402 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11120/12542 | Batch Loss: 1.3440 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11121/12542 | Batch Loss: 2.5817 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11122/12542 | Batch Loss: 2.1439 | Learning Rate: 0.000038 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11123/12542 | Batch Loss: 0.7774 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11124/12542 | Batch Loss: 2.4836 | Learning Rate: 0.000038 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11125/12542 | Batch Loss: 1.8779 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11126/12542 | Batch Loss: 1.4271 | Learning Rate: 0.000038 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11127/12542 | Batch Loss: 1.3626 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11128/12542 | Batch Loss: 2.3091 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11129/12542 | Batch Loss: 1.3867 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11130/12542 | Batch Loss: 1.2492 | Learning Rate: 0.000038 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11131/12542 | Batch Loss: 0.6025 | Learning Rate: 0.000038 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11132/12542 | Batch Loss: 0.4402 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11133/12542 | Batch Loss: 1.6511 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11134/12542 | Batch Loss: 0.6984 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11135/12542 | Batch Loss: 1.4081 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11136/12542 | Batch Loss: 0.8655 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11137/12542 | Batch Loss: 0.8875 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11138/12542 | Batch Loss: 1.5084 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11139/12542 | Batch Loss: 1.6825 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11140/12542 | Batch Loss: 1.6309 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11141/12542 | Batch Loss: 2.7013 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11142/12542 | Batch Loss: 2.4674 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11143/12542 | Batch Loss: 1.0492 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11144/12542 | Batch Loss: 2.0304 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11145/12542 | Batch Loss: 1.2640 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11146/12542 | Batch Loss: 0.9311 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11147/12542 | Batch Loss: 0.9119 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11148/12542 | Batch Loss: 3.5019 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11149/12542 | Batch Loss: 1.2042 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11150/12542 | Batch Loss: 2.7634 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11151/12542 | Batch Loss: 1.1429 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11152/12542 | Batch Loss: 1.8756 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11153/12542 | Batch Loss: 1.5832 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11154/12542 | Batch Loss: 2.0098 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11155/12542 | Batch Loss: 1.4685 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11156/12542 | Batch Loss: 0.5056 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11157/12542 | Batch Loss: 0.4740 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11158/12542 | Batch Loss: 1.4558 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11159/12542 | Batch Loss: 1.1562 | Learning Rate: 0.000037 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11160/12542 | Batch Loss: 1.3082 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11161/12542 | Batch Loss: 1.9220 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11162/12542 | Batch Loss: 1.1700 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11163/12542 | Batch Loss: 1.6425 | Learning Rate: 0.000037 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11164/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11165/12542 | Batch Loss: 1.0622 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11166/12542 | Batch Loss: 1.1530 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11167/12542 | Batch Loss: 1.1560 | Learning Rate: 0.000037 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11168/12542 | Batch Loss: 0.7126 | Learning Rate: 0.000037 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11169/12542 | Batch Loss: 2.7888 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11170/12542 | Batch Loss: 2.4552 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11171/12542 | Batch Loss: 0.8872 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11172/12542 | Batch Loss: 1.7969 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11173/12542 | Batch Loss: 0.6297 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11174/12542 | Batch Loss: 1.7144 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11175/12542 | Batch Loss: 1.5542 | Learning Rate: 0.000036 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11176/12542 | Batch Loss: 2.4479 | Learning Rate: 0.000036 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11177/12542 | Batch Loss: 1.1601 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11178/12542 | Batch Loss: 2.5623 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11179/12542 | Batch Loss: 1.2660 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11180/12542 | Batch Loss: 1.9032 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11181/12542 | Batch Loss: 1.2632 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11182/12542 | Batch Loss: 1.2667 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11183/12542 | Batch Loss: 1.6792 | Learning Rate: 0.000036 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11184/12542 | Batch Loss: 0.8310 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11185/12542 | Batch Loss: 0.7858 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11186/12542 | Batch Loss: 1.5535 | Learning Rate: 0.000036 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11187/12542 | Batch Loss: 1.4264 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11188/12542 | Batch Loss: 2.1297 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11189/12542 | Batch Loss: 0.5493 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11190/12542 | Batch Loss: 1.7864 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11191/12542 | Batch Loss: 1.8507 | Learning Rate: 0.000036 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11192/12542 | Batch Loss: 1.8102 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11193/12542 | Batch Loss: 0.9103 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11194/12542 | Batch Loss: 1.2569 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11195/12542 | Batch Loss: 2.3927 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11196/12542 | Batch Loss: 2.7928 | Learning Rate: 0.000036 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11197/12542 | Batch Loss: 1.5617 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11198/12542 | Batch Loss: 1.0408 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11199/12542 | Batch Loss: 1.4591 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11200/12542 | Batch Loss: 0.8013 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11201/12542 | Batch Loss: 0.6464 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11202/12542 | Batch Loss: 1.1186 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11203/12542 | Batch Loss: 1.3598 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11204/12542 | Batch Loss: 1.3384 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11205/12542 | Batch Loss: 1.7540 | Learning Rate: 0.000036 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11206/12542 | Batch Loss: 0.7490 | Learning Rate: 0.000036 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11207/12542 | Batch Loss: 1.5486 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11208/12542 | Batch Loss: 0.9991 | Learning Rate: 0.000035 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11209/12542 | Batch Loss: 1.7469 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11210/12542 | Batch Loss: 0.8778 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11211/12542 | Batch Loss: 3.2240 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11212/12542 | Batch Loss: 1.2464 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11213/12542 | Batch Loss: 0.6617 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11214/12542 | Batch Loss: 1.4567 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11215/12542 | Batch Loss: 1.4673 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11216/12542 | Batch Loss: 1.0862 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11217/12542 | Batch Loss: 1.3019 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11218/12542 | Batch Loss: 0.8327 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11219/12542 | Batch Loss: 0.8175 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11220/12542 | Batch Loss: 0.9959 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11221/12542 | Batch Loss: 1.3707 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11222/12542 | Batch Loss: 1.0186 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11223/12542 | Batch Loss: 2.6355 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11224/12542 | Batch Loss: 0.9259 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11225/12542 | Batch Loss: 1.0586 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11226/12542 | Batch Loss: 2.3477 | Learning Rate: 0.000035 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11227/12542 | Batch Loss: 0.7515 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11228/12542 | Batch Loss: 1.8947 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11229/12542 | Batch Loss: 0.4637 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11230/12542 | Batch Loss: 2.4708 | Learning Rate: 0.000035 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11231/12542 | Batch Loss: 2.2386 | Learning Rate: 0.000035 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11232/12542 | Batch Loss: 1.5334 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11233/12542 | Batch Loss: 1.5608 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11234/12542 | Batch Loss: 1.1984 | Learning Rate: 0.000035 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11235/12542 | Batch Loss: 1.6334 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11236/12542 | Batch Loss: 0.9281 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11237/12542 | Batch Loss: 0.6069 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11238/12542 | Batch Loss: 0.6443 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11239/12542 | Batch Loss: 0.9627 | Learning Rate: 0.000035 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11240/12542 | Batch Loss: 0.8636 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11241/12542 | Batch Loss: 2.5819 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11242/12542 | Batch Loss: 1.8045 | Learning Rate: 0.000035 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11243/12542 | Batch Loss: 1.8239 | Learning Rate: 0.000035 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11244/12542 | Batch Loss: 1.9030 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11245/12542 | Batch Loss: 1.7197 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11246/12542 | Batch Loss: 1.7618 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11247/12542 | Batch Loss: 1.3123 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11248/12542 | Batch Loss: 1.2075 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11249/12542 | Batch Loss: 1.4933 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11250/12542 | Batch Loss: 1.1447 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11251/12542 | Batch Loss: 0.9987 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11252/12542 | Batch Loss: 2.2536 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11253/12542 | Batch Loss: 0.9948 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11254/12542 | Batch Loss: 2.6337 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11255/12542 | Batch Loss: 1.4858 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11256/12542 | Batch Loss: 1.4747 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11257/12542 | Batch Loss: 1.9506 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11258/12542 | Batch Loss: 0.6414 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11259/12542 | Batch Loss: 1.4131 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11260/12542 | Batch Loss: 1.1937 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11261/12542 | Batch Loss: 0.5589 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11262/12542 | Batch Loss: 1.7737 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11263/12542 | Batch Loss: 1.1642 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11264/12542 | Batch Loss: 1.1455 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11265/12542 | Batch Loss: 1.6733 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11266/12542 | Batch Loss: 0.7821 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11267/12542 | Batch Loss: 1.7547 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11268/12542 | Batch Loss: 1.0624 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11269/12542 | Batch Loss: 1.0162 | Learning Rate: 0.000034 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11270/12542 | Batch Loss: 1.4906 | Learning Rate: 0.000034 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11271/12542 | Batch Loss: 2.1083 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11272/12542 | Batch Loss: 1.2718 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11273/12542 | Batch Loss: 0.9051 | Learning Rate: 0.000034 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11274/12542 | Batch Loss: 1.7284 | Learning Rate: 0.000034 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11275/12542 | Batch Loss: 1.1474 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11276/12542 | Batch Loss: 2.0912 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11277/12542 | Batch Loss: 0.7967 | Learning Rate: 0.000034 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11278/12542 | Batch Loss: 1.4931 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11279/12542 | Batch Loss: 1.6339 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11280/12542 | Batch Loss: 1.2015 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11281/12542 | Batch Loss: 1.3709 | Learning Rate: 0.000034 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11282/12542 | Batch Loss: 1.1234 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11283/12542 | Batch Loss: 1.2199 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11284/12542 | Batch Loss: 1.2137 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11285/12542 | Batch Loss: 0.8185 | Learning Rate: 0.000033 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11286/12542 | Batch Loss: 1.0200 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11287/12542 | Batch Loss: 1.6022 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11288/12542 | Batch Loss: 1.2305 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11289/12542 | Batch Loss: 1.4398 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11290/12542 | Batch Loss: 1.4594 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11291/12542 | Batch Loss: 2.0267 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11292/12542 | Batch Loss: 0.9799 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11293/12542 | Batch Loss: 2.0447 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11294/12542 | Batch Loss: 1.7267 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11295/12542 | Batch Loss: 0.4338 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11296/12542 | Batch Loss: 1.5479 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11297/12542 | Batch Loss: 3.3436 | Learning Rate: 0.000033 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11298/12542 | Batch Loss: 1.7063 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11299/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11300/12542 | Batch Loss: 1.4020 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11301/12542 | Batch Loss: 1.1435 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11302/12542 | Batch Loss: 1.0766 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11303/12542 | Batch Loss: 1.1372 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11304/12542 | Batch Loss: 2.0377 | Learning Rate: 0.000033 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11305/12542 | Batch Loss: 1.3275 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11306/12542 | Batch Loss: 2.1329 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11307/12542 | Batch Loss: 1.0350 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11308/12542 | Batch Loss: 1.1516 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11309/12542 | Batch Loss: 0.9444 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11310/12542 | Batch Loss: 1.9656 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11311/12542 | Batch Loss: 1.8605 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11312/12542 | Batch Loss: 1.0703 | Learning Rate: 0.000033 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11313/12542 | Batch Loss: 1.1424 | Learning Rate: 0.000033 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11314/12542 | Batch Loss: 1.3168 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11315/12542 | Batch Loss: 2.2764 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11316/12542 | Batch Loss: 0.8536 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11317/12542 | Batch Loss: 0.8011 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11318/12542 | Batch Loss: 1.7432 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11319/12542 | Batch Loss: 0.8960 | Learning Rate: 0.000033 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11320/12542 | Batch Loss: 1.3902 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11321/12542 | Batch Loss: 1.1744 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11322/12542 | Batch Loss: 1.0252 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11323/12542 | Batch Loss: 1.6982 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11324/12542 | Batch Loss: 1.5074 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11325/12542 | Batch Loss: 0.6153 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11326/12542 | Batch Loss: 1.6979 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11327/12542 | Batch Loss: 1.2878 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11328/12542 | Batch Loss: 2.2699 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11329/12542 | Batch Loss: 0.6208 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11330/12542 | Batch Loss: 0.8658 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11331/12542 | Batch Loss: 1.0170 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11332/12542 | Batch Loss: 1.3072 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11333/12542 | Batch Loss: 0.8647 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11334/12542 | Batch Loss: 0.4147 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11335/12542 | Batch Loss: 0.6651 | Learning Rate: 0.000032 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11336/12542 | Batch Loss: 1.7943 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11337/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11338/12542 | Batch Loss: 1.4904 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11339/12542 | Batch Loss: 2.3042 | Learning Rate: 0.000032 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11340/12542 | Batch Loss: 2.1662 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11341/12542 | Batch Loss: 1.9014 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11342/12542 | Batch Loss: 0.9731 | Learning Rate: 0.000032 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11343/12542 | Batch Loss: 0.6802 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11344/12542 | Batch Loss: 1.4612 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11345/12542 | Batch Loss: 1.6665 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11346/12542 | Batch Loss: 1.3369 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11347/12542 | Batch Loss: 1.0056 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11348/12542 | Batch Loss: 2.2598 | Learning Rate: 0.000032 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11349/12542 | Batch Loss: 1.2117 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11350/12542 | Batch Loss: 1.1038 | Learning Rate: 0.000032 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11351/12542 | Batch Loss: 3.9381 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11352/12542 | Batch Loss: 1.5070 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11353/12542 | Batch Loss: 0.6776 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11354/12542 | Batch Loss: 1.4794 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11355/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000032 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11356/12542 | Batch Loss: 1.6754 | Learning Rate: 0.000032 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11357/12542 | Batch Loss: 1.5590 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11358/12542 | Batch Loss: 1.1329 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11359/12542 | Batch Loss: 1.4311 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11360/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000031 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11361/12542 | Batch Loss: 1.3315 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11362/12542 | Batch Loss: 1.4331 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11363/12542 | Batch Loss: 1.4751 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11364/12542 | Batch Loss: 0.7569 | Learning Rate: 0.000031 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11365/12542 | Batch Loss: 1.5745 | Learning Rate: 0.000031 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11366/12542 | Batch Loss: 2.8490 | Learning Rate: 0.000031 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 11367/12542 | Batch Loss: 1.5506 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11368/12542 | Batch Loss: 1.2921 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11369/12542 | Batch Loss: 0.8969 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11370/12542 | Batch Loss: 1.5793 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11371/12542 | Batch Loss: 1.0651 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11372/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11373/12542 | Batch Loss: 1.4061 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11374/12542 | Batch Loss: 1.1342 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11375/12542 | Batch Loss: 2.5937 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11376/12542 | Batch Loss: 0.8954 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11377/12542 | Batch Loss: 2.1945 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11378/12542 | Batch Loss: 1.3464 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11379/12542 | Batch Loss: 1.2608 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11380/12542 | Batch Loss: 0.9424 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11381/12542 | Batch Loss: 0.4473 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11382/12542 | Batch Loss: 1.3458 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11383/12542 | Batch Loss: 0.4157 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11384/12542 | Batch Loss: 0.7354 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11385/12542 | Batch Loss: 1.6339 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11386/12542 | Batch Loss: 1.0311 | Learning Rate: 0.000031 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11387/12542 | Batch Loss: 1.3547 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11388/12542 | Batch Loss: 1.7219 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11389/12542 | Batch Loss: 1.0358 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11390/12542 | Batch Loss: 0.9031 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11391/12542 | Batch Loss: 0.5385 | Learning Rate: 0.000031 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11392/12542 | Batch Loss: 0.7225 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11393/12542 | Batch Loss: 2.2405 | Learning Rate: 0.000031 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11394/12542 | Batch Loss: 2.2962 | Learning Rate: 0.000031 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11395/12542 | Batch Loss: 1.2634 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11396/12542 | Batch Loss: 1.7277 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11397/12542 | Batch Loss: 0.7161 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11398/12542 | Batch Loss: 1.4827 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11399/12542 | Batch Loss: 0.9658 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11400/12542 | Batch Loss: 1.3372 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11401/12542 | Batch Loss: 0.8462 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11402/12542 | Batch Loss: 0.6560 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11403/12542 | Batch Loss: 1.8181 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11404/12542 | Batch Loss: 1.1352 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11405/12542 | Batch Loss: 3.5024 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11406/12542 | Batch Loss: 1.4995 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11407/12542 | Batch Loss: 2.3586 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11408/12542 | Batch Loss: 0.4780 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11409/12542 | Batch Loss: 3.4232 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11410/12542 | Batch Loss: 0.7227 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11411/12542 | Batch Loss: 0.7242 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11412/12542 | Batch Loss: 2.0245 | Learning Rate: 0.000030 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11413/12542 | Batch Loss: 3.1265 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11414/12542 | Batch Loss: 0.9481 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11415/12542 | Batch Loss: 0.7795 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11416/12542 | Batch Loss: 1.7137 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11417/12542 | Batch Loss: 1.1950 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11418/12542 | Batch Loss: 1.2457 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11419/12542 | Batch Loss: 3.0833 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11420/12542 | Batch Loss: 1.4352 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11421/12542 | Batch Loss: 1.3504 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11422/12542 | Batch Loss: 1.3435 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11423/12542 | Batch Loss: 0.9203 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11424/12542 | Batch Loss: 0.9219 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11425/12542 | Batch Loss: 0.6021 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11426/12542 | Batch Loss: 1.4855 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11427/12542 | Batch Loss: 1.1083 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11428/12542 | Batch Loss: 0.8258 | Learning Rate: 0.000030 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11429/12542 | Batch Loss: 1.4039 | Learning Rate: 0.000030 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 11430/12542 | Batch Loss: 1.4778 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11431/12542 | Batch Loss: 0.4876 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11432/12542 | Batch Loss: 1.0985 | Learning Rate: 0.000030 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11433/12542 | Batch Loss: 2.3756 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11434/12542 | Batch Loss: 2.0402 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11435/12542 | Batch Loss: 1.2429 | Learning Rate: 0.000029 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11436/12542 | Batch Loss: 0.8303 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11437/12542 | Batch Loss: 2.3596 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11438/12542 | Batch Loss: 1.0454 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11439/12542 | Batch Loss: 1.8222 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11440/12542 | Batch Loss: 0.9239 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11441/12542 | Batch Loss: 1.8933 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11442/12542 | Batch Loss: 3.3584 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11443/12542 | Batch Loss: 1.5855 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11444/12542 | Batch Loss: 1.3828 | Learning Rate: 0.000029 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11445/12542 | Batch Loss: 1.4977 | Learning Rate: 0.000029 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11446/12542 | Batch Loss: 1.7301 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11447/12542 | Batch Loss: 0.8022 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11448/12542 | Batch Loss: 1.5014 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11449/12542 | Batch Loss: 1.4410 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11450/12542 | Batch Loss: 3.2897 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11451/12542 | Batch Loss: 0.8106 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11452/12542 | Batch Loss: 1.1361 | Learning Rate: 0.000029 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11453/12542 | Batch Loss: 1.2745 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11454/12542 | Batch Loss: 1.0499 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11455/12542 | Batch Loss: 1.4783 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11456/12542 | Batch Loss: 1.2500 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11457/12542 | Batch Loss: 1.5923 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11458/12542 | Batch Loss: 1.4788 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11459/12542 | Batch Loss: 1.1319 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11460/12542 | Batch Loss: 0.8678 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11461/12542 | Batch Loss: 1.8382 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11462/12542 | Batch Loss: 1.7318 | Learning Rate: 0.000029 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11463/12542 | Batch Loss: 2.5415 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11464/12542 | Batch Loss: 2.1373 | Learning Rate: 0.000029 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11465/12542 | Batch Loss: 1.6857 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11466/12542 | Batch Loss: 1.9935 | Learning Rate: 0.000029 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11467/12542 | Batch Loss: 2.3347 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11468/12542 | Batch Loss: 1.0736 | Learning Rate: 0.000029 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11469/12542 | Batch Loss: 0.5127 | Learning Rate: 0.000029 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11470/12542 | Batch Loss: 1.7290 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11471/12542 | Batch Loss: 0.7150 | Learning Rate: 0.000028 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11472/12542 | Batch Loss: 0.7347 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11473/12542 | Batch Loss: 2.2228 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11474/12542 | Batch Loss: 1.1381 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11475/12542 | Batch Loss: 1.2194 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11476/12542 | Batch Loss: 1.6092 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11477/12542 | Batch Loss: 0.6095 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11478/12542 | Batch Loss: 1.3704 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11479/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11480/12542 | Batch Loss: 1.2509 | Learning Rate: 0.000028 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11481/12542 | Batch Loss: 0.8022 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11482/12542 | Batch Loss: 1.7618 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11483/12542 | Batch Loss: 1.1214 | Learning Rate: 0.000028 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11484/12542 | Batch Loss: 3.2337 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11485/12542 | Batch Loss: 1.0949 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11486/12542 | Batch Loss: 1.1511 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11487/12542 | Batch Loss: 1.1901 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11488/12542 | Batch Loss: 1.5778 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11489/12542 | Batch Loss: 1.1950 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11490/12542 | Batch Loss: 2.0687 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11491/12542 | Batch Loss: 0.8717 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11492/12542 | Batch Loss: 1.2971 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11493/12542 | Batch Loss: 0.5697 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11494/12542 | Batch Loss: 1.3843 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11495/12542 | Batch Loss: 2.6456 | Learning Rate: 0.000028 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11496/12542 | Batch Loss: 2.6037 | Learning Rate: 0.000028 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11497/12542 | Batch Loss: 2.3010 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11498/12542 | Batch Loss: 0.8637 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11499/12542 | Batch Loss: 0.8850 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11500/12542 | Batch Loss: 1.1263 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11501/12542 | Batch Loss: 1.0253 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11502/12542 | Batch Loss: 2.8433 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11503/12542 | Batch Loss: 0.9857 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11504/12542 | Batch Loss: 0.6485 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11505/12542 | Batch Loss: 0.9241 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11506/12542 | Batch Loss: 0.8079 | Learning Rate: 0.000028 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11507/12542 | Batch Loss: 0.9355 | Learning Rate: 0.000028 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11508/12542 | Batch Loss: 1.0289 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11509/12542 | Batch Loss: 1.4570 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11510/12542 | Batch Loss: 1.5483 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11511/12542 | Batch Loss: 1.1806 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11512/12542 | Batch Loss: 1.1009 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11513/12542 | Batch Loss: 0.7218 | Learning Rate: 0.000027 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11514/12542 | Batch Loss: 0.5800 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11515/12542 | Batch Loss: 1.4646 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11516/12542 | Batch Loss: 1.3915 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11517/12542 | Batch Loss: 0.4118 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11518/12542 | Batch Loss: 1.3985 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11519/12542 | Batch Loss: 1.2625 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11520/12542 | Batch Loss: 0.4948 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11521/12542 | Batch Loss: 2.0039 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11522/12542 | Batch Loss: 2.1006 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11523/12542 | Batch Loss: 1.7190 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11524/12542 | Batch Loss: 0.5260 | Learning Rate: 0.000027 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11525/12542 | Batch Loss: 1.6953 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11526/12542 | Batch Loss: 1.7274 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11527/12542 | Batch Loss: 1.7185 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11528/12542 | Batch Loss: 2.0159 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11529/12542 | Batch Loss: 0.5412 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11530/12542 | Batch Loss: 0.9335 | Learning Rate: 0.000027 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11531/12542 | Batch Loss: 0.5159 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11532/12542 | Batch Loss: 0.8892 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11533/12542 | Batch Loss: 1.0347 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11534/12542 | Batch Loss: 1.6577 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11535/12542 | Batch Loss: 1.0912 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11536/12542 | Batch Loss: 1.9056 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11537/12542 | Batch Loss: 1.1975 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11538/12542 | Batch Loss: 0.5063 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11539/12542 | Batch Loss: 0.9840 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11540/12542 | Batch Loss: 2.0155 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11541/12542 | Batch Loss: 1.8780 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11542/12542 | Batch Loss: 1.1776 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11543/12542 | Batch Loss: 1.4853 | Learning Rate: 0.000027 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11544/12542 | Batch Loss: 1.3574 | Learning Rate: 0.000027 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11545/12542 | Batch Loss: 0.9730 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11546/12542 | Batch Loss: 1.0121 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11547/12542 | Batch Loss: 1.1673 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11548/12542 | Batch Loss: 1.0780 | Learning Rate: 0.000026 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11549/12542 | Batch Loss: 1.2527 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11550/12542 | Batch Loss: 0.5189 | Learning Rate: 0.000026 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11551/12542 | Batch Loss: 0.6483 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11552/12542 | Batch Loss: 0.5470 | Learning Rate: 0.000026 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11553/12542 | Batch Loss: 2.1923 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11554/12542 | Batch Loss: 0.6540 | Learning Rate: 0.000026 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11555/12542 | Batch Loss: 1.8118 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11556/12542 | Batch Loss: 1.5325 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11557/12542 | Batch Loss: 3.0350 | Learning Rate: 0.000026 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11558/12542 | Batch Loss: 0.9166 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11559/12542 | Batch Loss: 1.7129 | Learning Rate: 0.000026 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11560/12542 | Batch Loss: 1.0416 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11561/12542 | Batch Loss: 1.9368 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11562/12542 | Batch Loss: 0.5750 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11563/12542 | Batch Loss: 3.1088 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11564/12542 | Batch Loss: 0.8361 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11565/12542 | Batch Loss: 2.3185 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11566/12542 | Batch Loss: 0.7520 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11567/12542 | Batch Loss: 1.1495 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11568/12542 | Batch Loss: 0.7571 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11569/12542 | Batch Loss: 1.9822 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11570/12542 | Batch Loss: 0.8518 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11571/12542 | Batch Loss: 1.2041 | Learning Rate: 0.000026 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11572/12542 | Batch Loss: 1.7483 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11573/12542 | Batch Loss: 1.0049 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11574/12542 | Batch Loss: 1.7392 | Learning Rate: 0.000026 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11575/12542 | Batch Loss: 1.8469 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11576/12542 | Batch Loss: 1.2599 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11577/12542 | Batch Loss: 1.9362 | Learning Rate: 0.000026 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11578/12542 | Batch Loss: 1.6301 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11579/12542 | Batch Loss: 0.9863 | Learning Rate: 0.000026 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11580/12542 | Batch Loss: 4.5692 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11581/12542 | Batch Loss: 0.7891 | Learning Rate: 0.000026 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11582/12542 | Batch Loss: 0.9739 | Learning Rate: 0.000026 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11583/12542 | Batch Loss: 1.4198 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11584/12542 | Batch Loss: 0.8959 | Learning Rate: 0.000025 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11585/12542 | Batch Loss: 1.3663 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11586/12542 | Batch Loss: 1.3725 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11587/12542 | Batch Loss: 1.9254 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11588/12542 | Batch Loss: 1.0270 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11589/12542 | Batch Loss: 0.7608 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11590/12542 | Batch Loss: 1.6391 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11591/12542 | Batch Loss: 1.4406 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11592/12542 | Batch Loss: 1.3988 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11593/12542 | Batch Loss: 1.2610 | Learning Rate: 0.000025 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11594/12542 | Batch Loss: 0.3975 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11595/12542 | Batch Loss: 1.0060 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11596/12542 | Batch Loss: 0.8308 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11597/12542 | Batch Loss: 1.1192 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11598/12542 | Batch Loss: 2.1287 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11599/12542 | Batch Loss: 0.7254 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11600/12542 | Batch Loss: 1.0653 | Learning Rate: 0.000025 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11601/12542 | Batch Loss: 0.3113 | Learning Rate: 0.000025 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11602/12542 | Batch Loss: 4.1870 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11603/12542 | Batch Loss: 1.9865 | Learning Rate: 0.000025 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11604/12542 | Batch Loss: 0.9298 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11605/12542 | Batch Loss: 0.5919 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11606/12542 | Batch Loss: 1.4376 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11607/12542 | Batch Loss: 0.6887 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11608/12542 | Batch Loss: 0.4895 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11609/12542 | Batch Loss: 1.8788 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11610/12542 | Batch Loss: 0.9652 | Learning Rate: 0.000025 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11611/12542 | Batch Loss: 1.0434 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11612/12542 | Batch Loss: 0.8542 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11613/12542 | Batch Loss: 2.2335 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11614/12542 | Batch Loss: 1.6831 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11615/12542 | Batch Loss: 2.2368 | Learning Rate: 0.000025 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11616/12542 | Batch Loss: 1.2297 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11617/12542 | Batch Loss: 0.7026 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11618/12542 | Batch Loss: 1.7100 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11619/12542 | Batch Loss: 2.2589 | Learning Rate: 0.000025 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11620/12542 | Batch Loss: 1.5740 | Learning Rate: 0.000025 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11621/12542 | Batch Loss: 0.8758 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11622/12542 | Batch Loss: 1.0401 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11623/12542 | Batch Loss: 2.6781 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11624/12542 | Batch Loss: 1.7832 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11625/12542 | Batch Loss: 0.6517 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11626/12542 | Batch Loss: 1.1827 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11627/12542 | Batch Loss: 0.9394 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11628/12542 | Batch Loss: 1.4905 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11629/12542 | Batch Loss: 1.0824 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11630/12542 | Batch Loss: 1.7400 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11631/12542 | Batch Loss: 0.7354 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11632/12542 | Batch Loss: 1.7035 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11633/12542 | Batch Loss: 1.2442 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11634/12542 | Batch Loss: 0.7608 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11635/12542 | Batch Loss: 0.8570 | Learning Rate: 0.000024 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11636/12542 | Batch Loss: 2.1899 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11637/12542 | Batch Loss: 2.0014 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11638/12542 | Batch Loss: 1.4340 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11639/12542 | Batch Loss: 0.8978 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11640/12542 | Batch Loss: 1.1822 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11641/12542 | Batch Loss: 2.1684 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11642/12542 | Batch Loss: 1.1683 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11643/12542 | Batch Loss: 1.9388 | Learning Rate: 0.000024 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11644/12542 | Batch Loss: 0.8825 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11645/12542 | Batch Loss: 2.3040 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11646/12542 | Batch Loss: 1.6235 | Learning Rate: 0.000024 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11647/12542 | Batch Loss: 1.0115 | Learning Rate: 0.000024 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11648/12542 | Batch Loss: 0.9717 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11649/12542 | Batch Loss: 3.3696 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11650/12542 | Batch Loss: 0.9347 | Learning Rate: 0.000024 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11651/12542 | Batch Loss: 1.3233 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11652/12542 | Batch Loss: 1.4427 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11653/12542 | Batch Loss: 1.8141 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11654/12542 | Batch Loss: 1.3713 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11655/12542 | Batch Loss: 0.8469 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11656/12542 | Batch Loss: 1.1765 | Learning Rate: 0.000024 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11657/12542 | Batch Loss: 1.0288 | Learning Rate: 0.000024 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11658/12542 | Batch Loss: 1.2901 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11659/12542 | Batch Loss: 1.0303 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11660/12542 | Batch Loss: 3.2158 | Learning Rate: 0.000023 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11661/12542 | Batch Loss: 2.4169 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11662/12542 | Batch Loss: 1.8208 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11663/12542 | Batch Loss: 0.7903 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11664/12542 | Batch Loss: 1.2084 | Learning Rate: 0.000023 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11665/12542 | Batch Loss: 0.8596 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11666/12542 | Batch Loss: 2.4353 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11667/12542 | Batch Loss: 1.7433 | Learning Rate: 0.000023 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11668/12542 | Batch Loss: 0.5841 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11669/12542 | Batch Loss: 0.8802 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11670/12542 | Batch Loss: 1.6729 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11671/12542 | Batch Loss: 0.7804 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11672/12542 | Batch Loss: 0.9577 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11673/12542 | Batch Loss: 1.0612 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11674/12542 | Batch Loss: 1.0765 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11675/12542 | Batch Loss: 1.0022 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11676/12542 | Batch Loss: 1.7558 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11677/12542 | Batch Loss: 0.8683 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11678/12542 | Batch Loss: 1.7465 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11679/12542 | Batch Loss: 1.1746 | Learning Rate: 0.000023 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11680/12542 | Batch Loss: 3.5992 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11681/12542 | Batch Loss: 1.6849 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11682/12542 | Batch Loss: 1.4930 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11683/12542 | Batch Loss: 0.9507 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11684/12542 | Batch Loss: 0.6678 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11685/12542 | Batch Loss: 0.8342 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11686/12542 | Batch Loss: 0.7067 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11687/12542 | Batch Loss: 1.2718 | Learning Rate: 0.000023 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11688/12542 | Batch Loss: 0.7449 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11689/12542 | Batch Loss: 1.0313 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11690/12542 | Batch Loss: 1.6795 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11691/12542 | Batch Loss: 1.5316 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11692/12542 | Batch Loss: 1.1471 | Learning Rate: 0.000023 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11693/12542 | Batch Loss: 1.0761 | Learning Rate: 0.000023 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11694/12542 | Batch Loss: 1.8681 | Learning Rate: 0.000023 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11695/12542 | Batch Loss: 1.4877 | Learning Rate: 0.000023 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11696/12542 | Batch Loss: 2.4820 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11697/12542 | Batch Loss: 1.4444 | Learning Rate: 0.000022 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11698/12542 | Batch Loss: 0.6002 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11699/12542 | Batch Loss: 0.5553 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11700/12542 | Batch Loss: 1.3930 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11701/12542 | Batch Loss: 1.2410 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11702/12542 | Batch Loss: 0.7051 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11703/12542 | Batch Loss: 0.7518 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11704/12542 | Batch Loss: 0.5853 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11705/12542 | Batch Loss: 1.5117 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11706/12542 | Batch Loss: 2.1265 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11707/12542 | Batch Loss: 2.0125 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11708/12542 | Batch Loss: 2.6491 | Learning Rate: 0.000022 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11709/12542 | Batch Loss: 0.9586 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11710/12542 | Batch Loss: 0.8059 | Learning Rate: 0.000022 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11711/12542 | Batch Loss: 0.5219 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11712/12542 | Batch Loss: 0.6155 | Learning Rate: 0.000022 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11713/12542 | Batch Loss: 0.8372 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11714/12542 | Batch Loss: 0.9362 | Learning Rate: 0.000022 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11715/12542 | Batch Loss: 0.9621 | Learning Rate: 0.000022 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11716/12542 | Batch Loss: 1.6097 | Learning Rate: 0.000022 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11717/12542 | Batch Loss: 1.1094 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11718/12542 | Batch Loss: 1.0440 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11719/12542 | Batch Loss: 1.8380 | Learning Rate: 0.000022 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11720/12542 | Batch Loss: 0.9197 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11721/12542 | Batch Loss: 1.5493 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11722/12542 | Batch Loss: 1.4563 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11723/12542 | Batch Loss: 0.9627 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11724/12542 | Batch Loss: 1.2323 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11725/12542 | Batch Loss: 1.1584 | Learning Rate: 0.000022 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11726/12542 | Batch Loss: 0.8348 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11727/12542 | Batch Loss: 1.8742 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11728/12542 | Batch Loss: 1.9311 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11729/12542 | Batch Loss: 1.8162 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11730/12542 | Batch Loss: 1.8937 | Learning Rate: 0.000022 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11731/12542 | Batch Loss: 2.4126 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11732/12542 | Batch Loss: 2.5596 | Learning Rate: 0.000022 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11733/12542 | Batch Loss: 1.0626 | Learning Rate: 0.000022 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11734/12542 | Batch Loss: 1.3647 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11735/12542 | Batch Loss: 1.4706 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11736/12542 | Batch Loss: 1.2622 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11737/12542 | Batch Loss: 1.0091 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11738/12542 | Batch Loss: 2.8664 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11739/12542 | Batch Loss: 1.7481 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11740/12542 | Batch Loss: 1.7872 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11741/12542 | Batch Loss: 0.7833 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11742/12542 | Batch Loss: 0.9106 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11743/12542 | Batch Loss: 1.0080 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11744/12542 | Batch Loss: 2.1594 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11745/12542 | Batch Loss: 1.6910 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11746/12542 | Batch Loss: 0.8049 | Learning Rate: 0.000021 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11747/12542 | Batch Loss: 1.5908 | Learning Rate: 0.000021 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11748/12542 | Batch Loss: 1.4136 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11749/12542 | Batch Loss: 0.9364 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11750/12542 | Batch Loss: 0.8349 | Learning Rate: 0.000021 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 11751/12542 | Batch Loss: 0.8443 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11752/12542 | Batch Loss: 1.9800 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11753/12542 | Batch Loss: 2.6925 | Learning Rate: 0.000021 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11754/12542 | Batch Loss: 2.2905 | Learning Rate: 0.000021 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11755/12542 | Batch Loss: 1.2932 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11756/12542 | Batch Loss: 1.1260 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11757/12542 | Batch Loss: 1.5189 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11758/12542 | Batch Loss: 1.6426 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11759/12542 | Batch Loss: 1.0966 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11760/12542 | Batch Loss: 0.9546 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11761/12542 | Batch Loss: 1.7663 | Learning Rate: 0.000021 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11762/12542 | Batch Loss: 1.0299 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11763/12542 | Batch Loss: 2.2999 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11764/12542 | Batch Loss: 1.6793 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11765/12542 | Batch Loss: 0.8690 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11766/12542 | Batch Loss: 1.2326 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11767/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000021 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11768/12542 | Batch Loss: 0.6556 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11769/12542 | Batch Loss: 0.8989 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11770/12542 | Batch Loss: 0.6045 | Learning Rate: 0.000021 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11771/12542 | Batch Loss: 0.7973 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11772/12542 | Batch Loss: 2.5825 | Learning Rate: 0.000020 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11773/12542 | Batch Loss: 1.2720 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11774/12542 | Batch Loss: 1.0069 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11775/12542 | Batch Loss: 0.8804 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11776/12542 | Batch Loss: 0.7383 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11777/12542 | Batch Loss: 0.8803 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11778/12542 | Batch Loss: 1.4249 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11779/12542 | Batch Loss: 0.9898 | Learning Rate: 0.000020 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11780/12542 | Batch Loss: 1.3193 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11781/12542 | Batch Loss: 0.9652 | Learning Rate: 0.000020 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11782/12542 | Batch Loss: 2.0978 | Learning Rate: 0.000020 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11783/12542 | Batch Loss: 1.3434 | Learning Rate: 0.000020 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11784/12542 | Batch Loss: 0.7811 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11785/12542 | Batch Loss: 1.5143 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11786/12542 | Batch Loss: 1.1105 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11787/12542 | Batch Loss: 2.0817 | Learning Rate: 0.000020 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11788/12542 | Batch Loss: 1.0413 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11789/12542 | Batch Loss: 0.6806 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11790/12542 | Batch Loss: 1.5913 | Learning Rate: 0.000020 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11791/12542 | Batch Loss: 0.7906 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11792/12542 | Batch Loss: 2.5949 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11793/12542 | Batch Loss: 0.8559 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11794/12542 | Batch Loss: 1.2366 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11795/12542 | Batch Loss: 0.9414 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11796/12542 | Batch Loss: 1.2093 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11797/12542 | Batch Loss: 1.0577 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11798/12542 | Batch Loss: 1.1472 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11799/12542 | Batch Loss: 0.9821 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11800/12542 | Batch Loss: 0.4738 | Learning Rate: 0.000020 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11801/12542 | Batch Loss: 1.5015 | Learning Rate: 0.000020 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11802/12542 | Batch Loss: 0.5626 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11803/12542 | Batch Loss: 0.9221 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11804/12542 | Batch Loss: 0.5533 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11805/12542 | Batch Loss: 1.5411 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11806/12542 | Batch Loss: 2.6573 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11807/12542 | Batch Loss: 0.8039 | Learning Rate: 0.000020 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11808/12542 | Batch Loss: 0.7463 | Learning Rate: 0.000020 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11809/12542 | Batch Loss: 2.3959 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11810/12542 | Batch Loss: 0.7373 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11811/12542 | Batch Loss: 1.4254 | Learning Rate: 0.000019 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11812/12542 | Batch Loss: 0.5812 | Learning Rate: 0.000019 | Batch Time: 0.55s\n",
      "Epoch 3 | Step 11813/12542 | Batch Loss: 2.2754 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11814/12542 | Batch Loss: 0.8218 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11815/12542 | Batch Loss: 0.4840 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11816/12542 | Batch Loss: 0.6244 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11817/12542 | Batch Loss: 1.4274 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11818/12542 | Batch Loss: 1.5765 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11819/12542 | Batch Loss: 0.9178 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11820/12542 | Batch Loss: 0.5637 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11821/12542 | Batch Loss: 1.6255 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11822/12542 | Batch Loss: 0.8773 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11823/12542 | Batch Loss: 1.4814 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11824/12542 | Batch Loss: 1.9382 | Learning Rate: 0.000019 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11825/12542 | Batch Loss: 0.9142 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11826/12542 | Batch Loss: 1.6582 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11827/12542 | Batch Loss: 0.5767 | Learning Rate: 0.000019 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11828/12542 | Batch Loss: 0.9361 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11829/12542 | Batch Loss: 1.0263 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11830/12542 | Batch Loss: 0.8985 | Learning Rate: 0.000019 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11831/12542 | Batch Loss: 1.6920 | Learning Rate: 0.000019 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11832/12542 | Batch Loss: 1.1196 | Learning Rate: 0.000019 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11833/12542 | Batch Loss: 1.3506 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11834/12542 | Batch Loss: 1.1255 | Learning Rate: 0.000019 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11835/12542 | Batch Loss: 0.7357 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11836/12542 | Batch Loss: 1.0640 | Learning Rate: 0.000019 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11837/12542 | Batch Loss: 2.0200 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11838/12542 | Batch Loss: 0.2270 | Learning Rate: 0.000019 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11839/12542 | Batch Loss: 0.8829 | Learning Rate: 0.000019 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11840/12542 | Batch Loss: 2.0748 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11841/12542 | Batch Loss: 0.9305 | Learning Rate: 0.000019 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11842/12542 | Batch Loss: 1.5211 | Learning Rate: 0.000019 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11843/12542 | Batch Loss: 1.0973 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11844/12542 | Batch Loss: 0.5161 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11845/12542 | Batch Loss: 1.3849 | Learning Rate: 0.000019 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11846/12542 | Batch Loss: 2.1905 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11847/12542 | Batch Loss: 0.9459 | Learning Rate: 0.000018 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11848/12542 | Batch Loss: 2.0721 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11849/12542 | Batch Loss: 1.8634 | Learning Rate: 0.000018 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11850/12542 | Batch Loss: 1.5287 | Learning Rate: 0.000018 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 11851/12542 | Batch Loss: 0.8762 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11852/12542 | Batch Loss: 1.9888 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11853/12542 | Batch Loss: 1.2017 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11854/12542 | Batch Loss: 1.4753 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11855/12542 | Batch Loss: 2.4119 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11856/12542 | Batch Loss: 2.4345 | Learning Rate: 0.000018 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11857/12542 | Batch Loss: 0.9217 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11858/12542 | Batch Loss: 2.7672 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11859/12542 | Batch Loss: 1.7882 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11860/12542 | Batch Loss: 1.0408 | Learning Rate: 0.000018 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11861/12542 | Batch Loss: 1.8309 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11862/12542 | Batch Loss: 1.1140 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11863/12542 | Batch Loss: 0.6307 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11864/12542 | Batch Loss: 1.5207 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11865/12542 | Batch Loss: 1.1919 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11866/12542 | Batch Loss: 0.6446 | Learning Rate: 0.000018 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11867/12542 | Batch Loss: 0.8248 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11868/12542 | Batch Loss: 1.6744 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11869/12542 | Batch Loss: 2.7468 | Learning Rate: 0.000018 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11870/12542 | Batch Loss: 0.8004 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11871/12542 | Batch Loss: 0.6555 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11872/12542 | Batch Loss: 0.8137 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11873/12542 | Batch Loss: 0.7094 | Learning Rate: 0.000018 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11874/12542 | Batch Loss: 1.0146 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11875/12542 | Batch Loss: 0.7118 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11876/12542 | Batch Loss: 1.7659 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11877/12542 | Batch Loss: 1.3440 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11878/12542 | Batch Loss: 1.6104 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11879/12542 | Batch Loss: 1.0352 | Learning Rate: 0.000018 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 11880/12542 | Batch Loss: 1.2846 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11881/12542 | Batch Loss: 1.1523 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11882/12542 | Batch Loss: 1.4749 | Learning Rate: 0.000018 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11883/12542 | Batch Loss: 1.8263 | Learning Rate: 0.000018 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11884/12542 | Batch Loss: 3.4211 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11885/12542 | Batch Loss: 0.9232 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11886/12542 | Batch Loss: 1.4085 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11887/12542 | Batch Loss: 0.9830 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11888/12542 | Batch Loss: 0.6565 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11889/12542 | Batch Loss: 1.9597 | Learning Rate: 0.000017 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11890/12542 | Batch Loss: 1.4980 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11891/12542 | Batch Loss: 3.0651 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11892/12542 | Batch Loss: 1.1029 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11893/12542 | Batch Loss: 1.2671 | Learning Rate: 0.000017 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11894/12542 | Batch Loss: 1.3606 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11895/12542 | Batch Loss: 1.5738 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11896/12542 | Batch Loss: 0.6483 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11897/12542 | Batch Loss: 1.3599 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11898/12542 | Batch Loss: 0.6771 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11899/12542 | Batch Loss: 1.6011 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11900/12542 | Batch Loss: 1.5963 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11901/12542 | Batch Loss: 0.6019 | Learning Rate: 0.000017 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11902/12542 | Batch Loss: 0.7340 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11903/12542 | Batch Loss: 1.2960 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11904/12542 | Batch Loss: 0.8486 | Learning Rate: 0.000017 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11905/12542 | Batch Loss: 0.9644 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11906/12542 | Batch Loss: 1.6543 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11907/12542 | Batch Loss: 0.9047 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11908/12542 | Batch Loss: 0.9137 | Learning Rate: 0.000017 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11909/12542 | Batch Loss: 3.2626 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11910/12542 | Batch Loss: 1.1062 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11911/12542 | Batch Loss: 1.1101 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11912/12542 | Batch Loss: 1.7641 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11913/12542 | Batch Loss: 1.3259 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11914/12542 | Batch Loss: 1.0520 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11915/12542 | Batch Loss: 0.4401 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11916/12542 | Batch Loss: 1.2818 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11917/12542 | Batch Loss: 1.0404 | Learning Rate: 0.000017 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11918/12542 | Batch Loss: 0.5334 | Learning Rate: 0.000017 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11919/12542 | Batch Loss: 1.0485 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11920/12542 | Batch Loss: 0.8616 | Learning Rate: 0.000017 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11921/12542 | Batch Loss: 1.3907 | Learning Rate: 0.000017 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11922/12542 | Batch Loss: 2.3623 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11923/12542 | Batch Loss: 3.3738 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11924/12542 | Batch Loss: 1.9026 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11925/12542 | Batch Loss: 1.5196 | Learning Rate: 0.000016 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11926/12542 | Batch Loss: 1.0733 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11927/12542 | Batch Loss: 0.6323 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11928/12542 | Batch Loss: 2.5312 | Learning Rate: 0.000016 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11929/12542 | Batch Loss: 1.7984 | Learning Rate: 0.000016 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11930/12542 | Batch Loss: 1.1777 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11931/12542 | Batch Loss: 0.6229 | Learning Rate: 0.000016 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11932/12542 | Batch Loss: 0.5252 | Learning Rate: 0.000016 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 11933/12542 | Batch Loss: 0.9022 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11934/12542 | Batch Loss: 1.8545 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11935/12542 | Batch Loss: 1.1240 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11936/12542 | Batch Loss: 1.5127 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11937/12542 | Batch Loss: 1.4665 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11938/12542 | Batch Loss: 1.1186 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11939/12542 | Batch Loss: 0.7597 | Learning Rate: 0.000016 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11940/12542 | Batch Loss: 1.1355 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11941/12542 | Batch Loss: 1.4765 | Learning Rate: 0.000016 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11942/12542 | Batch Loss: 1.5220 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11943/12542 | Batch Loss: 1.1766 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11944/12542 | Batch Loss: 1.2632 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11945/12542 | Batch Loss: 0.6432 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11946/12542 | Batch Loss: 1.3634 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11947/12542 | Batch Loss: 1.7000 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11948/12542 | Batch Loss: 2.0244 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11949/12542 | Batch Loss: 1.8876 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11950/12542 | Batch Loss: 1.4409 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11951/12542 | Batch Loss: 1.4439 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11952/12542 | Batch Loss: 0.7079 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11953/12542 | Batch Loss: 1.8413 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11954/12542 | Batch Loss: 1.4676 | Learning Rate: 0.000016 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11955/12542 | Batch Loss: 1.4604 | Learning Rate: 0.000016 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11956/12542 | Batch Loss: 1.1387 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11957/12542 | Batch Loss: 1.1658 | Learning Rate: 0.000016 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11958/12542 | Batch Loss: 1.2382 | Learning Rate: 0.000016 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11959/12542 | Batch Loss: 1.0983 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11960/12542 | Batch Loss: 0.5898 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11961/12542 | Batch Loss: 1.3235 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11962/12542 | Batch Loss: 1.5984 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11963/12542 | Batch Loss: 1.5324 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11964/12542 | Batch Loss: 1.4824 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11965/12542 | Batch Loss: 1.1301 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11966/12542 | Batch Loss: 0.6001 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11967/12542 | Batch Loss: 1.1880 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11968/12542 | Batch Loss: 2.5514 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11969/12542 | Batch Loss: 1.4952 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11970/12542 | Batch Loss: 2.3351 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11971/12542 | Batch Loss: 1.7998 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11972/12542 | Batch Loss: 1.5487 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11973/12542 | Batch Loss: 0.8779 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11974/12542 | Batch Loss: 1.2356 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11975/12542 | Batch Loss: 1.4945 | Learning Rate: 0.000015 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 11976/12542 | Batch Loss: 1.3089 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11977/12542 | Batch Loss: 0.3433 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11978/12542 | Batch Loss: 0.4778 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11979/12542 | Batch Loss: 2.1138 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11980/12542 | Batch Loss: 0.7701 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11981/12542 | Batch Loss: 1.3842 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11982/12542 | Batch Loss: 1.6566 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11983/12542 | Batch Loss: 0.9642 | Learning Rate: 0.000015 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11984/12542 | Batch Loss: 0.9593 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11985/12542 | Batch Loss: 2.3134 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11986/12542 | Batch Loss: 1.0590 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11987/12542 | Batch Loss: 1.1736 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11988/12542 | Batch Loss: 0.5335 | Learning Rate: 0.000015 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 11989/12542 | Batch Loss: 0.6749 | Learning Rate: 0.000015 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 11990/12542 | Batch Loss: 1.0591 | Learning Rate: 0.000015 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 11991/12542 | Batch Loss: 0.9135 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11992/12542 | Batch Loss: 0.5127 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11993/12542 | Batch Loss: 1.1270 | Learning Rate: 0.000015 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11994/12542 | Batch Loss: 2.6594 | Learning Rate: 0.000015 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11995/12542 | Batch Loss: 1.3152 | Learning Rate: 0.000015 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 11996/12542 | Batch Loss: 1.0563 | Learning Rate: 0.000015 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 11997/12542 | Batch Loss: 0.5766 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11998/12542 | Batch Loss: 2.6050 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 11999/12542 | Batch Loss: 1.3923 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12000/12542 | Batch Loss: 3.5152 | Learning Rate: 0.000014 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12001/12542 | Batch Loss: 1.3810 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12002/12542 | Batch Loss: 1.3971 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12003/12542 | Batch Loss: 1.6349 | Learning Rate: 0.000014 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12004/12542 | Batch Loss: 0.9753 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12005/12542 | Batch Loss: 0.7465 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12006/12542 | Batch Loss: 1.3697 | Learning Rate: 0.000014 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12007/12542 | Batch Loss: 0.2911 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12008/12542 | Batch Loss: 0.8635 | Learning Rate: 0.000014 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12009/12542 | Batch Loss: 1.1402 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12010/12542 | Batch Loss: 2.0990 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12011/12542 | Batch Loss: 0.6205 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12012/12542 | Batch Loss: 0.7749 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12013/12542 | Batch Loss: 0.5556 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12014/12542 | Batch Loss: 2.1703 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12015/12542 | Batch Loss: 2.4025 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12016/12542 | Batch Loss: 0.7141 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12017/12542 | Batch Loss: 0.9307 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12018/12542 | Batch Loss: 1.1335 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12019/12542 | Batch Loss: 1.8269 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12020/12542 | Batch Loss: 0.9238 | Learning Rate: 0.000014 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 12021/12542 | Batch Loss: 2.1220 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12022/12542 | Batch Loss: 0.5138 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12023/12542 | Batch Loss: 1.5866 | Learning Rate: 0.000014 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12024/12542 | Batch Loss: 0.8542 | Learning Rate: 0.000014 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12025/12542 | Batch Loss: 0.9816 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12026/12542 | Batch Loss: 0.5821 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12027/12542 | Batch Loss: 0.6217 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12028/12542 | Batch Loss: 0.5754 | Learning Rate: 0.000014 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12029/12542 | Batch Loss: 1.3526 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12030/12542 | Batch Loss: 0.7273 | Learning Rate: 0.000014 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12031/12542 | Batch Loss: 3.1113 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12032/12542 | Batch Loss: 1.6414 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12033/12542 | Batch Loss: 0.5049 | Learning Rate: 0.000014 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12034/12542 | Batch Loss: 1.0645 | Learning Rate: 0.000014 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12035/12542 | Batch Loss: 1.3604 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12036/12542 | Batch Loss: 1.8256 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12037/12542 | Batch Loss: 1.3520 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12038/12542 | Batch Loss: 1.5676 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12039/12542 | Batch Loss: 2.0950 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12040/12542 | Batch Loss: 0.8539 | Learning Rate: 0.000013 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12041/12542 | Batch Loss: 2.2382 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12042/12542 | Batch Loss: 1.9552 | Learning Rate: 0.000013 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12043/12542 | Batch Loss: 1.4992 | Learning Rate: 0.000013 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12044/12542 | Batch Loss: 0.9560 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12045/12542 | Batch Loss: 0.7244 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12046/12542 | Batch Loss: 1.4745 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12047/12542 | Batch Loss: 1.8627 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12048/12542 | Batch Loss: 0.5602 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12049/12542 | Batch Loss: 1.4057 | Learning Rate: 0.000013 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12050/12542 | Batch Loss: 0.5977 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12051/12542 | Batch Loss: 1.2244 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12052/12542 | Batch Loss: 1.6684 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12053/12542 | Batch Loss: 0.9768 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12054/12542 | Batch Loss: 0.8644 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12055/12542 | Batch Loss: 1.4045 | Learning Rate: 0.000013 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12056/12542 | Batch Loss: 1.4858 | Learning Rate: 0.000013 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12057/12542 | Batch Loss: 1.2221 | Learning Rate: 0.000013 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12058/12542 | Batch Loss: 1.6830 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12059/12542 | Batch Loss: 1.0060 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12060/12542 | Batch Loss: 1.3934 | Learning Rate: 0.000013 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12061/12542 | Batch Loss: 0.8174 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12062/12542 | Batch Loss: 0.9325 | Learning Rate: 0.000013 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12063/12542 | Batch Loss: 0.9638 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12064/12542 | Batch Loss: 1.1940 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12065/12542 | Batch Loss: 1.7449 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12066/12542 | Batch Loss: 1.0982 | Learning Rate: 0.000013 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12067/12542 | Batch Loss: 1.5415 | Learning Rate: 0.000013 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12068/12542 | Batch Loss: 2.6995 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12069/12542 | Batch Loss: 1.3406 | Learning Rate: 0.000013 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12070/12542 | Batch Loss: 0.9392 | Learning Rate: 0.000013 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12071/12542 | Batch Loss: 0.9335 | Learning Rate: 0.000013 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12072/12542 | Batch Loss: 0.7416 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12073/12542 | Batch Loss: 1.5063 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12074/12542 | Batch Loss: 1.1347 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12075/12542 | Batch Loss: 1.2046 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12076/12542 | Batch Loss: 1.5501 | Learning Rate: 0.000012 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12077/12542 | Batch Loss: 0.4520 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12078/12542 | Batch Loss: 0.9091 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12079/12542 | Batch Loss: 1.4457 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12080/12542 | Batch Loss: 1.3037 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12081/12542 | Batch Loss: 2.2169 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12082/12542 | Batch Loss: 1.0096 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12083/12542 | Batch Loss: 1.4814 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12084/12542 | Batch Loss: 1.7057 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12085/12542 | Batch Loss: 2.8301 | Learning Rate: 0.000012 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12086/12542 | Batch Loss: 1.5779 | Learning Rate: 0.000012 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12087/12542 | Batch Loss: 3.3545 | Learning Rate: 0.000012 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 12088/12542 | Batch Loss: 1.0864 | Learning Rate: 0.000012 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12089/12542 | Batch Loss: 1.4028 | Learning Rate: 0.000012 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12090/12542 | Batch Loss: 1.0204 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12091/12542 | Batch Loss: 1.2636 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12092/12542 | Batch Loss: 2.0323 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12093/12542 | Batch Loss: 0.9225 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12094/12542 | Batch Loss: 0.5449 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12095/12542 | Batch Loss: 3.0578 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12096/12542 | Batch Loss: 1.6745 | Learning Rate: 0.000012 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12097/12542 | Batch Loss: 1.7025 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12098/12542 | Batch Loss: 1.9003 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12099/12542 | Batch Loss: 0.9337 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12100/12542 | Batch Loss: 2.0736 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12101/12542 | Batch Loss: 2.1570 | Learning Rate: 0.000012 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12102/12542 | Batch Loss: 1.4380 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12103/12542 | Batch Loss: 0.9087 | Learning Rate: 0.000012 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12104/12542 | Batch Loss: 1.7114 | Learning Rate: 0.000012 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12105/12542 | Batch Loss: 1.7181 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12106/12542 | Batch Loss: 1.0683 | Learning Rate: 0.000012 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12107/12542 | Batch Loss: 0.9573 | Learning Rate: 0.000012 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12108/12542 | Batch Loss: 1.0739 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12109/12542 | Batch Loss: 1.3661 | Learning Rate: 0.000012 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12110/12542 | Batch Loss: 2.0179 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12111/12542 | Batch Loss: 1.1465 | Learning Rate: 0.000011 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12112/12542 | Batch Loss: 0.7318 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12113/12542 | Batch Loss: 1.4906 | Learning Rate: 0.000011 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 12114/12542 | Batch Loss: 1.0764 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12115/12542 | Batch Loss: 0.6341 | Learning Rate: 0.000011 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12116/12542 | Batch Loss: 1.7673 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12117/12542 | Batch Loss: 1.6426 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12118/12542 | Batch Loss: 2.0007 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12119/12542 | Batch Loss: 1.0417 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12120/12542 | Batch Loss: 2.0837 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12121/12542 | Batch Loss: 2.0035 | Learning Rate: 0.000011 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12122/12542 | Batch Loss: 1.8918 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12123/12542 | Batch Loss: 1.5377 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12124/12542 | Batch Loss: 2.2123 | Learning Rate: 0.000011 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 12125/12542 | Batch Loss: 1.1812 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12126/12542 | Batch Loss: 3.1665 | Learning Rate: 0.000011 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12127/12542 | Batch Loss: 1.5486 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12128/12542 | Batch Loss: 0.8345 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12129/12542 | Batch Loss: 2.3199 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12130/12542 | Batch Loss: 1.4686 | Learning Rate: 0.000011 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12131/12542 | Batch Loss: 1.0181 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12132/12542 | Batch Loss: 0.7206 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12133/12542 | Batch Loss: 1.7729 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12134/12542 | Batch Loss: 0.8148 | Learning Rate: 0.000011 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12135/12542 | Batch Loss: 1.7100 | Learning Rate: 0.000011 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12136/12542 | Batch Loss: 0.9611 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12137/12542 | Batch Loss: 1.9915 | Learning Rate: 0.000011 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 12138/12542 | Batch Loss: 1.4404 | Learning Rate: 0.000011 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12139/12542 | Batch Loss: 1.4767 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12140/12542 | Batch Loss: 0.9595 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12141/12542 | Batch Loss: 1.6795 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12142/12542 | Batch Loss: 2.9305 | Learning Rate: 0.000011 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12143/12542 | Batch Loss: 0.5001 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12144/12542 | Batch Loss: 1.3864 | Learning Rate: 0.000011 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12145/12542 | Batch Loss: 1.4681 | Learning Rate: 0.000011 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12146/12542 | Batch Loss: 0.5800 | Learning Rate: 0.000011 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12147/12542 | Batch Loss: 1.0200 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12148/12542 | Batch Loss: 1.4563 | Learning Rate: 0.000010 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12149/12542 | Batch Loss: 0.8399 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12150/12542 | Batch Loss: 0.8431 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12151/12542 | Batch Loss: 2.0649 | Learning Rate: 0.000010 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12152/12542 | Batch Loss: 2.5362 | Learning Rate: 0.000010 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12153/12542 | Batch Loss: 1.2785 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12154/12542 | Batch Loss: 1.2037 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12155/12542 | Batch Loss: 1.1417 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12156/12542 | Batch Loss: 0.7664 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12157/12542 | Batch Loss: 0.9649 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12158/12542 | Batch Loss: 2.3708 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12159/12542 | Batch Loss: 1.3708 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12160/12542 | Batch Loss: 1.1745 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12161/12542 | Batch Loss: 0.6691 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12162/12542 | Batch Loss: 1.1571 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12163/12542 | Batch Loss: 0.9618 | Learning Rate: 0.000010 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12164/12542 | Batch Loss: 0.5904 | Learning Rate: 0.000010 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12165/12542 | Batch Loss: 2.5981 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12166/12542 | Batch Loss: 1.3504 | Learning Rate: 0.000010 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 12167/12542 | Batch Loss: 0.8124 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12168/12542 | Batch Loss: 1.4585 | Learning Rate: 0.000010 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12169/12542 | Batch Loss: 1.1807 | Learning Rate: 0.000010 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12170/12542 | Batch Loss: 1.8867 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12171/12542 | Batch Loss: 1.2518 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12172/12542 | Batch Loss: 0.9531 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12173/12542 | Batch Loss: 1.2968 | Learning Rate: 0.000010 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12174/12542 | Batch Loss: 1.1677 | Learning Rate: 0.000010 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12175/12542 | Batch Loss: 0.3896 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12176/12542 | Batch Loss: 1.7765 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12177/12542 | Batch Loss: 1.7115 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12178/12542 | Batch Loss: 1.0028 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12179/12542 | Batch Loss: 1.5976 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12180/12542 | Batch Loss: 1.8824 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12181/12542 | Batch Loss: 1.4009 | Learning Rate: 0.000010 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12182/12542 | Batch Loss: 1.2226 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12183/12542 | Batch Loss: 0.8390 | Learning Rate: 0.000010 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12184/12542 | Batch Loss: 1.4831 | Learning Rate: 0.000010 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12185/12542 | Batch Loss: 2.3572 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12186/12542 | Batch Loss: 1.3719 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12187/12542 | Batch Loss: 2.4234 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12188/12542 | Batch Loss: 1.0024 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12189/12542 | Batch Loss: 1.3109 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12190/12542 | Batch Loss: 1.7341 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12191/12542 | Batch Loss: 1.9318 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12192/12542 | Batch Loss: 2.2182 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12193/12542 | Batch Loss: 1.3487 | Learning Rate: 0.000009 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12194/12542 | Batch Loss: 2.6939 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12195/12542 | Batch Loss: 1.2928 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12196/12542 | Batch Loss: 1.7684 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12197/12542 | Batch Loss: 1.0333 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12198/12542 | Batch Loss: 1.3204 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12199/12542 | Batch Loss: 1.1164 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12200/12542 | Batch Loss: 1.7780 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12201/12542 | Batch Loss: 0.7911 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12202/12542 | Batch Loss: 1.9390 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12203/12542 | Batch Loss: 1.7638 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12204/12542 | Batch Loss: 1.0439 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12205/12542 | Batch Loss: 0.5816 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12206/12542 | Batch Loss: 1.4417 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12207/12542 | Batch Loss: 0.4145 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12208/12542 | Batch Loss: 2.4891 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12209/12542 | Batch Loss: 0.8130 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12210/12542 | Batch Loss: 1.1602 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12211/12542 | Batch Loss: 0.9494 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12212/12542 | Batch Loss: 3.2862 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12213/12542 | Batch Loss: 0.9322 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12214/12542 | Batch Loss: 0.9226 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12215/12542 | Batch Loss: 2.3029 | Learning Rate: 0.000009 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12216/12542 | Batch Loss: 1.9568 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12217/12542 | Batch Loss: 0.9579 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12218/12542 | Batch Loss: 1.7376 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12219/12542 | Batch Loss: 1.6612 | Learning Rate: 0.000009 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12220/12542 | Batch Loss: 1.7565 | Learning Rate: 0.000009 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12221/12542 | Batch Loss: 0.9655 | Learning Rate: 0.000009 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12222/12542 | Batch Loss: 1.7620 | Learning Rate: 0.000009 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12223/12542 | Batch Loss: 1.3687 | Learning Rate: 0.000008 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12224/12542 | Batch Loss: 0.8641 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12225/12542 | Batch Loss: 1.0167 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12226/12542 | Batch Loss: 0.3482 | Learning Rate: 0.000008 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12227/12542 | Batch Loss: 1.1116 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12228/12542 | Batch Loss: 1.0867 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12229/12542 | Batch Loss: 1.7470 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12230/12542 | Batch Loss: 1.8059 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12231/12542 | Batch Loss: 1.5778 | Learning Rate: 0.000008 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12232/12542 | Batch Loss: 0.6147 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12233/12542 | Batch Loss: 0.9539 | Learning Rate: 0.000008 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12234/12542 | Batch Loss: 1.2351 | Learning Rate: 0.000008 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12235/12542 | Batch Loss: 0.5012 | Learning Rate: 0.000008 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12236/12542 | Batch Loss: 0.5893 | Learning Rate: 0.000008 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12237/12542 | Batch Loss: 1.1692 | Learning Rate: 0.000008 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12238/12542 | Batch Loss: 1.4918 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12239/12542 | Batch Loss: 1.3527 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12240/12542 | Batch Loss: 1.8065 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12241/12542 | Batch Loss: 1.8165 | Learning Rate: 0.000008 | Batch Time: 0.54s\n",
      "Epoch 3 | Step 12242/12542 | Batch Loss: 0.7733 | Learning Rate: 0.000008 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12243/12542 | Batch Loss: 0.8018 | Learning Rate: 0.000008 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12244/12542 | Batch Loss: 1.0058 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12245/12542 | Batch Loss: 0.8856 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12246/12542 | Batch Loss: 0.7889 | Learning Rate: 0.000008 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12247/12542 | Batch Loss: 1.1050 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12248/12542 | Batch Loss: 0.8359 | Learning Rate: 0.000008 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12249/12542 | Batch Loss: 1.4819 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12250/12542 | Batch Loss: 1.0706 | Learning Rate: 0.000008 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12251/12542 | Batch Loss: 1.3115 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12252/12542 | Batch Loss: 1.7098 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12253/12542 | Batch Loss: 0.6947 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12254/12542 | Batch Loss: 2.0579 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12255/12542 | Batch Loss: 1.3412 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12256/12542 | Batch Loss: 1.5185 | Learning Rate: 0.000008 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12257/12542 | Batch Loss: 1.7328 | Learning Rate: 0.000008 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12258/12542 | Batch Loss: 0.9262 | Learning Rate: 0.000008 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12259/12542 | Batch Loss: 1.0663 | Learning Rate: 0.000008 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12260/12542 | Batch Loss: 1.0333 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12261/12542 | Batch Loss: 0.9317 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12262/12542 | Batch Loss: 2.8335 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12263/12542 | Batch Loss: 0.6113 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12264/12542 | Batch Loss: 0.4632 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12265/12542 | Batch Loss: 0.8500 | Learning Rate: 0.000007 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12266/12542 | Batch Loss: 1.8429 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12267/12542 | Batch Loss: 1.8006 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12268/12542 | Batch Loss: 1.5073 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12269/12542 | Batch Loss: 1.2667 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12270/12542 | Batch Loss: 1.3097 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12271/12542 | Batch Loss: 1.4850 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12272/12542 | Batch Loss: 0.8621 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12273/12542 | Batch Loss: 2.0227 | Learning Rate: 0.000007 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12274/12542 | Batch Loss: 1.4629 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12275/12542 | Batch Loss: 1.3245 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12276/12542 | Batch Loss: 2.1286 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12277/12542 | Batch Loss: 0.7343 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12278/12542 | Batch Loss: 1.5254 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12279/12542 | Batch Loss: 5.4592 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12280/12542 | Batch Loss: 1.6196 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12281/12542 | Batch Loss: 0.9150 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12282/12542 | Batch Loss: 3.2545 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12283/12542 | Batch Loss: 1.5809 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12284/12542 | Batch Loss: 0.7133 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12285/12542 | Batch Loss: 1.6761 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12286/12542 | Batch Loss: 1.2979 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12287/12542 | Batch Loss: 1.4595 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12288/12542 | Batch Loss: 1.0765 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12289/12542 | Batch Loss: 1.2583 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12290/12542 | Batch Loss: 1.7205 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12291/12542 | Batch Loss: 0.8750 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12292/12542 | Batch Loss: 0.7766 | Learning Rate: 0.000007 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12293/12542 | Batch Loss: 1.9529 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12294/12542 | Batch Loss: 1.3223 | Learning Rate: 0.000007 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12295/12542 | Batch Loss: 0.9016 | Learning Rate: 0.000007 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12296/12542 | Batch Loss: 0.7475 | Learning Rate: 0.000007 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12297/12542 | Batch Loss: 0.7909 | Learning Rate: 0.000007 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12298/12542 | Batch Loss: 1.4783 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12299/12542 | Batch Loss: 2.3663 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12300/12542 | Batch Loss: 1.8960 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12301/12542 | Batch Loss: 1.1096 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12302/12542 | Batch Loss: 1.0964 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12303/12542 | Batch Loss: 0.5714 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12304/12542 | Batch Loss: 1.1473 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12305/12542 | Batch Loss: 1.3336 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12306/12542 | Batch Loss: 1.0422 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12307/12542 | Batch Loss: 1.1368 | Learning Rate: 0.000006 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12308/12542 | Batch Loss: 2.4292 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12309/12542 | Batch Loss: 2.4003 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12310/12542 | Batch Loss: 2.0095 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12311/12542 | Batch Loss: 2.3955 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12312/12542 | Batch Loss: 1.1310 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12313/12542 | Batch Loss: 0.5694 | Learning Rate: 0.000006 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12314/12542 | Batch Loss: 0.8102 | Learning Rate: 0.000006 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12315/12542 | Batch Loss: 0.4294 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12316/12542 | Batch Loss: 0.9366 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12317/12542 | Batch Loss: 1.0845 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12318/12542 | Batch Loss: 1.3806 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12319/12542 | Batch Loss: 2.2154 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12320/12542 | Batch Loss: 1.8126 | Learning Rate: 0.000006 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12321/12542 | Batch Loss: 0.9186 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12322/12542 | Batch Loss: 1.0297 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12323/12542 | Batch Loss: 1.8151 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12324/12542 | Batch Loss: 0.9086 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12325/12542 | Batch Loss: 0.9961 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12326/12542 | Batch Loss: 0.8389 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12327/12542 | Batch Loss: 1.6028 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12328/12542 | Batch Loss: 1.0530 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12329/12542 | Batch Loss: 0.7142 | Learning Rate: 0.000006 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12330/12542 | Batch Loss: 0.9529 | Learning Rate: 0.000006 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12331/12542 | Batch Loss: 1.5084 | Learning Rate: 0.000006 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12332/12542 | Batch Loss: 2.1697 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12333/12542 | Batch Loss: 0.6398 | Learning Rate: 0.000006 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12334/12542 | Batch Loss: 1.3563 | Learning Rate: 0.000006 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12335/12542 | Batch Loss: 0.8147 | Learning Rate: 0.000006 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12336/12542 | Batch Loss: 0.9139 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12337/12542 | Batch Loss: 0.6175 | Learning Rate: 0.000005 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 12338/12542 | Batch Loss: 0.7993 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12339/12542 | Batch Loss: 1.0762 | Learning Rate: 0.000005 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12340/12542 | Batch Loss: 0.8380 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12341/12542 | Batch Loss: 0.8521 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12342/12542 | Batch Loss: 1.7061 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12343/12542 | Batch Loss: 1.1310 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12344/12542 | Batch Loss: 2.7084 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12345/12542 | Batch Loss: 2.1909 | Learning Rate: 0.000005 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12346/12542 | Batch Loss: 0.6832 | Learning Rate: 0.000005 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12347/12542 | Batch Loss: 1.4860 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12348/12542 | Batch Loss: 1.1753 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12349/12542 | Batch Loss: 1.1188 | Learning Rate: 0.000005 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12350/12542 | Batch Loss: 0.6076 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12351/12542 | Batch Loss: 1.5042 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12352/12542 | Batch Loss: 1.1763 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12353/12542 | Batch Loss: 1.6256 | Learning Rate: 0.000005 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12354/12542 | Batch Loss: 0.7931 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12355/12542 | Batch Loss: 1.4636 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12356/12542 | Batch Loss: 2.5219 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12357/12542 | Batch Loss: 0.7881 | Learning Rate: 0.000005 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12358/12542 | Batch Loss: 1.6758 | Learning Rate: 0.000005 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12359/12542 | Batch Loss: 0.9309 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12360/12542 | Batch Loss: 0.8228 | Learning Rate: 0.000005 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12361/12542 | Batch Loss: 1.4706 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12362/12542 | Batch Loss: 0.8015 | Learning Rate: 0.000005 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12363/12542 | Batch Loss: 1.2555 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12364/12542 | Batch Loss: 1.6269 | Learning Rate: 0.000005 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12365/12542 | Batch Loss: 1.0304 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12366/12542 | Batch Loss: 0.7931 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12367/12542 | Batch Loss: 0.7276 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12368/12542 | Batch Loss: 1.7704 | Learning Rate: 0.000005 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12369/12542 | Batch Loss: 0.9125 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12370/12542 | Batch Loss: 1.2830 | Learning Rate: 0.000005 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12371/12542 | Batch Loss: 1.9803 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12372/12542 | Batch Loss: 1.1434 | Learning Rate: 0.000005 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12373/12542 | Batch Loss: 1.4092 | Learning Rate: 0.000004 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12374/12542 | Batch Loss: 1.0956 | Learning Rate: 0.000004 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12375/12542 | Batch Loss: 0.7870 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12376/12542 | Batch Loss: 2.3654 | Learning Rate: 0.000004 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12377/12542 | Batch Loss: 1.1028 | Learning Rate: 0.000004 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12378/12542 | Batch Loss: 0.9611 | Learning Rate: 0.000004 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12379/12542 | Batch Loss: 0.8795 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12380/12542 | Batch Loss: 0.8454 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12381/12542 | Batch Loss: 1.8266 | Learning Rate: 0.000004 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12382/12542 | Batch Loss: 1.6841 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12383/12542 | Batch Loss: 1.6081 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12384/12542 | Batch Loss: 0.9951 | Learning Rate: 0.000004 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12385/12542 | Batch Loss: 0.8925 | Learning Rate: 0.000004 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12386/12542 | Batch Loss: 0.7329 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12387/12542 | Batch Loss: 1.0567 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12388/12542 | Batch Loss: 0.6052 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12389/12542 | Batch Loss: 2.3362 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12390/12542 | Batch Loss: 0.4949 | Learning Rate: 0.000004 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12391/12542 | Batch Loss: 1.6046 | Learning Rate: 0.000004 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12392/12542 | Batch Loss: 0.5690 | Learning Rate: 0.000004 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12393/12542 | Batch Loss: 1.2925 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12394/12542 | Batch Loss: 0.8548 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12395/12542 | Batch Loss: 1.2593 | Learning Rate: 0.000004 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12396/12542 | Batch Loss: 0.7909 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12397/12542 | Batch Loss: 1.2069 | Learning Rate: 0.000004 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12398/12542 | Batch Loss: 1.1689 | Learning Rate: 0.000004 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12399/12542 | Batch Loss: 0.7801 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12400/12542 | Batch Loss: 1.3992 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12401/12542 | Batch Loss: 1.2844 | Learning Rate: 0.000004 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12402/12542 | Batch Loss: 2.0140 | Learning Rate: 0.000004 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12403/12542 | Batch Loss: 1.3394 | Learning Rate: 0.000004 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12404/12542 | Batch Loss: 0.9117 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12405/12542 | Batch Loss: 0.6200 | Learning Rate: 0.000004 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12406/12542 | Batch Loss: 1.4040 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12407/12542 | Batch Loss: 0.8482 | Learning Rate: 0.000004 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12408/12542 | Batch Loss: 1.3814 | Learning Rate: 0.000004 | Batch Time: 0.53s\n",
      "Epoch 3 | Step 12409/12542 | Batch Loss: 1.4748 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12410/12542 | Batch Loss: 1.5266 | Learning Rate: 0.000004 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12411/12542 | Batch Loss: 0.8489 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12412/12542 | Batch Loss: 2.1857 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12413/12542 | Batch Loss: 0.4688 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12414/12542 | Batch Loss: 0.9519 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12415/12542 | Batch Loss: 0.6570 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12416/12542 | Batch Loss: 0.7786 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12417/12542 | Batch Loss: 1.1241 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12418/12542 | Batch Loss: 1.2360 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12419/12542 | Batch Loss: 3.2449 | Learning Rate: 0.000003 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12420/12542 | Batch Loss: 1.4612 | Learning Rate: 0.000003 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12421/12542 | Batch Loss: 0.8525 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12422/12542 | Batch Loss: 1.2734 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12423/12542 | Batch Loss: 1.6028 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12424/12542 | Batch Loss: 1.1433 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12425/12542 | Batch Loss: 1.0363 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12426/12542 | Batch Loss: 0.8586 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12427/12542 | Batch Loss: 0.5771 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12428/12542 | Batch Loss: 1.3676 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12429/12542 | Batch Loss: 1.6404 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12430/12542 | Batch Loss: 2.6799 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12431/12542 | Batch Loss: 1.9331 | Learning Rate: 0.000003 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12432/12542 | Batch Loss: 1.2773 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12433/12542 | Batch Loss: 1.5889 | Learning Rate: 0.000003 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12434/12542 | Batch Loss: 1.0377 | Learning Rate: 0.000003 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12435/12542 | Batch Loss: 1.0282 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12436/12542 | Batch Loss: 0.4325 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12437/12542 | Batch Loss: 0.7724 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12438/12542 | Batch Loss: 1.2159 | Learning Rate: 0.000003 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12439/12542 | Batch Loss: 0.7341 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12440/12542 | Batch Loss: 0.6387 | Learning Rate: 0.000003 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12441/12542 | Batch Loss: 1.3385 | Learning Rate: 0.000003 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12442/12542 | Batch Loss: 1.1761 | Learning Rate: 0.000003 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12443/12542 | Batch Loss: 1.7135 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12444/12542 | Batch Loss: 1.7000 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12445/12542 | Batch Loss: 1.4452 | Learning Rate: 0.000003 | Batch Time: 0.46s\n",
      "Epoch 3 | Step 12446/12542 | Batch Loss: 1.7678 | Learning Rate: 0.000003 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12447/12542 | Batch Loss: 1.3521 | Learning Rate: 0.000003 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12448/12542 | Batch Loss: 0.4203 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12449/12542 | Batch Loss: 1.7902 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12450/12542 | Batch Loss: 1.5998 | Learning Rate: 0.000002 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12451/12542 | Batch Loss: 1.5352 | Learning Rate: 0.000002 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12452/12542 | Batch Loss: 1.6272 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12453/12542 | Batch Loss: 1.3381 | Learning Rate: 0.000002 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12454/12542 | Batch Loss: 1.2630 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12455/12542 | Batch Loss: 0.9654 | Learning Rate: 0.000002 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12456/12542 | Batch Loss: 0.6913 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12457/12542 | Batch Loss: 1.1034 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12458/12542 | Batch Loss: 1.8909 | Learning Rate: 0.000002 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12459/12542 | Batch Loss: 0.6297 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12460/12542 | Batch Loss: 0.7711 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12461/12542 | Batch Loss: 0.7146 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12462/12542 | Batch Loss: 1.3234 | Learning Rate: 0.000002 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12463/12542 | Batch Loss: 1.6154 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12464/12542 | Batch Loss: 0.5596 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12465/12542 | Batch Loss: 1.1990 | Learning Rate: 0.000002 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12466/12542 | Batch Loss: 0.9197 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12467/12542 | Batch Loss: 1.1525 | Learning Rate: 0.000002 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12468/12542 | Batch Loss: 1.2610 | Learning Rate: 0.000002 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12469/12542 | Batch Loss: 0.5430 | Learning Rate: 0.000002 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12470/12542 | Batch Loss: 0.9542 | Learning Rate: 0.000002 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12471/12542 | Batch Loss: 0.7989 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12472/12542 | Batch Loss: 1.5880 | Learning Rate: 0.000002 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12473/12542 | Batch Loss: 1.7628 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12474/12542 | Batch Loss: 0.5530 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12475/12542 | Batch Loss: 1.0583 | Learning Rate: 0.000002 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12476/12542 | Batch Loss: 2.3925 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12477/12542 | Batch Loss: 0.5225 | Learning Rate: 0.000002 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12478/12542 | Batch Loss: 3.0854 | Learning Rate: 0.000002 | Batch Time: 0.56s\n",
      "Epoch 3 | Step 12479/12542 | Batch Loss: 0.7741 | Learning Rate: 0.000002 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12480/12542 | Batch Loss: 1.3262 | Learning Rate: 0.000002 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12481/12542 | Batch Loss: 1.2688 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12482/12542 | Batch Loss: 2.2550 | Learning Rate: 0.000002 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12483/12542 | Batch Loss: 0.7515 | Learning Rate: 0.000002 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12484/12542 | Batch Loss: 0.8937 | Learning Rate: 0.000002 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12485/12542 | Batch Loss: 0.7341 | Learning Rate: 0.000002 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12486/12542 | Batch Loss: 0.4446 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12487/12542 | Batch Loss: 1.3856 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12488/12542 | Batch Loss: 1.3310 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12489/12542 | Batch Loss: 1.0594 | Learning Rate: 0.000001 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12490/12542 | Batch Loss: 1.7995 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12491/12542 | Batch Loss: 1.1149 | Learning Rate: 0.000001 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12492/12542 | Batch Loss: 0.6339 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12493/12542 | Batch Loss: 1.8176 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12494/12542 | Batch Loss: 3.1363 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12495/12542 | Batch Loss: 0.5688 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12496/12542 | Batch Loss: 0.9906 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12497/12542 | Batch Loss: 0.9834 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12498/12542 | Batch Loss: 1.3489 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12499/12542 | Batch Loss: 0.9026 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12500/12542 | Batch Loss: 1.2122 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12501/12542 | Batch Loss: 0.9066 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12502/12542 | Batch Loss: 1.2718 | Learning Rate: 0.000001 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12503/12542 | Batch Loss: 1.4139 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12504/12542 | Batch Loss: 1.4034 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12505/12542 | Batch Loss: 1.7704 | Learning Rate: 0.000001 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12506/12542 | Batch Loss: 1.5289 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12507/12542 | Batch Loss: 0.9921 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12508/12542 | Batch Loss: 0.7645 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12509/12542 | Batch Loss: 1.2978 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12510/12542 | Batch Loss: 0.9340 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12511/12542 | Batch Loss: 1.8525 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12512/12542 | Batch Loss: 0.9341 | Learning Rate: 0.000001 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12513/12542 | Batch Loss: 0.6659 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12514/12542 | Batch Loss: 0.8987 | Learning Rate: 0.000001 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12515/12542 | Batch Loss: 0.7704 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12516/12542 | Batch Loss: 3.8527 | Learning Rate: 0.000001 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12517/12542 | Batch Loss: 2.0124 | Learning Rate: 0.000001 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12518/12542 | Batch Loss: 0.8286 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12519/12542 | Batch Loss: 0.7398 | Learning Rate: 0.000001 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12520/12542 | Batch Loss: 1.5382 | Learning Rate: 0.000001 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12521/12542 | Batch Loss: 2.2950 | Learning Rate: 0.000001 | Batch Time: 0.52s\n",
      "Epoch 3 | Step 12522/12542 | Batch Loss: 1.2126 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12523/12542 | Batch Loss: 0.5255 | Learning Rate: 0.000001 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12524/12542 | Batch Loss: 0.7156 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12525/12542 | Batch Loss: 0.7746 | Learning Rate: 0.000000 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12526/12542 | Batch Loss: 2.1004 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12527/12542 | Batch Loss: 0.8554 | Learning Rate: 0.000000 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12528/12542 | Batch Loss: 0.8687 | Learning Rate: 0.000000 | Batch Time: 0.51s\n",
      "Epoch 3 | Step 12529/12542 | Batch Loss: 0.9918 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12530/12542 | Batch Loss: 1.3219 | Learning Rate: 0.000000 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12531/12542 | Batch Loss: 2.1396 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12532/12542 | Batch Loss: 1.6818 | Learning Rate: 0.000000 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12533/12542 | Batch Loss: 1.9257 | Learning Rate: 0.000000 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12534/12542 | Batch Loss: 1.5023 | Learning Rate: 0.000000 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12535/12542 | Batch Loss: 0.8214 | Learning Rate: 0.000000 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12536/12542 | Batch Loss: 1.5176 | Learning Rate: 0.000000 | Batch Time: 0.49s\n",
      "Epoch 3 | Step 12537/12542 | Batch Loss: 1.4531 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12538/12542 | Batch Loss: 1.2296 | Learning Rate: 0.000000 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12539/12542 | Batch Loss: 2.1955 | Learning Rate: 0.000000 | Batch Time: 0.48s\n",
      "Epoch 3 | Step 12540/12542 | Batch Loss: 1.3229 | Learning Rate: 0.000000 | Batch Time: 0.50s\n",
      "Epoch 3 | Step 12541/12542 | Batch Loss: 2.8787 | Learning Rate: 0.000000 | Batch Time: 0.47s\n",
      "Epoch 3 | Step 12542/12542 | Batch Loss: 5.2607 | Learning Rate: 0.000000 | Batch Time: 0.17s\n",
      "Epoch 3 completed. Average Loss: 1.3280 | Epoch Time: 7595.32s\n",
      "Training completed in 25256.96s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import AdamW, get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Robust optimizer - Adam - most effective\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3 # epochs\n",
    "num_training_steps = num_epochs * len(train_loader) # steps\n",
    "\n",
    "#scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# Set the model to train mode\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Loop over the training batches\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        \n",
    "        batch_start_time = time.time()\n",
    "        # data feeding    \n",
    "        inputs = batch['input_ids'].to(device)  # input from batch\n",
    "        attention_mask = batch['attention_mask'].to(device) # padding - attention_mask\n",
    "        labels = batch['labels'].to(device) # target from batch\n",
    "        \n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)  # forward pass\n",
    "        loss = outputs.loss # compute loss\n",
    "               \n",
    "        loss.backward() # Backward pass \n",
    "        optimizer.step() # Update model parameters\n",
    "        lr_scheduler.step() # Update learning rate\n",
    "        optimizer.zero_grad()  # Clear the gradients for the next iteration\n",
    "        \n",
    "        progress_bar.update(1) # Update the progress bar\n",
    "        \n",
    "        total_loss += loss.item() # Accumulate the loss\n",
    "        \n",
    "        current_lr = lr_scheduler.get_last_lr()[0] # Get the current learning rate \n",
    "        batch_time = time.time() - batch_start_time # compute batch time\n",
    "        print(f\"Epoch {epoch + 1} | Step {step + 1}/{len(train_loader)} | \"\n",
    "              f\"Batch Loss: {loss.item():.4f} | Learning Rate: {current_lr:.6f} | \"\n",
    "              f\"Batch Time: {batch_time:.2f}s\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader) # compute average loss\n",
    "    epoch_time = time.time() - epoch_start_time  # compute bepoch time\n",
    "    # Print batch-level training information\n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_loss:.4f} | \"\n",
    "          f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "total_training_time = time.time() - start_time # compute train time\n",
    "print(f\"Training completed in {total_training_time:.2f}s\") # Print final training information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/mohan/infy/models/fine_tuned_bart/tokenizer_config.json',\n",
       " '/home/mohan/infy/models/fine_tuned_bart/special_tokens_map.json',\n",
       " '/home/mohan/infy/models/fine_tuned_bart/vocab.json',\n",
       " '/home/mohan/infy/models/fine_tuned_bart/merges.txt',\n",
       " '/home/mohan/infy/models/fine_tuned_bart/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine tuned transformer model & its tokenizer\n",
    "model.save_pretrained(\"/home/mohan/infy/models/fine_tuned_bart\")\n",
    "tokenizer.save_pretrained(\"/home/mohan/infy/models/fine_tuned_bart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For extra training - multiple trains \n",
    "Multiple epochs is possible - divided into few smaller epochs\n",
    "This way, domestic GPU can be used to train large models with more epochs.\n",
    "'''\n",
    "\n",
    "#if start from first \n",
    "'''\n",
    "model_path = '/home/mohan/infy/models/fine_tuned_bart'\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "'''\n",
    "\n",
    "# SAME training loop\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        \n",
    "        batch_start_time = time.time()    \n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "               \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        current_lr = lr_scheduler.get_last_lr()[0]\n",
    "        batch_time = time.time() - batch_start_time\n",
    "        print(f\"Epoch {epoch + 1} | Step {step + 1}/{len(train_loader)} | \"\n",
    "              f\"Batch Loss: {loss.item():.4f} | Learning Rate: {current_lr:.6f} | \"\n",
    "              f\"Batch Time: {batch_time:.2f}s\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_loss:.4f} | \"\n",
    "          f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"Training completed in {total_training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Step 1/1568 | Batch Loss: 1.3169 | Batch Time: 0.41s\n",
      "Validation Step 2/1568 | Batch Loss: 2.5463 | Batch Time: 0.14s\n",
      "Validation Step 3/1568 | Batch Loss: 1.7110 | Batch Time: 0.13s\n",
      "Validation Step 4/1568 | Batch Loss: 2.1756 | Batch Time: 0.13s\n",
      "Validation Step 5/1568 | Batch Loss: 1.8531 | Batch Time: 0.14s\n",
      "Validation Step 6/1568 | Batch Loss: 1.8267 | Batch Time: 0.13s\n",
      "Validation Step 7/1568 | Batch Loss: 1.7501 | Batch Time: 0.14s\n",
      "Validation Step 8/1568 | Batch Loss: 2.1318 | Batch Time: 0.13s\n",
      "Validation Step 9/1568 | Batch Loss: 1.4122 | Batch Time: 0.14s\n",
      "Validation Step 10/1568 | Batch Loss: 5.5929 | Batch Time: 0.13s\n",
      "Validation Step 11/1568 | Batch Loss: 2.7742 | Batch Time: 0.14s\n",
      "Validation Step 12/1568 | Batch Loss: 1.5455 | Batch Time: 0.14s\n",
      "Validation Step 13/1568 | Batch Loss: 1.5875 | Batch Time: 0.14s\n",
      "Validation Step 14/1568 | Batch Loss: 2.6606 | Batch Time: 0.14s\n",
      "Validation Step 15/1568 | Batch Loss: 3.6347 | Batch Time: 0.14s\n",
      "Validation Step 16/1568 | Batch Loss: 2.4970 | Batch Time: 0.14s\n",
      "Validation Step 17/1568 | Batch Loss: 1.8532 | Batch Time: 0.14s\n",
      "Validation Step 18/1568 | Batch Loss: 2.0887 | Batch Time: 0.14s\n",
      "Validation Step 19/1568 | Batch Loss: 1.7216 | Batch Time: 0.14s\n",
      "Validation Step 20/1568 | Batch Loss: 3.5605 | Batch Time: 0.14s\n",
      "Validation Step 21/1568 | Batch Loss: 2.5902 | Batch Time: 0.13s\n",
      "Validation Step 22/1568 | Batch Loss: 2.3406 | Batch Time: 0.15s\n",
      "Validation Step 23/1568 | Batch Loss: 3.3610 | Batch Time: 0.13s\n",
      "Validation Step 24/1568 | Batch Loss: 3.0376 | Batch Time: 0.14s\n",
      "Validation Step 25/1568 | Batch Loss: 2.2454 | Batch Time: 0.14s\n",
      "Validation Step 26/1568 | Batch Loss: 1.7393 | Batch Time: 0.14s\n",
      "Validation Step 27/1568 | Batch Loss: 2.4230 | Batch Time: 0.14s\n",
      "Validation Step 28/1568 | Batch Loss: 1.2746 | Batch Time: 0.14s\n",
      "Validation Step 29/1568 | Batch Loss: 3.8408 | Batch Time: 0.14s\n",
      "Validation Step 30/1568 | Batch Loss: 3.4182 | Batch Time: 0.14s\n",
      "Validation Step 31/1568 | Batch Loss: 2.7258 | Batch Time: 0.14s\n",
      "Validation Step 32/1568 | Batch Loss: 1.6460 | Batch Time: 0.14s\n",
      "Validation Step 33/1568 | Batch Loss: 2.6314 | Batch Time: 0.14s\n",
      "Validation Step 34/1568 | Batch Loss: 2.7774 | Batch Time: 0.13s\n",
      "Validation Step 35/1568 | Batch Loss: 1.8174 | Batch Time: 0.14s\n",
      "Validation Step 36/1568 | Batch Loss: 2.5652 | Batch Time: 0.14s\n",
      "Validation Step 37/1568 | Batch Loss: 2.9399 | Batch Time: 0.14s\n",
      "Validation Step 38/1568 | Batch Loss: 1.6522 | Batch Time: 0.14s\n",
      "Validation Step 39/1568 | Batch Loss: 2.3902 | Batch Time: 0.14s\n",
      "Validation Step 40/1568 | Batch Loss: 1.9405 | Batch Time: 0.14s\n",
      "Validation Step 41/1568 | Batch Loss: 1.5107 | Batch Time: 0.14s\n",
      "Validation Step 42/1568 | Batch Loss: 1.8866 | Batch Time: 0.14s\n",
      "Validation Step 43/1568 | Batch Loss: 2.3384 | Batch Time: 0.14s\n",
      "Validation Step 44/1568 | Batch Loss: 2.4668 | Batch Time: 0.14s\n",
      "Validation Step 45/1568 | Batch Loss: 1.5657 | Batch Time: 0.14s\n",
      "Validation Step 46/1568 | Batch Loss: 1.6637 | Batch Time: 0.14s\n",
      "Validation Step 47/1568 | Batch Loss: 2.6129 | Batch Time: 0.13s\n",
      "Validation Step 48/1568 | Batch Loss: 1.7492 | Batch Time: 0.14s\n",
      "Validation Step 49/1568 | Batch Loss: 1.9790 | Batch Time: 0.14s\n",
      "Validation Step 50/1568 | Batch Loss: 3.4624 | Batch Time: 0.14s\n",
      "Validation Step 51/1568 | Batch Loss: 1.6664 | Batch Time: 0.14s\n",
      "Validation Step 52/1568 | Batch Loss: 2.5849 | Batch Time: 0.14s\n",
      "Validation Step 53/1568 | Batch Loss: 2.2320 | Batch Time: 0.14s\n",
      "Validation Step 54/1568 | Batch Loss: 1.6306 | Batch Time: 0.14s\n",
      "Validation Step 55/1568 | Batch Loss: 2.2376 | Batch Time: 0.14s\n",
      "Validation Step 56/1568 | Batch Loss: 1.6015 | Batch Time: 0.14s\n",
      "Validation Step 57/1568 | Batch Loss: 2.2608 | Batch Time: 0.14s\n",
      "Validation Step 58/1568 | Batch Loss: 2.2490 | Batch Time: 0.14s\n",
      "Validation Step 59/1568 | Batch Loss: 1.8417 | Batch Time: 0.14s\n",
      "Validation Step 60/1568 | Batch Loss: 2.4745 | Batch Time: 0.13s\n",
      "Validation Step 61/1568 | Batch Loss: 2.4980 | Batch Time: 0.14s\n",
      "Validation Step 62/1568 | Batch Loss: 2.2067 | Batch Time: 0.14s\n",
      "Validation Step 63/1568 | Batch Loss: 2.7940 | Batch Time: 0.14s\n",
      "Validation Step 64/1568 | Batch Loss: 2.0373 | Batch Time: 0.14s\n",
      "Validation Step 65/1568 | Batch Loss: 1.7775 | Batch Time: 0.14s\n",
      "Validation Step 66/1568 | Batch Loss: 2.0981 | Batch Time: 0.14s\n",
      "Validation Step 67/1568 | Batch Loss: 2.7405 | Batch Time: 0.14s\n",
      "Validation Step 68/1568 | Batch Loss: 1.7641 | Batch Time: 0.14s\n",
      "Validation Step 69/1568 | Batch Loss: 1.9245 | Batch Time: 0.14s\n",
      "Validation Step 70/1568 | Batch Loss: 1.6538 | Batch Time: 0.14s\n",
      "Validation Step 71/1568 | Batch Loss: 2.2518 | Batch Time: 0.14s\n",
      "Validation Step 72/1568 | Batch Loss: 3.5443 | Batch Time: 0.14s\n",
      "Validation Step 73/1568 | Batch Loss: 1.5070 | Batch Time: 0.14s\n",
      "Validation Step 74/1568 | Batch Loss: 2.1628 | Batch Time: 0.14s\n",
      "Validation Step 75/1568 | Batch Loss: 2.9744 | Batch Time: 0.14s\n",
      "Validation Step 76/1568 | Batch Loss: 2.5744 | Batch Time: 0.14s\n",
      "Validation Step 77/1568 | Batch Loss: 3.3557 | Batch Time: 0.14s\n",
      "Validation Step 78/1568 | Batch Loss: 3.0823 | Batch Time: 0.14s\n",
      "Validation Step 79/1568 | Batch Loss: 3.7817 | Batch Time: 0.14s\n",
      "Validation Step 80/1568 | Batch Loss: 1.6641 | Batch Time: 0.14s\n",
      "Validation Step 81/1568 | Batch Loss: 1.6356 | Batch Time: 0.14s\n",
      "Validation Step 82/1568 | Batch Loss: 2.5632 | Batch Time: 0.14s\n",
      "Validation Step 83/1568 | Batch Loss: 1.8612 | Batch Time: 0.14s\n",
      "Validation Step 84/1568 | Batch Loss: 2.0410 | Batch Time: 0.14s\n",
      "Validation Step 85/1568 | Batch Loss: 2.2505 | Batch Time: 0.14s\n",
      "Validation Step 86/1568 | Batch Loss: 2.7900 | Batch Time: 0.14s\n",
      "Validation Step 87/1568 | Batch Loss: 1.8187 | Batch Time: 0.14s\n",
      "Validation Step 88/1568 | Batch Loss: 2.6026 | Batch Time: 0.14s\n",
      "Validation Step 89/1568 | Batch Loss: 2.4838 | Batch Time: 0.14s\n",
      "Validation Step 90/1568 | Batch Loss: 1.5064 | Batch Time: 0.14s\n",
      "Validation Step 91/1568 | Batch Loss: 2.3084 | Batch Time: 0.14s\n",
      "Validation Step 92/1568 | Batch Loss: 1.9830 | Batch Time: 0.14s\n",
      "Validation Step 93/1568 | Batch Loss: 2.4640 | Batch Time: 0.14s\n",
      "Validation Step 94/1568 | Batch Loss: 2.3422 | Batch Time: 0.14s\n",
      "Validation Step 95/1568 | Batch Loss: 2.0894 | Batch Time: 0.14s\n",
      "Validation Step 96/1568 | Batch Loss: 3.1408 | Batch Time: 0.15s\n",
      "Validation Step 97/1568 | Batch Loss: 1.7601 | Batch Time: 0.14s\n",
      "Validation Step 98/1568 | Batch Loss: 2.5325 | Batch Time: 0.14s\n",
      "Validation Step 99/1568 | Batch Loss: 2.4131 | Batch Time: 0.14s\n",
      "Validation Step 100/1568 | Batch Loss: 1.8829 | Batch Time: 0.14s\n",
      "Validation Step 101/1568 | Batch Loss: 2.4182 | Batch Time: 0.14s\n",
      "Validation Step 102/1568 | Batch Loss: 2.0276 | Batch Time: 0.14s\n",
      "Validation Step 103/1568 | Batch Loss: 1.7313 | Batch Time: 0.14s\n",
      "Validation Step 104/1568 | Batch Loss: 2.9999 | Batch Time: 0.14s\n",
      "Validation Step 105/1568 | Batch Loss: 2.6325 | Batch Time: 0.14s\n",
      "Validation Step 106/1568 | Batch Loss: 1.8252 | Batch Time: 0.14s\n",
      "Validation Step 107/1568 | Batch Loss: 4.3207 | Batch Time: 0.14s\n",
      "Validation Step 108/1568 | Batch Loss: 3.0022 | Batch Time: 0.14s\n",
      "Validation Step 109/1568 | Batch Loss: 3.7772 | Batch Time: 0.14s\n",
      "Validation Step 110/1568 | Batch Loss: 2.2314 | Batch Time: 0.14s\n",
      "Validation Step 111/1568 | Batch Loss: 1.6414 | Batch Time: 0.14s\n",
      "Validation Step 112/1568 | Batch Loss: 3.1925 | Batch Time: 0.14s\n",
      "Validation Step 113/1568 | Batch Loss: 2.7726 | Batch Time: 0.14s\n",
      "Validation Step 114/1568 | Batch Loss: 3.5639 | Batch Time: 0.14s\n",
      "Validation Step 115/1568 | Batch Loss: 2.9381 | Batch Time: 0.14s\n",
      "Validation Step 116/1568 | Batch Loss: 1.8960 | Batch Time: 0.14s\n",
      "Validation Step 117/1568 | Batch Loss: 2.9740 | Batch Time: 0.14s\n",
      "Validation Step 118/1568 | Batch Loss: 2.7300 | Batch Time: 0.14s\n",
      "Validation Step 119/1568 | Batch Loss: 2.8243 | Batch Time: 0.14s\n",
      "Validation Step 120/1568 | Batch Loss: 2.3398 | Batch Time: 0.13s\n",
      "Validation Step 121/1568 | Batch Loss: 2.4199 | Batch Time: 0.14s\n",
      "Validation Step 122/1568 | Batch Loss: 1.9158 | Batch Time: 0.14s\n",
      "Validation Step 123/1568 | Batch Loss: 2.4108 | Batch Time: 0.14s\n",
      "Validation Step 124/1568 | Batch Loss: 2.8169 | Batch Time: 0.14s\n",
      "Validation Step 125/1568 | Batch Loss: 2.1459 | Batch Time: 0.14s\n",
      "Validation Step 126/1568 | Batch Loss: 2.0356 | Batch Time: 0.14s\n",
      "Validation Step 127/1568 | Batch Loss: 4.4050 | Batch Time: 0.14s\n",
      "Validation Step 128/1568 | Batch Loss: 2.6486 | Batch Time: 0.14s\n",
      "Validation Step 129/1568 | Batch Loss: 2.4121 | Batch Time: 0.14s\n",
      "Validation Step 130/1568 | Batch Loss: 2.3701 | Batch Time: 0.14s\n",
      "Validation Step 131/1568 | Batch Loss: 1.9074 | Batch Time: 0.14s\n",
      "Validation Step 132/1568 | Batch Loss: 2.5623 | Batch Time: 0.14s\n",
      "Validation Step 133/1568 | Batch Loss: 1.7626 | Batch Time: 0.14s\n",
      "Validation Step 134/1568 | Batch Loss: 2.8582 | Batch Time: 0.14s\n",
      "Validation Step 135/1568 | Batch Loss: 3.5526 | Batch Time: 0.14s\n",
      "Validation Step 136/1568 | Batch Loss: 1.8201 | Batch Time: 0.14s\n",
      "Validation Step 137/1568 | Batch Loss: 2.1234 | Batch Time: 0.15s\n",
      "Validation Step 138/1568 | Batch Loss: 1.9699 | Batch Time: 0.14s\n",
      "Validation Step 139/1568 | Batch Loss: 1.7647 | Batch Time: 0.14s\n",
      "Validation Step 140/1568 | Batch Loss: 2.7790 | Batch Time: 0.14s\n",
      "Validation Step 141/1568 | Batch Loss: 4.3520 | Batch Time: 0.14s\n",
      "Validation Step 142/1568 | Batch Loss: 2.3616 | Batch Time: 0.14s\n",
      "Validation Step 143/1568 | Batch Loss: 1.3676 | Batch Time: 0.14s\n",
      "Validation Step 144/1568 | Batch Loss: 2.9696 | Batch Time: 0.14s\n",
      "Validation Step 145/1568 | Batch Loss: 2.7407 | Batch Time: 0.14s\n",
      "Validation Step 146/1568 | Batch Loss: 3.3253 | Batch Time: 0.14s\n",
      "Validation Step 147/1568 | Batch Loss: 3.4968 | Batch Time: 0.13s\n",
      "Validation Step 148/1568 | Batch Loss: 1.7588 | Batch Time: 0.14s\n",
      "Validation Step 149/1568 | Batch Loss: 2.9730 | Batch Time: 0.14s\n",
      "Validation Step 150/1568 | Batch Loss: 2.5876 | Batch Time: 0.14s\n",
      "Validation Step 151/1568 | Batch Loss: 2.0524 | Batch Time: 0.14s\n",
      "Validation Step 152/1568 | Batch Loss: 1.5592 | Batch Time: 0.14s\n",
      "Validation Step 153/1568 | Batch Loss: 1.8105 | Batch Time: 0.14s\n",
      "Validation Step 154/1568 | Batch Loss: 1.6846 | Batch Time: 0.14s\n",
      "Validation Step 155/1568 | Batch Loss: 1.8683 | Batch Time: 0.14s\n",
      "Validation Step 156/1568 | Batch Loss: 4.0119 | Batch Time: 0.14s\n",
      "Validation Step 157/1568 | Batch Loss: 1.8063 | Batch Time: 0.14s\n",
      "Validation Step 158/1568 | Batch Loss: 2.0661 | Batch Time: 0.14s\n",
      "Validation Step 159/1568 | Batch Loss: 3.8935 | Batch Time: 0.13s\n",
      "Validation Step 160/1568 | Batch Loss: 1.8107 | Batch Time: 0.14s\n",
      "Validation Step 161/1568 | Batch Loss: 2.7050 | Batch Time: 0.14s\n",
      "Validation Step 162/1568 | Batch Loss: 2.9401 | Batch Time: 0.14s\n",
      "Validation Step 163/1568 | Batch Loss: 2.8657 | Batch Time: 0.14s\n",
      "Validation Step 164/1568 | Batch Loss: 1.8758 | Batch Time: 0.14s\n",
      "Validation Step 165/1568 | Batch Loss: 1.7804 | Batch Time: 0.14s\n",
      "Validation Step 166/1568 | Batch Loss: 1.9226 | Batch Time: 0.14s\n",
      "Validation Step 167/1568 | Batch Loss: 1.6972 | Batch Time: 0.14s\n",
      "Validation Step 168/1568 | Batch Loss: 2.3654 | Batch Time: 0.14s\n",
      "Validation Step 169/1568 | Batch Loss: 5.0490 | Batch Time: 0.14s\n",
      "Validation Step 170/1568 | Batch Loss: 3.7210 | Batch Time: 0.14s\n",
      "Validation Step 171/1568 | Batch Loss: 1.5433 | Batch Time: 0.14s\n",
      "Validation Step 172/1568 | Batch Loss: 2.8642 | Batch Time: 0.14s\n",
      "Validation Step 173/1568 | Batch Loss: 1.8409 | Batch Time: 0.15s\n",
      "Validation Step 174/1568 | Batch Loss: 3.1478 | Batch Time: 0.14s\n",
      "Validation Step 175/1568 | Batch Loss: 2.7709 | Batch Time: 0.14s\n",
      "Validation Step 176/1568 | Batch Loss: 2.7510 | Batch Time: 0.14s\n",
      "Validation Step 177/1568 | Batch Loss: 1.7017 | Batch Time: 0.14s\n",
      "Validation Step 178/1568 | Batch Loss: 2.9452 | Batch Time: 0.14s\n",
      "Validation Step 179/1568 | Batch Loss: 2.2396 | Batch Time: 0.14s\n",
      "Validation Step 180/1568 | Batch Loss: 1.8679 | Batch Time: 0.14s\n",
      "Validation Step 181/1568 | Batch Loss: 3.1150 | Batch Time: 0.14s\n",
      "Validation Step 182/1568 | Batch Loss: 2.2780 | Batch Time: 0.14s\n",
      "Validation Step 183/1568 | Batch Loss: 1.5993 | Batch Time: 0.14s\n",
      "Validation Step 184/1568 | Batch Loss: 2.3571 | Batch Time: 0.14s\n",
      "Validation Step 185/1568 | Batch Loss: 2.1064 | Batch Time: 0.14s\n",
      "Validation Step 186/1568 | Batch Loss: 3.5070 | Batch Time: 0.14s\n",
      "Validation Step 187/1568 | Batch Loss: 4.7205 | Batch Time: 0.14s\n",
      "Validation Step 188/1568 | Batch Loss: 3.1578 | Batch Time: 0.14s\n",
      "Validation Step 189/1568 | Batch Loss: 2.5803 | Batch Time: 0.14s\n",
      "Validation Step 190/1568 | Batch Loss: 1.8729 | Batch Time: 0.14s\n",
      "Validation Step 191/1568 | Batch Loss: 2.4955 | Batch Time: 0.14s\n",
      "Validation Step 192/1568 | Batch Loss: 2.8174 | Batch Time: 0.14s\n",
      "Validation Step 193/1568 | Batch Loss: 1.6516 | Batch Time: 0.14s\n",
      "Validation Step 194/1568 | Batch Loss: 3.8633 | Batch Time: 0.14s\n",
      "Validation Step 195/1568 | Batch Loss: 3.9554 | Batch Time: 0.14s\n",
      "Validation Step 196/1568 | Batch Loss: 3.3869 | Batch Time: 0.14s\n",
      "Validation Step 197/1568 | Batch Loss: 2.9060 | Batch Time: 0.14s\n",
      "Validation Step 198/1568 | Batch Loss: 1.7960 | Batch Time: 0.14s\n",
      "Validation Step 199/1568 | Batch Loss: 2.9692 | Batch Time: 0.14s\n",
      "Validation Step 200/1568 | Batch Loss: 3.0927 | Batch Time: 0.14s\n",
      "Validation Step 201/1568 | Batch Loss: 3.1371 | Batch Time: 0.14s\n",
      "Validation Step 202/1568 | Batch Loss: 2.4296 | Batch Time: 0.14s\n",
      "Validation Step 203/1568 | Batch Loss: 2.6250 | Batch Time: 0.13s\n",
      "Validation Step 204/1568 | Batch Loss: 2.4978 | Batch Time: 0.14s\n",
      "Validation Step 205/1568 | Batch Loss: 1.8293 | Batch Time: 0.14s\n",
      "Validation Step 206/1568 | Batch Loss: 1.9458 | Batch Time: 0.14s\n",
      "Validation Step 207/1568 | Batch Loss: 1.6476 | Batch Time: 0.14s\n",
      "Validation Step 208/1568 | Batch Loss: 2.4934 | Batch Time: 0.14s\n",
      "Validation Step 209/1568 | Batch Loss: 1.9886 | Batch Time: 0.14s\n",
      "Validation Step 210/1568 | Batch Loss: 2.4748 | Batch Time: 0.14s\n",
      "Validation Step 211/1568 | Batch Loss: 3.1651 | Batch Time: 0.15s\n",
      "Validation Step 212/1568 | Batch Loss: 2.5692 | Batch Time: 0.13s\n",
      "Validation Step 213/1568 | Batch Loss: 2.2445 | Batch Time: 0.14s\n",
      "Validation Step 214/1568 | Batch Loss: 2.1641 | Batch Time: 0.14s\n",
      "Validation Step 215/1568 | Batch Loss: 1.9703 | Batch Time: 0.14s\n",
      "Validation Step 216/1568 | Batch Loss: 2.4865 | Batch Time: 0.14s\n",
      "Validation Step 217/1568 | Batch Loss: 1.7969 | Batch Time: 0.14s\n",
      "Validation Step 218/1568 | Batch Loss: 3.3619 | Batch Time: 0.14s\n",
      "Validation Step 219/1568 | Batch Loss: 2.8871 | Batch Time: 0.14s\n",
      "Validation Step 220/1568 | Batch Loss: 3.8215 | Batch Time: 0.14s\n",
      "Validation Step 221/1568 | Batch Loss: 2.4735 | Batch Time: 0.14s\n",
      "Validation Step 222/1568 | Batch Loss: 3.8261 | Batch Time: 0.14s\n",
      "Validation Step 223/1568 | Batch Loss: 1.6650 | Batch Time: 0.14s\n",
      "Validation Step 224/1568 | Batch Loss: 3.0596 | Batch Time: 0.14s\n",
      "Validation Step 225/1568 | Batch Loss: 3.7075 | Batch Time: 0.14s\n",
      "Validation Step 226/1568 | Batch Loss: 2.6068 | Batch Time: 0.14s\n",
      "Validation Step 227/1568 | Batch Loss: 3.7017 | Batch Time: 0.14s\n",
      "Validation Step 228/1568 | Batch Loss: 4.4244 | Batch Time: 0.14s\n",
      "Validation Step 229/1568 | Batch Loss: 2.4644 | Batch Time: 0.14s\n",
      "Validation Step 230/1568 | Batch Loss: 1.3121 | Batch Time: 0.14s\n",
      "Validation Step 231/1568 | Batch Loss: 1.9030 | Batch Time: 0.14s\n",
      "Validation Step 232/1568 | Batch Loss: 3.1648 | Batch Time: 0.14s\n",
      "Validation Step 233/1568 | Batch Loss: 2.5921 | Batch Time: 0.14s\n",
      "Validation Step 234/1568 | Batch Loss: 1.7831 | Batch Time: 0.14s\n",
      "Validation Step 235/1568 | Batch Loss: 2.8441 | Batch Time: 0.14s\n",
      "Validation Step 236/1568 | Batch Loss: 2.2868 | Batch Time: 0.14s\n",
      "Validation Step 237/1568 | Batch Loss: 2.6187 | Batch Time: 0.14s\n",
      "Validation Step 238/1568 | Batch Loss: 1.5981 | Batch Time: 0.14s\n",
      "Validation Step 239/1568 | Batch Loss: 1.7984 | Batch Time: 0.14s\n",
      "Validation Step 240/1568 | Batch Loss: 2.6447 | Batch Time: 0.14s\n",
      "Validation Step 241/1568 | Batch Loss: 2.1540 | Batch Time: 0.14s\n",
      "Validation Step 242/1568 | Batch Loss: 2.1834 | Batch Time: 0.14s\n",
      "Validation Step 243/1568 | Batch Loss: 1.5451 | Batch Time: 0.14s\n",
      "Validation Step 244/1568 | Batch Loss: 2.0406 | Batch Time: 0.14s\n",
      "Validation Step 245/1568 | Batch Loss: 2.1609 | Batch Time: 0.14s\n",
      "Validation Step 246/1568 | Batch Loss: 2.8112 | Batch Time: 0.14s\n",
      "Validation Step 247/1568 | Batch Loss: 3.8866 | Batch Time: 0.14s\n",
      "Validation Step 248/1568 | Batch Loss: 2.2751 | Batch Time: 0.14s\n",
      "Validation Step 249/1568 | Batch Loss: 3.3482 | Batch Time: 0.14s\n",
      "Validation Step 250/1568 | Batch Loss: 2.4075 | Batch Time: 0.14s\n",
      "Validation Step 251/1568 | Batch Loss: 1.7806 | Batch Time: 0.14s\n",
      "Validation Step 252/1568 | Batch Loss: 2.1377 | Batch Time: 0.14s\n",
      "Validation Step 253/1568 | Batch Loss: 2.2253 | Batch Time: 0.14s\n",
      "Validation Step 254/1568 | Batch Loss: 2.7824 | Batch Time: 0.14s\n",
      "Validation Step 255/1568 | Batch Loss: 2.7393 | Batch Time: 0.14s\n",
      "Validation Step 256/1568 | Batch Loss: 2.4262 | Batch Time: 0.14s\n",
      "Validation Step 257/1568 | Batch Loss: 2.6466 | Batch Time: 0.15s\n",
      "Validation Step 258/1568 | Batch Loss: 2.2663 | Batch Time: 0.14s\n",
      "Validation Step 259/1568 | Batch Loss: 2.1790 | Batch Time: 0.14s\n",
      "Validation Step 260/1568 | Batch Loss: 1.9047 | Batch Time: 0.14s\n",
      "Validation Step 261/1568 | Batch Loss: 2.0631 | Batch Time: 0.14s\n",
      "Validation Step 262/1568 | Batch Loss: 2.9421 | Batch Time: 0.14s\n",
      "Validation Step 263/1568 | Batch Loss: 2.3799 | Batch Time: 0.14s\n",
      "Validation Step 264/1568 | Batch Loss: 3.1003 | Batch Time: 0.14s\n",
      "Validation Step 265/1568 | Batch Loss: 1.6780 | Batch Time: 0.14s\n",
      "Validation Step 266/1568 | Batch Loss: 2.3560 | Batch Time: 0.13s\n",
      "Validation Step 267/1568 | Batch Loss: 3.3093 | Batch Time: 0.14s\n",
      "Validation Step 268/1568 | Batch Loss: 2.5023 | Batch Time: 0.14s\n",
      "Validation Step 269/1568 | Batch Loss: 2.2903 | Batch Time: 0.14s\n",
      "Validation Step 270/1568 | Batch Loss: 2.2203 | Batch Time: 0.14s\n",
      "Validation Step 271/1568 | Batch Loss: 2.7307 | Batch Time: 0.14s\n",
      "Validation Step 272/1568 | Batch Loss: 2.9527 | Batch Time: 0.14s\n",
      "Validation Step 273/1568 | Batch Loss: 1.7674 | Batch Time: 0.14s\n",
      "Validation Step 274/1568 | Batch Loss: 2.3791 | Batch Time: 0.14s\n",
      "Validation Step 275/1568 | Batch Loss: 2.8389 | Batch Time: 0.14s\n",
      "Validation Step 276/1568 | Batch Loss: 1.4562 | Batch Time: 0.14s\n",
      "Validation Step 277/1568 | Batch Loss: 2.2625 | Batch Time: 0.14s\n",
      "Validation Step 278/1568 | Batch Loss: 2.4970 | Batch Time: 0.14s\n",
      "Validation Step 279/1568 | Batch Loss: 1.8782 | Batch Time: 0.14s\n",
      "Validation Step 280/1568 | Batch Loss: 1.8021 | Batch Time: 0.14s\n",
      "Validation Step 281/1568 | Batch Loss: 3.2783 | Batch Time: 0.14s\n",
      "Validation Step 282/1568 | Batch Loss: 2.2931 | Batch Time: 0.14s\n",
      "Validation Step 283/1568 | Batch Loss: 1.8742 | Batch Time: 0.14s\n",
      "Validation Step 284/1568 | Batch Loss: 3.7240 | Batch Time: 0.14s\n",
      "Validation Step 285/1568 | Batch Loss: 3.1896 | Batch Time: 0.14s\n",
      "Validation Step 286/1568 | Batch Loss: 2.2672 | Batch Time: 0.14s\n",
      "Validation Step 287/1568 | Batch Loss: 4.5809 | Batch Time: 0.13s\n",
      "Validation Step 288/1568 | Batch Loss: 2.4141 | Batch Time: 0.14s\n",
      "Validation Step 289/1568 | Batch Loss: 1.9191 | Batch Time: 0.15s\n",
      "Validation Step 290/1568 | Batch Loss: 2.9335 | Batch Time: 0.14s\n",
      "Validation Step 291/1568 | Batch Loss: 1.4348 | Batch Time: 0.14s\n",
      "Validation Step 292/1568 | Batch Loss: 2.0961 | Batch Time: 0.13s\n",
      "Validation Step 293/1568 | Batch Loss: 2.2112 | Batch Time: 0.14s\n",
      "Validation Step 294/1568 | Batch Loss: 2.3393 | Batch Time: 0.14s\n",
      "Validation Step 295/1568 | Batch Loss: 2.2926 | Batch Time: 0.14s\n",
      "Validation Step 296/1568 | Batch Loss: 2.6962 | Batch Time: 0.14s\n",
      "Validation Step 297/1568 | Batch Loss: 1.7537 | Batch Time: 0.14s\n",
      "Validation Step 298/1568 | Batch Loss: 1.5732 | Batch Time: 0.14s\n",
      "Validation Step 299/1568 | Batch Loss: 1.8038 | Batch Time: 0.14s\n",
      "Validation Step 300/1568 | Batch Loss: 1.4610 | Batch Time: 0.14s\n",
      "Validation Step 301/1568 | Batch Loss: 2.3801 | Batch Time: 0.15s\n",
      "Validation Step 302/1568 | Batch Loss: 2.4943 | Batch Time: 0.14s\n",
      "Validation Step 303/1568 | Batch Loss: 2.8370 | Batch Time: 0.13s\n",
      "Validation Step 304/1568 | Batch Loss: 1.6341 | Batch Time: 0.14s\n",
      "Validation Step 305/1568 | Batch Loss: 1.7473 | Batch Time: 0.14s\n",
      "Validation Step 306/1568 | Batch Loss: 1.8376 | Batch Time: 0.14s\n",
      "Validation Step 307/1568 | Batch Loss: 2.0950 | Batch Time: 0.14s\n",
      "Validation Step 308/1568 | Batch Loss: 2.8810 | Batch Time: 0.14s\n",
      "Validation Step 309/1568 | Batch Loss: 2.1543 | Batch Time: 0.14s\n",
      "Validation Step 310/1568 | Batch Loss: 2.5956 | Batch Time: 0.14s\n",
      "Validation Step 311/1568 | Batch Loss: 2.0638 | Batch Time: 0.14s\n",
      "Validation Step 312/1568 | Batch Loss: 2.6500 | Batch Time: 0.14s\n",
      "Validation Step 313/1568 | Batch Loss: 4.7788 | Batch Time: 0.14s\n",
      "Validation Step 314/1568 | Batch Loss: 2.9894 | Batch Time: 0.14s\n",
      "Validation Step 315/1568 | Batch Loss: 1.6423 | Batch Time: 0.14s\n",
      "Validation Step 316/1568 | Batch Loss: 3.0846 | Batch Time: 0.14s\n",
      "Validation Step 317/1568 | Batch Loss: 2.6747 | Batch Time: 0.14s\n",
      "Validation Step 318/1568 | Batch Loss: 1.5434 | Batch Time: 0.14s\n",
      "Validation Step 319/1568 | Batch Loss: 1.8004 | Batch Time: 0.14s\n",
      "Validation Step 320/1568 | Batch Loss: 3.1329 | Batch Time: 0.14s\n",
      "Validation Step 321/1568 | Batch Loss: 1.4488 | Batch Time: 0.14s\n",
      "Validation Step 322/1568 | Batch Loss: 2.1291 | Batch Time: 0.14s\n",
      "Validation Step 323/1568 | Batch Loss: 1.4389 | Batch Time: 0.14s\n",
      "Validation Step 324/1568 | Batch Loss: 2.9360 | Batch Time: 0.14s\n",
      "Validation Step 325/1568 | Batch Loss: 2.2544 | Batch Time: 0.14s\n",
      "Validation Step 326/1568 | Batch Loss: 2.8299 | Batch Time: 0.14s\n",
      "Validation Step 327/1568 | Batch Loss: 3.5431 | Batch Time: 0.14s\n",
      "Validation Step 328/1568 | Batch Loss: 1.8555 | Batch Time: 0.14s\n",
      "Validation Step 329/1568 | Batch Loss: 1.5240 | Batch Time: 0.14s\n",
      "Validation Step 330/1568 | Batch Loss: 2.6911 | Batch Time: 0.14s\n",
      "Validation Step 331/1568 | Batch Loss: 2.1954 | Batch Time: 0.13s\n",
      "Validation Step 332/1568 | Batch Loss: 1.5962 | Batch Time: 0.14s\n",
      "Validation Step 333/1568 | Batch Loss: 2.2459 | Batch Time: 0.14s\n",
      "Validation Step 334/1568 | Batch Loss: 1.8390 | Batch Time: 0.14s\n",
      "Validation Step 335/1568 | Batch Loss: 2.0886 | Batch Time: 0.14s\n",
      "Validation Step 336/1568 | Batch Loss: 2.0039 | Batch Time: 0.14s\n",
      "Validation Step 337/1568 | Batch Loss: 1.7122 | Batch Time: 0.14s\n",
      "Validation Step 338/1568 | Batch Loss: 2.8001 | Batch Time: 0.14s\n",
      "Validation Step 339/1568 | Batch Loss: 2.3177 | Batch Time: 0.14s\n",
      "Validation Step 340/1568 | Batch Loss: 3.6681 | Batch Time: 0.14s\n",
      "Validation Step 341/1568 | Batch Loss: 2.7913 | Batch Time: 0.14s\n",
      "Validation Step 342/1568 | Batch Loss: 1.9287 | Batch Time: 0.14s\n",
      "Validation Step 343/1568 | Batch Loss: 1.3766 | Batch Time: 0.14s\n",
      "Validation Step 344/1568 | Batch Loss: 4.3478 | Batch Time: 0.14s\n",
      "Validation Step 345/1568 | Batch Loss: 3.4316 | Batch Time: 0.14s\n",
      "Validation Step 346/1568 | Batch Loss: 2.4225 | Batch Time: 0.14s\n",
      "Validation Step 347/1568 | Batch Loss: 1.5053 | Batch Time: 0.14s\n",
      "Validation Step 348/1568 | Batch Loss: 2.0616 | Batch Time: 0.14s\n",
      "Validation Step 349/1568 | Batch Loss: 1.9304 | Batch Time: 0.14s\n",
      "Validation Step 350/1568 | Batch Loss: 2.1383 | Batch Time: 0.14s\n",
      "Validation Step 351/1568 | Batch Loss: 5.4261 | Batch Time: 0.14s\n",
      "Validation Step 352/1568 | Batch Loss: 2.0670 | Batch Time: 0.14s\n",
      "Validation Step 353/1568 | Batch Loss: 2.4368 | Batch Time: 0.14s\n",
      "Validation Step 354/1568 | Batch Loss: 1.9869 | Batch Time: 0.14s\n",
      "Validation Step 355/1568 | Batch Loss: 2.1976 | Batch Time: 0.14s\n",
      "Validation Step 356/1568 | Batch Loss: 1.8708 | Batch Time: 0.14s\n",
      "Validation Step 357/1568 | Batch Loss: 3.6356 | Batch Time: 0.14s\n",
      "Validation Step 358/1568 | Batch Loss: 3.1654 | Batch Time: 0.15s\n",
      "Validation Step 359/1568 | Batch Loss: 3.0982 | Batch Time: 0.14s\n",
      "Validation Step 360/1568 | Batch Loss: 2.6847 | Batch Time: 0.14s\n",
      "Validation Step 361/1568 | Batch Loss: 1.9589 | Batch Time: 0.14s\n",
      "Validation Step 362/1568 | Batch Loss: 2.7145 | Batch Time: 0.14s\n",
      "Validation Step 363/1568 | Batch Loss: 4.8355 | Batch Time: 0.14s\n",
      "Validation Step 364/1568 | Batch Loss: 2.2205 | Batch Time: 0.14s\n",
      "Validation Step 365/1568 | Batch Loss: 3.8024 | Batch Time: 0.14s\n",
      "Validation Step 366/1568 | Batch Loss: 2.5195 | Batch Time: 0.14s\n",
      "Validation Step 367/1568 | Batch Loss: 2.3898 | Batch Time: 0.14s\n",
      "Validation Step 368/1568 | Batch Loss: 1.7452 | Batch Time: 0.14s\n",
      "Validation Step 369/1568 | Batch Loss: 3.2967 | Batch Time: 0.14s\n",
      "Validation Step 370/1568 | Batch Loss: 2.5414 | Batch Time: 0.14s\n",
      "Validation Step 371/1568 | Batch Loss: 2.3705 | Batch Time: 0.14s\n",
      "Validation Step 372/1568 | Batch Loss: 2.7333 | Batch Time: 0.14s\n",
      "Validation Step 373/1568 | Batch Loss: 2.7624 | Batch Time: 0.14s\n",
      "Validation Step 374/1568 | Batch Loss: 1.5847 | Batch Time: 0.14s\n",
      "Validation Step 375/1568 | Batch Loss: 2.1794 | Batch Time: 0.14s\n",
      "Validation Step 376/1568 | Batch Loss: 3.0693 | Batch Time: 0.14s\n",
      "Validation Step 377/1568 | Batch Loss: 1.8224 | Batch Time: 0.14s\n",
      "Validation Step 378/1568 | Batch Loss: 2.4699 | Batch Time: 0.14s\n",
      "Validation Step 379/1568 | Batch Loss: 1.8979 | Batch Time: 0.14s\n",
      "Validation Step 380/1568 | Batch Loss: 2.7689 | Batch Time: 0.14s\n",
      "Validation Step 381/1568 | Batch Loss: 2.4382 | Batch Time: 0.14s\n",
      "Validation Step 382/1568 | Batch Loss: 2.3254 | Batch Time: 0.14s\n",
      "Validation Step 383/1568 | Batch Loss: 2.9532 | Batch Time: 0.14s\n",
      "Validation Step 384/1568 | Batch Loss: 2.7383 | Batch Time: 0.14s\n",
      "Validation Step 385/1568 | Batch Loss: 2.3476 | Batch Time: 0.14s\n",
      "Validation Step 386/1568 | Batch Loss: 2.4218 | Batch Time: 0.14s\n",
      "Validation Step 387/1568 | Batch Loss: 2.6125 | Batch Time: 0.14s\n",
      "Validation Step 388/1568 | Batch Loss: 1.7511 | Batch Time: 0.14s\n",
      "Validation Step 389/1568 | Batch Loss: 3.6838 | Batch Time: 0.14s\n",
      "Validation Step 390/1568 | Batch Loss: 1.7787 | Batch Time: 0.14s\n",
      "Validation Step 391/1568 | Batch Loss: 1.6099 | Batch Time: 0.14s\n",
      "Validation Step 392/1568 | Batch Loss: 2.7757 | Batch Time: 0.14s\n",
      "Validation Step 393/1568 | Batch Loss: 3.8104 | Batch Time: 0.14s\n",
      "Validation Step 394/1568 | Batch Loss: 1.3772 | Batch Time: 0.14s\n",
      "Validation Step 395/1568 | Batch Loss: 3.5308 | Batch Time: 0.14s\n",
      "Validation Step 396/1568 | Batch Loss: 2.5768 | Batch Time: 0.14s\n",
      "Validation Step 397/1568 | Batch Loss: 2.7585 | Batch Time: 0.14s\n",
      "Validation Step 398/1568 | Batch Loss: 3.2835 | Batch Time: 0.14s\n",
      "Validation Step 399/1568 | Batch Loss: 2.6345 | Batch Time: 0.14s\n",
      "Validation Step 400/1568 | Batch Loss: 3.4091 | Batch Time: 0.14s\n",
      "Validation Step 401/1568 | Batch Loss: 3.1868 | Batch Time: 0.14s\n",
      "Validation Step 402/1568 | Batch Loss: 2.2073 | Batch Time: 0.14s\n",
      "Validation Step 403/1568 | Batch Loss: 1.7120 | Batch Time: 0.14s\n",
      "Validation Step 404/1568 | Batch Loss: 2.1778 | Batch Time: 0.14s\n",
      "Validation Step 405/1568 | Batch Loss: 1.8418 | Batch Time: 0.14s\n",
      "Validation Step 406/1568 | Batch Loss: 3.1394 | Batch Time: 0.14s\n",
      "Validation Step 407/1568 | Batch Loss: 2.1663 | Batch Time: 0.14s\n",
      "Validation Step 408/1568 | Batch Loss: 2.2181 | Batch Time: 0.14s\n",
      "Validation Step 409/1568 | Batch Loss: 2.3615 | Batch Time: 0.14s\n",
      "Validation Step 410/1568 | Batch Loss: 2.5897 | Batch Time: 0.14s\n",
      "Validation Step 411/1568 | Batch Loss: 1.8401 | Batch Time: 0.14s\n",
      "Validation Step 412/1568 | Batch Loss: 3.2325 | Batch Time: 0.14s\n",
      "Validation Step 413/1568 | Batch Loss: 2.7599 | Batch Time: 0.14s\n",
      "Validation Step 414/1568 | Batch Loss: 3.2838 | Batch Time: 0.14s\n",
      "Validation Step 415/1568 | Batch Loss: 1.6819 | Batch Time: 0.14s\n",
      "Validation Step 416/1568 | Batch Loss: 2.3015 | Batch Time: 0.14s\n",
      "Validation Step 417/1568 | Batch Loss: 4.0887 | Batch Time: 0.14s\n",
      "Validation Step 418/1568 | Batch Loss: 2.4899 | Batch Time: 0.14s\n",
      "Validation Step 419/1568 | Batch Loss: 2.1332 | Batch Time: 0.14s\n",
      "Validation Step 420/1568 | Batch Loss: 1.9474 | Batch Time: 0.14s\n",
      "Validation Step 421/1568 | Batch Loss: 4.3128 | Batch Time: 0.14s\n",
      "Validation Step 422/1568 | Batch Loss: 2.0622 | Batch Time: 0.14s\n",
      "Validation Step 423/1568 | Batch Loss: 3.7098 | Batch Time: 0.14s\n",
      "Validation Step 424/1568 | Batch Loss: 2.2794 | Batch Time: 0.14s\n",
      "Validation Step 425/1568 | Batch Loss: 3.1014 | Batch Time: 0.14s\n",
      "Validation Step 426/1568 | Batch Loss: 1.3375 | Batch Time: 0.14s\n",
      "Validation Step 427/1568 | Batch Loss: 2.4367 | Batch Time: 0.14s\n",
      "Validation Step 428/1568 | Batch Loss: 3.9145 | Batch Time: 0.14s\n",
      "Validation Step 429/1568 | Batch Loss: 1.5559 | Batch Time: 0.14s\n",
      "Validation Step 430/1568 | Batch Loss: 1.9532 | Batch Time: 0.14s\n",
      "Validation Step 431/1568 | Batch Loss: 3.0395 | Batch Time: 0.14s\n",
      "Validation Step 432/1568 | Batch Loss: 3.0557 | Batch Time: 0.14s\n",
      "Validation Step 433/1568 | Batch Loss: 1.9236 | Batch Time: 0.14s\n",
      "Validation Step 434/1568 | Batch Loss: 1.7129 | Batch Time: 0.14s\n",
      "Validation Step 435/1568 | Batch Loss: 2.1969 | Batch Time: 0.14s\n",
      "Validation Step 436/1568 | Batch Loss: 1.9762 | Batch Time: 0.14s\n",
      "Validation Step 437/1568 | Batch Loss: 2.3722 | Batch Time: 0.13s\n",
      "Validation Step 438/1568 | Batch Loss: 3.0559 | Batch Time: 0.14s\n",
      "Validation Step 439/1568 | Batch Loss: 1.9522 | Batch Time: 0.14s\n",
      "Validation Step 440/1568 | Batch Loss: 2.4552 | Batch Time: 0.14s\n",
      "Validation Step 441/1568 | Batch Loss: 3.5689 | Batch Time: 0.14s\n",
      "Validation Step 442/1568 | Batch Loss: 1.9762 | Batch Time: 0.13s\n",
      "Validation Step 443/1568 | Batch Loss: 2.6118 | Batch Time: 0.14s\n",
      "Validation Step 444/1568 | Batch Loss: 2.0256 | Batch Time: 0.14s\n",
      "Validation Step 445/1568 | Batch Loss: 2.1501 | Batch Time: 0.14s\n",
      "Validation Step 446/1568 | Batch Loss: 3.3689 | Batch Time: 0.14s\n",
      "Validation Step 447/1568 | Batch Loss: 4.6325 | Batch Time: 0.14s\n",
      "Validation Step 448/1568 | Batch Loss: 3.3446 | Batch Time: 0.13s\n",
      "Validation Step 449/1568 | Batch Loss: 2.4890 | Batch Time: 0.14s\n",
      "Validation Step 450/1568 | Batch Loss: 2.8225 | Batch Time: 0.14s\n",
      "Validation Step 451/1568 | Batch Loss: 1.6232 | Batch Time: 0.14s\n",
      "Validation Step 452/1568 | Batch Loss: 2.4958 | Batch Time: 0.14s\n",
      "Validation Step 453/1568 | Batch Loss: 2.9105 | Batch Time: 0.14s\n",
      "Validation Step 454/1568 | Batch Loss: 2.7924 | Batch Time: 0.14s\n",
      "Validation Step 455/1568 | Batch Loss: 1.4236 | Batch Time: 0.14s\n",
      "Validation Step 456/1568 | Batch Loss: 1.7003 | Batch Time: 0.14s\n",
      "Validation Step 457/1568 | Batch Loss: 3.3771 | Batch Time: 0.14s\n",
      "Validation Step 458/1568 | Batch Loss: 2.3743 | Batch Time: 0.14s\n",
      "Validation Step 459/1568 | Batch Loss: 2.0849 | Batch Time: 0.14s\n",
      "Validation Step 460/1568 | Batch Loss: 1.7344 | Batch Time: 0.14s\n",
      "Validation Step 461/1568 | Batch Loss: 1.7245 | Batch Time: 0.14s\n",
      "Validation Step 462/1568 | Batch Loss: 2.2157 | Batch Time: 0.14s\n",
      "Validation Step 463/1568 | Batch Loss: 1.2962 | Batch Time: 0.14s\n",
      "Validation Step 464/1568 | Batch Loss: 2.7417 | Batch Time: 0.15s\n",
      "Validation Step 465/1568 | Batch Loss: 3.1910 | Batch Time: 0.13s\n",
      "Validation Step 466/1568 | Batch Loss: 3.1712 | Batch Time: 0.14s\n",
      "Validation Step 467/1568 | Batch Loss: 2.3464 | Batch Time: 0.14s\n",
      "Validation Step 468/1568 | Batch Loss: 3.1048 | Batch Time: 0.14s\n",
      "Validation Step 469/1568 | Batch Loss: 3.2909 | Batch Time: 0.14s\n",
      "Validation Step 470/1568 | Batch Loss: 2.7793 | Batch Time: 0.14s\n",
      "Validation Step 471/1568 | Batch Loss: 1.9726 | Batch Time: 0.14s\n",
      "Validation Step 472/1568 | Batch Loss: 1.9193 | Batch Time: 0.14s\n",
      "Validation Step 473/1568 | Batch Loss: 1.5695 | Batch Time: 0.14s\n",
      "Validation Step 474/1568 | Batch Loss: 2.2217 | Batch Time: 0.14s\n",
      "Validation Step 475/1568 | Batch Loss: 2.8790 | Batch Time: 0.14s\n",
      "Validation Step 476/1568 | Batch Loss: 1.7236 | Batch Time: 0.14s\n",
      "Validation Step 477/1568 | Batch Loss: 2.3852 | Batch Time: 0.13s\n",
      "Validation Step 478/1568 | Batch Loss: 2.0768 | Batch Time: 0.14s\n",
      "Validation Step 479/1568 | Batch Loss: 1.3199 | Batch Time: 0.14s\n",
      "Validation Step 480/1568 | Batch Loss: 3.5894 | Batch Time: 0.14s\n",
      "Validation Step 481/1568 | Batch Loss: 2.4979 | Batch Time: 0.14s\n",
      "Validation Step 482/1568 | Batch Loss: 1.5719 | Batch Time: 0.14s\n",
      "Validation Step 483/1568 | Batch Loss: 2.0579 | Batch Time: 0.14s\n",
      "Validation Step 484/1568 | Batch Loss: 4.3073 | Batch Time: 0.13s\n",
      "Validation Step 485/1568 | Batch Loss: 2.2385 | Batch Time: 0.14s\n",
      "Validation Step 486/1568 | Batch Loss: 1.6573 | Batch Time: 0.14s\n",
      "Validation Step 487/1568 | Batch Loss: 3.2893 | Batch Time: 0.14s\n",
      "Validation Step 488/1568 | Batch Loss: 1.4985 | Batch Time: 0.14s\n",
      "Validation Step 489/1568 | Batch Loss: 1.8757 | Batch Time: 0.14s\n",
      "Validation Step 490/1568 | Batch Loss: 2.6076 | Batch Time: 0.14s\n",
      "Validation Step 491/1568 | Batch Loss: 1.6585 | Batch Time: 0.14s\n",
      "Validation Step 492/1568 | Batch Loss: 2.4620 | Batch Time: 0.14s\n",
      "Validation Step 493/1568 | Batch Loss: 2.7701 | Batch Time: 0.14s\n",
      "Validation Step 494/1568 | Batch Loss: 1.9823 | Batch Time: 0.14s\n",
      "Validation Step 495/1568 | Batch Loss: 2.3949 | Batch Time: 0.14s\n",
      "Validation Step 496/1568 | Batch Loss: 2.6538 | Batch Time: 0.14s\n",
      "Validation Step 497/1568 | Batch Loss: 2.4119 | Batch Time: 0.14s\n",
      "Validation Step 498/1568 | Batch Loss: 1.5409 | Batch Time: 0.14s\n",
      "Validation Step 499/1568 | Batch Loss: 2.3638 | Batch Time: 0.14s\n",
      "Validation Step 500/1568 | Batch Loss: 3.2666 | Batch Time: 0.14s\n",
      "Validation Step 501/1568 | Batch Loss: 3.0362 | Batch Time: 0.13s\n",
      "Validation Step 502/1568 | Batch Loss: 2.6300 | Batch Time: 0.14s\n",
      "Validation Step 503/1568 | Batch Loss: 2.6833 | Batch Time: 0.14s\n",
      "Validation Step 504/1568 | Batch Loss: 2.7841 | Batch Time: 0.14s\n",
      "Validation Step 505/1568 | Batch Loss: 1.8155 | Batch Time: 0.14s\n",
      "Validation Step 506/1568 | Batch Loss: 2.1553 | Batch Time: 0.14s\n",
      "Validation Step 507/1568 | Batch Loss: 1.2895 | Batch Time: 0.14s\n",
      "Validation Step 508/1568 | Batch Loss: 2.5696 | Batch Time: 0.14s\n",
      "Validation Step 509/1568 | Batch Loss: 2.2669 | Batch Time: 0.14s\n",
      "Validation Step 510/1568 | Batch Loss: 1.5967 | Batch Time: 0.15s\n",
      "Validation Step 511/1568 | Batch Loss: 3.4321 | Batch Time: 0.14s\n",
      "Validation Step 512/1568 | Batch Loss: 1.4678 | Batch Time: 0.14s\n",
      "Validation Step 513/1568 | Batch Loss: 3.0497 | Batch Time: 0.14s\n",
      "Validation Step 514/1568 | Batch Loss: 2.9531 | Batch Time: 0.14s\n",
      "Validation Step 515/1568 | Batch Loss: 2.2969 | Batch Time: 0.14s\n",
      "Validation Step 516/1568 | Batch Loss: 2.6327 | Batch Time: 0.14s\n",
      "Validation Step 517/1568 | Batch Loss: 2.1820 | Batch Time: 0.14s\n",
      "Validation Step 518/1568 | Batch Loss: 3.0229 | Batch Time: 0.14s\n",
      "Validation Step 519/1568 | Batch Loss: 2.6051 | Batch Time: 0.14s\n",
      "Validation Step 520/1568 | Batch Loss: 2.3255 | Batch Time: 0.14s\n",
      "Validation Step 521/1568 | Batch Loss: 3.3877 | Batch Time: 0.14s\n",
      "Validation Step 522/1568 | Batch Loss: 1.4846 | Batch Time: 0.14s\n",
      "Validation Step 523/1568 | Batch Loss: 1.8630 | Batch Time: 0.14s\n",
      "Validation Step 524/1568 | Batch Loss: 2.8564 | Batch Time: 0.14s\n",
      "Validation Step 525/1568 | Batch Loss: 1.8515 | Batch Time: 0.14s\n",
      "Validation Step 526/1568 | Batch Loss: 2.9454 | Batch Time: 0.14s\n",
      "Validation Step 527/1568 | Batch Loss: 4.1256 | Batch Time: 0.13s\n",
      "Validation Step 528/1568 | Batch Loss: 3.3475 | Batch Time: 0.14s\n",
      "Validation Step 529/1568 | Batch Loss: 1.8493 | Batch Time: 0.14s\n",
      "Validation Step 530/1568 | Batch Loss: 1.9334 | Batch Time: 0.14s\n",
      "Validation Step 531/1568 | Batch Loss: 2.7957 | Batch Time: 0.13s\n",
      "Validation Step 532/1568 | Batch Loss: 3.0800 | Batch Time: 0.14s\n",
      "Validation Step 533/1568 | Batch Loss: 3.3251 | Batch Time: 0.14s\n",
      "Validation Step 534/1568 | Batch Loss: 1.5379 | Batch Time: 0.14s\n",
      "Validation Step 535/1568 | Batch Loss: 1.5040 | Batch Time: 0.14s\n",
      "Validation Step 536/1568 | Batch Loss: 3.7541 | Batch Time: 0.14s\n",
      "Validation Step 537/1568 | Batch Loss: 1.6768 | Batch Time: 0.14s\n",
      "Validation Step 538/1568 | Batch Loss: 2.1245 | Batch Time: 0.15s\n",
      "Validation Step 539/1568 | Batch Loss: 3.9901 | Batch Time: 0.14s\n",
      "Validation Step 540/1568 | Batch Loss: 2.8970 | Batch Time: 0.14s\n",
      "Validation Step 541/1568 | Batch Loss: 1.8208 | Batch Time: 0.14s\n",
      "Validation Step 542/1568 | Batch Loss: 1.6204 | Batch Time: 0.14s\n",
      "Validation Step 543/1568 | Batch Loss: 3.8816 | Batch Time: 0.14s\n",
      "Validation Step 544/1568 | Batch Loss: 3.0142 | Batch Time: 0.14s\n",
      "Validation Step 545/1568 | Batch Loss: 3.0703 | Batch Time: 0.14s\n",
      "Validation Step 546/1568 | Batch Loss: 1.7928 | Batch Time: 0.14s\n",
      "Validation Step 547/1568 | Batch Loss: 1.6316 | Batch Time: 0.14s\n",
      "Validation Step 548/1568 | Batch Loss: 1.6470 | Batch Time: 0.14s\n",
      "Validation Step 549/1568 | Batch Loss: 1.9360 | Batch Time: 0.14s\n",
      "Validation Step 550/1568 | Batch Loss: 2.0840 | Batch Time: 0.14s\n",
      "Validation Step 551/1568 | Batch Loss: 1.8030 | Batch Time: 0.14s\n",
      "Validation Step 552/1568 | Batch Loss: 1.5545 | Batch Time: 0.14s\n",
      "Validation Step 553/1568 | Batch Loss: 2.7570 | Batch Time: 0.15s\n",
      "Validation Step 554/1568 | Batch Loss: 2.3296 | Batch Time: 0.14s\n",
      "Validation Step 555/1568 | Batch Loss: 2.7820 | Batch Time: 0.14s\n",
      "Validation Step 556/1568 | Batch Loss: 2.2851 | Batch Time: 0.14s\n",
      "Validation Step 557/1568 | Batch Loss: 2.9985 | Batch Time: 0.14s\n",
      "Validation Step 558/1568 | Batch Loss: 3.0710 | Batch Time: 0.14s\n",
      "Validation Step 559/1568 | Batch Loss: 1.8437 | Batch Time: 0.14s\n",
      "Validation Step 560/1568 | Batch Loss: 2.2185 | Batch Time: 0.14s\n",
      "Validation Step 561/1568 | Batch Loss: 2.0215 | Batch Time: 0.14s\n",
      "Validation Step 562/1568 | Batch Loss: 1.4558 | Batch Time: 0.14s\n",
      "Validation Step 563/1568 | Batch Loss: 1.6734 | Batch Time: 0.14s\n",
      "Validation Step 564/1568 | Batch Loss: 2.3702 | Batch Time: 0.14s\n",
      "Validation Step 565/1568 | Batch Loss: 3.1403 | Batch Time: 0.14s\n",
      "Validation Step 566/1568 | Batch Loss: 2.3034 | Batch Time: 0.14s\n",
      "Validation Step 567/1568 | Batch Loss: 3.2352 | Batch Time: 0.14s\n",
      "Validation Step 568/1568 | Batch Loss: 2.5346 | Batch Time: 0.14s\n",
      "Validation Step 569/1568 | Batch Loss: 2.2290 | Batch Time: 0.14s\n",
      "Validation Step 570/1568 | Batch Loss: 2.8594 | Batch Time: 0.14s\n",
      "Validation Step 571/1568 | Batch Loss: 1.2862 | Batch Time: 0.14s\n",
      "Validation Step 572/1568 | Batch Loss: 2.2229 | Batch Time: 0.14s\n",
      "Validation Step 573/1568 | Batch Loss: 4.6878 | Batch Time: 0.14s\n",
      "Validation Step 574/1568 | Batch Loss: 2.0477 | Batch Time: 0.14s\n",
      "Validation Step 575/1568 | Batch Loss: 2.5792 | Batch Time: 0.14s\n",
      "Validation Step 576/1568 | Batch Loss: 2.3251 | Batch Time: 0.14s\n",
      "Validation Step 577/1568 | Batch Loss: 2.2086 | Batch Time: 0.14s\n",
      "Validation Step 578/1568 | Batch Loss: 3.2791 | Batch Time: 0.14s\n",
      "Validation Step 579/1568 | Batch Loss: 2.3813 | Batch Time: 0.14s\n",
      "Validation Step 580/1568 | Batch Loss: 2.3850 | Batch Time: 0.14s\n",
      "Validation Step 581/1568 | Batch Loss: 3.4886 | Batch Time: 0.14s\n",
      "Validation Step 582/1568 | Batch Loss: 2.6501 | Batch Time: 0.14s\n",
      "Validation Step 583/1568 | Batch Loss: 3.3579 | Batch Time: 0.14s\n",
      "Validation Step 584/1568 | Batch Loss: 1.9625 | Batch Time: 0.15s\n",
      "Validation Step 585/1568 | Batch Loss: 1.6319 | Batch Time: 0.14s\n",
      "Validation Step 586/1568 | Batch Loss: 1.3407 | Batch Time: 0.14s\n",
      "Validation Step 587/1568 | Batch Loss: 2.3051 | Batch Time: 0.14s\n",
      "Validation Step 588/1568 | Batch Loss: 1.8497 | Batch Time: 0.14s\n",
      "Validation Step 589/1568 | Batch Loss: 2.6633 | Batch Time: 0.14s\n",
      "Validation Step 590/1568 | Batch Loss: 1.9693 | Batch Time: 0.14s\n",
      "Validation Step 591/1568 | Batch Loss: 4.0496 | Batch Time: 0.14s\n",
      "Validation Step 592/1568 | Batch Loss: 3.0199 | Batch Time: 0.14s\n",
      "Validation Step 593/1568 | Batch Loss: 2.3885 | Batch Time: 0.14s\n",
      "Validation Step 594/1568 | Batch Loss: 4.3048 | Batch Time: 0.14s\n",
      "Validation Step 595/1568 | Batch Loss: 1.6233 | Batch Time: 0.15s\n",
      "Validation Step 596/1568 | Batch Loss: 3.1312 | Batch Time: 0.14s\n",
      "Validation Step 597/1568 | Batch Loss: 2.4872 | Batch Time: 0.15s\n",
      "Validation Step 598/1568 | Batch Loss: 2.7284 | Batch Time: 0.14s\n",
      "Validation Step 599/1568 | Batch Loss: 1.6395 | Batch Time: 0.14s\n",
      "Validation Step 600/1568 | Batch Loss: 2.2175 | Batch Time: 0.14s\n",
      "Validation Step 601/1568 | Batch Loss: 2.2317 | Batch Time: 0.14s\n",
      "Validation Step 602/1568 | Batch Loss: 1.8000 | Batch Time: 0.15s\n",
      "Validation Step 603/1568 | Batch Loss: 2.4771 | Batch Time: 0.14s\n",
      "Validation Step 604/1568 | Batch Loss: 2.3950 | Batch Time: 0.14s\n",
      "Validation Step 605/1568 | Batch Loss: 1.5255 | Batch Time: 0.14s\n",
      "Validation Step 606/1568 | Batch Loss: 1.8136 | Batch Time: 0.14s\n",
      "Validation Step 607/1568 | Batch Loss: 2.0624 | Batch Time: 0.14s\n",
      "Validation Step 608/1568 | Batch Loss: 2.0655 | Batch Time: 0.14s\n",
      "Validation Step 609/1568 | Batch Loss: 3.1214 | Batch Time: 0.14s\n",
      "Validation Step 610/1568 | Batch Loss: 2.3458 | Batch Time: 0.14s\n",
      "Validation Step 611/1568 | Batch Loss: 2.7761 | Batch Time: 0.14s\n",
      "Validation Step 612/1568 | Batch Loss: 2.7445 | Batch Time: 0.14s\n",
      "Validation Step 613/1568 | Batch Loss: 1.4089 | Batch Time: 0.14s\n",
      "Validation Step 614/1568 | Batch Loss: 2.0932 | Batch Time: 0.14s\n",
      "Validation Step 615/1568 | Batch Loss: 1.5001 | Batch Time: 0.14s\n",
      "Validation Step 616/1568 | Batch Loss: 1.6892 | Batch Time: 0.14s\n",
      "Validation Step 617/1568 | Batch Loss: 1.9341 | Batch Time: 0.14s\n",
      "Validation Step 618/1568 | Batch Loss: 1.9496 | Batch Time: 0.14s\n",
      "Validation Step 619/1568 | Batch Loss: 2.1296 | Batch Time: 0.14s\n",
      "Validation Step 620/1568 | Batch Loss: 2.6312 | Batch Time: 0.14s\n",
      "Validation Step 621/1568 | Batch Loss: 3.2859 | Batch Time: 0.14s\n",
      "Validation Step 622/1568 | Batch Loss: 2.1996 | Batch Time: 0.14s\n",
      "Validation Step 623/1568 | Batch Loss: 2.4800 | Batch Time: 0.14s\n",
      "Validation Step 624/1568 | Batch Loss: 2.3783 | Batch Time: 0.13s\n",
      "Validation Step 625/1568 | Batch Loss: 3.9078 | Batch Time: 0.14s\n",
      "Validation Step 626/1568 | Batch Loss: 2.3664 | Batch Time: 0.14s\n",
      "Validation Step 627/1568 | Batch Loss: 2.9006 | Batch Time: 0.14s\n",
      "Validation Step 628/1568 | Batch Loss: 2.3212 | Batch Time: 0.14s\n",
      "Validation Step 629/1568 | Batch Loss: 2.7088 | Batch Time: 0.14s\n",
      "Validation Step 630/1568 | Batch Loss: 2.7612 | Batch Time: 0.14s\n",
      "Validation Step 631/1568 | Batch Loss: 2.4606 | Batch Time: 0.14s\n",
      "Validation Step 632/1568 | Batch Loss: 2.3812 | Batch Time: 0.14s\n",
      "Validation Step 633/1568 | Batch Loss: 3.4689 | Batch Time: 0.14s\n",
      "Validation Step 634/1568 | Batch Loss: 2.8515 | Batch Time: 0.13s\n",
      "Validation Step 635/1568 | Batch Loss: 1.3543 | Batch Time: 0.14s\n",
      "Validation Step 636/1568 | Batch Loss: 1.5785 | Batch Time: 0.14s\n",
      "Validation Step 637/1568 | Batch Loss: 3.6408 | Batch Time: 0.14s\n",
      "Validation Step 638/1568 | Batch Loss: 3.3193 | Batch Time: 0.14s\n",
      "Validation Step 639/1568 | Batch Loss: 3.4265 | Batch Time: 0.14s\n",
      "Validation Step 640/1568 | Batch Loss: 1.8306 | Batch Time: 0.14s\n",
      "Validation Step 641/1568 | Batch Loss: 2.0479 | Batch Time: 0.13s\n",
      "Validation Step 642/1568 | Batch Loss: 1.6275 | Batch Time: 0.14s\n",
      "Validation Step 643/1568 | Batch Loss: 2.9420 | Batch Time: 0.14s\n",
      "Validation Step 644/1568 | Batch Loss: 3.3686 | Batch Time: 0.14s\n",
      "Validation Step 645/1568 | Batch Loss: 2.0916 | Batch Time: 0.14s\n",
      "Validation Step 646/1568 | Batch Loss: 2.4956 | Batch Time: 0.14s\n",
      "Validation Step 647/1568 | Batch Loss: 1.7401 | Batch Time: 0.14s\n",
      "Validation Step 648/1568 | Batch Loss: 1.4850 | Batch Time: 0.14s\n",
      "Validation Step 649/1568 | Batch Loss: 2.1252 | Batch Time: 0.14s\n",
      "Validation Step 650/1568 | Batch Loss: 2.9729 | Batch Time: 0.14s\n",
      "Validation Step 651/1568 | Batch Loss: 2.0657 | Batch Time: 0.14s\n",
      "Validation Step 652/1568 | Batch Loss: 1.5350 | Batch Time: 0.14s\n",
      "Validation Step 653/1568 | Batch Loss: 2.7064 | Batch Time: 0.14s\n",
      "Validation Step 654/1568 | Batch Loss: 2.1257 | Batch Time: 0.14s\n",
      "Validation Step 655/1568 | Batch Loss: 2.6368 | Batch Time: 0.14s\n",
      "Validation Step 656/1568 | Batch Loss: 2.2898 | Batch Time: 0.14s\n",
      "Validation Step 657/1568 | Batch Loss: 2.1430 | Batch Time: 0.14s\n",
      "Validation Step 658/1568 | Batch Loss: 2.5424 | Batch Time: 0.14s\n",
      "Validation Step 659/1568 | Batch Loss: 2.3071 | Batch Time: 0.14s\n",
      "Validation Step 660/1568 | Batch Loss: 1.7223 | Batch Time: 0.14s\n",
      "Validation Step 661/1568 | Batch Loss: 1.5130 | Batch Time: 0.14s\n",
      "Validation Step 662/1568 | Batch Loss: 2.1347 | Batch Time: 0.14s\n",
      "Validation Step 663/1568 | Batch Loss: 2.8663 | Batch Time: 0.14s\n",
      "Validation Step 664/1568 | Batch Loss: 1.9448 | Batch Time: 0.15s\n",
      "Validation Step 665/1568 | Batch Loss: 4.2934 | Batch Time: 0.14s\n",
      "Validation Step 666/1568 | Batch Loss: 4.1964 | Batch Time: 0.14s\n",
      "Validation Step 667/1568 | Batch Loss: 2.1611 | Batch Time: 0.14s\n",
      "Validation Step 668/1568 | Batch Loss: 3.2868 | Batch Time: 0.14s\n",
      "Validation Step 669/1568 | Batch Loss: 1.7749 | Batch Time: 0.14s\n",
      "Validation Step 670/1568 | Batch Loss: 1.9431 | Batch Time: 0.14s\n",
      "Validation Step 671/1568 | Batch Loss: 3.6448 | Batch Time: 0.14s\n",
      "Validation Step 672/1568 | Batch Loss: 2.1880 | Batch Time: 0.14s\n",
      "Validation Step 673/1568 | Batch Loss: 1.8437 | Batch Time: 0.14s\n",
      "Validation Step 674/1568 | Batch Loss: 1.7980 | Batch Time: 0.14s\n",
      "Validation Step 675/1568 | Batch Loss: 3.3154 | Batch Time: 0.14s\n",
      "Validation Step 676/1568 | Batch Loss: 1.5578 | Batch Time: 0.14s\n",
      "Validation Step 677/1568 | Batch Loss: 2.0260 | Batch Time: 0.14s\n",
      "Validation Step 678/1568 | Batch Loss: 1.4902 | Batch Time: 0.14s\n",
      "Validation Step 679/1568 | Batch Loss: 1.7986 | Batch Time: 0.14s\n",
      "Validation Step 680/1568 | Batch Loss: 3.5042 | Batch Time: 0.14s\n",
      "Validation Step 681/1568 | Batch Loss: 2.3760 | Batch Time: 0.14s\n",
      "Validation Step 682/1568 | Batch Loss: 2.9181 | Batch Time: 0.14s\n",
      "Validation Step 683/1568 | Batch Loss: 2.4974 | Batch Time: 0.14s\n",
      "Validation Step 684/1568 | Batch Loss: 3.1606 | Batch Time: 0.14s\n",
      "Validation Step 685/1568 | Batch Loss: 3.0134 | Batch Time: 0.14s\n",
      "Validation Step 686/1568 | Batch Loss: 2.4593 | Batch Time: 0.14s\n",
      "Validation Step 687/1568 | Batch Loss: 3.2965 | Batch Time: 0.14s\n",
      "Validation Step 688/1568 | Batch Loss: 2.7499 | Batch Time: 0.14s\n",
      "Validation Step 689/1568 | Batch Loss: 3.0544 | Batch Time: 0.14s\n",
      "Validation Step 690/1568 | Batch Loss: 2.2694 | Batch Time: 0.14s\n",
      "Validation Step 691/1568 | Batch Loss: 2.5274 | Batch Time: 0.14s\n",
      "Validation Step 692/1568 | Batch Loss: 1.5684 | Batch Time: 0.14s\n",
      "Validation Step 693/1568 | Batch Loss: 3.3287 | Batch Time: 0.14s\n",
      "Validation Step 694/1568 | Batch Loss: 2.2822 | Batch Time: 0.14s\n",
      "Validation Step 695/1568 | Batch Loss: 2.1330 | Batch Time: 0.14s\n",
      "Validation Step 696/1568 | Batch Loss: 1.8171 | Batch Time: 0.13s\n",
      "Validation Step 697/1568 | Batch Loss: 1.6403 | Batch Time: 0.14s\n",
      "Validation Step 698/1568 | Batch Loss: 2.2589 | Batch Time: 0.14s\n",
      "Validation Step 699/1568 | Batch Loss: 3.1011 | Batch Time: 0.14s\n",
      "Validation Step 700/1568 | Batch Loss: 2.3397 | Batch Time: 0.14s\n",
      "Validation Step 701/1568 | Batch Loss: 2.3147 | Batch Time: 0.14s\n",
      "Validation Step 702/1568 | Batch Loss: 1.4959 | Batch Time: 0.14s\n",
      "Validation Step 703/1568 | Batch Loss: 1.6835 | Batch Time: 0.14s\n",
      "Validation Step 704/1568 | Batch Loss: 1.8144 | Batch Time: 0.14s\n",
      "Validation Step 705/1568 | Batch Loss: 2.4164 | Batch Time: 0.14s\n",
      "Validation Step 706/1568 | Batch Loss: 1.7436 | Batch Time: 0.15s\n",
      "Validation Step 707/1568 | Batch Loss: 3.1983 | Batch Time: 0.14s\n",
      "Validation Step 708/1568 | Batch Loss: 4.2544 | Batch Time: 0.15s\n",
      "Validation Step 709/1568 | Batch Loss: 1.8987 | Batch Time: 0.14s\n",
      "Validation Step 710/1568 | Batch Loss: 1.8700 | Batch Time: 0.14s\n",
      "Validation Step 711/1568 | Batch Loss: 1.6838 | Batch Time: 0.14s\n",
      "Validation Step 712/1568 | Batch Loss: 2.3851 | Batch Time: 0.14s\n",
      "Validation Step 713/1568 | Batch Loss: 2.5962 | Batch Time: 0.14s\n",
      "Validation Step 714/1568 | Batch Loss: 2.2887 | Batch Time: 0.14s\n",
      "Validation Step 715/1568 | Batch Loss: 2.7934 | Batch Time: 0.14s\n",
      "Validation Step 716/1568 | Batch Loss: 1.6744 | Batch Time: 0.14s\n",
      "Validation Step 717/1568 | Batch Loss: 2.0424 | Batch Time: 0.14s\n",
      "Validation Step 718/1568 | Batch Loss: 2.1009 | Batch Time: 0.14s\n",
      "Validation Step 719/1568 | Batch Loss: 1.8181 | Batch Time: 0.14s\n",
      "Validation Step 720/1568 | Batch Loss: 1.5447 | Batch Time: 0.14s\n",
      "Validation Step 721/1568 | Batch Loss: 1.6847 | Batch Time: 0.14s\n",
      "Validation Step 722/1568 | Batch Loss: 1.6529 | Batch Time: 0.14s\n",
      "Validation Step 723/1568 | Batch Loss: 3.4655 | Batch Time: 0.14s\n",
      "Validation Step 724/1568 | Batch Loss: 2.3388 | Batch Time: 0.14s\n",
      "Validation Step 725/1568 | Batch Loss: 2.6380 | Batch Time: 0.15s\n",
      "Validation Step 726/1568 | Batch Loss: 3.5408 | Batch Time: 0.14s\n",
      "Validation Step 727/1568 | Batch Loss: 1.7778 | Batch Time: 0.14s\n",
      "Validation Step 728/1568 | Batch Loss: 2.5332 | Batch Time: 0.14s\n",
      "Validation Step 729/1568 | Batch Loss: 2.2158 | Batch Time: 0.15s\n",
      "Validation Step 730/1568 | Batch Loss: 2.5273 | Batch Time: 0.14s\n",
      "Validation Step 731/1568 | Batch Loss: 1.5941 | Batch Time: 0.14s\n",
      "Validation Step 732/1568 | Batch Loss: 4.0791 | Batch Time: 0.14s\n",
      "Validation Step 733/1568 | Batch Loss: 1.7397 | Batch Time: 0.14s\n",
      "Validation Step 734/1568 | Batch Loss: 2.8120 | Batch Time: 0.14s\n",
      "Validation Step 735/1568 | Batch Loss: 2.0021 | Batch Time: 0.14s\n",
      "Validation Step 736/1568 | Batch Loss: 3.4850 | Batch Time: 0.14s\n",
      "Validation Step 737/1568 | Batch Loss: 2.2568 | Batch Time: 0.14s\n",
      "Validation Step 738/1568 | Batch Loss: 2.5102 | Batch Time: 0.14s\n",
      "Validation Step 739/1568 | Batch Loss: 2.0594 | Batch Time: 0.14s\n",
      "Validation Step 740/1568 | Batch Loss: 1.2319 | Batch Time: 0.14s\n",
      "Validation Step 741/1568 | Batch Loss: 3.0786 | Batch Time: 0.14s\n",
      "Validation Step 742/1568 | Batch Loss: 3.4972 | Batch Time: 0.14s\n",
      "Validation Step 743/1568 | Batch Loss: 2.1282 | Batch Time: 0.14s\n",
      "Validation Step 744/1568 | Batch Loss: 3.3826 | Batch Time: 0.14s\n",
      "Validation Step 745/1568 | Batch Loss: 2.0528 | Batch Time: 0.14s\n",
      "Validation Step 746/1568 | Batch Loss: 2.2346 | Batch Time: 0.14s\n",
      "Validation Step 747/1568 | Batch Loss: 2.6002 | Batch Time: 0.14s\n",
      "Validation Step 748/1568 | Batch Loss: 3.3194 | Batch Time: 0.14s\n",
      "Validation Step 749/1568 | Batch Loss: 2.2828 | Batch Time: 0.13s\n",
      "Validation Step 750/1568 | Batch Loss: 2.6763 | Batch Time: 0.14s\n",
      "Validation Step 751/1568 | Batch Loss: 1.4669 | Batch Time: 0.14s\n",
      "Validation Step 752/1568 | Batch Loss: 2.4722 | Batch Time: 0.14s\n",
      "Validation Step 753/1568 | Batch Loss: 2.2731 | Batch Time: 0.13s\n",
      "Validation Step 754/1568 | Batch Loss: 3.8014 | Batch Time: 0.14s\n",
      "Validation Step 755/1568 | Batch Loss: 2.7301 | Batch Time: 0.13s\n",
      "Validation Step 756/1568 | Batch Loss: 2.2730 | Batch Time: 0.14s\n",
      "Validation Step 757/1568 | Batch Loss: 2.8778 | Batch Time: 0.14s\n",
      "Validation Step 758/1568 | Batch Loss: 1.6427 | Batch Time: 0.14s\n",
      "Validation Step 759/1568 | Batch Loss: 2.3760 | Batch Time: 0.14s\n",
      "Validation Step 760/1568 | Batch Loss: 3.3432 | Batch Time: 0.14s\n",
      "Validation Step 761/1568 | Batch Loss: 2.2046 | Batch Time: 0.14s\n",
      "Validation Step 762/1568 | Batch Loss: 2.5366 | Batch Time: 0.14s\n",
      "Validation Step 763/1568 | Batch Loss: 3.1524 | Batch Time: 0.14s\n",
      "Validation Step 764/1568 | Batch Loss: 2.6592 | Batch Time: 0.14s\n",
      "Validation Step 765/1568 | Batch Loss: 1.6046 | Batch Time: 0.15s\n",
      "Validation Step 766/1568 | Batch Loss: 2.5359 | Batch Time: 0.14s\n",
      "Validation Step 767/1568 | Batch Loss: 2.4299 | Batch Time: 0.14s\n",
      "Validation Step 768/1568 | Batch Loss: 2.0821 | Batch Time: 0.14s\n",
      "Validation Step 769/1568 | Batch Loss: 2.1909 | Batch Time: 0.14s\n",
      "Validation Step 770/1568 | Batch Loss: 2.5303 | Batch Time: 0.14s\n",
      "Validation Step 771/1568 | Batch Loss: 2.3617 | Batch Time: 0.14s\n",
      "Validation Step 772/1568 | Batch Loss: 1.4806 | Batch Time: 0.14s\n",
      "Validation Step 773/1568 | Batch Loss: 2.4914 | Batch Time: 0.15s\n",
      "Validation Step 774/1568 | Batch Loss: 1.8121 | Batch Time: 0.14s\n",
      "Validation Step 775/1568 | Batch Loss: 3.6930 | Batch Time: 0.14s\n",
      "Validation Step 776/1568 | Batch Loss: 2.9674 | Batch Time: 0.14s\n",
      "Validation Step 777/1568 | Batch Loss: 1.9605 | Batch Time: 0.14s\n",
      "Validation Step 778/1568 | Batch Loss: 1.5740 | Batch Time: 0.14s\n",
      "Validation Step 779/1568 | Batch Loss: 4.2599 | Batch Time: 0.14s\n",
      "Validation Step 780/1568 | Batch Loss: 3.2308 | Batch Time: 0.14s\n",
      "Validation Step 781/1568 | Batch Loss: 1.3504 | Batch Time: 0.14s\n",
      "Validation Step 782/1568 | Batch Loss: 3.2068 | Batch Time: 0.14s\n",
      "Validation Step 783/1568 | Batch Loss: 4.7862 | Batch Time: 0.14s\n",
      "Validation Step 784/1568 | Batch Loss: 3.0154 | Batch Time: 0.14s\n",
      "Validation Step 785/1568 | Batch Loss: 2.6921 | Batch Time: 0.14s\n",
      "Validation Step 786/1568 | Batch Loss: 2.2632 | Batch Time: 0.14s\n",
      "Validation Step 787/1568 | Batch Loss: 4.2912 | Batch Time: 0.14s\n",
      "Validation Step 788/1568 | Batch Loss: 1.7391 | Batch Time: 0.14s\n",
      "Validation Step 789/1568 | Batch Loss: 2.6980 | Batch Time: 0.14s\n",
      "Validation Step 790/1568 | Batch Loss: 2.2307 | Batch Time: 0.14s\n",
      "Validation Step 791/1568 | Batch Loss: 2.3321 | Batch Time: 0.14s\n",
      "Validation Step 792/1568 | Batch Loss: 3.8135 | Batch Time: 0.14s\n",
      "Validation Step 793/1568 | Batch Loss: 2.2915 | Batch Time: 0.14s\n",
      "Validation Step 794/1568 | Batch Loss: 2.3520 | Batch Time: 0.14s\n",
      "Validation Step 795/1568 | Batch Loss: 2.3039 | Batch Time: 0.14s\n",
      "Validation Step 796/1568 | Batch Loss: 2.4344 | Batch Time: 0.14s\n",
      "Validation Step 797/1568 | Batch Loss: 2.6622 | Batch Time: 0.14s\n",
      "Validation Step 798/1568 | Batch Loss: 3.0242 | Batch Time: 0.14s\n",
      "Validation Step 799/1568 | Batch Loss: 3.0278 | Batch Time: 0.14s\n",
      "Validation Step 800/1568 | Batch Loss: 1.3964 | Batch Time: 0.14s\n",
      "Validation Step 801/1568 | Batch Loss: 3.4813 | Batch Time: 0.13s\n",
      "Validation Step 802/1568 | Batch Loss: 1.7945 | Batch Time: 0.14s\n",
      "Validation Step 803/1568 | Batch Loss: 2.0042 | Batch Time: 0.14s\n",
      "Validation Step 804/1568 | Batch Loss: 3.2964 | Batch Time: 0.14s\n",
      "Validation Step 805/1568 | Batch Loss: 1.7001 | Batch Time: 0.14s\n",
      "Validation Step 806/1568 | Batch Loss: 2.1478 | Batch Time: 0.14s\n",
      "Validation Step 807/1568 | Batch Loss: 3.1411 | Batch Time: 0.14s\n",
      "Validation Step 808/1568 | Batch Loss: 1.6978 | Batch Time: 0.14s\n",
      "Validation Step 809/1568 | Batch Loss: 1.5091 | Batch Time: 0.14s\n",
      "Validation Step 810/1568 | Batch Loss: 3.0261 | Batch Time: 0.14s\n",
      "Validation Step 811/1568 | Batch Loss: 2.3741 | Batch Time: 0.14s\n",
      "Validation Step 812/1568 | Batch Loss: 2.2589 | Batch Time: 0.14s\n",
      "Validation Step 813/1568 | Batch Loss: 2.1275 | Batch Time: 0.14s\n",
      "Validation Step 814/1568 | Batch Loss: 1.8775 | Batch Time: 0.14s\n",
      "Validation Step 815/1568 | Batch Loss: 1.5390 | Batch Time: 0.14s\n",
      "Validation Step 816/1568 | Batch Loss: 3.0096 | Batch Time: 0.14s\n",
      "Validation Step 817/1568 | Batch Loss: 2.0840 | Batch Time: 0.14s\n",
      "Validation Step 818/1568 | Batch Loss: 1.5981 | Batch Time: 0.14s\n",
      "Validation Step 819/1568 | Batch Loss: 3.7174 | Batch Time: 0.14s\n",
      "Validation Step 820/1568 | Batch Loss: 2.2684 | Batch Time: 0.14s\n",
      "Validation Step 821/1568 | Batch Loss: 1.9668 | Batch Time: 0.14s\n",
      "Validation Step 822/1568 | Batch Loss: 1.9401 | Batch Time: 0.14s\n",
      "Validation Step 823/1568 | Batch Loss: 2.6704 | Batch Time: 0.14s\n",
      "Validation Step 824/1568 | Batch Loss: 2.1776 | Batch Time: 0.14s\n",
      "Validation Step 825/1568 | Batch Loss: 2.7748 | Batch Time: 0.15s\n",
      "Validation Step 826/1568 | Batch Loss: 3.9466 | Batch Time: 0.13s\n",
      "Validation Step 827/1568 | Batch Loss: 2.1906 | Batch Time: 0.14s\n",
      "Validation Step 828/1568 | Batch Loss: 3.6190 | Batch Time: 0.14s\n",
      "Validation Step 829/1568 | Batch Loss: 2.8980 | Batch Time: 0.14s\n",
      "Validation Step 830/1568 | Batch Loss: 2.7626 | Batch Time: 0.14s\n",
      "Validation Step 831/1568 | Batch Loss: 1.5280 | Batch Time: 0.15s\n",
      "Validation Step 832/1568 | Batch Loss: 3.2546 | Batch Time: 0.14s\n",
      "Validation Step 833/1568 | Batch Loss: 3.6257 | Batch Time: 0.14s\n",
      "Validation Step 834/1568 | Batch Loss: 2.0602 | Batch Time: 0.15s\n",
      "Validation Step 835/1568 | Batch Loss: 1.8116 | Batch Time: 0.14s\n",
      "Validation Step 836/1568 | Batch Loss: 3.3520 | Batch Time: 0.14s\n",
      "Validation Step 837/1568 | Batch Loss: 3.0368 | Batch Time: 0.14s\n",
      "Validation Step 838/1568 | Batch Loss: 2.5933 | Batch Time: 0.15s\n",
      "Validation Step 839/1568 | Batch Loss: 2.1289 | Batch Time: 0.14s\n",
      "Validation Step 840/1568 | Batch Loss: 2.0442 | Batch Time: 0.14s\n",
      "Validation Step 841/1568 | Batch Loss: 2.4085 | Batch Time: 0.14s\n",
      "Validation Step 842/1568 | Batch Loss: 3.3507 | Batch Time: 0.15s\n",
      "Validation Step 843/1568 | Batch Loss: 2.6326 | Batch Time: 0.14s\n",
      "Validation Step 844/1568 | Batch Loss: 2.0865 | Batch Time: 0.14s\n",
      "Validation Step 845/1568 | Batch Loss: 3.1574 | Batch Time: 0.14s\n",
      "Validation Step 846/1568 | Batch Loss: 1.9167 | Batch Time: 0.14s\n",
      "Validation Step 847/1568 | Batch Loss: 2.1168 | Batch Time: 0.14s\n",
      "Validation Step 848/1568 | Batch Loss: 2.1796 | Batch Time: 0.14s\n",
      "Validation Step 849/1568 | Batch Loss: 2.0677 | Batch Time: 0.14s\n",
      "Validation Step 850/1568 | Batch Loss: 3.1162 | Batch Time: 0.14s\n",
      "Validation Step 851/1568 | Batch Loss: 2.2051 | Batch Time: 0.14s\n",
      "Validation Step 852/1568 | Batch Loss: 1.7499 | Batch Time: 0.14s\n",
      "Validation Step 853/1568 | Batch Loss: 3.1334 | Batch Time: 0.14s\n",
      "Validation Step 854/1568 | Batch Loss: 1.7906 | Batch Time: 0.14s\n",
      "Validation Step 855/1568 | Batch Loss: 2.8076 | Batch Time: 0.15s\n",
      "Validation Step 856/1568 | Batch Loss: 1.8659 | Batch Time: 0.16s\n",
      "Validation Step 857/1568 | Batch Loss: 2.3064 | Batch Time: 0.14s\n",
      "Validation Step 858/1568 | Batch Loss: 2.7021 | Batch Time: 0.14s\n",
      "Validation Step 859/1568 | Batch Loss: 1.8248 | Batch Time: 0.14s\n",
      "Validation Step 860/1568 | Batch Loss: 1.9956 | Batch Time: 0.14s\n",
      "Validation Step 861/1568 | Batch Loss: 1.7459 | Batch Time: 0.14s\n",
      "Validation Step 862/1568 | Batch Loss: 3.4993 | Batch Time: 0.14s\n",
      "Validation Step 863/1568 | Batch Loss: 2.8575 | Batch Time: 0.14s\n",
      "Validation Step 864/1568 | Batch Loss: 1.9456 | Batch Time: 0.14s\n",
      "Validation Step 865/1568 | Batch Loss: 2.6957 | Batch Time: 0.14s\n",
      "Validation Step 866/1568 | Batch Loss: 1.8383 | Batch Time: 0.14s\n",
      "Validation Step 867/1568 | Batch Loss: 2.9820 | Batch Time: 0.14s\n",
      "Validation Step 868/1568 | Batch Loss: 3.5633 | Batch Time: 0.14s\n",
      "Validation Step 869/1568 | Batch Loss: 2.7782 | Batch Time: 0.14s\n",
      "Validation Step 870/1568 | Batch Loss: 2.1846 | Batch Time: 0.14s\n",
      "Validation Step 871/1568 | Batch Loss: 2.9680 | Batch Time: 0.14s\n",
      "Validation Step 872/1568 | Batch Loss: 2.0827 | Batch Time: 0.14s\n",
      "Validation Step 873/1568 | Batch Loss: 2.4963 | Batch Time: 0.14s\n",
      "Validation Step 874/1568 | Batch Loss: 3.9138 | Batch Time: 0.14s\n",
      "Validation Step 875/1568 | Batch Loss: 2.8710 | Batch Time: 0.15s\n",
      "Validation Step 876/1568 | Batch Loss: 1.7571 | Batch Time: 0.14s\n",
      "Validation Step 877/1568 | Batch Loss: 1.6952 | Batch Time: 0.14s\n",
      "Validation Step 878/1568 | Batch Loss: 2.0128 | Batch Time: 0.14s\n",
      "Validation Step 879/1568 | Batch Loss: 2.0503 | Batch Time: 0.14s\n",
      "Validation Step 880/1568 | Batch Loss: 2.7997 | Batch Time: 0.14s\n",
      "Validation Step 881/1568 | Batch Loss: 2.1880 | Batch Time: 0.14s\n",
      "Validation Step 882/1568 | Batch Loss: 2.5926 | Batch Time: 0.14s\n",
      "Validation Step 883/1568 | Batch Loss: 2.8433 | Batch Time: 0.14s\n",
      "Validation Step 884/1568 | Batch Loss: 2.4937 | Batch Time: 0.14s\n",
      "Validation Step 885/1568 | Batch Loss: 3.1366 | Batch Time: 0.14s\n",
      "Validation Step 886/1568 | Batch Loss: 1.5825 | Batch Time: 0.14s\n",
      "Validation Step 887/1568 | Batch Loss: 2.0838 | Batch Time: 0.14s\n",
      "Validation Step 888/1568 | Batch Loss: 2.0155 | Batch Time: 0.14s\n",
      "Validation Step 889/1568 | Batch Loss: 1.3498 | Batch Time: 0.14s\n",
      "Validation Step 890/1568 | Batch Loss: 2.9228 | Batch Time: 0.14s\n",
      "Validation Step 891/1568 | Batch Loss: 1.5228 | Batch Time: 0.14s\n",
      "Validation Step 892/1568 | Batch Loss: 2.9752 | Batch Time: 0.14s\n",
      "Validation Step 893/1568 | Batch Loss: 2.7518 | Batch Time: 0.14s\n",
      "Validation Step 894/1568 | Batch Loss: 1.8657 | Batch Time: 0.14s\n",
      "Validation Step 895/1568 | Batch Loss: 5.0182 | Batch Time: 0.14s\n",
      "Validation Step 896/1568 | Batch Loss: 1.6207 | Batch Time: 0.14s\n",
      "Validation Step 897/1568 | Batch Loss: 1.9600 | Batch Time: 0.14s\n",
      "Validation Step 898/1568 | Batch Loss: 2.0685 | Batch Time: 0.14s\n",
      "Validation Step 899/1568 | Batch Loss: 1.7833 | Batch Time: 0.14s\n",
      "Validation Step 900/1568 | Batch Loss: 2.5785 | Batch Time: 0.14s\n",
      "Validation Step 901/1568 | Batch Loss: 2.8322 | Batch Time: 0.14s\n",
      "Validation Step 902/1568 | Batch Loss: 2.2530 | Batch Time: 0.14s\n",
      "Validation Step 903/1568 | Batch Loss: 1.8985 | Batch Time: 0.14s\n",
      "Validation Step 904/1568 | Batch Loss: 1.6853 | Batch Time: 0.14s\n",
      "Validation Step 905/1568 | Batch Loss: 2.3222 | Batch Time: 0.14s\n",
      "Validation Step 906/1568 | Batch Loss: 2.7250 | Batch Time: 0.14s\n",
      "Validation Step 907/1568 | Batch Loss: 2.1888 | Batch Time: 0.14s\n",
      "Validation Step 908/1568 | Batch Loss: 2.4228 | Batch Time: 0.14s\n",
      "Validation Step 909/1568 | Batch Loss: 1.5180 | Batch Time: 0.14s\n",
      "Validation Step 910/1568 | Batch Loss: 1.6719 | Batch Time: 0.14s\n",
      "Validation Step 911/1568 | Batch Loss: 4.1955 | Batch Time: 0.12s\n",
      "Validation Step 912/1568 | Batch Loss: 1.9778 | Batch Time: 0.14s\n",
      "Validation Step 913/1568 | Batch Loss: 4.6435 | Batch Time: 0.14s\n",
      "Validation Step 914/1568 | Batch Loss: 2.0058 | Batch Time: 0.15s\n",
      "Validation Step 915/1568 | Batch Loss: 3.2783 | Batch Time: 0.13s\n",
      "Validation Step 916/1568 | Batch Loss: 2.1909 | Batch Time: 0.14s\n",
      "Validation Step 917/1568 | Batch Loss: 4.1746 | Batch Time: 0.14s\n",
      "Validation Step 918/1568 | Batch Loss: 2.2437 | Batch Time: 0.14s\n",
      "Validation Step 919/1568 | Batch Loss: 3.3375 | Batch Time: 0.14s\n",
      "Validation Step 920/1568 | Batch Loss: 2.6716 | Batch Time: 0.13s\n",
      "Validation Step 921/1568 | Batch Loss: 2.7475 | Batch Time: 0.14s\n",
      "Validation Step 922/1568 | Batch Loss: 3.4229 | Batch Time: 0.14s\n",
      "Validation Step 923/1568 | Batch Loss: 3.3758 | Batch Time: 0.14s\n",
      "Validation Step 924/1568 | Batch Loss: 2.8715 | Batch Time: 0.14s\n",
      "Validation Step 925/1568 | Batch Loss: 3.5005 | Batch Time: 0.14s\n",
      "Validation Step 926/1568 | Batch Loss: 2.5727 | Batch Time: 0.14s\n",
      "Validation Step 927/1568 | Batch Loss: 3.7262 | Batch Time: 0.14s\n",
      "Validation Step 928/1568 | Batch Loss: 4.3598 | Batch Time: 0.14s\n",
      "Validation Step 929/1568 | Batch Loss: 1.9199 | Batch Time: 0.14s\n",
      "Validation Step 930/1568 | Batch Loss: 2.3575 | Batch Time: 0.14s\n",
      "Validation Step 931/1568 | Batch Loss: 1.7367 | Batch Time: 0.14s\n",
      "Validation Step 932/1568 | Batch Loss: 3.3587 | Batch Time: 0.14s\n",
      "Validation Step 933/1568 | Batch Loss: 2.1046 | Batch Time: 0.14s\n",
      "Validation Step 934/1568 | Batch Loss: 2.0866 | Batch Time: 0.14s\n",
      "Validation Step 935/1568 | Batch Loss: 3.5048 | Batch Time: 0.14s\n",
      "Validation Step 936/1568 | Batch Loss: 3.1968 | Batch Time: 0.14s\n",
      "Validation Step 937/1568 | Batch Loss: 2.4791 | Batch Time: 0.14s\n",
      "Validation Step 938/1568 | Batch Loss: 1.5498 | Batch Time: 0.14s\n",
      "Validation Step 939/1568 | Batch Loss: 3.2591 | Batch Time: 0.14s\n",
      "Validation Step 940/1568 | Batch Loss: 1.5839 | Batch Time: 0.14s\n",
      "Validation Step 941/1568 | Batch Loss: 2.0051 | Batch Time: 0.14s\n",
      "Validation Step 942/1568 | Batch Loss: 2.3086 | Batch Time: 0.14s\n",
      "Validation Step 943/1568 | Batch Loss: 1.9242 | Batch Time: 0.14s\n",
      "Validation Step 944/1568 | Batch Loss: 3.0465 | Batch Time: 0.14s\n",
      "Validation Step 945/1568 | Batch Loss: 1.7378 | Batch Time: 0.14s\n",
      "Validation Step 946/1568 | Batch Loss: 2.5117 | Batch Time: 0.14s\n",
      "Validation Step 947/1568 | Batch Loss: 1.7449 | Batch Time: 0.14s\n",
      "Validation Step 948/1568 | Batch Loss: 1.7886 | Batch Time: 0.14s\n",
      "Validation Step 949/1568 | Batch Loss: 2.4613 | Batch Time: 0.14s\n",
      "Validation Step 950/1568 | Batch Loss: 2.6733 | Batch Time: 0.14s\n",
      "Validation Step 951/1568 | Batch Loss: 1.3530 | Batch Time: 0.14s\n",
      "Validation Step 952/1568 | Batch Loss: 1.7601 | Batch Time: 0.14s\n",
      "Validation Step 953/1568 | Batch Loss: 2.3725 | Batch Time: 0.14s\n",
      "Validation Step 954/1568 | Batch Loss: 1.6432 | Batch Time: 0.14s\n",
      "Validation Step 955/1568 | Batch Loss: 2.5239 | Batch Time: 0.14s\n",
      "Validation Step 956/1568 | Batch Loss: 2.1758 | Batch Time: 0.14s\n",
      "Validation Step 957/1568 | Batch Loss: 2.9108 | Batch Time: 0.14s\n",
      "Validation Step 958/1568 | Batch Loss: 1.7066 | Batch Time: 0.14s\n",
      "Validation Step 959/1568 | Batch Loss: 3.3116 | Batch Time: 0.14s\n",
      "Validation Step 960/1568 | Batch Loss: 2.3580 | Batch Time: 0.14s\n",
      "Validation Step 961/1568 | Batch Loss: 1.8655 | Batch Time: 0.14s\n",
      "Validation Step 962/1568 | Batch Loss: 1.9611 | Batch Time: 0.12s\n",
      "Validation Step 963/1568 | Batch Loss: 1.4710 | Batch Time: 0.15s\n",
      "Validation Step 964/1568 | Batch Loss: 3.0075 | Batch Time: 0.15s\n",
      "Validation Step 965/1568 | Batch Loss: 2.2460 | Batch Time: 0.15s\n",
      "Validation Step 966/1568 | Batch Loss: 2.5487 | Batch Time: 0.14s\n",
      "Validation Step 967/1568 | Batch Loss: 1.7374 | Batch Time: 0.15s\n",
      "Validation Step 968/1568 | Batch Loss: 3.9534 | Batch Time: 0.14s\n",
      "Validation Step 969/1568 | Batch Loss: 2.1162 | Batch Time: 0.14s\n",
      "Validation Step 970/1568 | Batch Loss: 4.5507 | Batch Time: 0.13s\n",
      "Validation Step 971/1568 | Batch Loss: 2.6727 | Batch Time: 0.14s\n",
      "Validation Step 972/1568 | Batch Loss: 2.4586 | Batch Time: 0.14s\n",
      "Validation Step 973/1568 | Batch Loss: 1.7491 | Batch Time: 0.14s\n",
      "Validation Step 974/1568 | Batch Loss: 2.4806 | Batch Time: 0.14s\n",
      "Validation Step 975/1568 | Batch Loss: 1.6616 | Batch Time: 0.14s\n",
      "Validation Step 976/1568 | Batch Loss: 4.7943 | Batch Time: 0.14s\n",
      "Validation Step 977/1568 | Batch Loss: 2.4837 | Batch Time: 0.14s\n",
      "Validation Step 978/1568 | Batch Loss: 2.0829 | Batch Time: 0.14s\n",
      "Validation Step 979/1568 | Batch Loss: 1.7634 | Batch Time: 0.14s\n",
      "Validation Step 980/1568 | Batch Loss: 3.1995 | Batch Time: 0.14s\n",
      "Validation Step 981/1568 | Batch Loss: 2.1811 | Batch Time: 0.14s\n",
      "Validation Step 982/1568 | Batch Loss: 2.0012 | Batch Time: 0.14s\n",
      "Validation Step 983/1568 | Batch Loss: 2.0416 | Batch Time: 0.14s\n",
      "Validation Step 984/1568 | Batch Loss: 1.8272 | Batch Time: 0.14s\n",
      "Validation Step 985/1568 | Batch Loss: 1.6831 | Batch Time: 0.14s\n",
      "Validation Step 986/1568 | Batch Loss: 1.9358 | Batch Time: 0.14s\n",
      "Validation Step 987/1568 | Batch Loss: 1.6478 | Batch Time: 0.14s\n",
      "Validation Step 988/1568 | Batch Loss: 1.5833 | Batch Time: 0.14s\n",
      "Validation Step 989/1568 | Batch Loss: 2.7032 | Batch Time: 0.14s\n",
      "Validation Step 990/1568 | Batch Loss: 3.3682 | Batch Time: 0.14s\n",
      "Validation Step 991/1568 | Batch Loss: 4.2073 | Batch Time: 0.15s\n",
      "Validation Step 992/1568 | Batch Loss: 3.4507 | Batch Time: 0.15s\n",
      "Validation Step 993/1568 | Batch Loss: 1.5774 | Batch Time: 0.15s\n",
      "Validation Step 994/1568 | Batch Loss: 2.0796 | Batch Time: 0.14s\n",
      "Validation Step 995/1568 | Batch Loss: 1.5274 | Batch Time: 0.14s\n",
      "Validation Step 996/1568 | Batch Loss: 2.3501 | Batch Time: 0.15s\n",
      "Validation Step 997/1568 | Batch Loss: 2.2582 | Batch Time: 0.16s\n",
      "Validation Step 998/1568 | Batch Loss: 2.1813 | Batch Time: 0.15s\n",
      "Validation Step 999/1568 | Batch Loss: 1.5113 | Batch Time: 0.14s\n",
      "Validation Step 1000/1568 | Batch Loss: 2.1920 | Batch Time: 0.14s\n",
      "Validation Step 1001/1568 | Batch Loss: 3.9275 | Batch Time: 0.14s\n",
      "Validation Step 1002/1568 | Batch Loss: 1.6951 | Batch Time: 0.14s\n",
      "Validation Step 1003/1568 | Batch Loss: 2.5387 | Batch Time: 0.14s\n",
      "Validation Step 1004/1568 | Batch Loss: 2.5827 | Batch Time: 0.14s\n",
      "Validation Step 1005/1568 | Batch Loss: 1.5694 | Batch Time: 0.15s\n",
      "Validation Step 1006/1568 | Batch Loss: 2.2352 | Batch Time: 0.14s\n",
      "Validation Step 1007/1568 | Batch Loss: 2.2361 | Batch Time: 0.14s\n",
      "Validation Step 1008/1568 | Batch Loss: 2.8820 | Batch Time: 0.14s\n",
      "Validation Step 1009/1568 | Batch Loss: 2.6826 | Batch Time: 0.14s\n",
      "Validation Step 1010/1568 | Batch Loss: 1.5521 | Batch Time: 0.14s\n",
      "Validation Step 1011/1568 | Batch Loss: 1.9872 | Batch Time: 0.14s\n",
      "Validation Step 1012/1568 | Batch Loss: 3.4125 | Batch Time: 0.14s\n",
      "Validation Step 1013/1568 | Batch Loss: 2.4265 | Batch Time: 0.14s\n",
      "Validation Step 1014/1568 | Batch Loss: 2.2247 | Batch Time: 0.14s\n",
      "Validation Step 1015/1568 | Batch Loss: 1.7926 | Batch Time: 0.14s\n",
      "Validation Step 1016/1568 | Batch Loss: 3.0439 | Batch Time: 0.14s\n",
      "Validation Step 1017/1568 | Batch Loss: 1.4135 | Batch Time: 0.14s\n",
      "Validation Step 1018/1568 | Batch Loss: 1.8033 | Batch Time: 0.14s\n",
      "Validation Step 1019/1568 | Batch Loss: 2.1143 | Batch Time: 0.14s\n",
      "Validation Step 1020/1568 | Batch Loss: 2.5079 | Batch Time: 0.14s\n",
      "Validation Step 1021/1568 | Batch Loss: 2.4418 | Batch Time: 0.14s\n",
      "Validation Step 1022/1568 | Batch Loss: 3.2908 | Batch Time: 0.14s\n",
      "Validation Step 1023/1568 | Batch Loss: 2.1661 | Batch Time: 0.14s\n",
      "Validation Step 1024/1568 | Batch Loss: 2.2821 | Batch Time: 0.14s\n",
      "Validation Step 1025/1568 | Batch Loss: 3.1816 | Batch Time: 0.14s\n",
      "Validation Step 1026/1568 | Batch Loss: 2.7471 | Batch Time: 0.14s\n",
      "Validation Step 1027/1568 | Batch Loss: 2.0834 | Batch Time: 0.13s\n",
      "Validation Step 1028/1568 | Batch Loss: 2.9455 | Batch Time: 0.15s\n",
      "Validation Step 1029/1568 | Batch Loss: 1.8432 | Batch Time: 0.15s\n",
      "Validation Step 1030/1568 | Batch Loss: 2.0040 | Batch Time: 0.15s\n",
      "Validation Step 1031/1568 | Batch Loss: 2.9122 | Batch Time: 0.15s\n",
      "Validation Step 1032/1568 | Batch Loss: 2.3422 | Batch Time: 0.14s\n",
      "Validation Step 1033/1568 | Batch Loss: 2.3713 | Batch Time: 0.14s\n",
      "Validation Step 1034/1568 | Batch Loss: 2.5304 | Batch Time: 0.14s\n",
      "Validation Step 1035/1568 | Batch Loss: 3.0414 | Batch Time: 0.14s\n",
      "Validation Step 1036/1568 | Batch Loss: 2.4418 | Batch Time: 0.15s\n",
      "Validation Step 1037/1568 | Batch Loss: 1.8914 | Batch Time: 0.15s\n",
      "Validation Step 1038/1568 | Batch Loss: 2.3667 | Batch Time: 0.14s\n",
      "Validation Step 1039/1568 | Batch Loss: 2.8442 | Batch Time: 0.14s\n",
      "Validation Step 1040/1568 | Batch Loss: 2.2290 | Batch Time: 0.14s\n",
      "Validation Step 1041/1568 | Batch Loss: 2.7432 | Batch Time: 0.14s\n",
      "Validation Step 1042/1568 | Batch Loss: 1.3577 | Batch Time: 0.14s\n",
      "Validation Step 1043/1568 | Batch Loss: 1.9396 | Batch Time: 0.14s\n",
      "Validation Step 1044/1568 | Batch Loss: 4.5143 | Batch Time: 0.14s\n",
      "Validation Step 1045/1568 | Batch Loss: 1.6405 | Batch Time: 0.14s\n",
      "Validation Step 1046/1568 | Batch Loss: 3.5239 | Batch Time: 0.14s\n",
      "Validation Step 1047/1568 | Batch Loss: 2.0182 | Batch Time: 0.14s\n",
      "Validation Step 1048/1568 | Batch Loss: 1.5279 | Batch Time: 0.14s\n",
      "Validation Step 1049/1568 | Batch Loss: 1.7049 | Batch Time: 0.14s\n",
      "Validation Step 1050/1568 | Batch Loss: 2.9930 | Batch Time: 0.14s\n",
      "Validation Step 1051/1568 | Batch Loss: 2.5548 | Batch Time: 0.14s\n",
      "Validation Step 1052/1568 | Batch Loss: 3.0239 | Batch Time: 0.13s\n",
      "Validation Step 1053/1568 | Batch Loss: 1.4950 | Batch Time: 0.14s\n",
      "Validation Step 1054/1568 | Batch Loss: 2.0199 | Batch Time: 0.14s\n",
      "Validation Step 1055/1568 | Batch Loss: 3.6034 | Batch Time: 0.14s\n",
      "Validation Step 1056/1568 | Batch Loss: 2.0880 | Batch Time: 0.14s\n",
      "Validation Step 1057/1568 | Batch Loss: 3.1613 | Batch Time: 0.14s\n",
      "Validation Step 1058/1568 | Batch Loss: 5.0647 | Batch Time: 0.14s\n",
      "Validation Step 1059/1568 | Batch Loss: 1.9031 | Batch Time: 0.14s\n",
      "Validation Step 1060/1568 | Batch Loss: 2.5185 | Batch Time: 0.14s\n",
      "Validation Step 1061/1568 | Batch Loss: 1.8059 | Batch Time: 0.14s\n",
      "Validation Step 1062/1568 | Batch Loss: 1.6137 | Batch Time: 0.14s\n",
      "Validation Step 1063/1568 | Batch Loss: 2.1977 | Batch Time: 0.14s\n",
      "Validation Step 1064/1568 | Batch Loss: 1.8120 | Batch Time: 0.15s\n",
      "Validation Step 1065/1568 | Batch Loss: 2.3997 | Batch Time: 0.14s\n",
      "Validation Step 1066/1568 | Batch Loss: 1.9701 | Batch Time: 0.14s\n",
      "Validation Step 1067/1568 | Batch Loss: 2.4911 | Batch Time: 0.14s\n",
      "Validation Step 1068/1568 | Batch Loss: 1.8966 | Batch Time: 0.14s\n",
      "Validation Step 1069/1568 | Batch Loss: 2.2773 | Batch Time: 0.14s\n",
      "Validation Step 1070/1568 | Batch Loss: 3.0000 | Batch Time: 0.13s\n",
      "Validation Step 1071/1568 | Batch Loss: 2.0128 | Batch Time: 0.14s\n",
      "Validation Step 1072/1568 | Batch Loss: 3.7780 | Batch Time: 0.15s\n",
      "Validation Step 1073/1568 | Batch Loss: 2.1179 | Batch Time: 0.13s\n",
      "Validation Step 1074/1568 | Batch Loss: 2.0989 | Batch Time: 0.14s\n",
      "Validation Step 1075/1568 | Batch Loss: 2.2268 | Batch Time: 0.14s\n",
      "Validation Step 1076/1568 | Batch Loss: 2.6225 | Batch Time: 0.14s\n",
      "Validation Step 1077/1568 | Batch Loss: 2.6335 | Batch Time: 0.14s\n",
      "Validation Step 1078/1568 | Batch Loss: 3.6844 | Batch Time: 0.14s\n",
      "Validation Step 1079/1568 | Batch Loss: 2.2530 | Batch Time: 0.14s\n",
      "Validation Step 1080/1568 | Batch Loss: 2.5750 | Batch Time: 0.14s\n",
      "Validation Step 1081/1568 | Batch Loss: 2.6005 | Batch Time: 0.14s\n",
      "Validation Step 1082/1568 | Batch Loss: 2.3232 | Batch Time: 0.14s\n",
      "Validation Step 1083/1568 | Batch Loss: 4.2326 | Batch Time: 0.14s\n",
      "Validation Step 1084/1568 | Batch Loss: 2.3054 | Batch Time: 0.14s\n",
      "Validation Step 1085/1568 | Batch Loss: 2.4123 | Batch Time: 0.14s\n",
      "Validation Step 1086/1568 | Batch Loss: 2.6574 | Batch Time: 0.15s\n",
      "Validation Step 1087/1568 | Batch Loss: 2.1411 | Batch Time: 0.14s\n",
      "Validation Step 1088/1568 | Batch Loss: 2.5283 | Batch Time: 0.14s\n",
      "Validation Step 1089/1568 | Batch Loss: 2.0015 | Batch Time: 0.18s\n",
      "Validation Step 1090/1568 | Batch Loss: 3.2264 | Batch Time: 0.16s\n",
      "Validation Step 1091/1568 | Batch Loss: 1.3435 | Batch Time: 0.14s\n",
      "Validation Step 1092/1568 | Batch Loss: 2.9259 | Batch Time: 0.13s\n",
      "Validation Step 1093/1568 | Batch Loss: 2.7250 | Batch Time: 0.14s\n",
      "Validation Step 1094/1568 | Batch Loss: 2.2517 | Batch Time: 0.14s\n",
      "Validation Step 1095/1568 | Batch Loss: 1.8820 | Batch Time: 0.14s\n",
      "Validation Step 1096/1568 | Batch Loss: 2.4481 | Batch Time: 0.14s\n",
      "Validation Step 1097/1568 | Batch Loss: 2.6977 | Batch Time: 0.14s\n",
      "Validation Step 1098/1568 | Batch Loss: 2.2145 | Batch Time: 0.14s\n",
      "Validation Step 1099/1568 | Batch Loss: 2.2606 | Batch Time: 0.14s\n",
      "Validation Step 1100/1568 | Batch Loss: 1.7644 | Batch Time: 0.14s\n",
      "Validation Step 1101/1568 | Batch Loss: 2.8373 | Batch Time: 0.14s\n",
      "Validation Step 1102/1568 | Batch Loss: 3.3707 | Batch Time: 0.14s\n",
      "Validation Step 1103/1568 | Batch Loss: 1.9838 | Batch Time: 0.14s\n",
      "Validation Step 1104/1568 | Batch Loss: 1.4426 | Batch Time: 0.14s\n",
      "Validation Step 1105/1568 | Batch Loss: 3.3694 | Batch Time: 0.14s\n",
      "Validation Step 1106/1568 | Batch Loss: 1.3715 | Batch Time: 0.14s\n",
      "Validation Step 1107/1568 | Batch Loss: 1.5312 | Batch Time: 0.14s\n",
      "Validation Step 1108/1568 | Batch Loss: 3.1812 | Batch Time: 0.14s\n",
      "Validation Step 1109/1568 | Batch Loss: 3.5456 | Batch Time: 0.14s\n",
      "Validation Step 1110/1568 | Batch Loss: 3.0871 | Batch Time: 0.14s\n",
      "Validation Step 1111/1568 | Batch Loss: 2.3473 | Batch Time: 0.14s\n",
      "Validation Step 1112/1568 | Batch Loss: 2.2346 | Batch Time: 0.14s\n",
      "Validation Step 1113/1568 | Batch Loss: 2.9844 | Batch Time: 0.14s\n",
      "Validation Step 1114/1568 | Batch Loss: 1.5093 | Batch Time: 0.14s\n",
      "Validation Step 1115/1568 | Batch Loss: 1.7974 | Batch Time: 0.14s\n",
      "Validation Step 1116/1568 | Batch Loss: 3.4200 | Batch Time: 0.13s\n",
      "Validation Step 1117/1568 | Batch Loss: 2.5574 | Batch Time: 0.15s\n",
      "Validation Step 1118/1568 | Batch Loss: 1.8657 | Batch Time: 0.15s\n",
      "Validation Step 1119/1568 | Batch Loss: 1.6931 | Batch Time: 0.14s\n",
      "Validation Step 1120/1568 | Batch Loss: 2.5015 | Batch Time: 0.14s\n",
      "Validation Step 1121/1568 | Batch Loss: 3.8432 | Batch Time: 0.14s\n",
      "Validation Step 1122/1568 | Batch Loss: 3.1560 | Batch Time: 0.15s\n",
      "Validation Step 1123/1568 | Batch Loss: 1.6976 | Batch Time: 0.14s\n",
      "Validation Step 1124/1568 | Batch Loss: 2.6363 | Batch Time: 0.14s\n",
      "Validation Step 1125/1568 | Batch Loss: 2.7827 | Batch Time: 0.12s\n",
      "Validation Step 1126/1568 | Batch Loss: 2.6348 | Batch Time: 0.15s\n",
      "Validation Step 1127/1568 | Batch Loss: 2.9519 | Batch Time: 0.14s\n",
      "Validation Step 1128/1568 | Batch Loss: 1.6896 | Batch Time: 0.14s\n",
      "Validation Step 1129/1568 | Batch Loss: 1.9675 | Batch Time: 0.14s\n",
      "Validation Step 1130/1568 | Batch Loss: 1.9481 | Batch Time: 0.14s\n",
      "Validation Step 1131/1568 | Batch Loss: 1.9222 | Batch Time: 0.15s\n",
      "Validation Step 1132/1568 | Batch Loss: 1.3427 | Batch Time: 0.14s\n",
      "Validation Step 1133/1568 | Batch Loss: 2.8184 | Batch Time: 0.14s\n",
      "Validation Step 1134/1568 | Batch Loss: 1.5696 | Batch Time: 0.15s\n",
      "Validation Step 1135/1568 | Batch Loss: 2.5220 | Batch Time: 0.14s\n",
      "Validation Step 1136/1568 | Batch Loss: 2.9279 | Batch Time: 0.14s\n",
      "Validation Step 1137/1568 | Batch Loss: 1.5020 | Batch Time: 0.14s\n",
      "Validation Step 1138/1568 | Batch Loss: 2.6833 | Batch Time: 0.14s\n",
      "Validation Step 1139/1568 | Batch Loss: 1.7805 | Batch Time: 0.14s\n",
      "Validation Step 1140/1568 | Batch Loss: 2.5738 | Batch Time: 0.14s\n",
      "Validation Step 1141/1568 | Batch Loss: 3.0481 | Batch Time: 0.14s\n",
      "Validation Step 1142/1568 | Batch Loss: 2.0277 | Batch Time: 0.14s\n",
      "Validation Step 1143/1568 | Batch Loss: 2.0532 | Batch Time: 0.14s\n",
      "Validation Step 1144/1568 | Batch Loss: 2.0043 | Batch Time: 0.14s\n",
      "Validation Step 1145/1568 | Batch Loss: 1.7213 | Batch Time: 0.14s\n",
      "Validation Step 1146/1568 | Batch Loss: 3.4051 | Batch Time: 0.14s\n",
      "Validation Step 1147/1568 | Batch Loss: 2.8697 | Batch Time: 0.14s\n",
      "Validation Step 1148/1568 | Batch Loss: 3.4501 | Batch Time: 0.14s\n",
      "Validation Step 1149/1568 | Batch Loss: 1.9229 | Batch Time: 0.14s\n",
      "Validation Step 1150/1568 | Batch Loss: 2.8334 | Batch Time: 0.14s\n",
      "Validation Step 1151/1568 | Batch Loss: 2.6551 | Batch Time: 0.14s\n",
      "Validation Step 1152/1568 | Batch Loss: 3.3254 | Batch Time: 0.14s\n",
      "Validation Step 1153/1568 | Batch Loss: 3.4541 | Batch Time: 0.15s\n",
      "Validation Step 1154/1568 | Batch Loss: 2.5771 | Batch Time: 0.14s\n",
      "Validation Step 1155/1568 | Batch Loss: 2.6454 | Batch Time: 0.14s\n",
      "Validation Step 1156/1568 | Batch Loss: 1.8206 | Batch Time: 0.15s\n",
      "Validation Step 1157/1568 | Batch Loss: 2.6288 | Batch Time: 0.15s\n",
      "Validation Step 1158/1568 | Batch Loss: 1.8013 | Batch Time: 0.14s\n",
      "Validation Step 1159/1568 | Batch Loss: 1.9449 | Batch Time: 0.15s\n",
      "Validation Step 1160/1568 | Batch Loss: 2.3356 | Batch Time: 0.14s\n",
      "Validation Step 1161/1568 | Batch Loss: 3.0329 | Batch Time: 0.14s\n",
      "Validation Step 1162/1568 | Batch Loss: 2.1031 | Batch Time: 0.14s\n",
      "Validation Step 1163/1568 | Batch Loss: 1.6600 | Batch Time: 0.14s\n",
      "Validation Step 1164/1568 | Batch Loss: 3.0571 | Batch Time: 0.14s\n",
      "Validation Step 1165/1568 | Batch Loss: 2.7171 | Batch Time: 0.14s\n",
      "Validation Step 1166/1568 | Batch Loss: 1.9391 | Batch Time: 0.15s\n",
      "Validation Step 1167/1568 | Batch Loss: 3.1160 | Batch Time: 0.14s\n",
      "Validation Step 1168/1568 | Batch Loss: 2.1086 | Batch Time: 0.15s\n",
      "Validation Step 1169/1568 | Batch Loss: 2.4818 | Batch Time: 0.15s\n",
      "Validation Step 1170/1568 | Batch Loss: 2.6171 | Batch Time: 0.14s\n",
      "Validation Step 1171/1568 | Batch Loss: 1.6343 | Batch Time: 0.14s\n",
      "Validation Step 1172/1568 | Batch Loss: 2.0767 | Batch Time: 0.14s\n",
      "Validation Step 1173/1568 | Batch Loss: 2.1531 | Batch Time: 0.14s\n",
      "Validation Step 1174/1568 | Batch Loss: 2.7417 | Batch Time: 0.14s\n",
      "Validation Step 1175/1568 | Batch Loss: 1.7230 | Batch Time: 0.14s\n",
      "Validation Step 1176/1568 | Batch Loss: 1.7501 | Batch Time: 0.14s\n",
      "Validation Step 1177/1568 | Batch Loss: 2.8286 | Batch Time: 0.14s\n",
      "Validation Step 1178/1568 | Batch Loss: 1.5564 | Batch Time: 0.14s\n",
      "Validation Step 1179/1568 | Batch Loss: 2.3396 | Batch Time: 0.14s\n",
      "Validation Step 1180/1568 | Batch Loss: 3.1102 | Batch Time: 0.15s\n",
      "Validation Step 1181/1568 | Batch Loss: 2.8772 | Batch Time: 0.14s\n",
      "Validation Step 1182/1568 | Batch Loss: 2.3012 | Batch Time: 0.14s\n",
      "Validation Step 1183/1568 | Batch Loss: 2.9583 | Batch Time: 0.14s\n",
      "Validation Step 1184/1568 | Batch Loss: 1.9670 | Batch Time: 0.14s\n",
      "Validation Step 1185/1568 | Batch Loss: 1.2591 | Batch Time: 0.14s\n",
      "Validation Step 1186/1568 | Batch Loss: 5.0363 | Batch Time: 0.14s\n",
      "Validation Step 1187/1568 | Batch Loss: 3.4039 | Batch Time: 0.14s\n",
      "Validation Step 1188/1568 | Batch Loss: 1.5807 | Batch Time: 0.14s\n",
      "Validation Step 1189/1568 | Batch Loss: 3.1617 | Batch Time: 0.14s\n",
      "Validation Step 1190/1568 | Batch Loss: 2.2858 | Batch Time: 0.14s\n",
      "Validation Step 1191/1568 | Batch Loss: 2.2364 | Batch Time: 0.14s\n",
      "Validation Step 1192/1568 | Batch Loss: 2.4626 | Batch Time: 0.14s\n",
      "Validation Step 1193/1568 | Batch Loss: 1.9017 | Batch Time: 0.15s\n",
      "Validation Step 1194/1568 | Batch Loss: 1.9973 | Batch Time: 0.14s\n",
      "Validation Step 1195/1568 | Batch Loss: 1.7235 | Batch Time: 0.14s\n",
      "Validation Step 1196/1568 | Batch Loss: 1.9335 | Batch Time: 0.14s\n",
      "Validation Step 1197/1568 | Batch Loss: 2.7879 | Batch Time: 0.14s\n",
      "Validation Step 1198/1568 | Batch Loss: 2.5300 | Batch Time: 0.14s\n",
      "Validation Step 1199/1568 | Batch Loss: 1.7430 | Batch Time: 0.14s\n",
      "Validation Step 1200/1568 | Batch Loss: 2.4273 | Batch Time: 0.14s\n",
      "Validation Step 1201/1568 | Batch Loss: 2.0641 | Batch Time: 0.14s\n",
      "Validation Step 1202/1568 | Batch Loss: 2.0834 | Batch Time: 0.14s\n",
      "Validation Step 1203/1568 | Batch Loss: 1.9707 | Batch Time: 0.14s\n",
      "Validation Step 1204/1568 | Batch Loss: 2.5616 | Batch Time: 0.14s\n",
      "Validation Step 1205/1568 | Batch Loss: 3.0137 | Batch Time: 0.14s\n",
      "Validation Step 1206/1568 | Batch Loss: 1.7978 | Batch Time: 0.14s\n",
      "Validation Step 1207/1568 | Batch Loss: 3.2793 | Batch Time: 0.17s\n",
      "Validation Step 1208/1568 | Batch Loss: 1.9391 | Batch Time: 0.17s\n",
      "Validation Step 1209/1568 | Batch Loss: 2.6647 | Batch Time: 0.14s\n",
      "Validation Step 1210/1568 | Batch Loss: 1.8473 | Batch Time: 0.14s\n",
      "Validation Step 1211/1568 | Batch Loss: 1.6712 | Batch Time: 0.14s\n",
      "Validation Step 1212/1568 | Batch Loss: 3.0731 | Batch Time: 0.14s\n",
      "Validation Step 1213/1568 | Batch Loss: 2.1032 | Batch Time: 0.14s\n",
      "Validation Step 1214/1568 | Batch Loss: 3.6056 | Batch Time: 0.14s\n",
      "Validation Step 1215/1568 | Batch Loss: 4.3623 | Batch Time: 0.14s\n",
      "Validation Step 1216/1568 | Batch Loss: 3.6465 | Batch Time: 0.14s\n",
      "Validation Step 1217/1568 | Batch Loss: 2.4490 | Batch Time: 0.14s\n",
      "Validation Step 1218/1568 | Batch Loss: 2.2916 | Batch Time: 0.14s\n",
      "Validation Step 1219/1568 | Batch Loss: 1.7903 | Batch Time: 0.14s\n",
      "Validation Step 1220/1568 | Batch Loss: 2.1629 | Batch Time: 0.14s\n",
      "Validation Step 1221/1568 | Batch Loss: 1.6942 | Batch Time: 0.14s\n",
      "Validation Step 1222/1568 | Batch Loss: 1.8936 | Batch Time: 0.14s\n",
      "Validation Step 1223/1568 | Batch Loss: 2.9314 | Batch Time: 0.14s\n",
      "Validation Step 1224/1568 | Batch Loss: 2.8187 | Batch Time: 0.14s\n",
      "Validation Step 1225/1568 | Batch Loss: 3.2835 | Batch Time: 0.14s\n",
      "Validation Step 1226/1568 | Batch Loss: 2.7894 | Batch Time: 0.14s\n",
      "Validation Step 1227/1568 | Batch Loss: 2.0086 | Batch Time: 0.14s\n",
      "Validation Step 1228/1568 | Batch Loss: 1.8053 | Batch Time: 0.14s\n",
      "Validation Step 1229/1568 | Batch Loss: 2.0504 | Batch Time: 0.14s\n",
      "Validation Step 1230/1568 | Batch Loss: 2.4137 | Batch Time: 0.15s\n",
      "Validation Step 1231/1568 | Batch Loss: 2.3920 | Batch Time: 0.15s\n",
      "Validation Step 1232/1568 | Batch Loss: 2.7492 | Batch Time: 0.15s\n",
      "Validation Step 1233/1568 | Batch Loss: 4.2232 | Batch Time: 0.15s\n",
      "Validation Step 1234/1568 | Batch Loss: 1.3812 | Batch Time: 0.15s\n",
      "Validation Step 1235/1568 | Batch Loss: 2.4211 | Batch Time: 0.15s\n",
      "Validation Step 1236/1568 | Batch Loss: 2.5068 | Batch Time: 0.15s\n",
      "Validation Step 1237/1568 | Batch Loss: 1.8387 | Batch Time: 0.15s\n",
      "Validation Step 1238/1568 | Batch Loss: 3.4621 | Batch Time: 0.15s\n",
      "Validation Step 1239/1568 | Batch Loss: 1.5044 | Batch Time: 0.15s\n",
      "Validation Step 1240/1568 | Batch Loss: 1.4026 | Batch Time: 0.14s\n",
      "Validation Step 1241/1568 | Batch Loss: 2.6552 | Batch Time: 0.14s\n",
      "Validation Step 1242/1568 | Batch Loss: 2.1664 | Batch Time: 0.15s\n",
      "Validation Step 1243/1568 | Batch Loss: 2.7124 | Batch Time: 0.14s\n",
      "Validation Step 1244/1568 | Batch Loss: 2.2240 | Batch Time: 0.15s\n",
      "Validation Step 1245/1568 | Batch Loss: 2.3811 | Batch Time: 0.14s\n",
      "Validation Step 1246/1568 | Batch Loss: 3.6313 | Batch Time: 0.14s\n",
      "Validation Step 1247/1568 | Batch Loss: 2.0178 | Batch Time: 0.14s\n",
      "Validation Step 1248/1568 | Batch Loss: 1.4568 | Batch Time: 0.14s\n",
      "Validation Step 1249/1568 | Batch Loss: 1.9771 | Batch Time: 0.14s\n",
      "Validation Step 1250/1568 | Batch Loss: 3.4551 | Batch Time: 0.14s\n",
      "Validation Step 1251/1568 | Batch Loss: 1.9570 | Batch Time: 0.14s\n",
      "Validation Step 1252/1568 | Batch Loss: 2.2031 | Batch Time: 0.14s\n",
      "Validation Step 1253/1568 | Batch Loss: 1.9820 | Batch Time: 0.14s\n",
      "Validation Step 1254/1568 | Batch Loss: 1.2549 | Batch Time: 0.14s\n",
      "Validation Step 1255/1568 | Batch Loss: 4.3002 | Batch Time: 0.15s\n",
      "Validation Step 1256/1568 | Batch Loss: 3.1741 | Batch Time: 0.14s\n",
      "Validation Step 1257/1568 | Batch Loss: 2.2118 | Batch Time: 0.14s\n",
      "Validation Step 1258/1568 | Batch Loss: 2.0430 | Batch Time: 0.14s\n",
      "Validation Step 1259/1568 | Batch Loss: 2.7708 | Batch Time: 0.14s\n",
      "Validation Step 1260/1568 | Batch Loss: 1.8045 | Batch Time: 0.14s\n",
      "Validation Step 1261/1568 | Batch Loss: 3.0679 | Batch Time: 0.14s\n",
      "Validation Step 1262/1568 | Batch Loss: 2.6871 | Batch Time: 0.14s\n",
      "Validation Step 1263/1568 | Batch Loss: 3.0653 | Batch Time: 0.14s\n",
      "Validation Step 1264/1568 | Batch Loss: 3.1608 | Batch Time: 0.14s\n",
      "Validation Step 1265/1568 | Batch Loss: 2.7997 | Batch Time: 0.14s\n",
      "Validation Step 1266/1568 | Batch Loss: 2.1177 | Batch Time: 0.14s\n",
      "Validation Step 1267/1568 | Batch Loss: 3.1876 | Batch Time: 0.14s\n",
      "Validation Step 1268/1568 | Batch Loss: 1.9421 | Batch Time: 0.14s\n",
      "Validation Step 1269/1568 | Batch Loss: 2.8281 | Batch Time: 0.14s\n",
      "Validation Step 1270/1568 | Batch Loss: 1.7765 | Batch Time: 0.15s\n",
      "Validation Step 1271/1568 | Batch Loss: 2.3390 | Batch Time: 0.14s\n",
      "Validation Step 1272/1568 | Batch Loss: 1.4647 | Batch Time: 0.15s\n",
      "Validation Step 1273/1568 | Batch Loss: 2.4307 | Batch Time: 0.14s\n",
      "Validation Step 1274/1568 | Batch Loss: 2.7483 | Batch Time: 0.14s\n",
      "Validation Step 1275/1568 | Batch Loss: 2.7495 | Batch Time: 0.14s\n",
      "Validation Step 1276/1568 | Batch Loss: 2.1928 | Batch Time: 0.14s\n",
      "Validation Step 1277/1568 | Batch Loss: 3.3829 | Batch Time: 0.14s\n",
      "Validation Step 1278/1568 | Batch Loss: 4.3610 | Batch Time: 0.13s\n",
      "Validation Step 1279/1568 | Batch Loss: 2.9999 | Batch Time: 0.14s\n",
      "Validation Step 1280/1568 | Batch Loss: 1.8829 | Batch Time: 0.14s\n",
      "Validation Step 1281/1568 | Batch Loss: 2.7271 | Batch Time: 0.14s\n",
      "Validation Step 1282/1568 | Batch Loss: 2.2755 | Batch Time: 0.15s\n",
      "Validation Step 1283/1568 | Batch Loss: 2.9318 | Batch Time: 0.15s\n",
      "Validation Step 1284/1568 | Batch Loss: 3.3853 | Batch Time: 0.15s\n",
      "Validation Step 1285/1568 | Batch Loss: 2.9499 | Batch Time: 0.15s\n",
      "Validation Step 1286/1568 | Batch Loss: 1.5403 | Batch Time: 0.15s\n",
      "Validation Step 1287/1568 | Batch Loss: 2.3249 | Batch Time: 0.14s\n",
      "Validation Step 1288/1568 | Batch Loss: 2.4638 | Batch Time: 0.14s\n",
      "Validation Step 1289/1568 | Batch Loss: 1.8131 | Batch Time: 0.15s\n",
      "Validation Step 1290/1568 | Batch Loss: 2.4473 | Batch Time: 0.14s\n",
      "Validation Step 1291/1568 | Batch Loss: 1.5466 | Batch Time: 0.15s\n",
      "Validation Step 1292/1568 | Batch Loss: 2.3067 | Batch Time: 0.14s\n",
      "Validation Step 1293/1568 | Batch Loss: 2.7627 | Batch Time: 0.14s\n",
      "Validation Step 1294/1568 | Batch Loss: 3.1335 | Batch Time: 0.14s\n",
      "Validation Step 1295/1568 | Batch Loss: 2.3776 | Batch Time: 0.14s\n",
      "Validation Step 1296/1568 | Batch Loss: 1.9215 | Batch Time: 0.14s\n",
      "Validation Step 1297/1568 | Batch Loss: 2.4176 | Batch Time: 0.14s\n",
      "Validation Step 1298/1568 | Batch Loss: 2.9051 | Batch Time: 0.14s\n",
      "Validation Step 1299/1568 | Batch Loss: 2.9935 | Batch Time: 0.15s\n",
      "Validation Step 1300/1568 | Batch Loss: 3.4248 | Batch Time: 0.14s\n",
      "Validation Step 1301/1568 | Batch Loss: 2.7590 | Batch Time: 0.15s\n",
      "Validation Step 1302/1568 | Batch Loss: 3.1051 | Batch Time: 0.15s\n",
      "Validation Step 1303/1568 | Batch Loss: 1.7366 | Batch Time: 0.14s\n",
      "Validation Step 1304/1568 | Batch Loss: 2.0398 | Batch Time: 0.14s\n",
      "Validation Step 1305/1568 | Batch Loss: 2.6717 | Batch Time: 0.14s\n",
      "Validation Step 1306/1568 | Batch Loss: 2.0064 | Batch Time: 0.14s\n",
      "Validation Step 1307/1568 | Batch Loss: 2.0438 | Batch Time: 0.14s\n",
      "Validation Step 1308/1568 | Batch Loss: 1.9349 | Batch Time: 0.14s\n",
      "Validation Step 1309/1568 | Batch Loss: 1.4746 | Batch Time: 0.14s\n",
      "Validation Step 1310/1568 | Batch Loss: 1.9323 | Batch Time: 0.15s\n",
      "Validation Step 1311/1568 | Batch Loss: 3.1265 | Batch Time: 0.16s\n",
      "Validation Step 1312/1568 | Batch Loss: 1.8219 | Batch Time: 0.16s\n",
      "Validation Step 1313/1568 | Batch Loss: 2.3646 | Batch Time: 0.15s\n",
      "Validation Step 1314/1568 | Batch Loss: 1.8822 | Batch Time: 0.15s\n",
      "Validation Step 1315/1568 | Batch Loss: 1.6519 | Batch Time: 0.15s\n",
      "Validation Step 1316/1568 | Batch Loss: 1.7785 | Batch Time: 0.15s\n",
      "Validation Step 1317/1568 | Batch Loss: 2.9660 | Batch Time: 0.14s\n",
      "Validation Step 1318/1568 | Batch Loss: 1.5716 | Batch Time: 0.15s\n",
      "Validation Step 1319/1568 | Batch Loss: 3.1557 | Batch Time: 0.15s\n",
      "Validation Step 1320/1568 | Batch Loss: 1.9374 | Batch Time: 0.15s\n",
      "Validation Step 1321/1568 | Batch Loss: 1.7170 | Batch Time: 0.14s\n",
      "Validation Step 1322/1568 | Batch Loss: 3.6891 | Batch Time: 0.14s\n",
      "Validation Step 1323/1568 | Batch Loss: 2.1986 | Batch Time: 0.14s\n",
      "Validation Step 1324/1568 | Batch Loss: 2.9433 | Batch Time: 0.14s\n",
      "Validation Step 1325/1568 | Batch Loss: 2.0858 | Batch Time: 0.14s\n",
      "Validation Step 1326/1568 | Batch Loss: 2.0996 | Batch Time: 0.14s\n",
      "Validation Step 1327/1568 | Batch Loss: 1.7456 | Batch Time: 0.15s\n",
      "Validation Step 1328/1568 | Batch Loss: 2.7078 | Batch Time: 0.14s\n",
      "Validation Step 1329/1568 | Batch Loss: 4.3279 | Batch Time: 0.15s\n",
      "Validation Step 1330/1568 | Batch Loss: 2.4185 | Batch Time: 0.15s\n",
      "Validation Step 1331/1568 | Batch Loss: 1.2984 | Batch Time: 0.15s\n",
      "Validation Step 1332/1568 | Batch Loss: 2.6085 | Batch Time: 0.15s\n",
      "Validation Step 1333/1568 | Batch Loss: 2.7395 | Batch Time: 0.15s\n",
      "Validation Step 1334/1568 | Batch Loss: 3.5987 | Batch Time: 0.14s\n",
      "Validation Step 1335/1568 | Batch Loss: 3.2422 | Batch Time: 0.14s\n",
      "Validation Step 1336/1568 | Batch Loss: 4.1814 | Batch Time: 0.15s\n",
      "Validation Step 1337/1568 | Batch Loss: 2.3886 | Batch Time: 0.13s\n",
      "Validation Step 1338/1568 | Batch Loss: 3.3263 | Batch Time: 0.14s\n",
      "Validation Step 1339/1568 | Batch Loss: 2.5000 | Batch Time: 0.15s\n",
      "Validation Step 1340/1568 | Batch Loss: 2.2975 | Batch Time: 0.14s\n",
      "Validation Step 1341/1568 | Batch Loss: 2.5811 | Batch Time: 0.16s\n",
      "Validation Step 1342/1568 | Batch Loss: 3.7245 | Batch Time: 0.16s\n",
      "Validation Step 1343/1568 | Batch Loss: 3.0165 | Batch Time: 0.15s\n",
      "Validation Step 1344/1568 | Batch Loss: 2.9075 | Batch Time: 0.14s\n",
      "Validation Step 1345/1568 | Batch Loss: 2.5207 | Batch Time: 0.14s\n",
      "Validation Step 1346/1568 | Batch Loss: 2.5116 | Batch Time: 0.14s\n",
      "Validation Step 1347/1568 | Batch Loss: 2.0038 | Batch Time: 0.14s\n",
      "Validation Step 1348/1568 | Batch Loss: 2.3276 | Batch Time: 0.14s\n",
      "Validation Step 1349/1568 | Batch Loss: 2.4511 | Batch Time: 0.15s\n",
      "Validation Step 1350/1568 | Batch Loss: 2.9057 | Batch Time: 0.14s\n",
      "Validation Step 1351/1568 | Batch Loss: 1.8135 | Batch Time: 0.14s\n",
      "Validation Step 1352/1568 | Batch Loss: 2.6380 | Batch Time: 0.14s\n",
      "Validation Step 1353/1568 | Batch Loss: 2.9916 | Batch Time: 0.14s\n",
      "Validation Step 1354/1568 | Batch Loss: 2.3664 | Batch Time: 0.14s\n",
      "Validation Step 1355/1568 | Batch Loss: 2.5741 | Batch Time: 0.14s\n",
      "Validation Step 1356/1568 | Batch Loss: 2.1173 | Batch Time: 0.14s\n",
      "Validation Step 1357/1568 | Batch Loss: 2.1439 | Batch Time: 0.14s\n",
      "Validation Step 1358/1568 | Batch Loss: 2.2810 | Batch Time: 0.14s\n",
      "Validation Step 1359/1568 | Batch Loss: 2.1574 | Batch Time: 0.14s\n",
      "Validation Step 1360/1568 | Batch Loss: 2.1416 | Batch Time: 0.15s\n",
      "Validation Step 1361/1568 | Batch Loss: 2.0014 | Batch Time: 0.14s\n",
      "Validation Step 1362/1568 | Batch Loss: 1.8612 | Batch Time: 0.14s\n",
      "Validation Step 1363/1568 | Batch Loss: 2.4331 | Batch Time: 0.14s\n",
      "Validation Step 1364/1568 | Batch Loss: 2.9947 | Batch Time: 0.14s\n",
      "Validation Step 1365/1568 | Batch Loss: 2.4085 | Batch Time: 0.14s\n",
      "Validation Step 1366/1568 | Batch Loss: 2.8977 | Batch Time: 0.14s\n",
      "Validation Step 1367/1568 | Batch Loss: 2.7073 | Batch Time: 0.14s\n",
      "Validation Step 1368/1568 | Batch Loss: 2.1634 | Batch Time: 0.14s\n",
      "Validation Step 1369/1568 | Batch Loss: 3.6014 | Batch Time: 0.14s\n",
      "Validation Step 1370/1568 | Batch Loss: 1.4942 | Batch Time: 0.14s\n",
      "Validation Step 1371/1568 | Batch Loss: 3.3316 | Batch Time: 0.14s\n",
      "Validation Step 1372/1568 | Batch Loss: 3.0100 | Batch Time: 0.14s\n",
      "Validation Step 1373/1568 | Batch Loss: 1.6675 | Batch Time: 0.14s\n",
      "Validation Step 1374/1568 | Batch Loss: 2.3456 | Batch Time: 0.14s\n",
      "Validation Step 1375/1568 | Batch Loss: 2.8316 | Batch Time: 0.14s\n",
      "Validation Step 1376/1568 | Batch Loss: 2.5569 | Batch Time: 0.14s\n",
      "Validation Step 1377/1568 | Batch Loss: 4.4891 | Batch Time: 0.14s\n",
      "Validation Step 1378/1568 | Batch Loss: 2.1204 | Batch Time: 0.14s\n",
      "Validation Step 1379/1568 | Batch Loss: 3.0876 | Batch Time: 0.14s\n",
      "Validation Step 1380/1568 | Batch Loss: 2.0130 | Batch Time: 0.14s\n",
      "Validation Step 1381/1568 | Batch Loss: 1.7080 | Batch Time: 0.15s\n",
      "Validation Step 1382/1568 | Batch Loss: 1.8014 | Batch Time: 0.15s\n",
      "Validation Step 1383/1568 | Batch Loss: 2.0562 | Batch Time: 0.14s\n",
      "Validation Step 1384/1568 | Batch Loss: 1.5435 | Batch Time: 0.14s\n",
      "Validation Step 1385/1568 | Batch Loss: 3.5543 | Batch Time: 0.14s\n",
      "Validation Step 1386/1568 | Batch Loss: 2.3176 | Batch Time: 0.14s\n",
      "Validation Step 1387/1568 | Batch Loss: 2.3759 | Batch Time: 0.14s\n",
      "Validation Step 1388/1568 | Batch Loss: 1.7579 | Batch Time: 0.15s\n",
      "Validation Step 1389/1568 | Batch Loss: 4.0833 | Batch Time: 0.14s\n",
      "Validation Step 1390/1568 | Batch Loss: 3.4064 | Batch Time: 0.14s\n",
      "Validation Step 1391/1568 | Batch Loss: 2.4112 | Batch Time: 0.14s\n",
      "Validation Step 1392/1568 | Batch Loss: 2.9175 | Batch Time: 0.14s\n",
      "Validation Step 1393/1568 | Batch Loss: 2.5375 | Batch Time: 0.14s\n",
      "Validation Step 1394/1568 | Batch Loss: 1.7817 | Batch Time: 0.14s\n",
      "Validation Step 1395/1568 | Batch Loss: 1.5906 | Batch Time: 0.15s\n",
      "Validation Step 1396/1568 | Batch Loss: 1.3318 | Batch Time: 0.15s\n",
      "Validation Step 1397/1568 | Batch Loss: 1.3053 | Batch Time: 0.15s\n",
      "Validation Step 1398/1568 | Batch Loss: 2.2882 | Batch Time: 0.14s\n",
      "Validation Step 1399/1568 | Batch Loss: 1.9442 | Batch Time: 0.14s\n",
      "Validation Step 1400/1568 | Batch Loss: 1.9690 | Batch Time: 0.14s\n",
      "Validation Step 1401/1568 | Batch Loss: 3.7996 | Batch Time: 0.14s\n",
      "Validation Step 1402/1568 | Batch Loss: 2.8193 | Batch Time: 0.14s\n",
      "Validation Step 1403/1568 | Batch Loss: 1.4107 | Batch Time: 0.14s\n",
      "Validation Step 1404/1568 | Batch Loss: 3.2716 | Batch Time: 0.14s\n",
      "Validation Step 1405/1568 | Batch Loss: 2.9659 | Batch Time: 0.15s\n",
      "Validation Step 1406/1568 | Batch Loss: 2.0301 | Batch Time: 0.14s\n",
      "Validation Step 1407/1568 | Batch Loss: 1.4621 | Batch Time: 0.14s\n",
      "Validation Step 1408/1568 | Batch Loss: 2.6100 | Batch Time: 0.14s\n",
      "Validation Step 1409/1568 | Batch Loss: 2.4198 | Batch Time: 0.14s\n",
      "Validation Step 1410/1568 | Batch Loss: 3.4397 | Batch Time: 0.15s\n",
      "Validation Step 1411/1568 | Batch Loss: 1.9019 | Batch Time: 0.14s\n",
      "Validation Step 1412/1568 | Batch Loss: 2.6237 | Batch Time: 0.14s\n",
      "Validation Step 1413/1568 | Batch Loss: 2.2261 | Batch Time: 0.15s\n",
      "Validation Step 1414/1568 | Batch Loss: 2.1235 | Batch Time: 0.15s\n",
      "Validation Step 1415/1568 | Batch Loss: 2.1050 | Batch Time: 0.14s\n",
      "Validation Step 1416/1568 | Batch Loss: 2.2411 | Batch Time: 0.15s\n",
      "Validation Step 1417/1568 | Batch Loss: 2.5350 | Batch Time: 0.14s\n",
      "Validation Step 1418/1568 | Batch Loss: 3.2312 | Batch Time: 0.14s\n",
      "Validation Step 1419/1568 | Batch Loss: 2.6419 | Batch Time: 0.14s\n",
      "Validation Step 1420/1568 | Batch Loss: 2.0695 | Batch Time: 0.14s\n",
      "Validation Step 1421/1568 | Batch Loss: 3.1918 | Batch Time: 0.14s\n",
      "Validation Step 1422/1568 | Batch Loss: 1.8830 | Batch Time: 0.14s\n",
      "Validation Step 1423/1568 | Batch Loss: 3.2472 | Batch Time: 0.14s\n",
      "Validation Step 1424/1568 | Batch Loss: 3.8399 | Batch Time: 0.13s\n",
      "Validation Step 1425/1568 | Batch Loss: 1.8961 | Batch Time: 0.14s\n",
      "Validation Step 1426/1568 | Batch Loss: 1.4153 | Batch Time: 0.14s\n",
      "Validation Step 1427/1568 | Batch Loss: 1.8655 | Batch Time: 0.14s\n",
      "Validation Step 1428/1568 | Batch Loss: 2.6114 | Batch Time: 0.15s\n",
      "Validation Step 1429/1568 | Batch Loss: 2.5503 | Batch Time: 0.15s\n",
      "Validation Step 1430/1568 | Batch Loss: 2.2253 | Batch Time: 0.14s\n",
      "Validation Step 1431/1568 | Batch Loss: 3.4227 | Batch Time: 0.14s\n",
      "Validation Step 1432/1568 | Batch Loss: 1.9107 | Batch Time: 0.14s\n",
      "Validation Step 1433/1568 | Batch Loss: 2.0192 | Batch Time: 0.14s\n",
      "Validation Step 1434/1568 | Batch Loss: 3.0727 | Batch Time: 0.14s\n",
      "Validation Step 1435/1568 | Batch Loss: 2.2230 | Batch Time: 0.14s\n",
      "Validation Step 1436/1568 | Batch Loss: 2.5624 | Batch Time: 0.14s\n",
      "Validation Step 1437/1568 | Batch Loss: 1.6384 | Batch Time: 0.14s\n",
      "Validation Step 1438/1568 | Batch Loss: 1.5679 | Batch Time: 0.14s\n",
      "Validation Step 1439/1568 | Batch Loss: 3.5058 | Batch Time: 0.15s\n",
      "Validation Step 1440/1568 | Batch Loss: 2.9454 | Batch Time: 0.15s\n",
      "Validation Step 1441/1568 | Batch Loss: 2.3224 | Batch Time: 0.14s\n",
      "Validation Step 1442/1568 | Batch Loss: 2.4198 | Batch Time: 0.15s\n",
      "Validation Step 1443/1568 | Batch Loss: 2.0970 | Batch Time: 0.14s\n",
      "Validation Step 1444/1568 | Batch Loss: 2.2297 | Batch Time: 0.14s\n",
      "Validation Step 1445/1568 | Batch Loss: 2.5677 | Batch Time: 0.14s\n",
      "Validation Step 1446/1568 | Batch Loss: 1.9877 | Batch Time: 0.14s\n",
      "Validation Step 1447/1568 | Batch Loss: 2.5296 | Batch Time: 0.14s\n",
      "Validation Step 1448/1568 | Batch Loss: 1.7065 | Batch Time: 0.14s\n",
      "Validation Step 1449/1568 | Batch Loss: 2.3345 | Batch Time: 0.14s\n",
      "Validation Step 1450/1568 | Batch Loss: 2.7050 | Batch Time: 0.15s\n",
      "Validation Step 1451/1568 | Batch Loss: 1.8219 | Batch Time: 0.14s\n",
      "Validation Step 1452/1568 | Batch Loss: 2.6132 | Batch Time: 0.14s\n",
      "Validation Step 1453/1568 | Batch Loss: 2.8163 | Batch Time: 0.14s\n",
      "Validation Step 1454/1568 | Batch Loss: 2.1296 | Batch Time: 0.13s\n",
      "Validation Step 1455/1568 | Batch Loss: 1.4361 | Batch Time: 0.14s\n",
      "Validation Step 1456/1568 | Batch Loss: 2.9048 | Batch Time: 0.14s\n",
      "Validation Step 1457/1568 | Batch Loss: 2.2741 | Batch Time: 0.15s\n",
      "Validation Step 1458/1568 | Batch Loss: 3.7185 | Batch Time: 0.14s\n",
      "Validation Step 1459/1568 | Batch Loss: 1.9922 | Batch Time: 0.15s\n",
      "Validation Step 1460/1568 | Batch Loss: 2.4606 | Batch Time: 0.14s\n",
      "Validation Step 1461/1568 | Batch Loss: 1.4982 | Batch Time: 0.15s\n",
      "Validation Step 1462/1568 | Batch Loss: 2.0654 | Batch Time: 0.14s\n",
      "Validation Step 1463/1568 | Batch Loss: 2.6621 | Batch Time: 0.14s\n",
      "Validation Step 1464/1568 | Batch Loss: 2.1543 | Batch Time: 0.14s\n",
      "Validation Step 1465/1568 | Batch Loss: 1.8241 | Batch Time: 0.14s\n",
      "Validation Step 1466/1568 | Batch Loss: 1.2626 | Batch Time: 0.15s\n",
      "Validation Step 1467/1568 | Batch Loss: 2.8907 | Batch Time: 0.14s\n",
      "Validation Step 1468/1568 | Batch Loss: 1.6172 | Batch Time: 0.14s\n",
      "Validation Step 1469/1568 | Batch Loss: 3.2338 | Batch Time: 0.14s\n",
      "Validation Step 1470/1568 | Batch Loss: 2.3481 | Batch Time: 0.14s\n",
      "Validation Step 1471/1568 | Batch Loss: 1.9076 | Batch Time: 0.15s\n",
      "Validation Step 1472/1568 | Batch Loss: 2.8163 | Batch Time: 0.14s\n",
      "Validation Step 1473/1568 | Batch Loss: 1.7033 | Batch Time: 0.14s\n",
      "Validation Step 1474/1568 | Batch Loss: 2.0215 | Batch Time: 0.14s\n",
      "Validation Step 1475/1568 | Batch Loss: 1.7883 | Batch Time: 0.15s\n",
      "Validation Step 1476/1568 | Batch Loss: 1.7815 | Batch Time: 0.14s\n",
      "Validation Step 1477/1568 | Batch Loss: 2.3222 | Batch Time: 0.15s\n",
      "Validation Step 1478/1568 | Batch Loss: 2.2588 | Batch Time: 0.15s\n",
      "Validation Step 1479/1568 | Batch Loss: 2.4673 | Batch Time: 0.15s\n",
      "Validation Step 1480/1568 | Batch Loss: 1.6385 | Batch Time: 0.15s\n",
      "Validation Step 1481/1568 | Batch Loss: 1.3970 | Batch Time: 0.15s\n",
      "Validation Step 1482/1568 | Batch Loss: 3.2151 | Batch Time: 0.15s\n",
      "Validation Step 1483/1568 | Batch Loss: 2.2729 | Batch Time: 0.14s\n",
      "Validation Step 1484/1568 | Batch Loss: 2.9071 | Batch Time: 0.14s\n",
      "Validation Step 1485/1568 | Batch Loss: 2.4953 | Batch Time: 0.14s\n",
      "Validation Step 1486/1568 | Batch Loss: 2.6565 | Batch Time: 0.15s\n",
      "Validation Step 1487/1568 | Batch Loss: 1.4892 | Batch Time: 0.15s\n",
      "Validation Step 1488/1568 | Batch Loss: 1.9936 | Batch Time: 0.15s\n",
      "Validation Step 1489/1568 | Batch Loss: 2.1347 | Batch Time: 0.15s\n",
      "Validation Step 1490/1568 | Batch Loss: 2.5810 | Batch Time: 0.15s\n",
      "Validation Step 1491/1568 | Batch Loss: 3.0999 | Batch Time: 0.14s\n",
      "Validation Step 1492/1568 | Batch Loss: 1.9767 | Batch Time: 0.15s\n",
      "Validation Step 1493/1568 | Batch Loss: 1.4811 | Batch Time: 0.15s\n",
      "Validation Step 1494/1568 | Batch Loss: 2.2836 | Batch Time: 0.15s\n",
      "Validation Step 1495/1568 | Batch Loss: 2.9227 | Batch Time: 0.14s\n",
      "Validation Step 1496/1568 | Batch Loss: 2.4393 | Batch Time: 0.14s\n",
      "Validation Step 1497/1568 | Batch Loss: 2.6621 | Batch Time: 0.14s\n",
      "Validation Step 1498/1568 | Batch Loss: 2.6578 | Batch Time: 0.14s\n",
      "Validation Step 1499/1568 | Batch Loss: 3.0442 | Batch Time: 0.14s\n",
      "Validation Step 1500/1568 | Batch Loss: 2.4849 | Batch Time: 0.14s\n",
      "Validation Step 1501/1568 | Batch Loss: 2.7120 | Batch Time: 0.14s\n",
      "Validation Step 1502/1568 | Batch Loss: 2.3188 | Batch Time: 0.14s\n",
      "Validation Step 1503/1568 | Batch Loss: 2.0818 | Batch Time: 0.14s\n",
      "Validation Step 1504/1568 | Batch Loss: 2.4677 | Batch Time: 0.15s\n",
      "Validation Step 1505/1568 | Batch Loss: 2.3166 | Batch Time: 0.14s\n",
      "Validation Step 1506/1568 | Batch Loss: 2.7645 | Batch Time: 0.15s\n",
      "Validation Step 1507/1568 | Batch Loss: 1.9541 | Batch Time: 0.14s\n",
      "Validation Step 1508/1568 | Batch Loss: 2.8535 | Batch Time: 0.14s\n",
      "Validation Step 1509/1568 | Batch Loss: 2.5159 | Batch Time: 0.14s\n",
      "Validation Step 1510/1568 | Batch Loss: 2.3739 | Batch Time: 0.14s\n",
      "Validation Step 1511/1568 | Batch Loss: 2.3113 | Batch Time: 0.14s\n",
      "Validation Step 1512/1568 | Batch Loss: 2.2456 | Batch Time: 0.15s\n",
      "Validation Step 1513/1568 | Batch Loss: 2.2729 | Batch Time: 0.15s\n",
      "Validation Step 1514/1568 | Batch Loss: 3.9753 | Batch Time: 0.15s\n",
      "Validation Step 1515/1568 | Batch Loss: 1.7512 | Batch Time: 0.15s\n",
      "Validation Step 1516/1568 | Batch Loss: 1.5889 | Batch Time: 0.14s\n",
      "Validation Step 1517/1568 | Batch Loss: 2.5497 | Batch Time: 0.14s\n",
      "Validation Step 1518/1568 | Batch Loss: 2.5856 | Batch Time: 0.14s\n",
      "Validation Step 1519/1568 | Batch Loss: 1.7798 | Batch Time: 0.14s\n",
      "Validation Step 1520/1568 | Batch Loss: 2.5827 | Batch Time: 0.14s\n",
      "Validation Step 1521/1568 | Batch Loss: 2.2191 | Batch Time: 0.14s\n",
      "Validation Step 1522/1568 | Batch Loss: 4.2718 | Batch Time: 0.13s\n",
      "Validation Step 1523/1568 | Batch Loss: 1.6595 | Batch Time: 0.15s\n",
      "Validation Step 1524/1568 | Batch Loss: 2.2756 | Batch Time: 0.15s\n",
      "Validation Step 1525/1568 | Batch Loss: 1.8695 | Batch Time: 0.14s\n",
      "Validation Step 1526/1568 | Batch Loss: 2.1863 | Batch Time: 0.14s\n",
      "Validation Step 1527/1568 | Batch Loss: 2.1258 | Batch Time: 0.14s\n",
      "Validation Step 1528/1568 | Batch Loss: 2.1643 | Batch Time: 0.15s\n",
      "Validation Step 1529/1568 | Batch Loss: 3.3053 | Batch Time: 0.14s\n",
      "Validation Step 1530/1568 | Batch Loss: 1.9033 | Batch Time: 0.14s\n",
      "Validation Step 1531/1568 | Batch Loss: 1.5987 | Batch Time: 0.14s\n",
      "Validation Step 1532/1568 | Batch Loss: 1.7317 | Batch Time: 0.14s\n",
      "Validation Step 1533/1568 | Batch Loss: 2.1081 | Batch Time: 0.14s\n",
      "Validation Step 1534/1568 | Batch Loss: 2.2012 | Batch Time: 0.14s\n",
      "Validation Step 1535/1568 | Batch Loss: 2.1981 | Batch Time: 0.14s\n",
      "Validation Step 1536/1568 | Batch Loss: 1.9106 | Batch Time: 0.14s\n",
      "Validation Step 1537/1568 | Batch Loss: 2.2661 | Batch Time: 0.14s\n",
      "Validation Step 1538/1568 | Batch Loss: 2.3142 | Batch Time: 0.14s\n",
      "Validation Step 1539/1568 | Batch Loss: 1.8372 | Batch Time: 0.15s\n",
      "Validation Step 1540/1568 | Batch Loss: 3.2920 | Batch Time: 0.14s\n",
      "Validation Step 1541/1568 | Batch Loss: 1.8791 | Batch Time: 0.14s\n",
      "Validation Step 1542/1568 | Batch Loss: 2.0010 | Batch Time: 0.15s\n",
      "Validation Step 1543/1568 | Batch Loss: 1.8806 | Batch Time: 0.15s\n",
      "Validation Step 1544/1568 | Batch Loss: 3.3307 | Batch Time: 0.15s\n",
      "Validation Step 1545/1568 | Batch Loss: 1.8184 | Batch Time: 0.14s\n",
      "Validation Step 1546/1568 | Batch Loss: 1.5159 | Batch Time: 0.14s\n",
      "Validation Step 1547/1568 | Batch Loss: 3.2141 | Batch Time: 0.14s\n",
      "Validation Step 1548/1568 | Batch Loss: 2.4281 | Batch Time: 0.14s\n",
      "Validation Step 1549/1568 | Batch Loss: 1.5674 | Batch Time: 0.14s\n",
      "Validation Step 1550/1568 | Batch Loss: 2.2390 | Batch Time: 0.14s\n",
      "Validation Step 1551/1568 | Batch Loss: 3.0886 | Batch Time: 0.14s\n",
      "Validation Step 1552/1568 | Batch Loss: 2.2544 | Batch Time: 0.14s\n",
      "Validation Step 1553/1568 | Batch Loss: 2.6364 | Batch Time: 0.15s\n",
      "Validation Step 1554/1568 | Batch Loss: 1.8407 | Batch Time: 0.14s\n",
      "Validation Step 1555/1568 | Batch Loss: 1.9221 | Batch Time: 0.14s\n",
      "Validation Step 1556/1568 | Batch Loss: 2.3106 | Batch Time: 0.14s\n",
      "Validation Step 1557/1568 | Batch Loss: 2.2533 | Batch Time: 0.14s\n",
      "Validation Step 1558/1568 | Batch Loss: 2.5163 | Batch Time: 0.14s\n",
      "Validation Step 1559/1568 | Batch Loss: 2.6023 | Batch Time: 0.14s\n",
      "Validation Step 1560/1568 | Batch Loss: 4.1987 | Batch Time: 0.14s\n",
      "Validation Step 1561/1568 | Batch Loss: 3.1149 | Batch Time: 0.14s\n",
      "Validation Step 1562/1568 | Batch Loss: 3.6564 | Batch Time: 0.14s\n",
      "Validation Step 1563/1568 | Batch Loss: 2.2696 | Batch Time: 0.14s\n",
      "Validation Step 1564/1568 | Batch Loss: 1.9475 | Batch Time: 0.14s\n",
      "Validation Step 1565/1568 | Batch Loss: 2.7798 | Batch Time: 0.14s\n",
      "Validation Step 1566/1568 | Batch Loss: 1.5101 | Batch Time: 0.14s\n",
      "Validation Step 1567/1568 | Batch Loss: 3.7976 | Batch Time: 0.14s\n",
      "Validation Step 1568/1568 | Batch Loss: 2.6647 | Batch Time: 0.10s\n",
      "Validation Loss: 2.4502 | Evaluation Time: 237.97s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculates only the loss function \n",
    "No other performance metrics is used\n",
    "'''\n",
    "# Set the model to evaluation mode\n",
    "model.eval() \n",
    "total_eval_loss = 0 # Initialize \n",
    "eval_start_time = time.time() # starting time\n",
    "\n",
    "with torch.no_grad(): # no backpropagation needed\n",
    "    for step, batch in enumerate(val_loader):\n",
    "        batch_start_time = time.time() # starting time - batch\n",
    "\n",
    "        inputs = batch['input_ids'].to(device) # input from batch\n",
    "        attention_mask = batch['attention_mask'].to(device)  # padding - attention_mask\n",
    "        labels = batch['labels'].to(device) # target from batch\n",
    "\n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels) # forward pass\n",
    "        loss = outputs.loss # coompute loss\n",
    "\n",
    "        total_eval_loss += loss.item() # Accumulate the loss\n",
    "        \n",
    "        batch_time = time.time() - batch_start_time # compute batch processing time\n",
    "\n",
    "        # Print batch-level evaluation information\n",
    "        print(f\"Validation Step {step + 1}/{len(val_loader)} | \"\n",
    "              f\"Batch Loss: {loss.item():.4f} | Batch Time: {batch_time:.2f}s\")\n",
    "\n",
    "avg_eval_loss = total_eval_loss / len(val_loader) # compute average loss\n",
    "\n",
    "eval_time = time.time() - eval_start_time # compute evaluation processing time\n",
    "\n",
    "# Print final evaluation information\n",
    "print(f\"Validation Loss: {avg_eval_loss:.4f} | Evaluation Time: {eval_time:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infosys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
